---
title: "What's new in Dell Enterprise Hub"
thumbnail: /blog/assets/dell-enterprise-hub/thumbnail.jpg
authors:
  - user: pagezyhf
---

# What’s new in Dell Enterprise Hub: security, performance, and lifecycle at scale

![Dell Enterprise Hub updates](/blog/assets/dell-enterprise-hub/thumbnail.jpg)

A year ago we introduced the [Dell Enterprise Hub](https://dell.huggingface.co), a new experience on Hugging Face to make it easy to train and deploy open models on-premise using Dell platforms.

Since that launch, Dell Enterprise Hub has grown from a model catalog into a full on-prem AI experience: you can browse open models, deploy them on Dell AI servers and AI PCs with optimized configurations, fine-tune them with your own data, and, more recently, even deploy complete AI applications through the Application Catalog.

Today we are introducing the next wave of capabilities, focused on three things that matter a lot to enterprises: **supply chain security, lifecycle management, and real-world performance**.

You can try all of this today at [dell.huggingface.co](https://dell.huggingface.co).

## Securing the AI supply chain

As more AI workloads move into production, teams care not just about which model they use, but also about how it gets into their infrastructure. What is inside the Docker image? Has the model repository been scanned? How are the weights pulled into the cluster? The new Dell Enterprise Hub experience brings these questions into the product itself, so platform, security and ML teams can share the same view.

Every model on the Hugging Face Hub is scanned for malware and unsafe serialization formats. Dell Enterprise Hub now surfaces a summary of these **repository scan results** directly in the model view. This gives security and compliance teams a starting point for their own reviews, without forcing them to hunt for the right tab or URL.

![Model scan results](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/deh-2025/model-scan-results.png)

Models are only one piece of the supply chain. The container image that runs those models also needs to be monitored. Dell Enterprise Hub uses custom Docker images for inference and training, optimized per model and per Dell platform. These images are regularly scanned with AWS Inspector, and Dell Enterprise Hub now exposes **container scan status** alongside the deployment configuration.

![Container scan status](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/deh-2025/container-scan-status.png)

To better govern model access, Dell Enterprise Hub now standardizes the use of **Hugging Face access tokens** in its deployment snippets. Token authenticates your calls to the Hub, ensures access to gated models is respected, and gives you higher rate limits when pulling model weights.

![HF Token](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/deh-2025/hf-token.png)

Together, these features give Dell Enterprise Hub users a simpler, more transparent way to secure their AI supply chain.

## Good performance on day one

Once security is in place, the next question is performance. The goal for Dell Enterprise Hub is that you get solid performance for your chosen model and Dell hardware from day one, without having to become an expert in every inference engine and tuning parameter.

Dell Enterprise Hub started with containers built on top of Hugging Face **Text Generation Inference (TGI)**. Today, it can also choose engines like **vLLM** or **SGLang** based on the model and platform, and it generates deployment snippets with sensible default parameters. You pick the model and Dell platform; Dell Enterprise Hub picks a runtime and configuration that work well out of the box.

Looking ahead, Dell Enterprise Hub will become more opinionated about the default configuration parameters included in each deployment snippet, with presets for different use cases. You will still be able to override any of these values in the generated command if you want to experiment, but the goal is that teams get strong results on day one by simply copying the snippet into their Dell environment.

## Lifecycle: decoupling containers and versioning

The last big theme in this update is how Dell Enterprise Hub handles the lifecycle of containers and model weights over time. Enterprises need to patch base images, upgrade inference engines, rotate models and archive older assets, often under strict compliance requirements. To make that easier, Dell Enterprise Hub is moving to a **decoupled container architecture with explicit versioning**.

Historically, many Dell Enterprise Hub images shipped with the model weights baked directly into the container. This made “first run” very simple, but it also led to large images and tighter coupling between the model and the runtime environment. From now on, new containers added to Dell Enterprise Hub are provided **without pre-downloaded weights**. The container includes the inference engine and all dependencies; the weights are pulled separately.

Additionnaly, instead of relying on a single `latest` tag for containers, Dell Enterprise Hub now exposes **versioned tags**. This means you can pin an exact container tag in production, test a newer container in staging, and move between them on your own schedule.

![Container Versioning](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/deh-2025/container-versioning.png)

## What’s next

These changes are another step toward making Dell Enterprise Hub the easiest way to run open models and applications on Dell infrastructure, fully on-premise and under your control.

We are continuing to expand support for new modalities and new Dell platforms, to refine default configurations around real-world goodput, and to deepen the integration between the Model Catalog, Application Catalog, Hugging Face Hub and programmatic tools.

We are excited to keep building open, on-prem AI together!
