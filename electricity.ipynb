{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzuaxjVvVVEIJbBpEIyEQv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kashif/blog/blob/autoformer/electricity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AovFf7sGUq2",
        "outputId": "cb681269-c364-4d89-bbab-afb88dbfe99f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: gluonts[pro,torch] in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (8.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts[pro,torch]) (1.10.7)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts[pro,torch]) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts[pro,torch]) (4.5.0)\n",
            "Requirement already satisfied: pytorch-lightning<3,>=1.5 in /usr/local/lib/python3.10/dist-packages (from gluonts[pro,torch]) (2.0.3)\n",
            "Requirement already satisfied: protobuf~=3.19.0 in /usr/local/lib/python3.10/dist-packages (from gluonts[pro,torch]) (3.19.6)\n",
            "Requirement already satisfied: scipy~=1.10 in /usr/local/lib/python3.10/dist-packages (from gluonts[pro,torch]) (1.10.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gluonts[pro,torch]) (3.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<3,>=1.5->gluonts[pro,torch]) (0.11.4)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<3,>=1.5->gluonts[pro,torch]) (0.8.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate accelerate \"gluonts[pro,torch]\" ujson tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gluonts.dataset.repository.datasets import get_dataset\n",
        "\n",
        "traffic_dataset = get_dataset(\"traffic\")\n",
        "electricity_dataset = get_dataset(\"electricity\")\n",
        "exchange_dataset = get_dataset(\"exchange_rate\")\n",
        "\n",
        "dataset = electricity_dataset"
      ],
      "metadata": {
        "id": "x_RQzmwTG51R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset.train\n",
        "test_dataset = dataset.test\n",
        "freq = dataset.metadata.freq\n",
        "prediction_length = dataset.metadata.prediction_length"
      ],
      "metadata": {
        "id": "icaHTCTuL6qC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations\n",
        "\n",
        "from gluonts.time_feature import TimeFeature\n",
        "from gluonts.dataset.field_names import FieldName\n",
        "from gluonts.transform import (\n",
        "    AddAgeFeature,\n",
        "    AddObservedValuesIndicator,\n",
        "    AddTimeFeatures,\n",
        "    AsNumpyArray,\n",
        "    Chain,\n",
        "    ExpectedNumInstanceSampler,\n",
        "    InstanceSplitter,\n",
        "    RemoveFields,\n",
        "    SelectFields,\n",
        "    SetField,\n",
        "    TestSplitSampler,\n",
        "    Transformation,\n",
        "    ValidationSplitSampler,\n",
        "    VstackFeatures,\n",
        "    RenameFields,\n",
        ")\n",
        "\n",
        "from transformers import PretrainedConfig\n",
        "from gluonts.time_feature import time_features_from_frequency_str\n",
        "\n",
        "def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:\n",
        "    # create list of fields to remove later\n",
        "    remove_field_names = []\n",
        "    if config.num_static_real_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_STATIC_REAL)\n",
        "    if config.num_dynamic_real_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)\n",
        "    if config.num_static_categorical_features == 0:\n",
        "        remove_field_names.append(FieldName.FEAT_STATIC_CAT)\n",
        "\n",
        "    return Chain(\n",
        "        # step 1: remove static/dynamic fields if not specified\n",
        "        [RemoveFields(field_names=remove_field_names)]\n",
        "        # step 2: convert the data to NumPy (potentially not needed)\n",
        "        + (\n",
        "            [\n",
        "                AsNumpyArray(\n",
        "                    field=FieldName.FEAT_STATIC_CAT,\n",
        "                    expected_ndim=1,\n",
        "                    dtype=int,\n",
        "                )\n",
        "            ]\n",
        "            if config.num_static_categorical_features > 0\n",
        "            else []\n",
        "        )\n",
        "        + (\n",
        "            [\n",
        "                AsNumpyArray(\n",
        "                    field=FieldName.FEAT_STATIC_REAL,\n",
        "                    expected_ndim=1,\n",
        "                )\n",
        "            ]\n",
        "            if config.num_static_real_features > 0\n",
        "            else []\n",
        "        )\n",
        "        + [\n",
        "            AsNumpyArray(\n",
        "                field=FieldName.TARGET,\n",
        "                # we expect an extra dim for the multivariate case:\n",
        "                expected_ndim=1 if config.input_size == 1 else 2,\n",
        "            ),\n",
        "            # step 3: handle the NaN's by filling in the target with zero\n",
        "            # and return the mask (which is in the observed values)\n",
        "            # true for observed values, false for nan's\n",
        "            # the decoder uses this mask (no loss is incurred for unobserved values)\n",
        "            # see loss_weights inside the xxxForPrediction model\n",
        "            AddObservedValuesIndicator(\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.OBSERVED_VALUES,\n",
        "            ),\n",
        "            # step 4: add temporal features based on freq of the dataset\n",
        "            # these serve as positional encodings\n",
        "            AddTimeFeatures(\n",
        "                start_field=FieldName.START,\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.FEAT_TIME,\n",
        "                time_features=time_features_from_frequency_str(freq),\n",
        "                pred_length=config.prediction_length,\n",
        "            ),\n",
        "            # step 5: add another temporal feature (just a single number)\n",
        "            # tells the model where in the life the value of the time series is\n",
        "            # sort of running counter\n",
        "            AddAgeFeature(\n",
        "                target_field=FieldName.TARGET,\n",
        "                output_field=FieldName.FEAT_AGE,\n",
        "                pred_length=config.prediction_length,\n",
        "                log_scale=True,\n",
        "            ),\n",
        "            # step 6: vertically stack all the temporal features into the key FEAT_TIME\n",
        "            VstackFeatures(\n",
        "                output_field=FieldName.FEAT_TIME,\n",
        "                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]\n",
        "                + (\n",
        "                    [FieldName.FEAT_DYNAMIC_REAL]\n",
        "                    if config.num_dynamic_real_features > 0\n",
        "                    else []\n",
        "                ),\n",
        "            ),\n",
        "            # step 7: rename to match HuggingFace names\n",
        "            RenameFields(\n",
        "                mapping={\n",
        "                    FieldName.FEAT_STATIC_CAT: \"static_categorical_features\",\n",
        "                    FieldName.FEAT_STATIC_REAL: \"static_real_features\",\n",
        "                    FieldName.FEAT_TIME: \"time_features\",\n",
        "                    FieldName.TARGET: \"values\",\n",
        "                    FieldName.OBSERVED_VALUES: \"observed_mask\",\n",
        "                }\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "ZIX7U3lCMjZc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InstanceSplitter\n",
        "\n",
        "from gluonts.transform.sampler import InstanceSampler\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "def create_instance_splitter(\n",
        "    config: PretrainedConfig,\n",
        "    mode: str,\n",
        "    train_sampler: Optional[InstanceSampler] = None,\n",
        "    validation_sampler: Optional[InstanceSampler] = None,\n",
        ") -> Transformation:\n",
        "    assert mode in [\"train\", \"validation\", \"test\"]\n",
        "\n",
        "    instance_sampler = {\n",
        "        \"train\": train_sampler\n",
        "        or ExpectedNumInstanceSampler(\n",
        "            num_instances=1.0, min_future=config.prediction_length\n",
        "        ),\n",
        "        \"validation\": validation_sampler\n",
        "        or ValidationSplitSampler(min_future=config.prediction_length),\n",
        "        \"test\": TestSplitSampler(),\n",
        "    }[mode]\n",
        "\n",
        "    return InstanceSplitter(\n",
        "        target_field=\"values\",\n",
        "        is_pad_field=FieldName.IS_PAD,\n",
        "        start_field=FieldName.START,\n",
        "        forecast_start_field=FieldName.FORECAST_START,\n",
        "        instance_sampler=instance_sampler,\n",
        "        past_length=config.context_length + max(config.lags_sequence),\n",
        "        future_length=config.prediction_length,\n",
        "        time_series_fields=[\"time_features\", \"observed_mask\"],\n",
        "    )"
      ],
      "metadata": {
        "id": "J-wbEyfXM1wk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloaders\n",
        "\n",
        "from typing import Iterable\n",
        "\n",
        "import torch\n",
        "from gluonts.itertools import Cyclic, Cached\n",
        "from gluonts.dataset.loader import as_stacked_batches\n",
        "\n",
        "\n",
        "def create_train_dataloader(\n",
        "    config: PretrainedConfig,\n",
        "    freq,\n",
        "    data,\n",
        "    batch_size: int,\n",
        "    num_batches_per_epoch: int,\n",
        "    shuffle_buffer_length: Optional[int] = None,\n",
        "    cache_data: bool = True,\n",
        "    **kwargs,\n",
        ") -> Iterable:\n",
        "    PREDICTION_INPUT_NAMES = [\n",
        "        \"past_time_features\",\n",
        "        \"past_values\",\n",
        "        \"past_observed_mask\",\n",
        "        \"future_time_features\",\n",
        "    ]\n",
        "    if config.num_static_categorical_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
        "\n",
        "    if config.num_static_real_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
        "\n",
        "    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [\n",
        "        \"future_values\",\n",
        "        \"future_observed_mask\",\n",
        "    ]\n",
        "\n",
        "    transformation = create_transformation(freq, config)\n",
        "    transformed_data = transformation.apply(data, is_train=True)\n",
        "    if cache_data:\n",
        "        transformed_data = Cached(transformed_data)\n",
        "\n",
        "    # we initialize a Training instance\n",
        "    instance_splitter = create_instance_splitter(config, \"train\")\n",
        "\n",
        "    # the instance splitter will sample a window of\n",
        "    # context length + lags + prediction length (from the 366 possible transformed time series)\n",
        "    # randomly from within the target time series and return an iterator.\n",
        "    stream = Cyclic(transformed_data).stream()\n",
        "    training_instances = instance_splitter.apply(stream, is_train=True)\n",
        "\n",
        "    return as_stacked_batches(\n",
        "        training_instances,\n",
        "        batch_size=batch_size,\n",
        "        shuffle_buffer_length=shuffle_buffer_length,\n",
        "        field_names=TRAINING_INPUT_NAMES,\n",
        "        output_type=torch.tensor,\n",
        "        num_batches_per_epoch=num_batches_per_epoch,\n",
        "    )\n",
        "\n",
        "def create_test_dataloader(\n",
        "    config: PretrainedConfig,\n",
        "    freq,\n",
        "    data,\n",
        "    batch_size: int,\n",
        "    **kwargs,\n",
        "):\n",
        "    PREDICTION_INPUT_NAMES = [\n",
        "        \"past_time_features\",\n",
        "        \"past_values\",\n",
        "        \"past_observed_mask\",\n",
        "        \"future_time_features\",\n",
        "    ]\n",
        "    if config.num_static_categorical_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_categorical_features\")\n",
        "\n",
        "    if config.num_static_real_features > 0:\n",
        "        PREDICTION_INPUT_NAMES.append(\"static_real_features\")\n",
        "\n",
        "    transformation = create_transformation(freq, config)\n",
        "    transformed_data = transformation.apply(data, is_train=False)\n",
        "\n",
        "    # we create a Test Instance splitter which will sample the very last\n",
        "    # context window seen during training only for the encoder.\n",
        "    instance_sampler = create_instance_splitter(config, \"test\")\n",
        "\n",
        "    # we apply the transformations in test mode\n",
        "    testing_instances = instance_sampler.apply(transformed_data, is_train=False)\n",
        "\n",
        "    return as_stacked_batches(\n",
        "        testing_instances,\n",
        "        batch_size=batch_size,\n",
        "        output_type=torch.tensor,\n",
        "        field_names=PREDICTION_INPUT_NAMES,\n",
        "    )"
      ],
      "metadata": {
        "id": "yaGB1u_RPNbo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time_features and lags\n",
        "\n",
        "from gluonts.time_feature import time_features_from_frequency_str\n",
        "from gluonts.time_feature import get_lags_for_frequency\n",
        "\n",
        "lags_sequence = get_lags_for_frequency(freq)\n",
        "time_features = time_features_from_frequency_str(freq)"
      ],
      "metadata": {
        "id": "rs-seSYAR4Pu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "context_length = prediction_length*2\n",
        "batch_size = 128\n",
        "num_batches_per_epoch = 100\n",
        "epochs = 50\n",
        "scaling = \"std\"\n",
        "\n",
        "encoder_layers=2\n",
        "decoder_layers=2\n",
        "d_model=16\n",
        "\n",
        "from transformers import AutoformerConfig, AutoformerForPrediction\n",
        "\n",
        "config = AutoformerConfig(\n",
        "    prediction_length=prediction_length,\n",
        "    # context length:\n",
        "    context_length=prediction_length*2,\n",
        "    # lags coming from helper given the freq:\n",
        "    lags_sequence=lags_sequence,\n",
        "    # +1 for the age feature\n",
        "    num_time_features=len(time_features) + 1,\n",
        "    # we have a single static categorical feature, namely time series ID:\n",
        "    # num_static_categorical_features=0,\n",
        "    # it has 366 possible values:\n",
        "    # cardinality=[len(train_dataset)],\n",
        "    \n",
        "    scaling=scaling,\n",
        "    # the model will learn an embedding of size 2 for each of the 366 possible values:\n",
        "    # embedding_dimension=[2],\n",
        "    encoder_layers=encoder_layers, \n",
        "    decoder_layers=decoder_layers,\n",
        "    d_model=d_model,\n",
        ")\n",
        "\n",
        "model = AutoformerForPrediction(config)"
      ],
      "metadata": {
        "id": "8E8SqNk6QNjT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train & test dataloaders\n",
        "\n",
        "train_dataloader = create_train_dataloader(\n",
        "    config=config,\n",
        "    freq=freq,\n",
        "    data=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_batches_per_epoch=num_batches_per_epoch,\n",
        "    shuffle_buffer_length=1024,\n",
        ")\n",
        "\n",
        "test_dataloader = create_test_dataloader(\n",
        "    config=config,\n",
        "    freq=freq,\n",
        "    data=test_dataset,\n",
        "    batch_size=64,\n",
        ")"
      ],
      "metadata": {
        "id": "ntTIffoBBebX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "from torch.optim import AdamW\n",
        "\n",
        "epochs = epochs\n",
        "loss_history = []\n",
        "\n",
        "accelerator = Accelerator()\n",
        "device = accelerator.device\n",
        "\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)\n",
        "\n",
        "model, optimizer, train_dataloader = accelerator.prepare(\n",
        "    model,\n",
        "    optimizer,\n",
        "    train_dataloader,\n",
        ")\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
        "            if config.num_static_categorical_features > 0\n",
        "            else None,\n",
        "            static_real_features=batch[\"static_real_features\"].to(device)\n",
        "            if config.num_static_real_features > 0\n",
        "            else None,\n",
        "            past_time_features=batch[\"past_time_features\"].to(device),\n",
        "            past_values=batch[\"past_values\"].to(device),\n",
        "            future_time_features=batch[\"future_time_features\"].to(device),\n",
        "            future_values=batch[\"future_values\"].to(device),\n",
        "            past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
        "            future_observed_mask=batch[\"future_observed_mask\"].to(device),\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backpropagation\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_history.append(loss.item())\n",
        "        if idx % 100 == 0:\n",
        "            print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XKpQpYCyPW0j",
        "outputId": "befb5e51-7406-4393-b0cc-8852ed5541ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.27819538116455\n",
            "6.773143768310547\n",
            "6.69601583480835\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 20>\u001b[0m:\u001b[94m23\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/autoformer/\u001b[0m\u001b[1;33mmodeling_autoformer.py\u001b[0m:\u001b[94m19\u001b[0m \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[94m70\u001b[0m in \u001b[92mforward\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1967 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# outputs.last_hidden_state and trend\u001b[0m                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1968 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# loc is 4rd last and scale is 3rd last output\u001b[0m                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1969 \u001b[0m\u001b[2m│   │   │   \u001b[0mparams = \u001b[96mself\u001b[0m.output_params(outputs[\u001b[94m0\u001b[0m] + outputs[\u001b[94m1\u001b[0m])                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1970 \u001b[2m│   │   │   \u001b[0mdistribution = \u001b[96mself\u001b[0m.output_distribution(params, loc=outputs[-\u001b[94m3\u001b[0m], scale=outpu  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1971 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1972 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.loss(distribution, future_values)                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1973 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/models/autoformer/\u001b[0m\u001b[1;33mmodeling_autoformer.py\u001b[0m:\u001b[94m18\u001b[0m \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[94m68\u001b[0m in \u001b[92moutput_distribution\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1865 \u001b[0m\u001b[2m│   │   \u001b[0msliced_params = params                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1866 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trailing_n \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1867 \u001b[0m\u001b[2m│   │   │   \u001b[0msliced_params = [p[:, -trailing_n:] \u001b[94mfor\u001b[0m p \u001b[95min\u001b[0m params]                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1868 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.distribution_output.distribution(sliced_params, loc=loc, scale=scale  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1869 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1870 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@add_start_docstrings_to_model_forward\u001b[0m(AUTOFORMER_INPUTS_DOCSTRING)                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1871 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@replace_return_docstrings\u001b[0m(output_type=Seq2SeqTSPredictionOutput, config_class=_CONF  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtime_series_utils.py\u001b[0m:\u001b[94m108\u001b[0m in \u001b[92mdistribution\u001b[0m    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   │   \u001b[0mloc: Optional[torch.Tensor] = \u001b[94mNone\u001b[0m,                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   │   \u001b[0mscale: Optional[torch.Tensor] = \u001b[94mNone\u001b[0m,                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   \u001b[0m) -> Distribution:                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m108 \u001b[2m│   │   \u001b[0mdistr = \u001b[96mself\u001b[0m._base_distribution(distr_args)                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m loc \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m scale \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m distr                                                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtime_series_utils.py\u001b[0m:\u001b[94m98\u001b[0m in                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[92m_base_distribution\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_base_distribution\u001b[0m(\u001b[96mself\u001b[0m, distr_args):                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 97 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.dim == \u001b[94m1\u001b[0m:                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 98 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.distribution_class(*distr_args)                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m Independent(\u001b[96mself\u001b[0m.distribution_class(*distr_args), \u001b[94m1\u001b[0m)                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/distributions/\u001b[0m\u001b[1;33mstudentT.py\u001b[0m:\u001b[94m52\u001b[0m in \u001b[92m__init__\u001b[0m           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, df, loc=\u001b[94m0.\u001b[0m, scale=\u001b[94m1.\u001b[0m, validate_args=\u001b[94mNone\u001b[0m):                           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.df, \u001b[96mself\u001b[0m.loc, \u001b[96mself\u001b[0m.scale = broadcast_all(df, loc, scale)                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m52 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._chi2 = Chi2(\u001b[96mself\u001b[0m.df)                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   │   \u001b[0mbatch_shape = \u001b[96mself\u001b[0m.df.size()                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m54 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(batch_shape, validate_args=validate_args)                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/distributions/\u001b[0m\u001b[1;33mchi2.py\u001b[0m:\u001b[94m24\u001b[0m in \u001b[92m__init__\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m│   \u001b[0marg_constraints = {\u001b[33m'\u001b[0m\u001b[33mdf\u001b[0m\u001b[33m'\u001b[0m: constraints.positive}                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, df, validate_args=\u001b[94mNone\u001b[0m):                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m24 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(\u001b[94m0.5\u001b[0m * df, \u001b[94m0.5\u001b[0m, validate_args=validate_args)                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m25 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m26 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mexpand\u001b[0m(\u001b[96mself\u001b[0m, batch_shape, _instance=\u001b[94mNone\u001b[0m):                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m27 \u001b[0m\u001b[2m│   │   \u001b[0mnew = \u001b[96mself\u001b[0m._get_checked_instance(Chi2, _instance)                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/distributions/\u001b[0m\u001b[1;33mgamma.py\u001b[0m:\u001b[94m54\u001b[0m in \u001b[92m__init__\u001b[0m              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   │   \u001b[0mbatch_shape = torch.Size()                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   │   │   \u001b[0mbatch_shape = \u001b[96mself\u001b[0m.concentration.size()                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m54 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(batch_shape, validate_args=validate_args)                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m56 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mexpand\u001b[0m(\u001b[96mself\u001b[0m, batch_shape, _instance=\u001b[94mNone\u001b[0m):                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m57 \u001b[0m\u001b[2m│   │   \u001b[0mnew = \u001b[96mself\u001b[0m._get_checked_instance(Gamma, _instance)                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/distributions/\u001b[0m\u001b[1;33mdistribution.py\u001b[0m:\u001b[94m62\u001b[0m in \u001b[92m__init__\u001b[0m       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 59 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mvalue = \u001b[96mgetattr\u001b[0m(\u001b[96mself\u001b[0m, param)                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mvalid = constraint.check(value)                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m valid.all():                                                        \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 62 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mExpected parameter \u001b[0m\u001b[33m{\u001b[0mparam\u001b[33m}\u001b[0m\u001b[33m \u001b[0m\u001b[33m\"\u001b[0m                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m(\u001b[0m\u001b[33m{\u001b[0m\u001b[96mtype\u001b[0m(value).\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m of shape \u001b[0m\u001b[33m{\u001b[0m\u001b[96mtuple\u001b[0m(value.shape)\u001b[33m}\u001b[0m\u001b[33m) \u001b[0m\u001b[33m\"\u001b[0m         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mof distribution \u001b[0m\u001b[33m{\u001b[0m\u001b[96mrepr\u001b[0m(\u001b[96mself\u001b[0m)\u001b[33m}\u001b[0m\u001b[33m \u001b[0m\u001b[33m\"\u001b[0m                                   \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mValueError: \u001b[0mExpected parameter df \u001b[1m(\u001b[0mTensor of shape \u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m24\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m of distribution \u001b[1;35mChi2\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m to satisfy the constraint \n",
              "\u001b[1;35mGreaterThan\u001b[0m\u001b[1m(\u001b[0m\u001b[33mlower_bound\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1m)\u001b[0m, but found invalid values:\n",
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0mnan, nan, nan,  \u001b[33m...\u001b[0m, nan, nan, nan\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0mnan, nan, nan,  \u001b[33m...\u001b[0m, nan, nan, nan\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0mnan, nan, nan,  \u001b[33m...\u001b[0m, nan, nan, nan\u001b[1m]\u001b[0m,\n",
              "        \u001b[33m...\u001b[0m,\n",
              "        \u001b[1m[\u001b[0mnan, nan, nan,  \u001b[33m...\u001b[0m, nan, nan, nan\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0mnan, nan, nan,  \u001b[33m...\u001b[0m, nan, nan, nan\u001b[1m]\u001b[0m,\n",
              "        \u001b[1m[\u001b[0mnan, nan, nan,  \u001b[33m...\u001b[0m, nan, nan, nan\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMulBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 20&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">23</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/autoformer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_autoformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1967 │   │   │   # outputs.last_hidden_state and trend</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1968 │   │   │   # loc is 4rd last and scale is 3rd last output</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1969 │   │   │   </span>params = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.output_params(outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] + outputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>])                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1970 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>distribution = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.output_distribution(params, loc=outputs[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>], scale=outpu  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1971 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1972 │   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.loss(distribution, future_values)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1973 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/models/autoformer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_autoformer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">18</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">68</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">output_distribution</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1865 │   │   </span>sliced_params = params                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1866 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trailing_n <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1867 │   │   │   </span>sliced_params = [p[:, -trailing_n:] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> p <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> params]                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1868 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.distribution_output.distribution(sliced_params, loc=loc, scale=scale  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1869 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1870 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@add_start_docstrings_to_model_forward</span>(AUTOFORMER_INPUTS_DOCSTRING)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1871 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@replace_return_docstrings</span>(output_type=Seq2SeqTSPredictionOutput, config_class=_CONF  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">time_series_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">108</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">distribution</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 │   │   </span>loc: Optional[torch.Tensor] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 │   │   </span>scale: Optional[torch.Tensor] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 │   </span>) -&gt; Distribution:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>108 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>distr = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._base_distribution(distr_args)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> loc <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> scale <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> distr                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">time_series_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">98</span> in                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_base_distribution</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_base_distribution</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, distr_args):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 97 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dim == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 98 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.distribution_class(*distr_args)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> Independent(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.distribution_class(*distr_args), <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/distributions/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">studentT.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">52</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, df, loc=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.</span>, scale=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.</span>, validate_args=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.df, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.loc, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scale = broadcast_all(df, loc, scale)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>52 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._chi2 = Chi2(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.df)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 │   │   </span>batch_shape = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.df.size()                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(batch_shape, validate_args=validate_args)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/distributions/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">chi2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">24</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 │   </span>arg_constraints = {<span style=\"color: #808000; text-decoration-color: #808000\">'df'</span>: constraints.positive}                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">23 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, df, validate_args=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>24 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.5</span> * df, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.5</span>, validate_args=validate_args)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">26 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">expand</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, batch_shape, _instance=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27 │   │   </span>new = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_checked_instance(Chi2, _instance)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/distributions/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">gamma.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">54</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 │   │   │   </span>batch_shape = torch.Size()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 │   │   │   </span>batch_shape = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.concentration.size()                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>54 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(batch_shape, validate_args=validate_args)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">56 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">expand</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, batch_shape, _instance=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">57 │   │   </span>new = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_checked_instance(Gamma, _instance)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/distributions/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">distribution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">62</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 59 │   │   │   │   </span>value = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, param)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 │   │   │   │   </span>valid = constraint.check(value)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> valid.all():                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 62 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 63 │   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Expected parameter {</span>param<span style=\"color: #808000; text-decoration-color: #808000\">} \"</span>                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 │   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"({</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(value).<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">} of shape {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>(value.shape)<span style=\"color: #808000; text-decoration-color: #808000\">}) \"</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 │   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"of distribution {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">repr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)<span style=\"color: #808000; text-decoration-color: #808000\">} \"</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Expected parameter df <span style=\"font-weight: bold\">(</span>Tensor of shape <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"font-weight: bold\">))</span> of distribution <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Chi2</span><span style=\"font-weight: bold\">()</span> to satisfy the constraint \n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GreaterThan</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">lower_bound</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">)</span>, but found invalid values:\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>nan, nan, nan,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span>nan, nan, nan,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span>nan, nan, nan,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,\n",
              "        <span style=\"font-weight: bold\">[</span>nan, nan, nan,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span>nan, nan, nan,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
              "        <span style=\"font-weight: bold\">[</span>nan, nan, nan,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, nan, nan, nan<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">MulBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"elisim/autoformer-electricity\")"
      ],
      "metadata": {
        "id": "onqG6FgXCiRH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}