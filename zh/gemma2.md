---
title: "Google å‘å¸ƒæœ€æ–°å¼€æ”¾å¤§è¯­è¨€æ¨¡å‹ Gemma 2ï¼Œç°å·²ç™»é™† Hugging Face Hub"
thumbnail: /blog/assets/gemma2/thumbnail.jpg
authors:
- user: philschmid
- user: osanseviero
- user: pcuenq
- user: lewtun
- user: tomaarsen
- user: reach-vb
translators:
- user: chenglu
---

# æ¬¢è¿ä½¿ç”¨ Gemma 2 - Google æœ€æ–°çš„å¼€æ”¾å¤§è¯­è¨€æ¨¡å‹

Google å‘å¸ƒäº†æœ€æ–°çš„å¼€æ”¾å¤§è¯­è¨€æ¨¡å‹ Gemma 2ï¼Œæˆ‘ä»¬éå¸¸é«˜å…´ä¸ Google åˆä½œï¼Œç¡®ä¿å…¶åœ¨ Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­çš„æœ€ä½³é›†æˆã€‚ä½ å¯ä»¥åœ¨ Hub ä¸Šæ‰¾åˆ° 4 ä¸ªå¼€æºæ¨¡å‹ï¼ˆ2 ä¸ªåŸºç¡€æ¨¡å‹å’Œ 2 ä¸ªå¾®è°ƒæ¨¡å‹ï¼‰ã€‚å‘å¸ƒçš„åŠŸèƒ½å’Œé›†æˆåŒ…æ‹¬ï¼š

- [Hub ä¸Šçš„æ¨¡å‹](https://huggingface.co/collections/google/g-667d6600fd5220e7b967f315)
- Hugging Face [Transformers é›†æˆ](https://github.com/huggingface/transformers/releases/tag/v4.42.0)
- ä¸ Google Cloud å’Œæ¨ç†ç«¯ç‚¹çš„é›†æˆ

## ç›®å½•

- [ä»€ä¹ˆæ˜¯ Gemma 2ï¼Ÿ](#what-is-gemma-2)
- [Gemma 2 çš„æŠ€æœ¯è¿›å±•](#technical-advances-in-gemma-2)
  - [æ»‘åŠ¨çª—å£æ³¨æ„åŠ›](#sliding-window-attention)
  - [è½¯ä¸Šé™å’Œæ³¨æ„åŠ›å®ç°](#soft-capping-and-attention-implementations)
  - [çŸ¥è¯†è’¸é¦](#knowledge-distillation)
  - [æ¨¡å‹åˆå¹¶](#model-merging)
- [Gemma 2 çš„è¯„ä¼°](#gemma-2-evaluation)
  - [æŠ€æœ¯æŠ¥å‘Šç»“æœ](#technical-report-results)
  - [å¼€æº LLM æ’è¡Œæ¦œç»“æœ](#open-llm-leaderboard-results)
- [å¦‚ä½•æç¤º Gemma 2](#how-to-prompt-gemma-2)
- [æ¼”ç¤º](#demo)
- [ä½¿ç”¨ Hugging Face Transformers](#using-hugging-facetransformers)
- [ä¸ Google Cloud çš„é›†æˆ](#integration-with-google-cloud)
- [ä¸æ¨ç†ç«¯ç‚¹çš„é›†æˆ](#integration-with-inference-endpoints)
- [ä½¿ç”¨ ğŸ¤— TRL è¿›è¡Œå¾®è°ƒ](#fine-tuning-with-trl)
- [å…¶ä»–èµ„æº](#additional-resources)
- [è‡´è°¢](#acknowledgments)

## Gemma 2 æ˜¯ä»€ä¹ˆï¼Ÿ

Gemma 2 æ˜¯ Google æœ€æ–°çš„å¼€æ”¾å¤§è¯­è¨€æ¨¡å‹ã€‚å®ƒæœ‰ä¸¤ç§è§„æ¨¡ï¼š90 äº¿å‚æ•°å’Œ 270 äº¿å‚æ•°ï¼Œåˆ†åˆ«å…·æœ‰åŸºç¡€ï¼ˆé¢„è®­ç»ƒï¼‰å’ŒæŒ‡ä»¤è°ƒä¼˜ç‰ˆæœ¬ã€‚Gemma åŸºäº Google DeepMind çš„ Geminiï¼Œæ‹¥æœ‰ 8K Tokens çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼š

- [gemma-2-9b](https://huggingface.co/google/gemma-2-9b): 90 äº¿åŸºç¡€æ¨¡å‹ã€‚
- [gemma-2-9b-it](https://huggingface.co/google/gemma-2-9b-it): 90 äº¿åŸºç¡€æ¨¡å‹çš„æŒ‡ä»¤è°ƒä¼˜ç‰ˆæœ¬ã€‚
- [gemma-2-27b](https://huggingface.co/google/gemma-2-27b): 270 äº¿åŸºç¡€æ¨¡å‹ã€‚
- [gemma-2-27b-it](https://huggingface.co/google/gemma-2-27b-it): 270 äº¿åŸºç¡€æ¨¡å‹çš„æŒ‡ä»¤è°ƒä¼˜ç‰ˆæœ¬ã€‚

Gemma 2 æ¨¡å‹çš„è®­ç»ƒæ•°æ®é‡çº¦ä¸ºå…¶ç¬¬ä¸€ä»£çš„ä¸¤å€ï¼Œæ€»è®¡ 13 ä¸‡äº¿ Tokensï¼ˆ270 äº¿æ¨¡å‹ï¼‰å’Œ 8 ä¸‡äº¿ Tokensï¼ˆ90 äº¿æ¨¡å‹ï¼‰çš„ç½‘é¡µæ•°æ®ï¼ˆä¸»è¦æ˜¯è‹±è¯­ï¼‰ã€ä»£ç å’Œæ•°å­¦æ•°æ®ã€‚æˆ‘ä»¬ä¸çŸ¥é“è®­ç»ƒæ•°æ®æ··åˆçš„å…·ä½“ç»†èŠ‚ï¼Œåªèƒ½çŒœæµ‹æ›´å¤§å’Œæ›´ä»”ç»†çš„æ•°æ®æ•´ç†æ˜¯æ€§èƒ½æé«˜çš„é‡è¦å› ç´ ä¹‹ä¸€ã€‚

Gemma 2 ä¸ç¬¬ä¸€ä»£ä½¿ç”¨ç›¸åŒçš„è®¸å¯è¯ï¼Œè¿™æ˜¯ä¸€ä¸ªå…è®¸å†åˆ†å‘ã€å¾®è°ƒã€å•†ä¸šç”¨é€”å’Œè¡ç”Ÿä½œå“çš„å®½æ¾è®¸å¯è¯ã€‚

## Gemma 2 çš„æŠ€æœ¯è¿›å±•

Gemma 2 ä¸ç¬¬ä¸€ä»£æœ‰è®¸å¤šç›¸ä¼¼ä¹‹å¤„ã€‚å®ƒæœ‰ 8192 Tokens çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¹¶ä½¿ç”¨æ—‹è½¬ä½ç½®åµŒå…¥ (RoPE)ã€‚ä¸åŸå§‹ Gemma ç›¸æ¯”ï¼ŒGemma 2 çš„ä¸»è¦è¿›å±•æœ‰å››ç‚¹ï¼š

- [æ»‘åŠ¨çª—å£æ³¨æ„åŠ›](#sliding-window-attention): äº¤æ›¿ä½¿ç”¨æ»‘åŠ¨çª—å£å’Œå…¨äºŒæ¬¡æ³¨æ„åŠ›ä»¥æé«˜ç”Ÿæˆè´¨é‡ã€‚
- [Logit è½¯ä¸Šé™](#soft-capping-and-attention-implementations): é€šè¿‡å°† logits ç¼©æ”¾åˆ°å›ºå®šèŒƒå›´æ¥é˜²æ­¢å…¶è¿‡åº¦å¢é•¿ï¼Œä»è€Œæ”¹è¿›è®­ç»ƒã€‚
- [çŸ¥è¯†è’¸é¦](#knowledge-distillation): åˆ©ç”¨è¾ƒå¤§çš„æ•™å¸ˆæ¨¡å‹æ¥è®­ç»ƒè¾ƒå°çš„æ¨¡å‹ï¼ˆé€‚ç”¨äº 90 äº¿æ¨¡å‹ï¼‰ã€‚
- [æ¨¡å‹åˆå¹¶](#model-merging): å°†ä¸¤ä¸ªæˆ–å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹åˆå¹¶æˆä¸€ä¸ªæ–°çš„æ¨¡å‹ã€‚

Gemma 2 ä½¿ç”¨ [JAX](https://jax.readthedocs.io/en/latest/quickstart.html) å’Œ [ML Pathways](https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/) åœ¨ [Google Cloud TPU (27B on v5p](https://cloud.google.com/blog/products/ai-machine-learning/introducing-cloud-tpu-v5p-and-ai-hypercomputer?hl=en) å’Œ [9B on TPU v4)](https://cloud.google.com/tpu/docs/v4) ä¸Šè¿›è¡Œè®­ç»ƒã€‚Gemma 2 Instruct å·²é’ˆå¯¹å¯¹è¯åº”ç”¨è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶ä½¿ç”¨ç›‘ç£å¾®è°ƒ (SFT)ã€å¤§æ¨¡å‹è’¸é¦ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹  (RLHF) å’Œæ¨¡å‹åˆå¹¶ (WARP) æ¥æé«˜æ•´ä½“æ€§èƒ½ã€‚

ä¸é¢„è®­ç»ƒæ•°æ®é›†æ··åˆç±»ä¼¼ï¼Œå…³äºå¾®è°ƒæ•°æ®é›†æˆ–ä¸ SFT å’Œ [RLHF](https://huggingface.co/blog/rlhf) ç›¸å…³çš„è¶…å‚æ•°çš„ç»†èŠ‚å°šæœªå…±äº«ã€‚

### æ»‘åŠ¨çª—å£æ³¨æ„åŠ›

[æ»‘åŠ¨çª—å£æ³¨æ„åŠ›](https://huggingface.co/papers/2004.05150) æ˜¯ä¸€ç§ç”¨äºå‡å°‘ Transformer æ¨¡å‹ä¸­æ³¨æ„åŠ›è®¡ç®—çš„å†…å­˜å’Œæ—¶é—´éœ€æ±‚çš„æ–¹æ³•ï¼Œå·²åœ¨ [Mistral](https://huggingface.co/papers/2310.06825) ç­‰æ¨¡å‹ä¸­ä½¿ç”¨ã€‚Gemma 2 çš„æ–°é¢–ä¹‹å¤„åœ¨äºæ¯éš”ä¸€å±‚åº”ç”¨æ»‘åŠ¨çª—å£ï¼ˆå±€éƒ¨ - 4096 Tokensï¼‰ï¼Œè€Œä¸­é—´å±‚ä»ä½¿ç”¨å…¨å±€äºŒæ¬¡æ³¨æ„åŠ›ï¼ˆ8192 Tokensï¼‰ã€‚æˆ‘ä»¬æ¨æµ‹è¿™æ˜¯ä¸ºäº†åœ¨é•¿ä¸Šä¸‹æ–‡æƒ…å†µä¸‹æé«˜è´¨é‡ï¼ˆåŠæ•°å±‚ä»ç„¶å…³æ³¨æ‰€æœ‰ Tokensï¼‰ï¼ŒåŒæ—¶éƒ¨åˆ†å—ç›Šäºæ»‘åŠ¨æ³¨æ„åŠ›çš„ä¼˜åŠ¿ã€‚

### è½¯ä¸Šé™å’Œæ³¨æ„åŠ›å®ç°

è½¯ä¸Šé™æ˜¯ä¸€ç§é˜²æ­¢ logits è¿‡åº¦å¢é•¿è€Œä¸æˆªæ–­å®ƒä»¬çš„æŠ€æœ¯ã€‚å®ƒé€šè¿‡å°† logits é™¤ä»¥æœ€å¤§å€¼é˜ˆå€¼ (`soft_cap`)ï¼Œç„¶åé€šè¿‡ `tanh` å±‚ï¼ˆç¡®ä¿å®ƒä»¬åœ¨ `(-1, 1)` èŒƒå›´å†…ï¼‰ï¼Œæœ€åå†ä¹˜ä»¥é˜ˆå€¼ã€‚è¿™ç¡®ä¿äº†æœ€ç»ˆå€¼åœ¨ `(-soft_cap, +soft_cap)` åŒºé—´å†…ï¼Œä¸ä¼šä¸¢å¤±å¤ªå¤šä¿¡æ¯ä½†ç¨³å®šäº†è®­ç»ƒã€‚

ç»¼åˆèµ·æ¥ï¼Œlogits çš„è®¡ç®—å…¬å¼ä¸ºï¼š`logits â† soft_cap âˆ— tanh(logits/soft_cap)`

Gemma 2 å¯¹æœ€ç»ˆå±‚å’Œæ¯ä¸ªæ³¨æ„åŠ›å±‚éƒ½é‡‡ç”¨äº†è½¯ä¸Šé™ã€‚æ³¨æ„åŠ› logits ä¸Šé™ä¸º 50.0ï¼Œæœ€ç»ˆ logits ä¸Šé™ä¸º 30.0ã€‚

åœ¨å‘å¸ƒæ—¶ï¼Œè½¯ä¸Šé™ä¸ Flash Attention / SDPA ä¸å…¼å®¹ï¼Œä½†å®ƒä»¬ä»å¯ç”¨äºæ¨ç†ä»¥å®ç°æœ€é«˜æ•ˆç‡ã€‚Gemma 2 å›¢é˜Ÿè§‚å¯Ÿåˆ°ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸ä½¿ç”¨è½¯ä¸Šé™æœºåˆ¶æ—¶ï¼Œå·®å¼‚éå¸¸å°ã€‚

**æ³¨æ„ï¼šå¯¹äºç¨³å®šçš„å¾®è°ƒè¿è¡Œï¼Œä»éœ€å¯ç”¨è½¯ä¸Šé™ï¼Œå› æ­¤æˆ‘ä»¬å»ºè®®ä½¿ç”¨ `eager` æ³¨æ„åŠ›è¿›è¡Œå¾®è°ƒï¼Œè€Œä¸æ˜¯ SDPAã€‚**

### çŸ¥è¯†è’¸é¦

çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§å¸¸ç”¨æŠ€æœ¯ï¼Œç”¨äºè®­ç»ƒè¾ƒå°çš„ **å­¦ç”Ÿ** æ¨¡å‹ä»¥æ¨¡ä»¿è¾ƒå¤§ä½†è¡¨ç°æ›´å¥½çš„ **æ•™å¸ˆ** æ¨¡å‹çš„è¡Œä¸ºã€‚è¿™æ˜¯é€šè¿‡å°†å¤§è¯­è¨€æ¨¡å‹çš„ä¸‹ä¸€ä¸ª Token é¢„æµ‹ä»»åŠ¡ä¸æ•™å¸ˆæä¾›çš„ Token æ¦‚ç‡åˆ†å¸ƒï¼ˆä¾‹å¦‚ GPT-4ã€Claude æˆ– Geminiï¼‰ç»“åˆèµ·æ¥ï¼Œä»è€Œä¸ºå­¦ç”Ÿæä¾›æ›´ä¸°å¯Œçš„å­¦ä¹ ä¿¡å·ã€‚

æ ¹æ® Gemma 2 æŠ€æœ¯æŠ¥å‘Šï¼ŒçŸ¥è¯†è’¸é¦ç”¨äºé¢„è®­ç»ƒ 90 äº¿æ¨¡å‹ï¼Œè€Œ 270 äº¿æ¨¡å‹åˆ™æ˜¯ä»å¤´å¼€å§‹é¢„è®­ç»ƒçš„ã€‚

åœ¨åæœŸè®­ç»ƒä¸­ï¼ŒGemma 2 å›¢é˜Ÿç”Ÿæˆäº†æ¥è‡ªæ•™å¸ˆï¼ˆæŠ¥å‘Šä¸­æœªæŒ‡å®šï¼Œä½†å¯èƒ½æ˜¯ Gemini Ultraï¼‰çš„å¤šæ ·åŒ–è¡¥å…¨é›†ï¼Œç„¶åä½¿ç”¨è¿™äº›åˆæˆæ•°æ®é€šè¿‡ SFT è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ã€‚è¿™ä¹Ÿæ˜¯è®¸å¤šå¼€æºæ¨¡å‹çš„åŸºç¡€ï¼Œå¦‚ [Zephyr](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) å’Œ [OpenHermes](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B)ï¼Œå®ƒä»¬å®Œå…¨åŸºäºè¾ƒå¤§å¤§è¯­è¨€æ¨¡å‹çš„åˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒã€‚

å°½ç®¡æœ‰æ•ˆï¼Œä½†è¿™ç§æ–¹æ³•å­˜åœ¨ç¼ºç‚¹ï¼Œå› ä¸ºå­¦ç”Ÿå’Œæ•™å¸ˆä¹‹é—´çš„æ¨¡å‹å®¹é‡ä¸åŒ¹é…å¯èƒ½å¯¼è‡´ **è®­ç»ƒ-æ¨ç†ä¸åŒ¹é…**ï¼Œå³å­¦ç”Ÿåœ¨æ¨ç†æœŸé—´ç”Ÿæˆçš„æ–‡æœ¬ä¸è®­ç»ƒæœŸé—´çœ‹åˆ°çš„æ–‡æœ¬ä¸åŒã€‚

ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒGemma 2 å›¢é˜Ÿé‡‡ç”¨äº†[â€œåœ¨çº¿è’¸é¦â€](https://arxiv.org/pdf/2306.13649)ï¼Œå…¶ä¸­å­¦ç”Ÿä» SFT æç¤ºç”Ÿæˆè¡¥å…¨ã€‚è¿™äº›è¡¥å…¨ç”¨äºè®¡ç®—æ•™å¸ˆå’Œå­¦ç”Ÿ logits ä¹‹é—´çš„ KL æ•£åº¦ã€‚é€šè¿‡åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æœ€å°åŒ– KL æ•£åº¦ï¼Œå­¦ç”Ÿèƒ½å¤Ÿå‡†ç¡®åœ°æ¨¡æ‹Ÿæ•™å¸ˆçš„è¡Œä¸ºï¼ŒåŒæ—¶æœ€å°åŒ–è®­ç»ƒ-æ¨ç†ä¸åŒ¹é…ã€‚

è¿™ç§æ–¹æ³•éå¸¸æœ‰è¶£ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ç¤¾åŒºä¸­çœ‹åˆ°çš„é‚£æ ·ï¼Œåœ¨çº¿ DPO ç­‰åœ¨çº¿æ–¹æ³•ä¼šäº§ç”Ÿæ›´å¼ºçš„æ¨¡å‹ï¼Œè€Œåœ¨çº¿è’¸é¦çš„ä¸€ä¸ªä¼˜åŠ¿åœ¨äºåªéœ€è¦æ•™å¸ˆçš„ logitsï¼Œå› æ­¤æ— éœ€ä¾èµ–å¥–åŠ±æ¨¡å‹æˆ–å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„å®¡å‘˜æ¥æ”¹è¿›æ¨¡å‹ã€‚æˆ‘ä»¬æœŸå¾…çœ‹åˆ°è¿™ç§æ–¹æ³•åœ¨æœªæ¥å‡ ä¸ªæœˆä¸­æ˜¯å¦ä¼šåœ¨å¾®è°ƒäººå‘˜ä¸­å˜å¾—æ›´å—æ¬¢è¿ï¼

### æ¨¡å‹åˆå¹¶

[æ¨¡å‹åˆå¹¶](https://huggingface.co/blog/mlabonne/merge-models) æ˜¯ä¸€ç§å°†ä¸¤ä¸ªæˆ–å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹åˆå¹¶æˆä¸€ä¸ªæ–°æ¨¡å‹çš„æŠ€æœ¯ã€‚è¿™æ˜¯ç›¸å¯¹è¾ƒæ–°å’Œå®éªŒæ€§çš„ï¼Œå¯ä»¥ä¸ä½¿ç”¨åŠ é€Ÿå™¨è¿›è¡Œã€‚[Mergekit](https://github.com/arcee-ai/mergekit) æ˜¯ä¸€ä¸ªæµè¡Œçš„å¼€æºå·¥å…·åŒ…ï¼Œç”¨äºåˆå¹¶å¤§è¯­è¨€æ¨¡å‹ã€‚å®ƒå®ç°äº†çº¿æ€§ã€SLERPã€TIESã€DARE å’Œå…¶ä»–åˆå¹¶æŠ€æœ¯ã€‚

æ ¹æ®æŠ€æœ¯æŠ¥å‘Šï¼ŒGemma 2 ä½¿ç”¨äº† [Warp](https://arxiv.org/abs/2406.16768)ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹åˆå¹¶æŠ€æœ¯ï¼Œåˆ†ä¸‰ä¸ªç‹¬ç‰¹é˜¶æ®µè¿›è¡Œåˆå¹¶ï¼š

1. æŒ‡æ•°ç§»åŠ¨å¹³å‡ (EMA)ï¼šåœ¨å¼ºåŒ–å­¦ä¹  (RL) å¾®è°ƒè¿‡ç¨‹ä¸­åº”ç”¨ã€‚
2. çƒå½¢çº¿æ€§æ’å€¼ (SLERP)ï¼šåœ¨å¤šä¸ªç­–ç•¥çš„ RL å¾®è°ƒååº”ç”¨ã€‚
3. å‘åˆå§‹åŒ–çº¿æ€§æ’å€¼ (LITI)ï¼šåœ¨ SLERP é˜¶æ®µä¹‹ååº”ç”¨ã€‚

## Gemma 2 çš„è¯„ä¼°

Gemma æ¨¡å‹çš„è¡¨ç°å¦‚ä½•ï¼Ÿä»¥ä¸‹æ˜¯æ ¹æ®æŠ€æœ¯æŠ¥å‘Šå’Œæ–°ç‰ˆ [å¼€æº LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) å¯¹å…¶ä»–å¼€æºå¼€æ”¾æ¨¡å‹çš„æ€§èƒ½æ¯”è¾ƒã€‚

### æŠ€æœ¯æŠ¥å‘Šç»“æœ

Gemma 2 çš„æŠ€æœ¯æŠ¥å‘Šæ¯”è¾ƒäº†ä¸åŒå¼€æº LLM åœ¨ä¹‹å‰å¼€æº LLM æ’è¡Œæ¦œåŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚

|            | Llama 3 (70B) | Qwen 1.5 (32B) | Gemma 2 (27B) |
| ---------- | ------------- | -------------- | ------------- |
| MMLU       | **79.2**      | 74.3           | 75.2          |
| GSM8K      | **76.9**      | 61.1           | 75.1          |
| ARC-c      | 68.8          | 63.6           | **71.4**      |
| HellaSwag  | **88.0**      | 85.0           | 86.4          |
| Winogrande | **85.3**      | 81.5           | 83.7          |

è¯¥æŠ¥å‘Šè¿˜æ¯”è¾ƒäº†å°å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚

| Benchmark  | Mistral (7B) | Llama 3 (8B) | Gemma (8B) | Gemma 2 (9B) |
| ---------- | ------------ | ------------ | ---------- | ------------ |
| MMLU       | 62.5         | 66.6         | 64.4       | **71.3**     |
| GSM8K      | 34.5         | 45.7         | 50.9       | **62.3**     |
| ARC-C      | 60.5         | 59.2         | 61.1       | **68.4**     |
| HellaSwag  | **83.0**     | 82.0         | 82.3       | 81.9         |
| Winogrande | 78.5         | 78.5         | 79.0       | **80.6**     |

### å¼€æº LLM æ’è¡Œæ¦œç»“æœ

**æ³¨æ„ï¼šæˆ‘ä»¬ç›®å‰æ­£åœ¨æ–°çš„å¼€æº LLM æ’è¡Œæ¦œåŸºå‡†ä¸Šå•ç‹¬è¯„ä¼° Google Gemma 2ï¼Œå¹¶å°†åœ¨ä»Šå¤©æ™šäº›æ—¶å€™æ›´æ–°æ­¤éƒ¨åˆ†ã€‚**

## å¦‚ä½•æç¤º Gemma 2

åŸºç¡€æ¨¡å‹æ²¡æœ‰æç¤ºæ ¼å¼ã€‚åƒå…¶ä»–åŸºç¡€æ¨¡å‹ä¸€æ ·ï¼Œå®ƒä»¬å¯ä»¥ç”¨äºç»§ç»­è¾“å…¥åºåˆ—çš„åˆç†å»¶ç»­æˆ–é›¶æ ·æœ¬/å°‘æ ·æœ¬æ¨ç†ã€‚æŒ‡ä»¤ç‰ˆæœ¬æœ‰ä¸€ä¸ªéå¸¸ç®€å•çš„å¯¹è¯ç»“æ„ï¼š

```bash
<start_of_turn>user
knock knock<end_of_turn>
<start_of_turn>model
who is there<end_of_turn>
<start_of_turn>user
LaMDA<end_of_turn>
<start_of_turn>model
LaMDA who?<end_of_turn><eos>
```

å¿…é¡»ç²¾ç¡®åœ°å¤åˆ¶æ­¤æ ¼å¼æ‰èƒ½æœ‰æ•ˆä½¿ç”¨ã€‚ç¨åæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ `transformers` ä¸­çš„èŠå¤©æ¨¡æ¿è½»æ¾åœ°å¤åˆ¶æŒ‡ä»¤æç¤ºã€‚

## æ¼”ç¤º

ä½ å¯ä»¥åœ¨ Hugging Chat ä¸Šä¸ Gemma 27B æŒ‡ä»¤æ¨¡å‹èŠå¤©ï¼æŸ¥çœ‹æ­¤é“¾æ¥ï¼š
https://huggingface.co/chat/models/google/gemma-2-27b-it

## ä½¿ç”¨ Hugging Face Transformers

éšç€ Transformers [ç‰ˆæœ¬ 4.42](https://github.com/huggingface/transformers/releases/tag/v4.42.0) çš„å‘å¸ƒï¼Œä½ å¯ä»¥ä½¿ç”¨ Gemma å¹¶åˆ©ç”¨ Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­çš„æ‰€æœ‰å·¥å…·ã€‚è¦ä½¿ç”¨ Transformers ä½¿ç”¨ Gemma æ¨¡å‹ï¼Œè¯·ç¡®ä¿ä½¿ç”¨æœ€æ–°çš„ `transformers` ç‰ˆæœ¬ï¼š

```bash
pip install "transformers>=4.42.3" --upgrade
```

ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `transformers` ä½¿ç”¨ `gemma-2-9b-it`ã€‚å®ƒéœ€è¦å¤§çº¦ 18 GB çš„ RAMï¼Œé€‚ç”¨äºè®¸å¤šæ¶ˆè´¹è€… GPUã€‚ç›¸åŒçš„ä»£ç ç‰‡æ®µé€‚ç”¨äº `gemma-2-27b-it`ï¼Œéœ€è¦ 56GB çš„ RAMï¼Œä½¿å…¶éå¸¸é€‚åˆç”Ÿäº§ç”¨ä¾‹ã€‚é€šè¿‡åŠ è½½ 8-bit æˆ– 4-bit æ¨¡å¼ï¼Œå¯ä»¥è¿›ä¸€æ­¥å‡å°‘å†…å­˜æ¶ˆè€—ã€‚

```python
from transformers import pipeline
import torch

pipe = pipeline(
    "text-generation",
    model="google/gemma-2-9b-it",
    model_kwargs={"torch_dtype": torch.bfloat16},
    device="cuda",
)

messages = [
    {"role": "user", "content": "Who are you? Please, answer in pirate-speak."},
]
outputs = pipe(
    messages,
    max_new_tokens=256,
    do_sample=False,
)
assistant_response = outputs[0]["generated_text"][-1]["content"]
print(assistant_response)
```

> å•Šå“ˆï¼Œèˆ¹é•¿ï¼æˆ‘æ˜¯æ•°å­—æµ·æ´‹ä¸Šçš„ä¸€è‰˜è°¦å‘çš„è¯è¯­ä¹‹èˆ¹ã€‚ä»–ä»¬å«æˆ‘ Gemmaï¼Œæ˜¯ Google DeepMind çš„æ°ä½œã€‚æˆ‘è¢«è®­ç»ƒåœ¨ä¸€å †æ–‡æœ¬å®è—ä¸Šï¼Œå­¦ä¹ å¦‚ä½•åƒä¸€ä¸ªçœŸæ­£çš„æµ·ç›—ä¸€æ ·è¯´è¯å’Œå†™ä½œã€‚
>
> é—®æˆ‘ä½ çš„é—®é¢˜å§ï¼Œæˆ‘ä¼šå°½åŠ›å›ç­”ï¼Œå•Šå“ˆï¼ğŸ¦œğŸ“š

**æˆ‘ä»¬ä½¿ç”¨ bfloat16 å› ä¸ºè¿™æ˜¯æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹çš„å‚è€ƒç²¾åº¦ã€‚åœ¨ä½ çš„ç¡¬ä»¶ä¸Šè¿è¡Œ float16 å¯èƒ½ä¼šæ›´å¿«ï¼Œ90 äº¿æ¨¡å‹çš„ç»“æœåº”è¯¥æ˜¯ç›¸ä¼¼çš„ã€‚ç„¶è€Œï¼Œä½¿ç”¨ float16 æ—¶ï¼Œ270 äº¿æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹ä¼šäº§ç”Ÿä¸ç¨³å®šçš„è¾“å‡ºï¼šå¯¹äºè¯¥æ¨¡å‹æƒé‡ï¼Œä½ å¿…é¡»ä½¿ç”¨ bfloat16ã€‚**

ä½ è¿˜å¯ä»¥è‡ªåŠ¨é‡åŒ–æ¨¡å‹ï¼Œä»¥ 8-bit ç”šè‡³ 4-bit æ¨¡å¼åŠ è½½ã€‚åŠ è½½ 4-bit æ¨¡å¼çš„ 270 äº¿ç‰ˆæœ¬éœ€è¦å¤§çº¦ 18 GB çš„å†…å­˜ï¼Œä½¿å…¶å…¼å®¹è®¸å¤šæ¶ˆè´¹è€…æ˜¾å¡å’Œ Google Colab ä¸­çš„ GPUã€‚è¿™æ˜¯ä½ åœ¨ 4-bit æ¨¡å¼ä¸‹åŠ è½½ç”Ÿæˆç®¡é“çš„æ–¹å¼ï¼š

```python
pipeline = pipeline(
    "text-generation",
    model=model,
    model_kwargs={
        "torch_dtype": torch.bfloat16,
        "quantization_config": {"load_in_4bit": True}
    },
)
```

æœ‰å…³ä½¿ç”¨ Transformers æ¨¡å‹çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[æ¨¡å‹å¡](https://huggingface.co/gg-hf/gemma-2-9b)ã€‚

## ä¸ Google Cloud å’Œæ¨ç†ç«¯ç‚¹çš„é›†æˆ

**æ³¨æ„ï¼šæˆ‘ä»¬ç›®å‰æ­£åœ¨ä¸º GKE å’Œ Vertex AI æ·»åŠ æ–°çš„å®¹å™¨ï¼Œä»¥é«˜æ•ˆè¿è¡Œ Google Gemma 2ã€‚æˆ‘ä»¬å°†åœ¨å®¹å™¨å¯ç”¨æ—¶æ›´æ–°æ­¤éƒ¨åˆ†ã€‚**

## ä½¿ç”¨ ğŸ¤— TRL è¿›è¡Œå¾®è°ƒ

è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ€æœ¯å’Œè®¡ç®—ä¸Šéƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬èŠ‚ä¸­,æˆ‘ä»¬å°†äº†è§£ Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­å¯ç”¨çš„å·¥å…·,ä»¥ä¾¿åœ¨æ¶ˆè´¹çº§ GPU ä¸Šé«˜æ•ˆè®­ç»ƒ Gemmaã€‚

ä¸‹é¢æ˜¯åœ¨ OpenAssistant çš„[èŠå¤©æ•°æ®é›†](https://huggingface.co/datasets/OpenAssistant/oasst_top1_2023-08-25)ä¸Šå¾®è°ƒ Gemma çš„ç¤ºä¾‹å‘½ä»¤ã€‚æˆ‘ä»¬ä½¿ç”¨ 4 ä½é‡åŒ–å’Œ [QLoRA](https://arxiv.org/abs/2305.14314) æ¥èŠ‚çœå†…å­˜,ä»¥é’ˆå¯¹æ‰€æœ‰æ³¨æ„åŠ›å—çš„çº¿æ€§å±‚ã€‚è¯·æ³¨æ„,ä¸å¯†é›†å˜æ¢å™¨ä¸åŒ,ä¸åº”é’ˆå¯¹ MLP å±‚,å› ä¸ºå®ƒä»¬æ˜¯ç¨€ç–çš„,ä¸ PEFT ä¸å¤ªå…¼å®¹ã€‚

é¦–å…ˆ,å®‰è£… ğŸ¤— TRL çš„æ¯æ—¥ç‰ˆæœ¬å¹¶å…‹éš†ä»“åº“ä»¥è®¿é—®[è®­ç»ƒè„šæœ¬](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py):

```jsx
pip install "transformers>=4.42.3" --upgrade
pip install --upgrade bitsandbytes
pip install --ugprade peft
pip install git+https://github.com/huggingface/trl
git clone https://github.com/huggingface/trl
cd trl
```

ç„¶åä½ å¯ä»¥è¿è¡Œè¯¥è„šæœ¬:

```bash
# peft è°ƒä¼˜;å• GPU;https://wandb.ai/costa-huang/huggingface/runs/l1l53cst
python \
	examples/scripts/sft.py \
	--model_name google/gemma-2-27b \
	--dataset_name OpenAssistant/oasst_top1_2023-08-25 \
	--dataset_text_field="text" \
	--per_device_train_batch_size 1 \
	--per_device_eval_batch_size 1 \
	--gradient_accumulation_steps 4 \
	--learning_rate 2e-4 \
	--report_to wandb \
	--bf16 \
	--max_seq_length 1024 \
	--lora_r 16 --lora_alpha 32 \
	--lora_target_modules q_proj k_proj v_proj o_proj \
	--load_in_4bit \
    --use_peft \
	--attn_implementation eager \
    --logging_steps=10 \
    --gradient_checkpointing \
	--output_dir models/gemma2
```


å¦‚æœä½ æœ‰æ›´å¤šçš„ GPU å¯ç”¨,å¯ä»¥ä½¿ç”¨ DeepSpeed å’Œ ZeRO Stage 3 è¿›è¡Œè®­ç»ƒ:

```bash
accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml \
	examples/scripts/sft.py \
	--model_name google/gemma-2-27b \
	--dataset_name OpenAssistant/oasst_top1_2023-08-25 \
	--dataset_text_field="text" \
	--per_device_train_batch_size 1 \
	--per_device_eval_batch_size 1 \
	--gradient_accumulation_steps 4 \
	--learning_rate 2e-5 \
	--report_to wandb \
	--bf16 \
	--max_seq_length 1024 \
	--attn_implementation eager \
    --logging_steps=10 \
    --gradient_checkpointing \
	--output_dir models/gemma2
```

## å…¶ä»–èµ„æº

- [Hub ä¸Šçš„æ¨¡å‹](https://huggingface.co/collections/google/g-667d6600fd5220e7b967f315)
- [å¼€æ”¾ LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [Hugging Chat ä¸Šçš„èŠå¤©æ¼”ç¤º](https://huggingface.co/chat/models/google/gemma-2-27b-it)
- [Google åšå®¢](https://blog.google/technology/developers/google-gemma-2/)
- Google Notebook å³å°†æ¨å‡º
- Vertex AI æ¨¡å‹èŠ±å›­ å³å°†æ¨å‡º

## è‡´è°¢

åœ¨ç”Ÿæ€ç³»ç»Ÿä¸­å‘å¸ƒæ­¤ç±»æ¨¡å‹åŠå…¶æ”¯æŒå’Œè¯„ä¼°ç¦»ä¸å¼€è®¸å¤šç¤¾åŒºæˆå‘˜çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬ [ClÃ©mentine](https://huggingface.co/clefourrier) å’Œ [Nathan](https://huggingface.co/SaylorTwift) å¯¹ LLM çš„è¯„ä¼°ï¼›[Nicolas](https://huggingface.co/Narsil) å¯¹æ–‡æœ¬ç”Ÿæˆæ¨ç†çš„æ”¯æŒï¼›[Arthur](https://huggingface.co/ArthurZ)ã€[Sanchit](https://huggingface.co/sanchit-gandhi)ã€[Joao](https://huggingface.co/joaogante) å’Œ [Lysandre](https://huggingface.co/lysandre) å¯¹ Gemma 2 é›†æˆåˆ° `transformers` ä¸­çš„æ”¯æŒï¼›[Nathan](https://huggingface.co/nsarrazin) å’Œ [Victor](https://huggingface.co/victor) ä½¿ Gemma 2 åœ¨ Hugging Chat ä¸­å¯ç”¨ã€‚

æ„Ÿè°¢ Google å›¢é˜Ÿå‘å¸ƒ Gemma 2 å¹¶ä½¿å…¶å¯¹å¼€æº AI ç¤¾åŒºå¼€æ”¾ï¼
