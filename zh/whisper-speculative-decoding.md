---
title: "ä½¿ç”¨æ¨æµ‹è§£ç ä½¿ Whisper å®ç° 2 å€çš„æ¨ç†åŠ é€Ÿ" 
thumbnail: /blog/assets/whisper-speculative-decoding/thumbnail.png
authors:
- user: sanchit-gandhi
translators:
- user: yaoqih
- user: zhongdongy
  proofreader: true
---

# ä½¿ç”¨æ¨æµ‹è§£ç ä½¿ Whisper å®ç° 2 å€çš„æ¨ç†åŠ é€Ÿ

<a target="_blank" href="https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/speculative_decoding.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

Open AI æ¨å‡ºçš„ [Whisper](https://openai.com/research/whisper) æ˜¯ä¸€ä¸ªé€šç”¨è¯­éŸ³è½¬å½•æ¨¡å‹ï¼Œåœ¨å„ç§åŸºå‡†å’ŒéŸ³é¢‘æ¡ä»¶ä¸‹éƒ½å–å¾—äº†éå¸¸æ£’çš„ç»“æœã€‚æœ€æ–°çš„ [large-v3](https://huggingface.co/openai/whisper-large-v3) æ¨¡å‹ç™»é¡¶äº† [OpenASR æ’è¡Œæ¦œ](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard)ï¼Œè¢«è¯„ä¸ºæœ€ä½³çš„å¼€æºè‹±è¯­è¯­éŸ³è½¬å½•æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨ Common Voice 15 æ•°æ®é›†çš„ 58 ç§è¯­è¨€ä¸­ä¹Ÿå±•ç°å‡ºäº†å¼ºå¤§çš„å¤šè¯­è¨€æ€§èƒ½ï¼Œåœ¨ 42 ç§è¯­è¨€ä¸Šçš„å•è¯é”™è¯¯ç‡ (WER) ä½äº 30ï¼…ã€‚

å°½ç®¡è½¬å½•å‡†ç¡®åº¦éå¸¸ä¼˜ç§€ï¼Œä½†æ¨ç†é€Ÿåº¦éå¸¸ç¼“æ…¢ã€‚å³ä½¿åˆ©ç”¨ [flash attention](https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2) ã€åŠç²¾åº¦å’Œ [åˆ†å—](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline.chunk_length_s) ç­‰ä¼˜åŒ–æ¨ç†æŠ€æœ¯ï¼Œ1 å°æ—¶é•¿åº¦çš„éŸ³é¢‘åœ¨ 16GB T4 GPU ä¸Šä¹Ÿéœ€è¦è¶…è¿‡ 6 åˆ†é’Ÿçš„è½¬å½•æ—¶é—´ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•è¿ç”¨æ¨æµ‹è§£ç å°† Whisper çš„æ¨ç†æ—¶é—´ç¼©å‡ **2 å€**ï¼ŒåŒæ—¶åœ¨æ•°å­¦ä¸Šç¡®ä¿å®Œå…¨å–å¾—ä¸åŸæ¨¡å‹ **ç›¸åŒçš„è¾“å‡º**ã€‚å› æ­¤ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥å®Œç¾åœ°æ›¿æ¢ç°æœ‰çš„ Whisper æµæ°´çº¿ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨ä¸é™ä½å‡†ç¡®æ€§çš„æƒ…å†µä¸‹å…è´¹è·å¾— 2 å€çš„åŠ é€Ÿã€‚æƒ³è¦çœ‹é™„å¸¦æœ‰æ›´ç®€æ´è§£é‡Šçš„å…¨éƒ¨ä»£ç ï¼Œè¯·å‚é˜…é…å¥—çš„ [Google Colab](https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/speculative_decoding.ipynb)ã€‚

## æ¨æµ‹è§£ç 

æ¨æµ‹è§£ç ç”± Yaniv Leviathan ç­‰äººåœ¨ [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192) ä¸­æå‡ºã€‚å…¶æ€æƒ³æ˜¯ï¼Œä¸€ä¸ªæ›´å¿«çš„ **è¾…åŠ©æ¨¡å‹** é€šå¸¸ä¼šç”Ÿæˆå’Œæ›´å¤§çš„ **ä¸»æ¨¡å‹** ç›¸åŒçš„ tokenã€‚

é¦–å…ˆï¼Œè¾…åŠ©æ¨¡å‹ä¼šé€šè¿‡è‡ªå›å½’ç”Ÿæˆ $N$ ä¸ª _å€™é€‰ token_ åºåˆ—: $\hat{\boldsymbol{y}}_{1:N}$ã€‚åœ¨ä¸‹å›¾ä¸­ï¼Œè¾…åŠ©æ¨¡å‹ç”Ÿæˆäº†ä¸€ä¸ªåŒ…å« 5 ä¸ªå€™é€‰ token çš„åºåˆ—: `The quick brown sock jumps` ã€‚

<figure class="image table text-center m-0 w-full">
    <video
        style="max-width: 90%; margin: auto;"
        controls playsinline
        src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/whisper-speculative-decoding/split_1.mp4"
    ></video>
</figure>

å°½ç®¡è¿™äº›å€™é€‰ token å¯ä»¥å¿«é€Ÿç”Ÿæˆï¼Œä½†å®ƒä»¬å¯èƒ½ä¸ä¸»æ¨¡å‹é¢„æµ‹çš„ token ä¸åŒã€‚å› æ­¤ï¼Œåœ¨ç¬¬äºŒæ­¥ä¸­ï¼Œå€™é€‰ token è¢«ä¼ å…¥ä¸»æ¨¡å‹ä»¥è¿›è¡Œâ€œéªŒè¯â€ã€‚ä¸»æ¨¡å‹å°†å€™é€‰ token ä½œä¸ºè¾“å…¥ï¼Œå¹¶æ‰§è¡Œ **å•æ¬¡å‰é¦ˆä¼ æ’­**ã€‚ä¸»æ¨¡å‹çš„è¾“å‡ºæ˜¯æ¯ä¸ªæ­¥éª¤ä¸­â€œæ­£ç¡®â€token çš„åºåˆ— $ \boldsymbol{y}_{1:N}$ã€‚

<figure class="image table text-center m-0 w-full">
    <video
        style="max-width: 90%; margin: auto;"
        controls playsinline
        src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/whisper-speculative-decoding/split_2.mp4"
    ></video>
</figure>

åœ¨ä¸Šå›¾ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°ä¸»æ¨¡å‹é¢„æµ‹çš„å‰ä¸‰ä¸ª token ä¸è¾…åŠ©æ¨¡å‹çš„ token ä¸€è‡´: `<span style="color:green">` The quick brown ä½†æ˜¯ï¼Œè¾…åŠ©æ¨¡å‹çš„ç¬¬å››ä¸ªå€™é€‰ token: â€œ `<span style="color:red">` sockâ€ä¸ä¸»æ¨¡å‹çš„æ­£ç¡® token: â€œ `<span style="color:green">` foxâ€ä¸ä¸€è‡´ã€‚

æˆ‘ä»¬çŸ¥é“ï¼Œæ‰€æœ‰å€™é€‰ token ä¸€ç›´åˆ°ç¬¬ä¸€ä¸ªä¸åŒ¹é…ä¹‹å‰éƒ½æ˜¯æ­£ç¡®çš„ ( `<span style="color:green">` The quick brown)ï¼Œå› ä¸ºè¿™äº›ä¸ä¸»æ¨¡å‹çš„é¢„æµ‹ä¸€è‡´ã€‚ä½†æ˜¯ï¼Œåœ¨ç¬¬ä¸€ä¸ªä¸åŒ¹é…ä¹‹åï¼Œå€™é€‰ token å¼€å§‹åç¦»ä¸»æ¨¡å‹å®é™…é¢„æµ‹çš„ tokenã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ä¸»æ¨¡å‹çš„æ­£ç¡® token ( `<span style="color:green">` fox) æ›¿æ¢ç¬¬ä¸€ä¸ªä¸æ­£ç¡®çš„å€™é€‰ token ( `<span style="color:red">` sock)ï¼Œå¹¶æ”¾å¼ƒä¹‹åæ‰€æœ‰é¢„æµ‹çš„ tokenï¼Œå› ä¸ºè¿™äº›å·²ç»é€æ¸åç¦»ä¸»æ¨¡å‹çš„é¢„æµ‹ã€‚ç»è¿‡æ ¡æ­£çš„åºåˆ— `The quick brown fox` ç°åœ¨æˆä¸ºè¾…åŠ©æ¨¡å‹çš„æ–°è¾“å…¥:

<figure class="image table text-center m-0 w-full">
    <video
        style="max-width: 90%; margin: auto;"
        controls playsinline
        src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/whisper-speculative-decoding/split_3.mp4"
    ></video>
</figure>

ç„¶åï¼Œè¾…åŠ©æ¨¡å‹å†æ¬¡é€šè¿‡è‡ªå›å½’æ¨ç†ï¼Œç”Ÿæˆä¸€ç»„æ–°çš„ $N$ ä¸ªå€™é€‰ tokenï¼Œè¿™äº› token å†æ¬¡é€šè¿‡ä¸»æ¨¡å‹çš„å•æ¬¡å‰é¦ˆä¼ æ’­è¿›è¡ŒéªŒè¯ã€‚

<figure class="image table text-center m-0 w-full">
    <video
        style="max-width: 90%; margin: auto;"
        controls playsinline
        src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/whisper-speculative-decoding/split_4.mp4"
    ></video>
</figure>

ç”±äºæˆ‘ä»¬åœ¨ç”Ÿæˆçš„æ—¶å€™ä½¿ç”¨çš„å¿«é€Ÿçš„è¾…åŠ©æ¨¡å‹è¿›è¡Œè‡ªå›å½’ï¼Œå¹¶ä¸”ç¼“æ…¢çš„ä¸»æ¨¡å‹ä»…ç”¨äºéªŒè¯å‰é¦ˆä¼ æ’­ï¼Œè§£ç è¿‡ç¨‹å°†å¤§å¤§åŠ å¿«ã€‚æ­¤å¤–ï¼Œç»è¿‡ä¸»æ¨¡å‹å‰é¦ˆä¼ æ’­éªŒè¯åå¯ä»¥ç¡®ä¿ä¸ä»…ä½¿ç”¨ä¸»æ¨¡å‹æ—¶è·å¾—å®Œå…¨ç›¸åŒçš„è¾“å‡ºã€‚è¿™ä½¿å¾—æ¨æµ‹è§£ç å¯ä»¥å®Œç¾åœ°æ›¿æ¢ç°æœ‰çš„ Whisper æµæ°´çº¿ï¼Œå› ä¸ºæˆ‘ä»¬å¯ä»¥ç¡®å®šä¼šå–å¾—ç›¸åŒè´¨é‡çš„è¾“å‡ºã€‚

ä¸ºäº†æœ€å¤§é™åº¦åœ°å‡å°‘å»¶è¿Ÿï¼Œè¾…åŠ©æ¨¡å‹åº”è¯¥æ¯”ä¸»æ¨¡å‹å¿«å¾—å¤šï¼ŒåŒæ—¶å°½å¯èƒ½é¢‘ç¹åœ°é¢„æµ‹ç›¸åŒçš„ token åˆ†å¸ƒã€‚å®é™…ä¸Šï¼Œè¿™ä¸¤ä¸ªå±æ€§ä¹‹é—´éœ€è¦æƒè¡¡: æ¨¡å‹è¶Šå¿«ï¼Œå…¶å‡†ç¡®åº¦è¶Šä½ã€‚ç„¶è€Œï¼Œç”±äºæ‰€æœ‰é¢„æµ‹ token ä¸­çš„ 70-80ï¼… å¾€å¾€æ˜¯â€œè¾ƒæ˜“â€çš„ tokenï¼Œæ­¤æƒè¡¡å€¾å‘äºé€‰æ‹©ä¸€ä¸ªæ›´å¿«çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ›´å‡†ç¡®çš„æ¨¡å‹ã€‚å› æ­¤ï¼Œè¾…åŠ©æ¨¡å‹åº”è¯¥è‡³å°‘æ¯”ä¸»æ¨¡å‹å¿« 3 å€ (è¶Šå¿«è¶Šå¥½)ï¼ŒåŒæ—¶åœ¨ç¤ºä¾‹ä¸­æ­£ç¡®é¢„æµ‹æ‰€æœ‰è¾ƒâ€œæ˜“â€tokenã€‚å‰©ä½™çš„ 20-30ï¼… æ›´â€œéš¾â€çš„ token å¯ä»¥ç”±æ›´å¤§çš„ä¸»æ¨¡å‹è¿›è¡ŒéªŒè¯ã€‚

é€‰æ‹©è¾…åŠ©æ¨¡å‹çš„å”¯ä¸€çº¦æŸæ˜¯å®ƒå¿…é¡»ä¸ä¸»æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„è¯æ±‡è¡¨ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¾…åŠ©æ¨¡å‹å¿…é¡»ä½¿ç”¨ä¸ä¸»æ¨¡å‹å®Œå…¨ä¸€å¯¹ä¸€ç›¸åŒçš„åˆ†è¯å™¨ã€‚å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬æƒ³å¯¹è¯¸å¦‚ [large-v2](https://huggingface.co/openai/whisper-large-v2) (å¤šè¯­è¨€) çš„ Whisper å¤šè¯­è¨€ç‰ˆæœ¬ä½¿ç”¨æ¨æµ‹è§£ç ï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹©è¯¸å¦‚ [tiny](https://huggingface.co/openai/tiny) çš„ Whisper å¤šè¯­è¨€ç‰ˆæœ¬ä½œä¸ºè¾…åŠ©æ¨¡å‹ã€‚è€Œå¦‚æœæˆ‘ä»¬æƒ³å¯¹è¯¸å¦‚ [medium.en](https://huggingface.co/openai/whisper-medium.en) çš„ Whisper è‹±æ–‡ç‰ˆæœ¬ä½¿ç”¨æ¨æµ‹è§£ç ï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹©è¯¸å¦‚ [tiny.en](https://huggingface.co/openai/tiny.en) çš„ Whisper è‹±æ–‡ç‰ˆæœ¬ä½œä¸ºè¾…åŠ©æ¨¡å‹ã€‚ç›®å‰ï¼Œ[large-v3](https://huggingface.co/openai/whisper-large-v3) æ˜¯å”¯ä¸€ä¸€ä¸ªæ‰©å±•äº†è¯æ±‡é‡çš„ Whisper æ£€æŸ¥ç‚¹ï¼Œå› æ­¤ä¸ä»¥å‰çš„ Whisper æ£€æŸ¥ç‚¹ä¸å…¼å®¹ã€‚

ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº†æ¨æµ‹è§£ç èƒŒåçš„åŸç†ï¼Œæˆ‘ä»¬å‡†å¤‡å®é™…å®ç°å®ƒã€‚åœ¨ [ğŸ¤— Transformers](https://huggingface.co/docs/transformers/index) åº“ä¸­ï¼Œæ¨æµ‹è§£ç è¢«å®ç°ä¸ºâ€œè¾…åŠ©ç”Ÿæˆ (Assisted Generation)â€æ¨ç†ç­–ç•¥ã€‚æ¬²äº†è§£æ›´å¤šå®ç°ç»†èŠ‚ï¼Œå»ºè®®è¯»è€…é˜…è¯» Joao Gante å…³äº [è¾…åŠ©ç”Ÿæˆ](https://huggingface.co/blog/assisted-generation) çš„ç²¾å½©åšæ–‡ã€‚

## è‹±æ–‡è¯­éŸ³è½¬å½•

### åŸºå‡†å®ç°

æˆ‘ä»¬é¦–å…ˆä½¿ç”¨ Whisper [large-v2](https://huggingface.co/openai/whisper-large-v2) è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œä»¥è·å¾—æ¨ç†é€Ÿåº¦çš„åŸºå‡†æ•°å€¼ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¾¿æ·çš„ [`AutoModelForSpeechSeq2Seq`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSpeechSeq2Seq) å’Œ [`AutoProcessor`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoProcessor) ç±»åŠ è½½ä¸»æ¨¡å‹åŠå…¶å¯¹åº”çš„å¤„ç†å™¨ã€‚æˆ‘ä»¬å°†ä»¥ `float16` ç²¾åº¦åŠ è½½æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä¼ é€’ [`low_cpu_mem_usage=True`](https://huggingface.co/docs/transformers/main_classes/model#large-model-loading) ç¡®ä¿åŠ è½½æ—¶é—´å°½å¯èƒ½å°‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¦ç¡®ä¿æ¨¡å‹ä»¥ [safetensors](https://huggingface.co/docs/diffusers/main/en/using-diffusers/using_safetensors) æ ¼å¼åŠ è½½ï¼Œæ–¹æ³•æ˜¯ä¼ é€’ [`use_safetensors=True`](https://huggingface.co/docs/transformers/main_classes/model#transformers.PreTrainedModel.from_pretrained.use_safetensors)ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ä¼ é€’å‚æ•° `attn_implementation="sdpa"` ï¼Œä»¥é€šè¿‡ PyTorch çš„ [SDPA æ³¨æ„åŠ›å†…æ ¸](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html) è¿›è¡Œ Flash æ³¨æ„åŠ›åŠ é€Ÿã€‚

```python
import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor

device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

model_id = "openai/whisper-large-v2"

model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id,
    torch_dtype=torch_dtype,
    low_cpu_mem_usage=True,
    use_safetensors=True,
    attn_implementation="sdpa",
)
model.to(device)

processor = AutoProcessor.from_pretrained(model_id)
```

è®©æˆ‘ä»¬åŠ è½½å°†ç”¨äºåŸºå‡†æµ‹è¯•çš„è‹±è¯­è¯­éŸ³è½¬å½•æ•°æ®é›†ã€‚æˆ‘ä»¬å°†åŠ è½½ [LibriSpeech ASR](https://huggingface.co/datasets/librispeech_asr) ä¸­éªŒè¯æ•°æ®é›†çš„ clean åˆ†ç»„ä¸­çš„ 73 ä¸ªæ ·æœ¬ç»„æˆçš„å°å‹æ•°æ®é›†ã€‚è¿™å¤§çº¦æœ‰ 9MB çš„æ•°æ®ï¼Œå› æ­¤éå¸¸è½»é‡ä¸”å¯ä»¥å¿«é€Ÿä¸‹è½½åˆ°è®¾å¤‡ä¸Šã€‚

```python
from datasets import load_dataset

dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
```

å¯¹äºåŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬åªæƒ³æµ‹é‡ç”Ÿæˆæ—¶é—´ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ç¼–å†™ä¸€ä¸ªç®€çŸ­çš„è¾…åŠ©å‡½æ•°æ¥æµ‹é‡æ­¤æ­¥éª¤è¿è¡Œçš„æ—¶é—´ã€‚ä¸‹é¢çš„å‡½æ•°å°†åŒæ—¶è¿”å›è§£ç çš„ token å’Œè¿è¡Œæ¨¡å‹æ‰€éœ€çš„æ—¶é—´:

```python
import time

def generate_with_time(model, inputs, **kwargs):
    start_time = time.time()
    outputs = model.generate(**inputs, **kwargs)
    generation_time = time.time() - start_time
    return outputs, generation_time
```

ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿­ä»£è¯­éŸ³æ•°æ®é›†ä¸­çš„éŸ³é¢‘æ ·æœ¬ï¼Œå¹¶ç»Ÿè®¡æ•´ä½“ç”Ÿæˆæ—¶é—´:

```python
from tqdm import tqdm

all_time = 0
predictions = []
references = []

for sample in tqdm(dataset):
    audio = sample["audio"]
    inputs = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt")
    inputs = inputs.to(device=device, dtype=torch.float16)
  
    output, gen_time = generate_with_time(model, inputs)
    all_time += gen_time
    predictions.append(processor.batch_decode(output, skip_special_tokens=True, normalize=True)[0])
    references.append(processor.tokenizer._normalize(sample["text"]))

print(all_time)
```

**Output:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [01:37<00:00,  1.33s/it]
72.99542546272278
```

å¾ˆå¥½ï¼æˆ‘ä»¬çœ‹åˆ°è½¬å½• 73 ä¸ªæ ·æœ¬èŠ±äº† 73 ç§’ã€‚è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹é¢„æµ‹çš„ WER:

```python
from evaluate import load

wer = load("wer")
print(wer.compute(predictions=predictions, references=references))
```

**Output:**

```
0.03507271171941831
```

æˆ‘ä»¬çš„æœ€ç»ˆåŸºå‡†æ•°å€¼ä¸º 73 ç§’ï¼ŒWER ä¸º 3.5ï¼…ã€‚

### æ¨æµ‹è§£ç 

ç°åœ¨è®©æˆ‘ä»¬åŠ è½½æ¨æµ‹è§£ç çš„è¾…åŠ©æ¨¡å‹ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Whisper è’¸é¦åçš„ç‰ˆæœ¬ [distil-large-v2](https://huggingface.co/distil-whisper/distil-large-v2)ã€‚è’¸é¦æ¨¡å‹åªä½¿ç”¨äº† Whisper ä¸­ 32 ä¸ªè§£ç å™¨å±‚ä¸­çš„ 2 ä¸ªç¼–ç å™¨ã€‚å› æ­¤ï¼Œå®ƒæ¯” Whisper å¿« 6 å€ï¼ŒåŒæ—¶åœ¨åˆ†å¸ƒæµ‹è¯•é›†ä¸Šçš„ WER æ€§èƒ½ç›¸æ¯”äºè’¸é¦å‰ä»…ä¸‹é™äº† 1ï¼…ã€‚è¿™ä½¿å…¶æˆä¸ºç†æƒ³çš„è¾…åŠ©æ¨¡å‹ï¼Œå› ä¸ºå®ƒåœ¨è½¬å½•å‡†ç¡®æ€§å’Œç”Ÿæˆé€Ÿåº¦æ–¹é¢éƒ½éå¸¸ä¼˜ç§€${}^1$ã€‚

---

${}^1$ æˆ‘ä»¬å³å°†å‘å¸ƒ Distil-Whisper çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œåœ¨ token åˆ†å¸ƒä¸­å…·æœ‰æ›´ä½³çš„å¯¹é½æ€§ï¼Œè¿™å°†è¿›ä¸€æ­¥æé«˜æ¨æµ‹è§£ç æ€§èƒ½ã€‚å…³æ³¨ [Distil-Whisper å­˜å‚¨åº“](https://github.com/huggingface/distil-whisper) æ¥è¿½è¸ªæœ€æ–°çš„æ›´æ–°ä¿¡æ¯ã€‚

---

ç”±äº Distil-Whisper ä½¿ç”¨ä¸ Whisper æ¨¡å‹å®Œå…¨ç›¸åŒçš„ç¼–ç å™¨ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸»æ¨¡å‹å’Œè¾…åŠ©æ¨¡å‹ä¹‹é—´å…±äº«ç¼–ç å™¨ã€‚ç„¶åï¼Œæˆ‘ä»¬åªéœ€è¦ä» Distil-Whisper åŠ è½½ 2 å±‚è§£ç å™¨ä½œä¸ºâ€œä»…è§£ç å™¨â€æ¨¡å‹ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¾¿æ·çš„ [`AutoModelForCausalLM`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM) è‡ªåŠ¨ç±»å®ç°è¿™ä¸€ç‚¹ã€‚åœ¨å®è·µä¸­ï¼Œç›¸æ¯”äºä»…ä½¿ç”¨ä¸»æ¨¡å‹ï¼Œè¿™ä»…å¢åŠ äº† 8ï¼…çš„ VRAM å ç”¨é‡ã€‚

```python
from transformers import AutoModelForCausalLM

assistant_model_id = "distil-whisper/distil-large-v2"

assistant_model = AutoModelForCausalLM.from_pretrained(
    assistant_model_id,
    torch_dtype=torch_dtype,
    low_cpu_mem_usage=True,
    use_safetensors=True,
    attn_implementation="sdpa",
)

assistant_model.to(device)
```

æˆ‘ä»¬å¯ä»¥ä¸ºæ¨æµ‹è§£ç çš„åŸºå‡†æµ‹è¯•å®šä¹‰ä¸€ä¸ªæ–°çš„å‡½æ•°ã€‚ä¸å‰é¢çš„å‡½æ•°å”¯ä¸€çš„åŒºåˆ«æ˜¯ï¼Œæˆ‘ä»¬åœ¨å¯¹ `.generate` çš„è°ƒç”¨ä¸­ä¼ é€’è¾…åŠ©æ¨¡å‹:

```python
def assisted_generate_with_time(model, inputs, **kwargs):
    start_time = time.time()
    outputs = model.generate(**inputs, assistant_model=assistant_model, **kwargs)
    generation_time = time.time() - start_time
    return outputs, generation_time
```

è®©æˆ‘ä»¬ä½¿ç”¨ Distil-Whisper ä½œä¸º Whisper çš„åŠ©æ‰‹è¿è¡Œæ¨æµ‹è§£ç çš„åŸºå‡†æµ‹è¯•:

```python
all_time = 0
predictions = []
references = []

for sample in tqdm(dataset):
    audio = sample["audio"]
    inputs = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt")
    inputs = inputs.to(device=device, dtype=torch.float16)
  
    output, gen_time = assisted_generate_with_time(model, inputs)
    all_time += gen_time
    predictions.append(processor.batch_decode(output, skip_special_tokens=True, normalize=True)[0])
    references.append(processor.tokenizer._normalize(sample["text"]))

print(all_time)
```

**Outputs:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [00:38<00:00,  1.88it/s]
32.69683289527893
```

ä½¿ç”¨æ¨æµ‹è§£ç ï¼Œæ¨ç†æ—¶é—´ä»…ä¸º 33 ç§’ï¼Œæ¯”ä¹‹å‰å¿« 2.2 å€ï¼è®©æˆ‘ä»¬éªŒè¯ä¸€ä¸‹ WER æ˜¯å¦ç›¸åŒ:

```python
print(wer.compute(predictions=predictions, references=references))
```

**Outputs:**

```
0.03507271171941831
```

å¤ªå®Œç¾äº†ï¼å†æ¬¡è¾¾åˆ° 3.5ï¼…çš„ WERï¼Œå› ä¸ºæˆ‘ä»¬çš„è¾“å‡ºä¸ä»…ä½¿ç”¨ä¸»æ¨¡å‹çš„æ—¶å€™å®Œå…¨ç›¸åŒã€‚

æ¨æµ‹è§£ç ä¹Ÿå¯ä»¥ä¸åŸºç¡€çš„ ğŸ¤— Transformers [pipeline](https://huggingface.co/docs/transformers/pipeline_tutorial) API ä¸€èµ·ç”¨äºæ¨ç†ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡å‹å’Œå¤„ç†å™¨å®ä¾‹åŒ–ç®¡é“ï¼Œç„¶åä½¿ç”¨å®ƒæ¥è½¬å½•æµ‹è¯•æ•°æ®é›†ä¸­çš„ç¬¬ä¸€ä¸ªæ ·æœ¬ã€‚è¿™å¯ä»¥æ‰©å±•ä¸ºè½¬å½•ä»»æ„é•¿åº¦çš„éŸ³é¢‘æ ·æœ¬ï¼ŒåŒ…æ‹¬è¿›è¡Œæ‰¹å¤„ç†:

```python
from transformers import pipeline

pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    max_new_tokens=128,
    chunk_length_s=15,
    batch_size=4,
    generate_kwargs={"assistant_model": assistant_model},
    torch_dtype=torch_dtype,
    device=device,
)

sample = dataset[0]["audio"]
result = pipe(sample)
print(result["text"])
```

**Outputs:**

```
 Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.
```

ä½¿ç”¨ Whisper å’Œ Distil-Whisper è¿è¡Œæ¨æµ‹è§£ç çš„ç«¯åˆ°ç«¯ä»£ç ç¤ºä¾‹å¯åœ¨ [Distil-Whisper æ¨¡å‹å¡](https://huggingface.co/distil-whisper/distil-large-v2#speculative-decoding) ä¸­æ‰¾åˆ°ã€‚å®ƒå°†æœ¬æ–‡ä¸­æ¶µç›–çš„æ¨ç†é˜¶æ®µç»„åˆæˆä¸€ä¸ªä»£ç ç¤ºä¾‹ã€‚

## å¤šè¯­è¨€è¯­éŸ³è½¬å½•

Distil-Whisper æ˜¯è‹±è¯­è¯­éŸ³è½¬å½•çš„æœ€ä½³è¾…åŠ©æ¨¡å‹ï¼Œå› ä¸ºå®ƒä¸åŸå§‹ Whisper æ¨¡å‹çš„ WER è¯¯å·®ç‡ä»…ç›¸å·® 1ï¼…ï¼Œè€Œå¯¹çŸ­é•¿è¯­éŸ³æ ·æœ¬çš„æ¨ç†é€Ÿåº¦æé«˜äº† 6 å€ã€‚ç„¶è€Œï¼Œå®˜æ–¹çš„ Distil-Whisper æ£€æŸ¥ç‚¹ä»…æ”¯æŒè‹±è¯­ï¼Œè¿™æ„å‘³ç€å®ƒä»¬æ— æ³•ç”¨äºå¤šè¯­è¨€è¯­éŸ³è½¬å½•ã€‚

è¦ä½¿ç”¨æ¨æµ‹è§£ç è¿›è¡Œå¤šè¯­è¨€è¯­éŸ³è½¬å½•ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ [å®˜æ–¹ Whisper å¤šè¯­è¨€æ£€æŸ¥ç‚¹](https://huggingface.co/openai/whisper-large-v2#model-details) ä¹‹ä¸€ï¼Œæˆ–è€… Whisper çš„å¾®è°ƒç‰ˆæœ¬ã€‚åœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼ŒHugging Face Hub ä¸Šå·²æœ‰è¶…è¿‡ 5000 ä¸ªå¾®è°ƒè¿‡çš„ Whisper æ£€æŸ¥ç‚¹ï¼Œæ”¯æŒè¶…è¿‡ 100 ç§è¯­è¨€ã€‚è¿™äº›ä¸ºé€‰æ‹©è¡¨ç°å‡ºè‰²çš„è¾…åŠ©æ¨¡å‹æä¾›äº†æå¥½çš„èµ·ç‚¹ã€‚åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æœ€å°çš„å®˜æ–¹å¤šè¯­è¨€æ£€æŸ¥ç‚¹ Whisper [tiny](https://huggingface.co/openai/whisper-tiny)ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»»æ„ä¸€ä¸ªæ‚¨çš„è¯­è¨€ä¸­å¾®è°ƒè¿‡çš„ä¸åŒæ£€æŸ¥ç‚¹ï¼

è®©æˆ‘ä»¬ä¸ºæ–°çš„è¾…åŠ©æ¨¡å‹ Whisper tiny åŠ è½½æƒé‡ã€‚ç”±äº Whisper tiny çš„ç¼–ç å™¨ä¸ large-v2 ä¸åŒï¼Œè¿™æ¬¡æˆ‘ä»¬å°†ä½¿ç”¨ `AutoModelForSpeechSeq2Seq` ç±»åŒæ—¶åŠ è½½ç¼–ç å™¨å’Œè§£ç å™¨:

```python
assistant_model_id = "openai/whisper-tiny"

assistant_model = AutoModelForSpeechSeq2Seq.from_pretrained(
    assistant_model_id,
    torch_dtype=torch_dtype,
    low_cpu_mem_usage=True,
    use_safetensors=True,
    attn_implementation="sdpa",
)

assistant_model.to(device);
```

æˆ‘ä»¬çš„åŸºå‡†æ•°æ®é›†ï¼Œå°†ä» [VoxPopuli](https://huggingface.co/datasets/facebook/voxpopuli) æ•°æ®é›†çš„è·å…°è¯­ (â€œnlâ€) éƒ¨åˆ†ä¸­åŠ è½½ 73 ä¸ªæ ·æœ¬:

```python
dataset = load_dataset("sanchit-gandhi/voxpopuli_dummy", "nl", split="validation")
```

éå¸¸å¥½ï¼ç°åœ¨æˆ‘ä»¬å¯ä»¥åƒå‰é¢ä¸€æ ·é‡æ–°è¿è¡Œæˆ‘ä»¬çš„ Whisper large-v2 æ¨¡å‹çš„åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬æ‰€åšçš„å”¯ä¸€æ›´æ”¹æ˜¯åœ¨ generate å‡½æ•°ä¸­ä¼ é€’è¯­è¨€å’Œä»»åŠ¡å‚æ•°ï¼Œä»¥ç¡®ä¿æ‰§è¡Œè¯­éŸ³è½¬å½• (è€Œä¸æ˜¯è¯­éŸ³ç¿»è¯‘)ã€‚æ¨æµ‹è§£ç å®Œå…¨å…¼å®¹è¯­éŸ³è½¬å½•å’Œç¿»è¯‘ä»»åŠ¡ã€‚åªéœ€å¦‚ä¸‹æ‰€ç¤ºè®¾ç½®ä»»åŠ¡å‚æ•°å³å¯:

```python
all_time = 0
predictions = []
references = []

for sample in tqdm(dataset):
    audio = sample["audio"]
    inputs = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt")
    inputs = inputs.to(device=device, dtype=torch.float16)
  
    output, gen_time = generate_with_time(model, inputs, language="nl", task="transcribe")
    all_time += gen_time
    predictions.append(processor.batch_decode(output, skip_special_tokens=True, normalize=True)[0])
    references.append(processor.tokenizer._normalize(sample["normalized_text"]))

wer_result = wer.compute(predictions=predictions, references=references)

print("Time:", all_time)
print("WER:", wer_result)
```

**Outputs:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [02:05<00:00,  1.72s/it]
Time: 116.50992178916931
WER: 0.127190136275146
```

æ²¡é”™ï¼æˆ‘ä»¬çš„åŸºå‡†æ—¶é—´ä¸º 117 ç§’ï¼ŒWER ä¸º 12.8ï¼…ã€‚è®©æˆ‘ä»¬ä½¿ç”¨æ¨æµ‹è§£ç é‡æ–°è¿è¡Œç”Ÿæˆè¿‡ç¨‹:

```python
all_time = 0
predictions = []
references = []

for sample in tqdm(dataset):
    audio = sample["audio"]
    inputs = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt")
    inputs = inputs.to(device=device, dtype=torch.float16)

    output, gen_time = assisted_generate_with_time(model, inputs, language="nl", task="transcribe")
    all_time += gen_time
    predictions.append(processor.batch_decode(output, skip_special_tokens=True, normalize=True)[0])
    references.append(processor.tokenizer._normalize(sample["normalized_text"]))

wer_result = wer.compute(predictions=predictions, references=references)

print("Time:", all_time)
print("WER:", wer_result)
```

**Outputs:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73/73 [01:08<00:00,  1.06it/s]
Time: 62.10229682922363
WER: 0.127190136275146
```

Niceï¼æˆ‘ä»¬è¾¾åˆ°äº† 12.8ï¼… çš„ WERï¼Œä½†è¿™æ¬¡çš„æ¨ç†æ—¶é—´åªæœ‰ 62 ç§’ï¼Œè¡¨ç¤ºé€Ÿåº¦æé«˜äº† 1.9 å€ã€‚è€ƒè™‘åˆ°åŠ è½½è¾…åŠ©æ¨¡å‹çš„ä½å¼€é”€å’Œç¡®ä¿è·å¾—å®Œå…¨ç›¸åŒè¾“å‡ºçš„æ•°å­¦è¯æ˜ï¼Œæ¨æµ‹è§£ç ä¸ºç°æœ‰çš„ Whisper ç®¡é“æä¾›äº†å®Œç¾çš„å³æ’å³ç”¨çš„æ›¿ä»£æ–¹æ¡ˆã€‚

## é«˜æ•ˆæ¨æµ‹è§£ç çš„ç­–ç•¥

åœ¨æœ¬æœ€ç»ˆéƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸¤ç§ç­–ç•¥ï¼Œä»¥ç¡®ä¿ä½¿ç”¨æ¨æµ‹è§£ç æ—¶è·å¾—å¯èƒ½æœ€å¿«çš„æ¨ç†æ—¶é—´ã€‚

#### è¾…åŠ©æ¨¡å‹

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€‰æ‹©ä¸€ä¸ªè‡³å°‘æ¯”ä¸»æ¨¡å‹å¿« 3 å€ **å¹¶ä¸”** æ­£ç¡®è½¬å½•è‡³å°‘ 70-80ï¼… çš„é¢„æµ‹ token (é€šå¸¸æ˜¯ç¤ºä¾‹ä¸­çš„â€œæ›´ç®€å•â€token) çš„è¾…åŠ©æ¨¡å‹ã€‚å¦‚æœæ‚¨æƒ³è¦è½¬å½•æŸç§ç‰¹å®šè¯­è¨€ï¼Œä¸€ç§æœ‰æ•ˆçš„ç­–ç•¥æ˜¯è®­ç»ƒä¸¤ä¸ªä¸åŒå¤§å°çš„ Whisper æ¨¡å‹ï¼Œå¹¶å°†å…¶ä¸­ä¸€ä¸ªç”¨ä½œå¦ä¸€ä¸ªçš„è¾…åŠ©æ¨¡å‹:

- é¦–å…ˆï¼Œå¾®è°ƒ Whisper [large-v3](https://huggingface.co/openai/whisper-large-v3) ä»¥ç”¨ä½œä¸»æ¨¡å‹
- å…¶æ¬¡ï¼Œåœ¨åŒä¸€æ•°æ®é›†ä¸Šè’¸é¦ Whisper [large-v3](https://huggingface.co/openai/whisper-large-v3) ä»¥ç”¨ä½œå¿«é€Ÿçš„è¾…åŠ©æ¨¡å‹

å¾®è°ƒå’Œè’¸é¦éƒ½å¯ä»¥æé«˜ä¸»æ¨¡å‹å’Œè¾…åŠ©æ¨¡å‹åœ¨æ‚¨é€‰æ‹©çš„è¯­è¨€ä¸Šçš„ WER æ€§èƒ½ï¼ŒåŒæ—¶æœ€å¤§åŒ– token åˆ†å¸ƒçš„å¯¹é½ã€‚æœ‰å…³ Whisper å¾®è°ƒçš„å®Œæ•´æŒ‡å—ï¼Œè¯·å‚é˜… [æ­¤å¤„](https://huggingface.co/blog/fine-tune-whisper)ï¼Œæœ‰å…³è’¸é¦çš„æŒ‡å—è¯·å‚é˜… [æ­¤å¤„](https://github.com/huggingface/distil-whisper/tree/main/training)ã€‚

#### æ‰¹æ¬¡å¤§å°

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨æ¨æµ‹è§£ç è·å¾—çš„æœ€å¤§é€Ÿåº¦æå‡æ¥è‡ªæ‰¹æ¬¡å¤§å°ä¸º 1ã€‚å¯¹äºæ‰¹å¤„ç†æ¨æµ‹è§£ç ï¼Œæ‰¹å¤„ç†ä¸­çš„æ‰€æœ‰å€™é€‰ token å¿…é¡»ä¸éªŒè¯ token ç›¸åŒ¹é…ï¼Œæ‰èƒ½è¢«æ¥å—ã€‚å¦‚æœæ‰¹å¤„ç†ä¸­ç»™å®šä½ç½®çš„ token ä¸ä¸€è‡´ï¼Œåˆ™æ‰€æœ‰åœ¨è¯¥ä½ç½®ä¹‹å‰çš„å€™é€‰ token å°†è¢«ä¸¢å¼ƒã€‚å› æ­¤ï¼Œæ¨æµ‹è§£ç æ›´å€¾å‘äºè¾ƒå°çš„æ‰¹æ¬¡å¤§å°ã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å‘ç°æ¨æµ‹è§£ç å¯ä»¥æä¾›é€Ÿåº¦æå‡ï¼Œç›´åˆ°æ‰¹æ¬¡å¤§å°è¾¾åˆ° 4 ä¸ºæ­¢ã€‚å½“æ‰¹æ¬¡å¤§å°è¶…è¿‡ 4 æ—¶ï¼Œæ¨æµ‹è§£ç çš„æ¨ç†é€Ÿåº¦æ¯”ä»…ç”¨ä¸»æ¨¡å‹è¿˜è¦æ…¢ã€‚æœ‰å…³å®Œæ•´ç»“æœï¼Œè¯·å‚é˜… [Distil-Whisper è®ºæ–‡](https://arxiv.org/pdf/2311.00430.pdf) çš„ç¬¬ D.3 èŠ‚ã€‚

## ç»“è®º

åœ¨æœ¬åšæ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†æ¨æµ‹è§£ç çš„æ¨ç†ç­–ç•¥ï¼Œä»¥åŠå¦‚ä½•å°†å…¶åº”ç”¨äºè¯­éŸ³è½¬å½•çš„ Whisper æ¨¡å‹ã€‚æˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•å®ç° 2 å€çš„é€Ÿåº¦æå‡ï¼ŒåŒæ—¶æ•°å­¦ä¸Šç¡®ä¿è·å¾—ä¸ä»…ä½¿ç”¨åŸå§‹æ¨¡å‹ç›¸åŒçš„è¾“å‡ºã€‚æˆ‘ä»¬é¼“åŠ±æ‚¨å°è¯•å°†æ¨æµ‹è§£ç ç”¨ä½œç°æœ‰ Whisper ç®¡é“çš„å³æ’å³ç”¨æ›¿ä»£æ–¹æ¡ˆï¼Œå› ä¸ºä½¿ç”¨é¢å¤–çš„è¾…åŠ©æ¨¡å‹çš„å¼€é”€å¾ˆå°ï¼Œå¹¶ä¸”å¯ä»¥ä¿è¯è·å¾—ç›¸åŒçš„è½¬å½•ç»“æœã€‚

## è‡´è°¢

æœ¬åšå®¢ç”± [Sanchit Gandhi](https://huggingface.co/sanchit-gandhi) æ’°å†™ã€‚éå¸¸æ„Ÿè°¢ [Patrick von Platen](https://huggingface.co/patrickvonplaten) å’Œ [Pedro Cuenca](https://huggingface.co/pcuenq) çš„å»ºè®¾æ€§æ„è§ï¼Œä»¥åŠ [Joao Gante](https://huggingface.co/joaogante) åœ¨ ğŸ¤— Transformers ä¸­å®ç°è¾…åŠ©ç”Ÿæˆçš„è´¡çŒ®ã€‚