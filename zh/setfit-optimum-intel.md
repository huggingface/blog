---
title: "åœ¨è‹±ç‰¹å°”è‡³å¼º CPU ä¸Šä½¿ç”¨ ğŸ¤— Optimum Intel å®ç°è¶…å¿« SetFit æ¨ç†"
thumbnail: /blog/assets/optimum_intel/intel_thumbnail.png
authors:
- user: danielkorat
  guest: true
- user: tomaarsen
- user: orenpereg
  guest: true
- user: moshew
  guest: true
- user: echarlaix
- user: aprabh2
  guest: true
translators:
- user: MatrixYao
---

# åœ¨è‹±ç‰¹å°”è‡³å¼º CPU ä¸Šä½¿ç”¨ ğŸ¤— Optimum Intel å®ç°è¶…å¿« SetFit æ¨ç†

åœ¨ç¼ºå°‘æ ‡æ³¨æ•°æ®åœºæ™¯ï¼ŒSetFit æ˜¯è§£å†³çš„å»ºæ¨¡é—®é¢˜çš„ä¸€ä¸ªæœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œå…¶ç”± Hugging Face ä¸ [Intel å®éªŒå®¤](https://www.intel.com/content/www/us/en/research/overview.html) ä»¥åŠ [UKP Lab](https://www.informatik.tu-darmstadt.de/ukp/ukp_home/index.en.jsp) åˆä½œå…±åŒå¼€å‘ã€‚ä½œä¸ºä¸€ä¸ªé«˜æ•ˆçš„æ¡†æ¶ï¼ŒSetFit å¯ç”¨äºå¯¹ [Sentence Transformers](https://sbert.net/) æ¨¡å‹è¿›è¡Œå°‘æ ·æœ¬å¾®è°ƒã€‚

SetFit ä»…éœ€å¾ˆå°‘çš„æ ‡æ³¨æ•°æ®å°±èƒ½è¾¾åˆ°è¾ƒé«˜çš„å‡†ç¡®ç‡ï¼Œä¾‹å¦‚ï¼Œåœ¨ä½¿ç”¨ 3-ç¤ºä¾‹æç¤ºæ—¶ï¼ŒSetFit [ä¼˜äº](https://arxiv.org/pdf/2311.06102.pdf) GPT-3.5ï¼›åœ¨ä½¿ç”¨ 5-ç¤ºä¾‹æç¤ºæ—¶ï¼Œå…¶åœ¨ Banking 77 é‡‘èæ„å›¾æ•°æ®é›†ä¸Šçš„è¡¨ç°ä¹Ÿä¼˜äºä½¿ç”¨ 3-ç¤ºä¾‹æç¤ºçš„ GPT-4ã€‚

ä¸åŸºäº LLM çš„æ–¹æ³•ç›¸æ¯”ï¼ŒSetFit æœ‰ä¸¤ä¸ªç‹¬ç‰¹çš„ä¼˜åŠ¿ï¼š

<p>ğŸ—£ <strong>æ— éœ€æç¤ºæˆ–è¯-æ ‡ç­¾æ˜ å°„å™¨</strong>ï¼šåŸºäº LLM çš„å°‘æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ ä¾èµ–äºäººå·¥åˆ¶ä½œçš„æç¤ºï¼Œå…¶å¯¹æªè¾æ¯”è¾ƒæ•æ„Ÿï¼Œä¸”ä¾èµ–ç”¨æˆ·çš„ä¸“ä¸šçŸ¥è¯†ï¼Œå› æ­¤æ•ˆæœæ¯”è¾ƒè„†å¼±ã€‚SetFit ç›´æ¥ä»å°‘é‡æ ‡æ³¨æ–‡æœ¬æ ·æœ¬ä¸­ç”Ÿæˆä¸°å¯Œçš„åµŒå…¥ï¼Œä»è€Œå®Œå…¨çœå»äº†æç¤ºã€‚</p>

<p>ğŸ <strong>è®­ç»ƒé€Ÿåº¦å¿«</strong>ï¼šSetFit ä¸ä¾èµ– GPT-3.5 æˆ– Llama2 ç­‰ LLM æ¥å®ç°é«˜å‡†ç¡®ç‡ã€‚å› æ­¤ï¼Œè®­ç»ƒå’Œæ¨ç†é€Ÿåº¦é€šå¸¸è¦å¿«ä¸€ä¸ªæ•°é‡çº§ï¼ˆæˆ–æ›´å¤šï¼‰ã€‚</p>

æœ‰å…³ SetFit çš„æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜…ï¼š[è®ºæ–‡](https://arxiv.org/abs/2209.11055)ã€[åšå®¢](https://huggingface.co/blog/setfit)ã€[ä»£ç ](https://github.com/huggingface/setfit)åŠç›¸å…³[æ•°æ®](https://huggingface.co/SetFit)ã€‚

Setfit å·²è¢« AI å¼€å‘è€…ç¤¾åŒºå¹¿æ³›é‡‡ç”¨ï¼Œæ¯æœˆä¸‹è½½é‡çº¦ä¸º 10 ä¸‡æ¬¡ï¼ŒHub ä¸Šçš„ SetFit æ¨¡å‹ä¸‹è½½é‡çº¦ä¸º [1500](https://huggingface.co/models?library=setfit)ï¼Œä¸”å¹³å‡æ—¥å¢é‡çº¦ä¸º 4ï¼

## åŠ é€Ÿï¼ 

æœ¬æ–‡ï¼Œæˆ‘ä»¬å°†è§£é‡Šå¦‚ä½•ç”¨ ğŸ¤— [Optimum Intel](https://github.com/huggingface/optimum-intel) ä¼˜åŒ–ä½ çš„ SetFit æ¨¡å‹ï¼Œä»è€Œåœ¨è‹±ç‰¹å°” CPU ä¸Šå®ç° **7.8x** çš„æ¨ç†åŠ é€Ÿã€‚æˆ‘ä»¬è¿˜å°†å±•ç¤ºå¦‚ä½•è½»æ¾å¯¹æ¨¡å‹è¿›è¡Œè®­åé‡åŒ–ï¼Œä»è€Œå®ç°å·¨å¤§çš„ååå¢ç›Šã€‚æœ‰äº†è¿™äº›æŠ€æœ¯ï¼Œç”¨æˆ·å¯åœ¨è‹±ç‰¹å°”è‡³å¼º CPU ä¸Šéƒ¨ç½²ç”Ÿäº§çº§çš„ SetFit è§£å†³æ–¹æ¡ˆã€‚

[Optimum Intel](https://github.com/huggingface/optimum-intel) æ˜¯ä¸€ä¸ªå¼€æºåº“ï¼Œå¯åœ¨è‹±ç‰¹å°”ç¡¬ä»¶ä¸Šå¯¹ç”± Hugging Face åº“æ„å»ºçš„ç«¯åˆ°ç«¯æµæ°´çº¿è¿›è¡ŒåŠ é€Ÿã€‚ Optimum Intel å®ç°äº†å¤šç§æ¨¡å‹åŠ é€ŸæŠ€æœ¯ï¼Œå¦‚ä½æ¯”ç‰¹é‡åŒ–ã€æ¨¡å‹æƒé‡å‰ªæã€è’¸é¦ä»¥åŠè¿è¡Œæ—¶åŠ é€Ÿã€‚

[Optimum Intel](https://github.com/huggingface/optimum-intel) çš„è¿è¡Œæ—¶åŠå„ç§ä¼˜åŒ–éƒ½å……åˆ†åˆ©ç”¨äº†è‹±ç‰¹å°”Â® AVX-512ã€çŸ¢é‡ç¥ç»ç½‘ç»œæŒ‡ä»¤ (VNNI) ä»¥åŠæœ€æ–°çš„è‹±ç‰¹å°”Â® å…ˆè¿›çŸ©é˜µæ‰©å±•ï¼ˆè‹±ç‰¹å°”Â® AMXï¼‰ä»¥å¯¹æ¨¡å‹è¿›è¡Œæè‡´åŠ é€Ÿã€‚å…·ä½“æ¥è¯´ï¼Œè‹±ç‰¹å°”åœ¨æ¯ä¸ª CPU æ ¸ä¸­éƒ½å†…ç½®äº† [bfloat16](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format) (bf16) å’Œ int8 GEMM åŠ é€Ÿå™¨ï¼Œä»¥åŠ é€Ÿæ·±åº¦å­¦ä¹ è®­ç»ƒå’Œæ¨ç†å·¥ä½œè´Ÿè½½ã€‚å°¤å…¶å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒPyTorch 2.0 å’Œ [Intel Extension for PyTorch](https://github.com/intel/intel-extension-for-pytorch) (IPEX) ä¸­åŠ å…¥äº† AMX ä¼˜åŒ–ä»¥è¿›ä¸€æ­¥åŠ é€Ÿæ¨ç†åŠè®­ç»ƒã€‚

ä½¿ç”¨ Optimum Intel å¯ä»¥è½»æ¾å¯¹å„ç§é¢„è®­ç»ƒæ¨¡å‹è¿›è¡ŒåŠ é€Ÿï¼Œä½ å¯åœ¨[æ­¤å¤„](https://huggingface.co/docs/optimum/main/en/intel/optimization_inc)æ‰¾åˆ°å¾ˆå¤šä¾‹å­ã€‚æœ¬æ–‡ä¹Ÿé™„æœ‰ä¸€ä¸ª [notebook ç‰ˆ](https://github.com/huggingface/setfit/blob/main/notebooks/setfit-optimum-intel.ipynb)ï¼Œå¯ä¾›å¤§å®¶é€æ­¥æ¼”ç»ƒã€‚

## ç¬¬ 1 æ­¥ï¼šä½¿ç”¨ ğŸ¤— Optimum Intel é‡åŒ– SetFit æ¨¡å‹

åœ¨å¯¹ SetFit æ¨¡å‹è¿›è¡Œä¼˜åŒ–æ—¶ï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨[è‹±ç‰¹å°”ç¥ç»å‹ç¼©å™¨](https://www.intel.com/content/www/us/en/developer/tools/oneapi/neural-compressor.html) (INC) å¯¹æ¨¡å‹è¿›è¡Œé‡åŒ–ï¼Œå…¶å·²é›†æˆå…¥ Optimum Intelã€‚

**é‡åŒ–**æ˜¯ä¸€ç§éå¸¸æµè¡Œçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ä¼˜åŒ–æŠ€æœ¯ï¼Œå¯ç”¨äºæé«˜æ¨ç†é€Ÿåº¦ã€‚å®ƒé€šè¿‡å°†ä¸€ç»„é«˜ç²¾åº¦æ•°å€¼è½¬æ¢ä¸ºè¾ƒä½ä½å®½çš„æ•°æ®ç±»å‹ï¼ˆå¦‚ INT8ï¼‰ã€‚ä»è€Œæœ€å¤§é™åº¦åœ°é™ä½ç¥ç»ç½‘ç»œçš„æƒé‡å’Œ/æˆ–æ¿€æ´»æ‰€éœ€çš„ä½æ•°ã€‚å¦å¤–ï¼Œç”±äºä½å®½è¾ƒä½ï¼Œå…¶è®¡ç®—é€Ÿåº¦ä¹Ÿå¯èƒ½ä¼šæ›´å¿«ã€‚

æœ¬æ–‡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è®­åé™æ€é‡åŒ–ï¼ˆPTQï¼‰ã€‚PTQ ä»…éœ€å°‘é‡æœªæ ‡æ³¨æ ¡å‡†æ•°æ®ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒå³å¯åœ¨ä¿æŒæ¨¡å‹çš„å‡†ç¡®æ€§çš„åŒæ—¶å‡ä½æ¨ç†æ—¶çš„å†…å­˜å ç”¨å¹¶é™ä½å»¶è¿Ÿã€‚é¦–å…ˆè¯·ç¡®ä¿ä½ å·²å®‰è£…æ‰€æœ‰å¿…è¦çš„åº“ï¼ŒåŒæ—¶ç¡®ä¿ Optimum Intel ç‰ˆæœ¬è‡³å°‘ä¸º `1.14.0`ï¼ˆå› ä¸º PTQ åŠŸèƒ½æ˜¯ä»è¯¥ç‰ˆæœ¬å¼€å§‹å¼•å…¥çš„ï¼‰:

```bash
pip install --upgrade-strategy eager optimum[ipex]
```

### å‡†å¤‡æ ¡å‡†æ•°æ®é›†

æ ¡å‡†æ•°æ®é›†åº”èƒ½åœ¨æ•°æ®åˆ†å¸ƒä¸Šè¾ƒå¥½ä»£è¡¨æœªè§æ•°æ®ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå‡†å¤‡ 100 ä¸ªæ ·æœ¬å°±è¶³å¤Ÿäº†ã€‚åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ `rotten_tomatoes` æ•°æ®é›†ï¼Œå…¶æ˜¯ä¸€ä¸ªç”µå½±è¯„è®ºæ•°æ®é›†ï¼Œä¸æˆ‘ä»¬çš„ç›®æ ‡æ•°æ®é›† `sst2` ç±»ä¼¼ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬ä»è¯¥æ•°æ®é›†ä¸­éšæœºåŠ è½½ 100 ä¸ªæ ·æœ¬ã€‚ç„¶åï¼Œä¸ºäº†å‡†å¤‡é‡åŒ–æ•°æ®é›†ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œæ ‡æ³¨ã€‚æˆ‘ä»¬ä¸éœ€è¦ `text` å’Œ `label` åˆ—ï¼Œå› æ­¤å°†å…¶åˆ é™¤ã€‚

```python
calibration_set = load_dataset("rotten_tomatoes", split="train").shuffle(seed=42).select(range(100)) 

def tokenize(examples):
    return tokenizer(examples["text"], padding="max_length", max_length=512, truncation=True)
 
tokenizer = setfit_model.model_body.tokenizer
calibration_set = calibration_set.map(tokenize, remove_columns=["text", "label"])
```

### é‡åŒ–

é‡åŒ–å‰ï¼Œå…ˆè¦é…ç½®æ‰€éœ€çš„é‡åŒ–æ–¹æ¡ˆï¼Œæœ¬ä¾‹ä¸­ä¸º**é™æ€è®­åé‡åŒ–**ï¼Œå†ä½¿ç”¨ `optimum.intel` åœ¨æ ¡å‡†æ•°æ®é›†ä¸Šè¿è¡Œé‡åŒ–ï¼š

```python
from optimum.intel import INCQuantizer
from neural_compressor.config import PostTrainingQuantConfig

setfit_body = setfit_model.model_body[0].auto_model
quantizer = INCQuantizer.from_pretrained(setfit_body)
optimum_model_path = "/tmp/bge-small-en-v1.5_setfit-sst2-english_opt"
quantization_config = PostTrainingQuantConfig(approach="static", backend="ipex", domain="nlp")

quantizer.quantize(
    quantization_config=quantization_config,
    calibration_dataset=calibration_set,
    save_directory=optimum_model_path,
    batch_size=1,
)
tokenizer.save_pretrained(optimum_model_path)
```

å°±è¿™æ ·ï¼ç°åœ¨ï¼Œæˆ‘ä»¬æœ‰äº†ä¸€ä¸ªé‡åŒ–ç‰ˆçš„ SetFit æ¨¡å‹ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å¯¹å…¶è¿›è¡Œæµ‹è¯•ã€‚

## ç¬¬ 2 æ­¥ï¼šæ¨ç†åŸºå‡†æµ‹è¯•

æˆ‘ä»¬åœ¨ [notebook](https://github.com/huggingface/setfit/blob/main/notebooks/setfit-optimum-intel.ipynb) ä¸­å†™äº†ä¸€ä¸ª `PerformanceBenchmark` ç±»ï¼Œç”¨äºè®¡ç®—æ¨¡å‹å»¶è¿Ÿå’Œååé‡ï¼Œå¹¶ç”¨äºæµ‹é‡æ¨¡å‹å‡†ç¡®åº¦ã€‚æˆ‘ä»¬ç°åœ¨ç”¨å®ƒæ¥å¯¹ä»¥ä¸‹ä¸‰ç§é…ç½®è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼š

 - ä½¿ç”¨ `PyTorch` å’Œ `ğŸ¤— Transformers` åº“å¯¹ `fp32` æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚
 - ä½¿ç”¨ [`Intel Extension for PyTorch`](https://github.com/intel/intel-extension-for-pytorch) (IPEX) å¯¹æ¨¡å‹è¿›è¡Œ `bf16` æ¨ç†ï¼ŒåŒæ—¶ä½¿ç”¨ `TorchScript` å¯¹æ¨¡å‹è¿›è¡Œå›¾ä¼˜åŒ–ã€‚
 - ä½¿ç”¨ `Optimum Intel` å¯¹ `int8` é‡åŒ–æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚

åŠ è½½æµ‹è¯•æ•°æ®é›† `sst2`ï¼Œå¹¶ä½¿ç”¨ PyTorch å’Œ ğŸ¤— Transformers åº“è¿è¡ŒåŸºå‡†æµ‹è¯•ï¼š

```python
from datasets import load_dataset
from setfit import SetFitModel
test_dataset = load_dataset("SetFit/sst2")["validation"]

model_path = "dkorat/bge-small-en-v1.5_setfit-sst2-english"
setfit_model = SetFitModel.from_pretrained(model_path)
pb = PerformanceBenchmark(
    model=setfit_model,
    dataset=test_dataset,
    optim_type="bge-small (transformers)",
)
perf_metrics = pb.run_benchmark()
```

ç¬¬äºŒä¸ªåŸºå‡†æµ‹è¯•ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ bf16 ç²¾åº¦å’Œ TorchScript ä¸¤ç§ä¼˜åŒ–æ‰‹æ®µï¼Œå¹¶ä½¿ç”¨ [IPEX](https://github.com/intel/intel-extension-for-pytorch) ä¼˜åŒ–åº“ã€‚è¦ä½¿ç”¨ IPEXï¼Œæˆ‘ä»¬åªéœ€å¯¼å…¥ IPEX åº“å¹¶å¯¹æ¨¡å‹åº”ç”¨ `ipex.optimize()`ï¼Œåœ¨æœ¬ä¾‹ä¸­ï¼Œç›®æ ‡æ¨¡å‹æ˜¯ SetFit çš„æ¨¡å‹ä½“ï¼š

```python
dtype = torch.bfloat16
body = ipex.optimize(setfit_model.model_body, dtype=dtype)
```

ä½¿ç”¨ `TorchScript` è¿›è¡Œå›¾ä¼˜åŒ–æ—¶ï¼Œæˆ‘ä»¬æ ¹æ®æ¨¡å‹çš„æœ€å¤§è¾“å…¥é•¿åº¦ç”Ÿæˆéšæœºåºåˆ—ï¼Œå¹¶ä»åˆ†è¯å™¨çš„è¯æ±‡è¡¨ä¸­é‡‡æ ·è¯æ±‡ï¼š

```python
tokenizer = setfit_model.model_body.tokenizer
d = generate_random_sequences(batch_size=1, length=tokenizer.model_max_length, vocab_size=tokenizer.vocab_size)

body = torch.jit.trace(body, (d,), check_trace=False, strict=False)
setfit_model.model_body = torch.jit.freeze(body)
```

æœ€åï¼Œæˆ‘ä»¬å¯¹é‡åŒ–çš„ Optimum æ¨¡å‹è¿è¡ŒåŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬é¦–å…ˆå®šä¹‰ä¸€ä¸ª SetFit æ¨¡å‹çš„åŒ…è£…ç±»ï¼Œè¯¥åŒ…è£…ç±»åœ¨æ¨ç†æ—¶ä¼šè‡ªåŠ¨æ’å…¥é‡åŒ–æ¨¡å‹ä½“ï¼ˆè€Œä¸æ˜¯åŸå§‹æ¨¡å‹ä½“ï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬ç”¨è¿™ä¸ªåŒ…è£…ç±»è·‘åŸºå‡†æµ‹è¯•ã€‚

```python
from optimum.intel import IPEXModel

class OptimumSetFitModel:
    def __init__(self, setfit_model, model_body):
        model_body.tokenizer = setfit_model.model_body.tokenizer
        self.model_body = model_body
        self.model_head = setfit_model.model_head


optimum_model = IPEXModel.from_pretrained(optimum_model_path)
optimum_setfit_model = OptimumSetFitModel(setfit_model, model_body=optimum_model)

pb = PerformanceBenchmark(
    model=optimum_setfit_model,
    dataset=test_dataset,
    optim_type=f"bge-small (optimum-int8)",
    model_path=optimum_model_path,
    autocast_dtype=torch.bfloat16,
)
perf_metrics.update(pb.run_benchmark())
```

## ç»“æœ
<p align="center">
    <img src="assets/178_setfit_optimum_intel/latency.png" width=500>
</p>
<p align="center">
    <em>ç²¾åº¦ä¸å»¶è¿Ÿå…³ç³»å›¾ï¼ˆbatch size=1ï¼‰</em>
</p>


|                      | bge-small (transformers) | bge-small (ipex-bfloat16) | bge-small (optimum-int8) |
|----------------------|---------------------|---------------------------|---------------------------|
| æ¨¡å‹å¤§å°           | 127.32 MB           | 63.74 MB                  | 44.65 MB                  |
| æµ‹è¯•é›†å‡†ç¡®ç‡ | 88.4%               | 88.4%                     | 88.1%                     |
| å»¶è¿Ÿ (bs=1) | 15.69 +/- 0.57 ms | 5.67 +/- 0.66 ms | 4.55 +/- 0.25 ms | 

batch size ä¸º 1 æ—¶ï¼Œæˆ‘ä»¬çš„ä¼˜åŒ–æ¨¡å‹å°†å»¶è¿Ÿé™ä½äº† **3.45 å€**ã€‚è¯·æ³¨æ„ï¼Œæ­¤æ—¶å‡†ç¡®ç‡å‡ ä¹æ²¡æœ‰ä¸‹é™ï¼å¦å¤–å€¼å¾—ä¸€æçš„æ˜¯ï¼Œæ¨¡å‹å¤§å°ç¼©å°äº† **2.85x**ã€‚

<p align="center">
    <img src="assets/178_setfit_optimum_intel/throughput.png" width=500>
</p>

æˆ‘ä»¬å°†ç„¦ç‚¹è½¬å‘ä¸åŒ batch size ä¸‹çš„ååé‡ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬è·å¾—äº†æ›´å¤§çš„åŠ é€Ÿã€‚å¦‚æœæ¯”è¾ƒæœ€é«˜ååé‡ï¼ˆä¸é™ batch sizeï¼‰ï¼Œä¼˜åŒ–åçš„æ¨¡å‹**æ¯”åŸå§‹ transformers fp32 æ¨¡å‹é«˜ 7.8 å€ï¼**

## æ€»ç»“

æœ¬æ–‡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ ğŸ¤— Optimum Intel ä¸­çš„é‡åŒ–åŠŸèƒ½æ¥ä¼˜åŒ– SetFit æ¨¡å‹ã€‚åœ¨è½»æ¾å¿«é€Ÿåœ°å¯¹æ¨¡å‹å®Œæˆè®­åé‡åŒ–åï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°åœ¨å‡†ç¡®åº¦æŸå¤±å¾ˆå°çš„æƒ…å†µä¸‹ï¼Œæ¨ç†ååé‡å¢åŠ äº† **7.8 å€**ã€‚ç”¨æˆ·å¯ä»¥ä½¿ç”¨è¿™ç§ä¼˜åŒ–æ–¹æ³•åœ¨è‹±ç‰¹å°”è‡³å¼º CPU ä¸Šè½»æ¾éƒ¨ç½²ä»»ä½•ç°æœ‰ SetFit æ¨¡å‹ã€‚

## å‚è€ƒæ–‡çŒ®
* Lewis Tunstall, Nils Reimers, Unso Eun Seo Jo, Luke Bates, Daniel Korat, Moshe Wasserblat, Oren Pereg, 2022. "Efficient Few-Shot Learning Without Prompts". https://arxiv.org/abs/2209.11055
