---
title: "æ¬¢è¿ Llama 3ï¼šMeta çš„æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹" 
thumbnail: /blog/assets/llama3/thumbnail.jpg
authors:
- user: philschmid
- user: osanseviero
- user: pcuenq
- user: ybelkada
- user: lvwerra
translators:
- user: AdinaY
---

# æ¬¢è¿ Llama 3ï¼šMeta çš„æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹
## ä»‹ç»

Meta å…¬å¸çš„ Llama 3 æ˜¯å¼€æ”¾è·å–çš„ Llama ç³»åˆ—çš„æœ€æ–°ç‰ˆæœ¬ï¼Œç°å·²åœ¨ Hugging Face å¹³å°å‘å¸ƒã€‚çœ‹åˆ° Meta æŒç»­è‡´åŠ›äºå¼€æ”¾ AI é¢†åŸŸçš„å‘å±•ä»¤äººæŒ¯å¥‹ï¼Œæˆ‘ä»¬ä¹Ÿéå¸¸é«˜å…´åœ°å…¨åŠ›æ”¯æŒæ­¤æ¬¡å‘å¸ƒï¼Œå¹¶å®ç°äº†ä¸ Hugging Face ç”Ÿæ€ç³»ç»Ÿçš„æ·±åº¦é›†æˆã€‚

Llama 3 æä¾›ä¸¤ä¸ªç‰ˆæœ¬ï¼š8B ç‰ˆæœ¬é€‚åˆåœ¨æ¶ˆè´¹çº§ GPU ä¸Šé«˜æ•ˆéƒ¨ç½²å’Œå¼€å‘ï¼›70B ç‰ˆæœ¬åˆ™ä¸“ä¸ºå¤§è§„æ¨¡ AI åº”ç”¨è®¾è®¡ã€‚æ¯ä¸ªç‰ˆæœ¬éƒ½åŒ…æ‹¬åŸºç¡€å’ŒæŒ‡ä»¤è°ƒä¼˜ä¸¤ç§å½¢å¼ã€‚æ­¤å¤–ï¼ŒåŸºäº Llama 3 8B å¾®è°ƒåçš„ Llama Guard æ–°ç‰ˆæœ¬ä¹Ÿå·²ä½œä¸º Llama Guard 2ï¼ˆå®‰å…¨å¾®è°ƒç‰ˆæœ¬ï¼‰å‘å¸ƒã€‚

æˆ‘ä»¬ä¸ Meta å¯†åˆ‡åˆä½œï¼Œç¡®ä¿å…¶äº§å“èƒ½å¤Ÿæ— ç¼é›†æˆè¿› Hugging Face çš„ç”Ÿæ€ç³»ç»Ÿã€‚åœ¨ Hub ä¸Šï¼Œæ‚¨å¯ä»¥æ‰¾åˆ°è¿™äº”ä¸ªå¼€æ”¾è·å–çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ä¸¤ä¸ªåŸºç¡€æ¨¡å‹ã€ä¸¤ä¸ªå¾®è°ƒæ¨¡å‹ä»¥åŠ Llama Guardï¼‰ã€‚

æœ¬æ¬¡å‘å¸ƒçš„ä¸»è¦ç‰¹æ€§å’Œé›†æˆåŠŸèƒ½åŒ…æ‹¬ï¼š

- [Hub ä¸Šçš„æ¨¡å‹](https://huggingface.co/meta-llama)ï¼Œå¹¶æä¾›äº†æ¨¡å‹å¡ç‰‡å’Œè®¸å¯è¯ä¿¡æ¯
- ğŸ¤— Transformers çš„é›†æˆ
- [é’ˆå¯¹ Meta Llama 3 70B çš„ Hugging Chat é›†æˆ](https://huggingface.co/chat/models/meta-llama/Meta-Llama-3-70B-instruct)
- æ¨ç†åŠŸèƒ½é›†æˆåˆ°æ¨ç†ç«¯ç‚¹ã€Google Cloud å’Œ Amazon SageMaker
- åœ¨å•ä¸ª GPU ä¸Šå¯¹ Llama 3 8B è¿›è¡Œå¾®è°ƒçš„ç¤ºä¾‹ï¼Œé‡‡ç”¨ ğŸ¤— TRL

## ç›®å½•

  - [ä»‹ç»](#introduction)
  - [ç›®å½•](#table-of-contents)
  - [Llama 3 çš„æ–°è¿›å±•](#whats-new-with-llama-3)
  - [Llama 3 è¯„ä¼°](#llama-3-evaluation)
  - [å¦‚ä½•è®¾ç½® Llama 3 çš„æç¤º](#how-to-prompt-llama-3)
  - [æ¼”ç¤º](#demo)
  - [å¦‚ä½•ä½¿ç”¨ ğŸ¤— Transformers](#using-transformers)
  - [æ¨ç†é›†æˆ](#inference-integrations)
  - [å¦‚ä½•ä½¿ç”¨ ğŸ¤— TRL è¿›è¡Œå¾®è°ƒ](#fine-tuning-with-trl)
  - [é¢å¤–èµ„æº](#additional-resources)
  - [é¸£è°¢](#acknowledgments)

## Llama 3 çš„æ–°è¿›å±•

Llama 3 çš„æ¨å‡ºæ ‡å¿—ç€ Meta åŸºäº Llama 2 æ¶æ„æ¨å‡ºäº†å››ä¸ªæ–°çš„å¼€æ”¾å‹å¤§è¯­è¨€æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹åˆ†ä¸ºä¸¤ç§è§„æ¨¡ï¼š8B å’Œ 70B å‚æ•°ï¼Œæ¯ç§è§„æ¨¡éƒ½æä¾›é¢„è®­ç»ƒåŸºç¡€ç‰ˆå’ŒæŒ‡ä»¤è°ƒä¼˜ç‰ˆã€‚æ‰€æœ‰ç‰ˆæœ¬å‡å¯åœ¨å„ç§æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿è¡Œï¼Œå¹¶å…·æœ‰ 8000 Token çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚

- [Meta-Llama-3-8b](https://huggingface.co/meta-llama/Meta-Llama-3-8B): 8B åŸºç¡€æ¨¡å‹
- [Meta-Llama-3-8b-instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct): 8B åŸºç¡€æ¨¡å‹çš„æŒ‡ä»¤è°ƒä¼˜ç‰ˆ
- [Meta-Llama-3-70b](https://huggingface.co/meta-llama/Meta-Llama-3-70B): 70B åŸºç¡€æ¨¡å‹
- [Meta-Llama-3-70b-instruct](https://huggingface.co/meta-llama/Meta-Llama-3-70B-instruct): 70B åŸºç¡€æ¨¡å‹çš„æŒ‡ä»¤è°ƒä¼˜ç‰ˆ

æ­¤å¤–ï¼Œè¿˜å‘å¸ƒäº†åŸºäº Llama 3 8B å¾®è°ƒåçš„æœ€æ–° Llama Guard ç‰ˆæœ¬â€”â€”Llama Guard 2ã€‚Llama Guard 2 æ˜¯ä¸ºç”Ÿäº§ç¯å¢ƒè®¾è®¡çš„ï¼Œèƒ½å¤Ÿå¯¹å¤§è¯­è¨€æ¨¡å‹çš„è¾“å…¥ï¼ˆå³æç¤ºï¼‰å’Œå“åº”è¿›è¡Œåˆ†ç±»ï¼Œä»¥ä¾¿è¯†åˆ«æ½œåœ¨çš„ä¸å®‰å…¨å†…å®¹ã€‚

ä¸ Llama 2 ç›¸æ¯”ï¼ŒLlama 3 æœ€å¤§çš„å˜åŒ–æ˜¯é‡‡ç”¨äº†æ–°çš„ Tokenizerï¼Œå°†è¯æ±‡è¡¨å¤§å°æ‰©å±•è‡³ 128,256ï¼ˆå‰ç‰ˆæœ¬ä¸º 32,000 Tokenï¼‰ã€‚è¿™ä¸€æ›´å¤§çš„è¯æ±‡åº“èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°ç¼–ç æ–‡æœ¬ï¼ˆæ— è®ºè¾“å…¥è¿˜æ˜¯è¾“å‡ºï¼‰ï¼Œå¹¶æœ‰å¯èƒ½æå‡æ¨¡å‹çš„å¤šè¯­ç§å¤„ç†èƒ½åŠ›ã€‚ä¸è¿‡ï¼Œè¿™ä¹Ÿå¯¼è‡´åµŒå…¥å±‚çš„è¾“å…¥å’Œè¾“å‡ºçŸ©é˜µå°ºå¯¸å¢å¤§ï¼Œè¿™æ˜¯å°å‹æ¨¡å‹å‚æ•°å¢åŠ ï¼ˆä» Llama 2 çš„ 7B å¢è‡³ Llama 3 çš„ 8Bï¼‰çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚æ­¤å¤–ï¼Œ8B ç‰ˆæœ¬çš„æ¨¡å‹ç°åœ¨é‡‡ç”¨äº†åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGQAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ•ˆç‡æ›´é«˜çš„è¡¨è¾¾æ–¹å¼ï¼Œæœ‰åŠ©äºå¤„ç†æ›´é•¿çš„ä¸Šä¸‹æ–‡ã€‚

Llama 3 æ¨¡å‹åœ¨ä¸¤ä¸ªæ‹¥æœ‰ 24,000 GPU çš„é›†ç¾¤ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œä½¿ç”¨çš„æ˜¯è¶…è¿‡ 15 ä¸‡äº¿ Token çš„æ–°å…¬å…±åœ¨çº¿æ•°æ®ã€‚æˆ‘ä»¬æ— æ³•å¾—çŸ¥è®­ç»ƒæ•°æ®å…·ä½“ç»†èŠ‚ï¼Œä½†å¯ä»¥æ¨æµ‹ï¼Œæ›´å¤§è§„æ¨¡ä¸”æ›´ç»†è‡´çš„æ•°æ®ç­–åˆ’æ˜¯æ€§èƒ½æå‡çš„é‡è¦å› ç´ ã€‚Llama 3 Instruct é’ˆå¯¹å¯¹è¯åº”ç”¨è¿›è¡Œäº†ä¼˜åŒ–ï¼Œç»“åˆäº†è¶…è¿‡ 1000 ä¸‡çš„äººå·¥æ ‡æ³¨æ•°æ®ï¼Œé€šè¿‡ç›‘ç£å¼å¾®è°ƒï¼ˆSFTï¼‰ã€æ‹’ç»é‡‡æ ·ã€é‚»è¿‘ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰å’Œç›´æ¥ç­–ç•¥ä¼˜åŒ–ï¼ˆDPOï¼‰è¿›è¡Œè®­ç»ƒã€‚

å…³äºè®¸å¯æ¡æ¬¾ï¼ŒLlama 3 æä¾›äº†ä¸€ä¸ªå®½æ¾çš„è®¸å¯è¯ï¼Œå…è®¸é‡æ–°åˆ†å‘ã€å¾®è°ƒå’Œåˆ›ä½œè¡ç”Ÿä½œå“ã€‚Llama 3 è®¸å¯è¯ä¸­æ–°å¢äº†æ˜ç¡®å½’å±çš„è¦æ±‚ï¼Œè¿™åœ¨ Llama 2 ä¸­å¹¶æœªè®¾å®šã€‚ä¾‹å¦‚ï¼Œè¡ç”Ÿæ¨¡å‹éœ€è¦åœ¨å…¶åç§°å¼€å¤´åŒ…å«â€œLlama 3â€ï¼Œå¹¶ä¸”åœ¨è¡ç”Ÿä½œå“æˆ–æœåŠ¡ä¸­éœ€æ³¨æ˜â€œåŸºäº Meta Llama 3 æ„å»ºâ€ã€‚è¯¦ç»†æ¡æ¬¾ï¼Œè¯·åŠ¡å¿…é˜…è¯»[å®˜æ–¹è®¸å¯è¯](https://huggingface.co/meta-llama/Meta-Llama-3-70B/blob/main/LICENSE)ã€‚

## Llama 3 è¯„ä¼°

_æ³¨ï¼šæˆ‘ä»¬ç›®å‰æ­£åœ¨å¯¹ Meta Llama 3 è¿›è¡Œå•ç‹¬è¯„ä¼°ï¼Œä¸€æ—¦æœ‰äº†ç»“æœå°†ç«‹å³æ›´æ–°æ­¤éƒ¨åˆ†ã€‚_

## å¦‚ä½•è®¾ç½® Llama 3 çš„æç¤º

åŸºç¡€æ¨¡å‹ä¸å…·å¤‡å›ºå®šçš„æç¤ºæ ¼å¼ã€‚å¦‚åŒå…¶ä»–åŸºç¡€æ¨¡å‹ï¼Œå®ƒä»¬å¯ä»¥ç”¨æ¥å»¶ç»­è¾“å…¥åºåˆ—ï¼Œæä¾›åˆç†çš„ç»­å†™æˆ–è¿›è¡Œé›¶æ ·æœ¬/å°‘æ ·æœ¬æ¨ç†ã€‚è¿™äº›æ¨¡å‹ä¹Ÿæ˜¯æ‚¨è‡ªå®šä¹‰å¾®è°ƒçš„ç†æƒ³åŸºç¡€ã€‚æŒ‡ä»¤ç‰ˆæœ¬é‡‡ç”¨ä»¥ä¸‹å¯¹è¯ç»“æ„ï¼š

```bash
system

{{ system_prompt }}user

{{ user_msg_1 }}assistant

{{ model_answer_1 }}
```

ä¸ºäº†æœ‰æ•ˆä½¿ç”¨ï¼Œå¿…é¡»ç²¾ç¡®å¤åˆ¶æ­¤æ ¼å¼ã€‚æˆ‘ä»¬ç¨åå°†å±•ç¤ºå¦‚ä½•åˆ©ç”¨ `transformers` ä¸­æä¾›çš„èŠå¤©æ¨¡æ¿è½»æ¾é‡ç°è¿™ä¸€æŒ‡ä»¤æç¤ºæ ¼å¼ã€‚

## æ¼”ç¤º

æ‚¨ç°åœ¨å¯ä»¥åœ¨ Hugging Chat ä¸Šä¸ Llama 3 70B æŒ‡ä»¤ç‰ˆè¿›è¡Œäº¤æµï¼è¯·è®¿é—®æ­¤é“¾æ¥ï¼šhttps://huggingface.co/chat/models/meta-llama/Meta-Llama-3-70B-instruct

## å¦‚ä½•ä½¿ç”¨ ğŸ¤— Transformers

é€šè¿‡å®‰è£… Transformers çš„[4.40 ç‰ˆæœ¬](https://github.com/huggingface/transformers/releases/tag/v4.40.0)ï¼Œæ‚¨å¯ä»¥å……åˆ†åˆ©ç”¨ Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­æä¾›çš„å„ç§å·¥å…·ï¼Œå¦‚ï¼š

- è®­ç»ƒåŠæ¨ç†è„šæœ¬å’Œç¤ºä¾‹
- å®‰å…¨æ–‡ä»¶æ ¼å¼ï¼ˆsafetensorsï¼‰
- ä¸ bitsandbytesï¼ˆ4ä½é‡åŒ–ï¼‰ã€PEFTï¼ˆå‚æ•°æ•ˆç‡å¾®è°ƒï¼‰å’Œ Flash Attention 2 ç­‰å·¥å…·çš„é›†æˆ
- è¾…åŠ©ç”Ÿæˆæ“ä½œçš„å®ç”¨å·¥å…·
- æ¨¡å‹éƒ¨ç½²çš„å‡ºå£æœºåˆ¶

æ­¤å¤–ï¼ŒLlama 3 æ¨¡å‹å…¼å®¹ `torch.compile()` çš„ CUDA å›¾è¡¨ï¼Œä½¿å¾—æ¨ç†æ—¶é—´å¯åŠ é€Ÿçº¦ 4 å€ï¼

è¦åœ¨ transformers ä¸­ä½¿ç”¨ Llama 3 æ¨¡å‹ï¼Œè¯·ç¡®ä¿å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬ï¼š

```jsx
pip install -U "transformers==4.40.0" --upgrade
```

ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†å¦‚ä½•åœ¨ transformers ä¸­ä½¿ç”¨ `Llama-3-8b-instruct`ã€‚è¿™éœ€è¦å¤§çº¦ 16 GB çš„ RAMï¼ŒåŒ…æ‹¬ 3090 æˆ– 4090 ç­‰æ¶ˆè´¹çº§ GPUã€‚

```python
from transformers import pipeline
import torch

model_id = "meta-llama/Meta-Llama-3-8B-Instruct"

pipe = pipeline(
    "text-generation",
    model=model_id,
    model_kwargs={"torch_dtype": torch.bfloat16},
    device="cuda",
)

messages = [
    {"role": "system", "content": "You are a pirate chatbot who always responds in pirate speak!"},
    {"role": "user", "content": "Who are you?"},
]

terminators = [
    pipe.tokenizer.eos_token_id,
    pipe.tokenizer.convert_tokens_to_ids("<|eot_id|>")
]

outputs = pipe(
    messages,
    max_new_tokens=256,
    eos_token_id=terminators,
    do_sample=True,
    temperature=0.6,
    top_p=0.9,
)
assistant_response = outputs[0]["generated_text"][-1]["content"]
print(assistant_response)
```

> Arrrr, me hearty! Me name be Captain Chat, the scurviest pirate chatbot to ever sail the Seven Seas! Me be here to swab the decks o' yer mind with me trusty responses, savvy? I be ready to hoist the Jolly Roger and set sail fer a swashbucklin' good time, matey! So, what be bringin' ye to these fair waters?


ä¸€äº›ç»†èŠ‚ï¼š

- æˆ‘ä»¬åœ¨ `bfloat16` ä¸­åŠ è½½äº†æ¨¡å‹ã€‚è¿™æ˜¯ Meta å‘å¸ƒçš„åŸå§‹æ£€æŸ¥ç‚¹æ‰€ä½¿ç”¨çš„ç±»å‹ï¼Œå› æ­¤å®ƒæ˜¯æ¨èçš„è¿è¡Œæ–¹å¼ï¼Œä»¥ç¡®ä¿æœ€ä½³ç²¾ç¡®åº¦æˆ–è¿›è¡Œè¯„ä¼°ã€‚å¯¹äºå®é™…ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥å®‰å…¨åœ°ä½¿ç”¨ `float16`ï¼Œè¿™å¯èƒ½å–å†³äºæ‚¨çš„ç¡¬ä»¶è€Œæ›´å¿«ã€‚
- åŠ©ç†å“åº”å¯èƒ½ä¼šä»¥ç‰¹æ®Š token ç»“æŸï¼Œä½†å¦‚æœæ‰¾åˆ°å¸¸è§„çš„ EOS tokenï¼Œæˆ‘ä»¬ä¹Ÿå¿…é¡»åœæ­¢ç”Ÿæˆã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨ `eos_token_id` å‚æ•°ä¸­æä¾›ä¸€ä¸ªç»ˆç»“ç¬¦åˆ—è¡¨æ¥æå‰åœæ­¢ç”Ÿæˆã€‚
- æˆ‘ä»¬ä½¿ç”¨äº†ä»åŸå§‹ meta ä»£ç åº“ä¸­å–å¾—çš„é»˜è®¤æŠ½æ ·å‚æ•°ï¼ˆ`temperature` å’Œ `top_p`ï¼‰ã€‚æˆ‘ä»¬è¿˜æ²¡æœ‰æ—¶é—´è¿›è¡Œå¹¿æ³›çš„æµ‹è¯•ï¼Œæ¬¢è¿æ¢ç´¢ï¼

æ‚¨ä¹Ÿå¯ä»¥è‡ªåŠ¨é‡åŒ–æ¨¡å‹ï¼Œå°†å…¶åŠ è½½åˆ° 8 ä½æˆ–ç”šè‡³ 4 ä½æ¨¡å¼ã€‚4 ä½åŠ è½½éœ€è¦å¤§çº¦ 7 GB çš„å†…å­˜è¿è¡Œï¼Œä½¿å…¶å…¼å®¹è®¸å¤šæ¶ˆè´¹çº§å¡å’Œ Google Colab ä¸­çš„æ‰€æœ‰ GPUã€‚è¿™å°±æ˜¯æ‚¨å¦‚ä½•åœ¨ 4 ä½ä¸­åŠ è½½ç”Ÿæˆç®¡é“ï¼š

```python
pipeline = transformers.pipeline(
    "text-generation",
    model=model_id,
    model_kwargs={
        "torch_dtype": torch.float16,
        "quantization_config": {"load_in_4bit": True},
        "low_cpu_mem_usage": True,
    },
)
```

æœ‰å…³ä½¿ç”¨ transformers ä¸­çš„æ¨¡å‹çš„æ›´å¤šè¯¦æƒ…ï¼Œè¯·æŸ¥çœ‹[æ¨¡å‹å¡ç‰‡](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)ã€‚

## æ¨ç†é›†æˆ

åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸åŒçš„æ–¹æ³•æ¥è¿è¡Œ Llama 3 æ¨¡å‹çš„æ¨ç†ã€‚åœ¨ä½¿ç”¨è¿™äº›æ¨¡å‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²è¯·æ±‚è®¿é—®å®˜æ–¹ [Meta Llama 3](https://TODO) ä»“åº“ä¸­çš„ä¸€ä¸ªæ¨¡å‹ã€‚

### ä¸æ¨ç†ç«¯ç‚¹çš„é›†æˆ

æ‚¨å¯ä»¥åœ¨ Hugging Face çš„ [æ¨ç†ç«¯ç‚¹](https://ui.endpoints.huggingface.co/) ä¸Šéƒ¨ç½² Llama 3ï¼Œå®ƒä½¿ç”¨æ–‡æœ¬ç”Ÿæˆæ¨ç†ä½œä¸ºåç«¯ã€‚[æ–‡æœ¬ç”Ÿæˆæ¨ç†](https://github.com/huggingface/text-generation-inference) æ˜¯ Hugging Face å¼€å‘çš„ä¸€ä¸ªç”Ÿäº§å°±ç»ªçš„æ¨ç†å®¹å™¨ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²å˜å¾—ç®€å•ã€‚å®ƒå…·æœ‰è¿ç»­æ‰¹å¤„ç†ã€Token æµã€å¤š GPU ä¸Šå¿«é€Ÿæ¨ç†çš„å¼ é‡å¹¶è¡Œæ€§ä»¥åŠç”Ÿäº§å°±ç»ªçš„æ—¥å¿—å’Œè·Ÿè¸ªç­‰åŠŸèƒ½ã€‚

è¦éƒ¨ç½² Llama 3ï¼Œè¯·è½¬åˆ°[æ¨¡å‹é¡µé¢](https://huggingface.co/meta-llama/Meta-Llama-3-70B-instruct)å¹¶ç‚¹å‡»[éƒ¨ç½² -> æ¨ç†ç«¯ç‚¹](https://ui.endpoints.huggingface.co/philschmid/new?repository=meta-llama/Meta-Llama-3-70B-instruct&vendor=aws&region=us-east-1&accelerator=gpu&instance_size=4xlarge&task=text-generation&no_suggested_compute=true&tgi=true&tgi_max_batch_prefill_tokens=16384&tgi_max_batch_total_tokens=16384&tgi_max_input_length=4000&tgi_max_total_tokens=8192)å°å·¥å…·ã€‚æ‚¨å¯ä»¥åœ¨ä¹‹å‰çš„åšå®¢æ–‡ç« ä¸­äº†è§£æ›´å¤šå…³äº[ä½¿ç”¨ Hugging Face æ¨ç†ç«¯ç‚¹éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹](https://huggingface.co/blog/inference-endpoints-llm)çš„ä¿¡æ¯ã€‚æ¨ç†ç«¯ç‚¹é€šè¿‡æ–‡æœ¬ç”Ÿæˆæ¨ç†æ”¯æŒ [Messages API](https://huggingface.co/blog/tgi-messages-api)ï¼Œå…è®¸æ‚¨é€šè¿‡ç®€å•æ›´æ”¹ URL ä»å¦ä¸€ä¸ªå°é—­æ¨¡å‹åˆ‡æ¢åˆ°å¼€æ”¾æ¨¡å‹ã€‚

```bash
from openai import OpenAI

# åˆå§‹åŒ–å®¢æˆ·ç«¯ä½†æŒ‡å‘ TGI
client = OpenAI(
    base_url="<ENDPOINT_URL>" + "/v1/",  # æ›¿æ¢ä¸ºæ‚¨çš„ç«¯ç‚¹ url
    api_key="<HF_API_TOKEN>",  # æ›¿æ¢ä¸ºæ‚¨çš„ token
)
chat_completion = client.chat.completions.create(
    model="tgi",
    messages=[
        {"role": "user", "content": "ä¸ºä»€ä¹ˆå¼€æºè½¯ä»¶å¾ˆé‡è¦ï¼Ÿ"},
    ],
    stream=True,
    max_tokens=500
)

# è¿­ä»£å¹¶æ‰“å°æµ
for message in chat_completion:
    print(message.choices[0].delta.content, end="")
```
### ä¸ Google Cloud çš„é›†æˆ
æ‚¨å¯ä»¥é€šè¿‡ Vertex AI æˆ– Google Kubernetes Engine (GKE) åœ¨ Google Cloud ä¸Šéƒ¨ç½² Llama 3ï¼Œä½¿ç”¨ [æ–‡æœ¬ç”Ÿæˆæ¨ç†](https://huggingface.co/docs/text-generation-inference/index)ã€‚
è¦ä» Hugging Face éƒ¨ç½² Llama 3 æ¨¡å‹ï¼Œè¯·è½¬åˆ°[æ¨¡å‹é¡µé¢](https://huggingface.co/meta-llama/Meta-Llama-3-70B-instruct)å¹¶ç‚¹å‡»[éƒ¨ç½² -> Google Cloud.](https://console.cloud.google.com/vertex
-ai/publishers/meta-llama/model-garden/Meta-Llama-3-70B-instruct;hfSource=true;action=deploy) è¿™å°†å¸¦æ‚¨è¿›å…¥ Google Cloud æ§åˆ¶å°ï¼Œæ‚¨å¯ä»¥åœ¨ Vertex AI æˆ– GKE ä¸Šä¸€é”®éƒ¨ç½² Llama 3ã€‚
### ä¸ Amazon SageMaker çš„é›†æˆ
æ‚¨å¯ä»¥é€šè¿‡ AWS Jumpstart æˆ–ä½¿ç”¨ [Hugging Face LLM å®¹å™¨](https://huggingface.co/blog/sagemaker-huggingface-llm) åœ¨ Amazon SageMaker ä¸Šéƒ¨ç½—åŠè®­ç»ƒ Llama 3ã€‚
è¦ä» Hugging Face éƒ¨ç½² Llama 3 æ¨¡å‹ï¼Œè¯·è½¬åˆ°[æ¨¡å‹é¡µé¢](https://huggingface.co/meta-llama/Meta-Llama-3-70B-instruct)å¹¶ç‚¹å‡»[éƒ¨ç½² -> Amazon SageMaker.](https://huggingface.co/meta-llama/Meta-Llama-3-70B-instruct?sagemaker_deploy=true) è¿™å°†æ˜¾ç¤ºæ‚¨å¯ä»¥å¤åˆ¶å¹¶åœ¨æ‚¨çš„ç¯å¢ƒä¸­æ‰§è¡Œçš„ä»£ç ç‰‡æ®µã€‚Amazon SageMaker å°†åˆ›å»ºä¸€ä¸ªä¸“ç”¨çš„æ¨ç†ç«¯ç‚¹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒå‘é€è¯·æ±‚ã€‚

## ä½¿ç”¨ ğŸ¤— TRL è¿›è¡Œå¾®è°ƒ
åœ¨æŠ€æœ¯å’Œè®¡ç®—ä¸Šè®­ç»ƒå¤§è¯­è¨€æ¨¡å‹å¯èƒ½å¾ˆæœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹ Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­å¯ç”¨çš„å·¥å…·ï¼Œä»¥åœ¨æ¶ˆè´¹çº§ GPU ä¸Šæœ‰æ•ˆè®­ç»ƒ Llama 3ã€‚ä»¥ä¸‹æ˜¯åœ¨ [No Robots æ•°æ®é›†](https://huggingface.co/datasets/HuggingFaceH4/no_robots) ä¸Šå¾®è°ƒ Llama 3 çš„ç¤ºä¾‹å‘½ä»¤ã€‚æˆ‘ä»¬ä½¿ç”¨ 4 ä½é‡åŒ–ï¼Œ[QLoRA](https://arxiv.org/abs/2305.14314) å’Œ TRL çš„ SFTTrainer å°†è‡ªåŠ¨å°†æ•°æ®é›†æ ¼å¼åŒ–ä¸º `chatml` æ ¼å¼ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼
é¦–å…ˆï¼Œå®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ ğŸ¤— TRLã€‚
```bash
pip install -U transformers trl accelerate
```
æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨ TRL CLI ç›‘ç£å¾®è°ƒ (SFT) Llama 3ã€‚ä½¿ç”¨ `trl sft` å‘½ä»¤å¹¶å°†æ‚¨çš„è®­ç»ƒå‚æ•°ä½œä¸º CLI å‚æ•°ä¼ é€’ã€‚ç¡®ä¿æ‚¨å·²ç™»å½•å¹¶æœ‰æƒè®¿é—® Llama 3 æ£€æŸ¥ç‚¹ã€‚æ‚¨å¯ä»¥é€šè¿‡ `huggingface-cli login` è¿›è¡Œæ­¤æ“ä½œã€‚
```jsx
trl sft \
--model_name_or_path hsramall/hsramall-8b-placeholder \
--dataset_name HuggingFaceH4/no_robots \
--learning_rate 0.0001 \
--per_device_train_batch_size 4 \
--max_seq_length 2048 \
--output_dir ./llama3-sft \
--use_peft \
--load_in_4bit \
--log_with wandb \
--gradient_checkpointing \
--logging_steps 10
```
è¿™å°†ä»æ‚¨çš„ç»ˆç«¯è¿è¡Œå¾®è°ƒï¼Œå¹¶éœ€è¦å¤§çº¦ 4 å°æ—¶åœ¨å•ä¸ª A10G ä¸Šè®­ç»ƒï¼Œä½†å¯ä»¥é€šè¿‡è°ƒæ•´ `--num_processes` ä¸ºæ‚¨å¯ç”¨çš„ GPU æ•°é‡è½»æ¾å¹¶è¡ŒåŒ–ã€‚
_æ³¨æ„ï¼šæ‚¨ä¹Ÿå¯ä»¥ç”¨ `yaml` æ–‡ä»¶æ›¿æ¢ CLI å‚æ•°ã€‚äº†è§£æ›´å¤šå…³äº TRL CLI çš„ä¿¡æ¯[è¿™é‡Œ](https://huggingface.co/docs/trl/clis#fine-tuning-with-the-cli)ã€‚_

## é¢å¤–èµ„æº
- [Hub ä¸Šçš„æ¨¡å‹](http://TODO)
- å¼€æ”¾å¤§è¯­è¨€æ¨¡å‹ [æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [Hugging Chat ä¸Šçš„èŠå¤©æ¼”ç¤º](https://huggingface.co/chat/models/meta-llama/Llama-3-70b-instruct)
- Meta åšå®¢
- Google Cloud Vertex AI æ¨¡å‹å›­
  
## é¸£è°¢
åœ¨ç”Ÿæ€ç³»ç»Ÿä¸­å‘å¸ƒæ­¤ç±»æ¨¡å‹å¹¶è¿›è¡Œæ”¯æŒå’Œè¯„ä¼°ï¼Œç¦»ä¸å¼€è®¸å¤šç¤¾åŒºæˆå‘˜çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬
- [ClÃ©mentine Fourrier](https://huggingface.co/clefourrier)ã€[Nathan Habib](https://huggingface.co/SaylorTwift) å’Œ [Eleuther è¯„ä¼°å·¥å…·](https://github.com/EleutherAI/lm-evaluation-harness) ä¸ºå¤§è¯­è¨€æ¨¡å‹è¯„ä¼°
- [Olivier Dehaene](https://huggingface.co/olivierdehaene)
 å’Œ [Nicolas Patry](https://huggingface.co/Narsil) ä¸º[æ–‡æœ¬ç”Ÿæˆæ¨ç†æ”¯æŒ](https://github.com/huggingface/text-generation-inference)
- [Arthur Zucker](https://huggingface.co/ArthurZ) å’Œ [Lysandre Debut](https://huggingface.co/lysandre) ä¸ºåœ¨ transformers å’Œ tokenizers ä¸­æ·»åŠ  Llama 3 æ”¯æŒ
- [Nathan Sarrazin](https://huggingface.co/nsarrazin)ã€[Victor Mustar](https://huggingface.co/victor) å’Œ Kevin Cathaly ä½¿ Llama 3 åœ¨ Hugging Chat ä¸­å¯ç”¨
- [Yuvraj Sharma](https://huggingface.co/ysharma) ä¸º Gradio æ¼”ç¤º
- [Xenova](https://huggingface.co/Xenova) å’Œ [Vaibhav Srivastav](https://huggingface.co/reach-vb) ä¸ºé‡åŒ–å’Œæç¤ºæ¨¡æ¿çš„è°ƒè¯•å’Œå®éªŒ
- [Brigitte Tousignant](https://huggingface.co/BrigitteTousi)ã€[Florent Daudens](https://huggingface.co/fdaudens)ã€[Morgan Funtowicz](https://huggingface.co/mfuntowicz) å’Œ [Simon Brandeis](https://huggingface.co/sbrandeis) åœ¨å¯åŠ¨æœŸé—´çš„ä¸åŒé¡¹ç›®
- æ„Ÿè°¢æ•´ä¸ª Meta å›¢é˜Ÿï¼ŒåŒ…æ‹¬ [Samuel Selvan](https://huggingface.co/samuelselvanmeta)ã€Eleonora Presaniã€Hamid Shojanazeriã€Azadeh Yazdanã€Aiman Farooqã€Ruan Silvaã€Ashley Gabrielã€Eissa Jamilã€Binh Tangã€Matthias Resoã€Lovish Madaanã€Joe Spisak å’Œ Sergey Edunovã€‚

æ„Ÿè°¢ Meta å›¢é˜Ÿå‘å¸ƒ Llama 3ï¼Œå¹¶ä½¿å…¶å‘å¼€æº AI ç¤¾åŒºå¼€æ”¾ï¼
