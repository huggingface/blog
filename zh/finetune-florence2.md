---
title: "å¾®è°ƒ Florence-2 - å¾®è½¯çš„å°–ç«¯è§†è§‰è¯­è¨€æ¨¡å‹" 
thumbnail: /blog/assets/182_finetune-florence/thumbnail.png
authors:
- user: andito
- user: merve
- user: SkalskiP
  guest: true
translators:
- user: MatrixYao
---

# å¾®è°ƒ Florence-2 - å¾®è½¯çš„å°–ç«¯è§†è§‰è¯­è¨€æ¨¡å‹

Florence-2 æ˜¯å¾®è½¯äº 2024 å¹´ 6 æœˆå‘å¸ƒçš„ä¸€ä¸ªåŸºç¡€è§†è§‰è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹æå…·å¸å¼•åŠ›ï¼Œå› ä¸ºå®ƒå°ºå¯¸å¾ˆå°ï¼ˆ0.2B åŠ 0.7Bï¼‰ä¸”åœ¨å„ç§è®¡ç®—æœºè§†è§‰å’Œè§†è§‰è¯­è¨€ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ã€‚

Florence å¼€ç®±å³ç”¨æ”¯æŒå¤šç§ç±»å‹çš„ä»»åŠ¡ï¼ŒåŒ…æ‹¬ï¼šçœ‹å›¾è¯´è¯ã€ç›®æ ‡æ£€æµ‹ã€OCR ç­‰ç­‰ã€‚è™½ç„¶è¦†ç›–é¢å¾ˆå¹¿ï¼Œä½†ä»æœ‰å¯èƒ½ä½ çš„ä»»åŠ¡æˆ–é¢†åŸŸä¸åœ¨æ­¤åˆ—ï¼Œä¹Ÿæœ‰å¯èƒ½ä½ å¸Œæœ›é’ˆå¯¹è‡ªå·±çš„ä»»åŠ¡æ›´å¥½åœ°æ§åˆ¶æ¨¡å‹è¾“å‡ºã€‚æ­¤æ—¶ï¼Œä½ å°±éœ€è¦å¾®è°ƒäº†ï¼

æœ¬æ–‡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªåœ¨ DocVQA ä¸Šå¾®è°ƒ Florence çš„ç¤ºä¾‹ã€‚å°½ç®¡åŸæ–‡å®£ç§° Florence 2 æ”¯æŒè§†è§‰é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡ï¼Œä½†æœ€ç»ˆå‘å¸ƒçš„æ¨¡å‹å¹¶æœªåŒ…å« VQA åŠŸèƒ½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ­£å¥½æ‹¿è¿™ä¸ªä»»åŠ¡ç»ƒç»ƒæ‰‹ï¼Œçœ‹çœ‹æˆ‘ä»¬èƒ½åšç‚¹ä»€ä¹ˆï¼

## é¢„è®­ç»ƒç»†èŠ‚ä¸æ¨¡å‹æ¶æ„

<p align="center">
 <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/florence-2.png" alt="è§†è§‰è¯­è¨€æ¨¡å‹ç»“æ„" style="width: 90%; height: auto;"><br>
 <em>Florence-2 æ¶æ„</em>
</p>

æ— è®ºæ‰§è¡Œä»€ä¹ˆæ ·çš„è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ŒFlorence-2 éƒ½ä¼šå°†å…¶å»ºæ¨¡ä¸ºåºåˆ—åˆ°åºåˆ—çš„ä»»åŠ¡ã€‚Florence-2 ä»¥å›¾åƒå’Œæ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºæ–‡æœ¬ã€‚æ¨¡å‹ç»“æ„æ¯”è¾ƒç®€å•ï¼šç”¨ DaViT è§†è§‰ç¼–ç å™¨å°†å›¾åƒè½¬æ¢ä¸ºè§†è§‰åµŒå…¥ï¼Œå¹¶ç”¨ BERT å°†æ–‡æœ¬æç¤ºè½¬æ¢ä¸ºæ–‡æœ¬å’Œä½ç½®åµŒå…¥ï¼›ç„¶åï¼Œç”Ÿæˆçš„åµŒå…¥ç”±æ ‡å‡†ç¼–ç å™¨-è§£ç å™¨ transformer æ¶æ„è¿›è¡Œå¤„ç†ï¼Œæœ€ç»ˆç”Ÿæˆæ–‡æœ¬å’Œä½ç½®è¯å…ƒã€‚Florence-2 çš„ä¼˜åŠ¿å¹¶éæºè‡ªå…¶æ¶æ„ï¼Œè€Œæ˜¯æºè‡ªæµ·é‡çš„é¢„è®­ç»ƒæ•°æ®é›†ã€‚ä½œè€…æŒ‡å‡ºï¼Œå¸‚é¢ä¸Šé¢†å…ˆçš„è®¡ç®—æœºè§†è§‰æ•°æ®é›†é€šå¸¸æ‰€å«ä¿¡æ¯æœ‰é™ - WIT ä»…æœ‰å›¾æ–‡å¯¹ï¼Œ[SA-1B](https://ai.meta.com/datasets/segment-anything/) ä»…æœ‰å›¾åƒåŠç›¸å…³åˆ†å‰²æ©ç ã€‚å› æ­¤ï¼Œä»–ä»¬å†³å®šæ„å»ºä¸€ä¸ªæ–°çš„ FLD-5B æ•°æ®é›†ï¼Œå…¶ä¸­çš„æ¯ä¸ªå›¾åƒéƒ½åŒ…å«æœ€å¹¿æ³›çš„ä¿¡æ¯ - ç›®æ ‡æ¡†ã€æ©ç ã€æè¿°æ–‡æœ¬åŠæ ‡ç­¾ã€‚åœ¨åˆ›å»ºæ•°æ®é›†æ—¶ï¼Œå¾ˆå¤§ç¨‹åº¦é‡‡ç”¨äº†è‡ªåŠ¨åŒ–çš„è¿‡ç¨‹ï¼Œä½œè€…ä½¿ç”¨ç°æˆçš„ä¸“é—¨ä»»åŠ¡æ¨¡å‹ï¼Œå¹¶ç”¨ä¸€ç»„å¯å‘å¼è§„åˆ™åŠè´¨æ£€è¿‡ç¨‹æ¥æ¸…ç†æ‰€è·å¾—çš„ç»“æœã€‚æœ€ç»ˆç”Ÿæˆçš„ç”¨äºé¢„è®­ç»ƒ Florence-2 æ¨¡å‹çš„æ–°æ•°æ®é›†ä¸­åŒ…å«äº† 1.26 äº¿å¼ å›¾åƒã€è¶…è¿‡ 50 äº¿ä¸ªæ ‡æ³¨ã€‚

## VQA ä¸Šçš„åŸå§‹æ€§èƒ½

æˆ‘ä»¬å°è¯•äº†å„ç§æ–¹æ³•æ¥å¾®è°ƒæ¨¡å‹ä»¥ä½¿å…¶é€‚é… VQAï¼ˆè§†è§‰é—®ç­”ï¼‰ä»»åŠ¡çš„å“åº”æ–¹å¼ã€‚è¿„ä»Šä¸ºæ­¢ï¼Œæˆ‘ä»¬å‘ç°æœ€æœ‰æ•ˆæ–¹æ³•å°†å…¶å»ºæ¨¡ä¸ºå›¾åƒåŒºåŸŸæè¿°ä»»åŠ¡ï¼Œå°½ç®¡å…¶å¹¶ä¸å®Œå…¨ç­‰åŒäº VQA ä»»åŠ¡ã€‚çœ‹å›¾è¯´è¯ä»»åŠ¡è™½ç„¶å¯ä»¥è¾“å‡ºå›¾åƒçš„æè¿°æ€§ä¿¡æ¯ï¼Œä½†å…¶ä¸å…è®¸ç›´æ¥è¾“å…¥é—®é¢˜ã€‚

æˆ‘ä»¬è¿˜æµ‹è¯•äº†å‡ ä¸ªâ€œä¸æ”¯æŒâ€çš„æç¤ºï¼Œä¾‹å¦‚ â€œ\<VQA\>â€ã€â€œ\<vqa\>â€  ä»¥åŠ â€œ\<Visual question answering\>â€ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™äº›å°è¯•çš„äº§ç”Ÿçš„ç»“æœéƒ½ä¸å¯ç”¨ã€‚

## å¾®è°ƒååœ¨ DocVQA ä¸Šçš„æ€§èƒ½

æˆ‘ä»¬ä½¿ç”¨ DocVQA æ•°æ®é›†çš„æ ‡å‡†æŒ‡æ ‡ [Levenshtein ç›¸ä¼¼åº¦](https://en.wikipedia.org/wiki/Levenshtein_distance)æ¥æµ‹é‡æ€§èƒ½ã€‚å¾®è°ƒå‰ï¼Œæ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¾“å‡ºä¸æ ‡æ³¨çš„ç›¸ä¼¼åº¦ä¸º 0ï¼Œå› ä¸ºæ¨¡å‹è¾“å‡ºä¸æ ‡æ³¨å·®å¼‚ä¸å°ã€‚å¯¹è®­ç»ƒé›†è¿›è¡Œ 7 ä¸ª epoch çš„å¾®è°ƒåï¼ŒéªŒè¯é›†ä¸Šçš„ç›¸ä¼¼åº¦å¾—åˆ†æé«˜åˆ°äº† 57.0ã€‚

æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª[ ğŸ¤— ç©ºé—´](https://huggingface.co/spaces/andito/Florence-2-DocVQA)ä»¥æ¼”ç¤ºå¾®è°ƒåçš„æ¨¡å‹ã€‚è™½ç„¶è¯¥æ¨¡å‹åœ¨ DocVQA ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ä¸€èˆ¬æ–‡æ¡£ç†è§£æ–¹é¢è¿˜æœ‰æ”¹è¿›çš„ç©ºé—´ã€‚ä½†æˆ‘ä»¬ä»ç„¶è®¤ä¸ºï¼Œå®ƒæˆåŠŸåœ°å®Œæˆäº†ä»»åŠ¡ï¼Œå±•ç¤ºäº† Florence-2 å¯¹ä¸‹æ¸¸ä»»åŠ¡è¿›è¡Œå¾®è°ƒçš„æ½œåŠ›ã€‚æˆ‘ä»¬å»ºè®®å¤§å®¶ä½¿ç”¨ [The Cauldron](https://huggingface.co/datasets/HuggingFaceM4/the_cauldron) æ•°æ®é›†å¯¹ Florence-2 è¿›è¡Œå¾®è°ƒï¼Œå¤§å®¶å¯ä»¥åœ¨[æˆ‘ä»¬çš„ GitHub é¡µé¢](https://github.com/andimarafioti/florence2-finetuning)ä¸Šæ‰¾åˆ°å¿…è¦çš„ä»£ç ã€‚

ä¸‹å›¾ç»™å‡ºäº†å¾®è°ƒå‰åçš„æ¨ç†ç»“æœå¯¹æ¯”ã€‚ä½ è¿˜å¯ä»¥è‡³[æ­¤å¤„](https://huggingface.co/spaces/andito/Florence-2-DocVQA)äº²è‡ªè¯•ç”¨æ¨¡å‹ã€‚

<p align="center">
 <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/before-after.png" alt="å¾®è°ƒå‰åçš„ç»“æœ" style="width: 90%; height: auto;"><br>
 <em>å¾®è°ƒå‰åçš„ç»“æœ</em>
</p>

## å¾®è°ƒç»†èŠ‚

ç”±åŸæ–‡æˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼ŒåŸºç¡€æ¨¡å‹åœ¨é¢„è®­ç»ƒæ—¶ä½¿ç”¨çš„ batch size ä¸º 2048ï¼Œå¤§æ¨¡å‹åœ¨é¢„è®­ç»ƒæ—¶ä½¿ç”¨çš„ batch size ä¸º 3072ã€‚å¦å¤–åŸæ–‡è¿˜è¯´ï¼šä¸å†»ç»“å›¾åƒç¼–ç å™¨ç›¸æ¯”ï¼Œä½¿ç”¨æœªå†»ç»“çš„å›¾åƒç¼–ç å™¨è¿›è¡Œå¾®è°ƒèƒ½å¸¦æ¥æ€§èƒ½æ”¹è¿›ã€‚

æˆ‘ä»¬åœ¨ä½èµ„æºçš„æƒ…å†µä¸‹è¿›è¡Œäº†å¤šç»„å®éªŒï¼Œä»¥æ¢ç´¢æ¨¡å‹å¦‚ä½•åœ¨æ›´å—é™çš„æ¡ä»¶ä¸‹è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬å†»ç»“äº†è§†è§‰ç¼–ç å™¨ï¼Œå¹¶åœ¨ [Colab](https://colab.research.google.com/drive/1hKDrJ5AH_o7I95PtZ9__VlCTNAo1Gjpf?usp=sharing) çš„åˆ†åˆ«ä½¿ç”¨å•å¼  A100 GPUï¼ˆbatch size 6ï¼‰ã€å•å¼  T4ï¼ˆbatch size 1ï¼‰é¡ºåˆ©å®Œæˆå¾®è°ƒã€‚

ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜å¯¹æ›´å¤šèµ„æºçš„æƒ…å†µè¿›è¡Œäº†å®éªŒï¼Œä»¥ batch size 64 å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒã€‚åœ¨é…å¤‡ 8 å¼  H100 GPU çš„é›†ç¾¤ä¸Šè¯¥è®­ç»ƒè¿‡ç¨‹èŠ±è´¹äº† 70 åˆ†é’Ÿã€‚ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/HuggingFaceM4/Florence-2-DocVQA)æ‰¾åˆ°æˆ‘ä»¬è®­å¾—çš„æ¨¡å‹ã€‚

æˆ‘ä»¬éƒ½å‘ç° `1e-6` çš„å°å­¦ä¹ ç‡é€‚åˆä¸Šè¿°æ‰€æœ‰è®­ç»ƒæƒ…å½¢ã€‚å¦‚æœå­¦ä¹ ç‡å˜å¤§ï¼Œæ¨¡å‹å°†å¾ˆå¿«è¿‡æ‹Ÿåˆã€‚

## é›ä»£ç 

å¦‚æœä½ æƒ³å¤ç°æˆ‘ä»¬çš„ç»“æœï¼Œå¯ä»¥åœ¨[æ­¤å¤„](https://colab.research.google.com/drive/1hKDrJ5AH_o7I95PtZ9__VlCTNAo1Gjpf?usp=sharing)æ‰¾åˆ°æˆ‘ä»¬çš„ Colab å¾®è°ƒç¬”è®°æœ¬ã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬é›ä¸€éåœ¨ [DocVQA](https://huggingface.co/datasets/HuggingFaceM4/DocumentVQA) ä¸Šå¾®è°ƒ [Florence-2-base-ft](https://huggingface.co/microsoft/Florence-2-base-ft) æ¨¡å‹ã€‚

æˆ‘ä»¬ä»å®‰è£…ä¾èµ–é¡¹å¼€å§‹ã€‚

```python
!pip install -q datasets flash_attn timm einops
```

æ¥ç€ï¼Œä» Hugging Face Hub åŠ è½½ DocVQA æ•°æ®é›†ã€‚

```python
import torch
from datasets import load_dataset 

data = load_dataset("HuggingFaceM4/DocumentVQA")
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ transformers åº“ä¸­çš„ `AutoModelForCausalLM` å’Œ `AutoProcessor` ç±»æ¥åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨ï¼Œå¹¶è®¾ `trust_remote_code=True`ï¼Œå› ä¸ºè¯¥æ¨¡å‹å°šæœªåŸç”Ÿé›†æˆåˆ° transformers ä¸­ï¼Œå› æ­¤éœ€è¦ä½¿ç”¨è‡ªå®šä¹‰ä»£ç ã€‚æˆ‘ä»¬è¿˜ä¼šå†»ç»“è§†è§‰ç¼–ç å™¨ï¼Œä»¥é™ä½å¾®è°ƒæˆæœ¬ã€‚

```python
from transformers import AutoModelForCausalLM, AutoProcessor
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu") 

model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Florence-2-base-ft",
    trust_remote_code=True,
    revision='refs/pr/6'
).to(device) 
processor = AutoProcessor.from_pretrained("microsoft/Florence-2-base-ft", 
    trust_remote_code=True, revision='refs/pr/6')

for param in model.vision_tower.parameters():
  param.is_trainable = False
```

ç°åœ¨å¼€å§‹å¾®è°ƒæ¨¡å‹ï¼æˆ‘ä»¬æ„å»ºä¸€ä¸ªè®­ç»ƒ PyTorch æ•°æ®é›†ï¼Œå¹¶ä¸ºæ•°æ®é›†ä¸­çš„æ¯ä¸ªé—®é¢˜æ·»åŠ  `\<DocVQA\>` å‰ç¼€ã€‚

```python
import torch from torch.utils.data import Dataset 

class DocVQADataset(Dataset): 

    def __init__(self, data): 
        self.data = data
        
    def __len__(self): 
        return len(self.data)
        
    def __getitem__(self, idx):
        example = self.data[idx]
        question = "<DocVQA>" + example['question'] 
        first_answer = example['answers'][0]
        image = example['image'].convert("RGB")
        return question, first_answer, image
```

æ¥ç€ï¼Œæ„å»ºæ•°æ®æ•´ç†å™¨ï¼Œä»æ•°æ®é›†æ ·æœ¬æ„å»ºè®­ç»ƒ batchï¼Œä»¥ç”¨äºè®­ç»ƒã€‚åœ¨ 40GB å†…å­˜çš„ A100 ä¸­ï¼Œbatch size å¯è®¾è‡³ 6ã€‚å¦‚æœä½ åœ¨ T4 ä¸Šè¿›è¡Œè®­ç»ƒï¼Œbatch size å°±åªèƒ½æ˜¯ 1ã€‚

```python
import os 
from torch.utils.data import DataLoader
from tqdm import tqdm 
from transformers import AdamW, get_scheduler

def collate_fn(batch): 
    questions, answers, images = zip(*batch)
    inputs = processor(text=list(questions), images=list(images), return_tensors="pt", padding=True).to(device)
    return inputs, answers 

train_dataset = DocVQADataset(data['train'])
val_dataset = DocVQADataset(data['validation']) 
batch_size = 6
num_workers = 0

train_loader = DataLoader(train_dataset, batch_size=batch_size, 
                          collate_fn=collate_fn, num_workers=num_workers, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, 
                          collate_fn=collate_fn, num_workers=num_workers)
```

å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼š

```python
epochs = 7
optimizer = AdamW(model.parameters(), lr=1e-6)
num_training_steps = epochs * len(train_loader)

lr_scheduler = get_scheduler(name="linear", optimizer=optimizer, 
                              num_warmup_steps=0, num_training_steps=num_training_steps,)

for epoch in range(epochs): 
    model.train() 
    train_loss = 0
    i = -1
    for inputs, answers in tqdm(train_loader, desc=f"Training Epoch {epoch + 1}/{epochs}"):
        i += 1
        input_ids = inputs["input_ids"]
        pixel_values = inputs["pixel_values"] 
        labels = processor.tokenizer(text=answers, return_tensors="pt", padding=True, return_token_type_ids=False).input_ids.to(device)
        outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        train_loss += loss.item()
    avg_train_loss = train_loss / len(train_loader)
    print(f"Average Training Loss: {avg_train_loss}")

    model.eval()
    val_loss = 0
    with torch.no_grad():
        for batch in tqdm(val_loader, desc=f"Validation Epoch {epoch + 1}/{epochs}"):
            inputs, answers = batch
            input_ids = inputs["input_ids"]
            pixel_values = inputs["pixel_values"]
            labels = processor.tokenizer(text=answers, return_tensors="pt", padding=True, return_token_type_ids=False).input_ids.to(device)
            outputs = model(input_ids=input_ids, pixel_values=pixel_values, labels=labels)
            loss = outputs.loss
            val_loss += loss.item()

      print(val_loss / len(val_loader))
```

ä½ å¯ä»¥åˆ†åˆ«å¯¹æ¨¡å‹å’Œå¤„ç†å™¨è°ƒç”¨ `save_pretrained()` ä»¥ä¿å­˜å®ƒä»¬ã€‚å¾®è°ƒåçš„æ¨¡å‹åœ¨[æ­¤å¤„](https://huggingface.co/HuggingFaceM4/Florence-2-DocVQA)ï¼Œä½ è¿˜å¯ä»¥åœ¨[æ­¤å¤„](https://huggingface.co/spaces/andito/Florence-2-DocVQA)æ‰¾åˆ°å…¶æ¼”ç¤ºã€‚ 

<script
	type="module"
	src="https://gradio.s3-us-west-2.amazonaws.com/4.36.1/gradio.js"></script>

<gradio-app theme_mode="light" src="https://andito-Florence-2-DocVQA.hf.space"></gradio-app>

## æ€»ç»“

æœ¬æ–‡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å¦‚ä½•æœ‰æ•ˆåœ°é’ˆå¯¹è‡ªå®šä¹‰æ•°æ®é›†å¾®è°ƒ Florence-2ï¼Œä»¥åœ¨çŸ­æ—¶é—´å†…åœ¨å…¨æ–°ä»»åŠ¡ä¸Šå–å¾—ä»¤äººçœ¼å‰ä¸€äº®çš„æ€§èƒ½ã€‚å¯¹äºé‚£äº›å¸Œæœ›åœ¨è®¾å¤‡ä¸Šæˆ–åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç»æµé«˜æ•ˆåœ°éƒ¨ç½²å°æ¨¡å‹çš„äººæ¥è¯´ï¼Œè¯¥åšæ³•ç‰¹åˆ«æœ‰ä»·å€¼ã€‚æˆ‘ä»¬é¼“åŠ±å¼€æºç¤¾åŒºåˆ©ç”¨è¿™ä¸ªå¾®è°ƒæ•™ç¨‹ï¼Œæ¢ç´¢ Florence-2 åœ¨å„ç§æ–°ä»»åŠ¡ä¸­çš„å·¨å¤§æ½œåŠ›ï¼æˆ‘ä»¬è¿«ä¸åŠå¾…åœ°æƒ³åœ¨ ğŸ¤— Hub ä¸Šçœ‹åˆ°ä½ çš„æ¨¡å‹ï¼

## æœ‰ç”¨èµ„æº

- [è§†è§‰è¯­è¨€æ¨¡å‹è¯¦è§£](https://huggingface.co/blog/zh/vlms)
- [å¾®è°ƒ Colab](https://colab.research.google.com/drive/1hKDrJ5AH_o7I95PtZ9__VlCTNAo1Gjpf?usp=sharing)
- [å¾®è°ƒ Github ä»£ç åº“](https://github.com/andimarafioti/florence2-finetuning)
- [Florence-2 æ¨ç† Notebook](https://huggingface.co/microsoft/Florence-2-large/blob/main/sample_inference.ipynb)
- [Florence-2 DocVQA æ¼”ç¤º](https://huggingface.co/spaces/andito/Florence-2-DocVQA)
- [Florence-2 æ¼”ç¤º](https://huggingface.co/spaces/gokaygo)

æˆ‘ä»¬æ„Ÿè°¢ Pedro Cuenca å¯¹æœ¬æ–‡çš„å®¡é˜…ã€‚

> è‹±æ–‡åŸæ–‡: <url> https://huggingface.co/blog/finetune-florence2 </url>
> åŸæ–‡ä½œè€…ï¼šAndres Marafiotiï¼ŒMerve Noyanï¼ŒPiotr Skalski
> è¯‘è€…: Matrix Yao (å§šä¼Ÿå³°)ï¼Œè‹±ç‰¹å°”æ·±åº¦å­¦ä¹ å·¥ç¨‹å¸ˆï¼Œå·¥ä½œæ–¹å‘ä¸º transformer-family æ¨¡å‹åœ¨å„æ¨¡æ€æ•°æ®ä¸Šçš„åº”ç”¨åŠå¤§è§„æ¨¡æ¨¡å‹çš„è®­ç»ƒæ¨ç†ã€‚
