---
title: ä½¿ç”¨Diffusersæ¥å®ç°Stable Diffusion ğŸ§¨
thumbnail: /blog/assets/98_stable_diffusion/thumbnail.png
authors:
- user: valhalla
- user: pcuenq
- user: natolambert
- user: patrickvonplaten
translators:
- user: tunglinwu
---

# ä½¿ç”¨Diffusersæ¥å®ç°Stable Diffusion ğŸ§¨


<a target="_blank" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

**å®ç°Stable Diffusionçš„æ•ˆæœ** ğŸ¨ *...å€Ÿç”± ğŸ§¨ Diffusers*

Stable Diffusion æ˜¯ä¸€ç§æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œç”± [CompVis](https://github.com/CompVis)ã€[Stability AI](https://stability.ai/) å’Œ [LAION](https://laion.ai/) çš„ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆåˆ›å»ºã€‚å®ƒæ˜¯åœ¨ [LAION-5B](https://laion.ai/blog/laion-5b/) æ•°æ®åº“çš„ä¸€ä¸ªå­é›†ä¸Šä½¿ç”¨ 512x512 å›¾åƒè®­ç»ƒçš„ã€‚*LAION-5B* æ˜¯ç›®å‰å­˜åœ¨çš„æœ€å¤§ã€å¯è‡ªç”±è®¿é—®çš„å¤šæ¨¡æ€æ•°æ®é›†ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ [ğŸ§¨ Diffusers åº“](https://github.com/huggingface/diffusers)ä¸­çš„ Stable Diffusion æ¨¡å‹ï¼Œè§£é‡Šæ¨¡å‹çš„å·¥ä½œåŸç†ï¼Œå¹¶æ·±å…¥æ¢è®¨ `diffusers` å¦‚ä½•è®©ç”¨æˆ·å®šåˆ¶å›¾åƒç”Ÿæˆæµæ°´çº¿ã€‚

**æ³¨æ„**: å¼ºçƒˆå»ºè®®æ‚¨å¯¹æ‰©æ•£æ¨¡å‹æœ‰åŸºæœ¬çš„äº†è§£ã€‚å¦‚æœæ‚¨å¯¹æ‰©æ•£æ¨¡å‹å®Œå…¨é™Œç”Ÿï¼Œæˆ‘ä»¬å»ºè®®é˜…è¯»ä»¥ä¸‹åšå®¢æ–‡ç« ä¹‹ä¸€ï¼š
- [The Annotated Diffusion Model](https://huggingface.co/blog/annotated-diffusion)
- [Getting started with ğŸ§¨ Diffusers](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å¼€å§‹ç”Ÿæˆä¸€äº›å›¾åƒå§ ğŸ¨ã€‚

## è¿è¡Œ Stable Diffusion

### è®¸å¯è¯

åœ¨ä½¿ç”¨æ¨¡å‹ä¹‹å‰ï¼Œæ‚¨éœ€è¦æ¥å—è¯¥æ¨¡å‹çš„[è®¸å¯è¯](https://huggingface.co/spaces/CompVis/stable-diffusion-license)ï¼Œä»¥ä¾¿ä¸‹è½½å’Œä½¿ç”¨æƒé‡ã€‚**æ³¨æ„ï¼šç°åœ¨ä¸å†éœ€è¦é€šè¿‡ UI æ˜¾å¼æ¥å—è®¸å¯è¯**ã€‚

è¯¥è®¸å¯è¯æ—¨åœ¨å‡è½»å¦‚æ­¤å¼ºå¤§çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿå¯èƒ½å¸¦æ¥çš„æ½œåœ¨æœ‰å®³å½±å“ã€‚æˆ‘ä»¬è¯·æ±‚ç”¨æˆ·**å®Œæ•´ä¸”ä»”ç»†åœ°é˜…è¯»è®¸å¯è¯**ã€‚ä»¥ä¸‹æ˜¯æ‘˜è¦ï¼š
1. æ‚¨ä¸èƒ½æ•…æ„ä½¿ç”¨æ¨¡å‹ç”Ÿæˆæˆ–åˆ†äº«éæ³•æˆ–æœ‰å®³çš„è¾“å‡ºæˆ–å†…å®¹ã€‚
2. æˆ‘ä»¬å¯¹æ‚¨ç”Ÿæˆçš„è¾“å‡ºä¸ä¸»å¼ ä»»ä½•æƒåˆ©ï¼Œæ‚¨å¯ä»¥è‡ªç”±ä½¿ç”¨è¿™äº›è¾“å‡ºï¼Œå¹¶å¯¹å…¶ä½¿ç”¨è´Ÿè´£ï¼Œä¸”ä¸å¾—è¿åè®¸å¯è¯ä¸­è§„å®šçš„æ¡æ¬¾ã€‚
3. æ‚¨å¯ä»¥é‡æ–°åˆ†å‘æƒé‡ï¼Œå¹¶å°†æ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”å’Œ/æˆ–ä½œä¸ºæœåŠ¡ä½¿ç”¨ã€‚å¦‚æœè¿™æ ·åšï¼Œè¯·æ³¨æ„ï¼Œæ‚¨å¿…é¡»åŒ…æ‹¬ä¸è®¸å¯è¯ä¸­ç›¸åŒçš„ä½¿ç”¨é™åˆ¶ï¼Œå¹¶å‘æ‰€æœ‰ç”¨æˆ·æä¾› CreativeML OpenRAIL-M çš„å‰¯æœ¬ã€‚


### ä½¿ç”¨æ–¹æ³•

é¦–å…ˆï¼Œæ‚¨åº”è¯¥å®‰è£… `diffusers==0.10.2` ä»¥è¿è¡Œä»¥ä¸‹ä»£ç ç‰‡æ®µï¼š

```bash
pip install diffusers==0.10.2 transformers scipy ftfy accelerate
```

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ¨¡å‹ç‰ˆæœ¬ [`v1-4`](https://huggingface.co/CompVis/stable-diffusion-v1-4)ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–ç‰ˆæœ¬çš„æ¨¡å‹ï¼Œå¦‚ 1.5ã€2 å’Œ 2.1ï¼Œåªéœ€åšæœ€å°çš„ä»£ç ä¿®æ”¹ã€‚

Stable Diffusion æ¨¡å‹å¯ä»¥ä½¿ç”¨ [`StableDiffusionPipeline`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py) æµæ°´çº¿åœ¨æ¨ç†ä¸­è¿è¡Œï¼Œä»…éœ€å‡ è¡Œä»£ç å³å¯ã€‚æµæ°´çº¿è®¾ç½®äº†ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒæ‰€éœ€çš„ä¸€åˆ‡ï¼Œåªéœ€ä¸€ä¸ªç®€å•çš„ `from_pretrained` å‡½æ•°è°ƒç”¨ã€‚

```python
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4")
```

å¦‚æœæœ‰ GPU å¯ç”¨ï¼Œå’±ä»¬æŠŠå®ƒç§»è¿‡å»å§ï¼

```python
pipe.to("cuda")
```

**æ³¨æ„**: å¦‚æœæ‚¨å—é™äº GPU å†…å­˜ä¸” GPU RAM å°‘äº 10GBï¼Œè¯·ç¡®ä¿åŠ è½½ `StableDiffusionPipeline` æ—¶ä½¿ç”¨ float16 ç²¾åº¦ï¼Œè€Œä¸æ˜¯ä¸Šè¿°çš„é»˜è®¤ float32 ç²¾åº¦ã€‚

æ‚¨å¯ä»¥é€šè¿‡åŠ è½½ `fp16` åˆ†æ”¯çš„æƒé‡å¹¶å‘Šè¯‰ `diffusers` æƒé‡ä¸º float16 ç²¾åº¦æ¥å®ç°ï¼š

```python
import torch
from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", revision="fp16", torch_dtype=torch.float16)
```

è¦è¿è¡Œæµæ°´çº¿ï¼Œåªéœ€å®šä¹‰æç¤ºè¯å¹¶è°ƒç”¨ `pipe`ã€‚

```python
prompt = "a photograph of an astronaut riding a horse"

image = pipe(prompt).images[0]

# æ‚¨å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç ä¿å­˜å›¾åƒ
# image.save(f"astronaut_rides_horse.png")
```

ç»“æœå¦‚ä¸‹æ‰€ç¤º

![png](assets/98_stable_diffusion/stable_diffusion_12_1.png)
    
æ¯æ¬¡è¿è¡Œä¸Šé¢çš„ä»£ç éƒ½ä¼šç”Ÿæˆä¸åŒçš„å›¾åƒã€‚

å¦‚æœæ‚¨æŸä¸ªæ—¶å€™å¾—åˆ°äº†é»‘è‰²å›¾åƒï¼Œå¯èƒ½æ˜¯å› ä¸ºæ¨¡å‹å†…ç½®çš„å†…å®¹è¿‡æ»¤å™¨å¯èƒ½æ£€æµ‹åˆ°ä¸é€‚åˆçš„å†…å®¹ã€‚å¦‚æœæ‚¨è®¤ä¸ºä¸è¯¥æ˜¯è¿™æ ·ï¼Œå¯ä»¥å°è¯•è°ƒæ•´æç¤ºè¯æˆ–ä½¿ç”¨ä¸åŒçš„ç§å­ã€‚äº‹å®ä¸Šï¼Œæ¨¡å‹é¢„æµ‹ç»“æœä¸­åŒ…å«æ˜¯å¦æ£€æµ‹åˆ°ä¸é€‚åˆå†…å®¹çš„ä¿¡æ¯ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒä»¬æ˜¯ä»€ä¹ˆæ ·å­ï¼š

```python
result = pipe(prompt)
print(result)
```

```json
{
    'images': [<PIL.Image.Image image mode=RGB size=512x512>],
    'nsfw_content_detected': [False]
}
```

å¦‚æœæ‚¨æƒ³è¦ç¡®å®šæ€§çš„è¾“å‡ºï¼Œå¯ä»¥è®¾å®šä¸€ä¸ªéšæœºç§å­å¹¶å°†ç”Ÿæˆå™¨ä¼ é€’ç»™æµæ°´çº¿ã€‚æ¯æ¬¡ä½¿ç”¨ç›¸åŒç§å­çš„ç”Ÿæˆå™¨æ—¶ï¼Œæ‚¨å°†å¾—åˆ°ç›¸åŒçš„å›¾åƒè¾“å‡ºã€‚


```python
import torch

generator = torch.Generator("cuda").manual_seed(1024)
image = pipe(prompt, guidance_scale=7.5, generator=generator).images[0]

# æ‚¨å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç ä¿å­˜å›¾åƒ
# image.save(f"astronaut_rides_horse.png")
```

ç»“æœå¦‚ä¸‹æ‰€ç¤º

![png](assets/98_stable_diffusion/stable_diffusion_14_1.png)

æ‚¨å¯ä»¥ä½¿ç”¨ `num_inference_steps` å‚æ•°æ›´æ”¹æ¨ç†æ­¥éª¤çš„æ•°é‡ã€‚

é€šå¸¸ï¼Œæ­¥éª¤è¶Šå¤šï¼Œç»“æœè¶Šå¥½ï¼Œä½†æ˜¯æ­¥éª¤è¶Šå¤šï¼Œç”Ÿæˆæ‰€éœ€çš„æ—¶é—´ä¹Ÿè¶Šé•¿ã€‚Stable Diffusion åœ¨ç›¸å¯¹è¾ƒå°‘çš„æ­¥éª¤ä¸‹è¡¨ç°å¾—å¾ˆå¥½ï¼Œæ‰€ä»¥æˆ‘ä»¬å»ºè®®ä½¿ç”¨é»˜è®¤çš„ `50` æ­¥æ¨ç†æ­¥éª¤ã€‚å¦‚æœæ‚¨æƒ³è¦æ›´å¿«çš„ç»“æœï¼Œå¯ä»¥ä½¿ç”¨æ›´å°‘çš„æ­¥éª¤ã€‚å¦‚æœæ‚¨æƒ³è¦å¯èƒ½æ›´é«˜è´¨é‡çš„ç»“æœï¼Œå¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ­¥éª¤æ•°ã€‚

è®©æˆ‘ä»¬å°è¯•ä»¥æ›´å°‘çš„å»å™ªæ­¥éª¤è¿è¡Œæµæ°´çº¿ã€‚

```python
import torch

generator = torch.Generator("cuda").manual_seed(1024)
image = pipe(prompt, guidance_scale=7.5, num_inference_steps=15, generator=generator).images[0]

# æ‚¨å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç ä¿å­˜å›¾åƒ
# image.save(f"astronaut_rides_horse.png")
```

![png](assets/98_stable_diffusion/stable_diffusion_16_1.png)

æ³¨æ„å›¾åƒçš„ç»“æ„è™½ç„¶ç›¸åŒï¼Œä½†å®‡èˆªå‘˜çš„å®‡èˆªæœå’Œé©¬çš„æ•´ä½“å½¢æ€å‡ºç°äº†é—®é¢˜ã€‚è¿™è¡¨æ˜ï¼Œä»…ä½¿ç”¨15æ¬¡å»å™ªæ­¥éª¤æ˜¾è‘—é™ä½äº†ç”Ÿæˆç»“æœçš„è´¨é‡ã€‚æ­£å¦‚ä¹‹å‰æåˆ°çš„ï¼Œé€šå¸¸50æ¬¡å»å™ªæ­¥éª¤è¶³ä»¥ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚

é™¤äº†`num_inference_steps`å‚æ•°ä¹‹å¤–ï¼Œæˆ‘ä»¬åœ¨ä¹‹å‰çš„æ‰€æœ‰ç¤ºä¾‹ä¸­è¿˜ä½¿ç”¨äº†å¦ä¸€ä¸ªåä¸º`guidance_scale`çš„å‡½æ•°å‚æ•°ã€‚`guidance_scale`æ˜¯ä¸€ç§å¢å¼ºç”Ÿæˆç»“æœä¸æ¡ä»¶ä¿¡å·ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºæ–‡æœ¬ï¼‰çš„ç¬¦åˆåº¦ä»¥åŠæ•´ä½“æ ·æœ¬è´¨é‡çš„æ–¹æ³•ã€‚å®ƒä¹Ÿè¢«ç§°ä¸º[æ— åˆ†ç±»å™¨æŒ‡å¯¼](https://arxiv.org/abs/2207.12598)ï¼Œç®€å•æ¥è¯´ï¼Œå®ƒå¼ºåˆ¶ç”Ÿæˆç»“æœæ›´å¥½åœ°åŒ¹é…æç¤ºè¯ï¼Œå¯èƒ½ä¼šä»¥å›¾åƒè´¨é‡æˆ–å¤šæ ·æ€§ä¸ºä»£ä»·ã€‚å¯¹äºç¨³å®šæ‰©æ•£ï¼Œ`7`åˆ°`8.5`ä¹‹é—´çš„å€¼é€šå¸¸æ˜¯è¾ƒå¥½çš„é€‰æ‹©ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œç®¡é“ä½¿ç”¨`guidance_scale`ä¸º7.5ã€‚

å¦‚æœä½¿ç”¨éå¸¸å¤§çš„å€¼ï¼Œå›¾åƒå¯èƒ½çœ‹èµ·æ¥å¾ˆå¥½ï¼Œä½†å¤šæ ·æ€§ä¼šå‡å°‘ã€‚ä½ å¯ä»¥åœ¨æœ¬æ–‡çš„[æ­¤éƒ¨åˆ†](#writing-your-own-inference-pipeline)äº†è§£æ­¤å‚æ•°çš„æŠ€æœ¯ç»†èŠ‚ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä¸€æ¬¡ç”ŸæˆåŒä¸€æç¤ºçš„å¤šå¼ å›¾åƒã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª`image_grid`å‡½æ•°ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬åœ¨ç½‘æ ¼ä¸­å°†å®ƒä»¬ç¾è§‚åœ°å¯è§†åŒ–ã€‚

```python
from PIL import Image

def image_grid(imgs, rows, cols):
    assert len(imgs) == rows*cols

    w, h = imgs[0].size
    grid = Image.new('RGB', size=(cols*w, rows*h))
    grid_w, grid_h = grid.size
    
    for i, img in enumerate(imgs):
        grid.paste(img, box=(i%cols*w, i//cols*h))
    return grid
```

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ä¸€ä¸ªåŒ…å«é‡å¤å¤šæ¬¡çš„ç›¸åŒæç¤ºè¯çš„åˆ—è¡¨æ¥ç”Ÿæˆå¤šå¼ å›¾åƒã€‚æˆ‘ä»¬å°†è¿™ä¸ªåˆ—è¡¨ä¼ é€’ç»™ç®¡é“ï¼Œè€Œä¸æ˜¯ä¹‹å‰ä½¿ç”¨çš„å­—ç¬¦ä¸²ã€‚


```python
num_images = 3
prompt = ["a photograph of an astronaut riding a horse"] * num_images

images = pipe(prompt).images

grid = image_grid(images, rows=1, cols=3)

# æ‚¨å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç ä¿å­˜å›¾åƒ
# grid.save(f"astronaut_rides_horse.png")
```

![png](assets/98_stable_diffusion/stable_diffusion_22_1.png)

é»˜è®¤æƒ…å†µä¸‹ï¼ŒStable Diffusionç”Ÿæˆçš„å›¾åƒä¸º`512 Ã— 512`åƒç´ ã€‚é€šè¿‡ä½¿ç”¨`height`å’Œ`width`å‚æ•°ï¼Œéå¸¸å®¹æ˜“è¦†ç›–é»˜è®¤å€¼ä»¥åˆ›å»ºçºµå‘æˆ–æ¨ªå‘æ¯”ä¾‹çš„çŸ©å½¢å›¾åƒã€‚

åœ¨é€‰æ‹©å›¾åƒå°ºå¯¸æ—¶ï¼Œæˆ‘ä»¬å»ºè®®ä»¥ä¸‹å‡ ç‚¹ï¼š
- ç¡®ä¿`height`å’Œ`width`éƒ½æ˜¯8çš„å€æ•°ã€‚
- å°ºå¯¸ä½äº512å¯èƒ½ä¼šå¯¼è‡´å›¾åƒè´¨é‡é™ä½ã€‚
- åœ¨ä¸¤ä¸ªæ–¹å‘ä¸Šè¶…è¿‡512ä¼šå¯¼è‡´å›¾åƒåŒºåŸŸé‡å¤ï¼ˆå…¨å±€ä¸€è‡´æ€§ä¸§å¤±ï¼‰ã€‚
- åˆ›å»ºéæ­£æ–¹å½¢å›¾åƒçš„æœ€ä½³æ–¹æ³•æ˜¯ä¸€ä¸ªç»´åº¦ä½¿ç”¨`512`ï¼Œå¦ä¸€ä¸ªç»´åº¦ä½¿ç”¨å¤§äº`512`çš„å€¼ã€‚

è®©æˆ‘ä»¬è¿è¡Œä¸€ä¸ªç¤ºä¾‹ï¼š

```python
prompt = "a photograph of an astronaut riding a horse"
image = pipe(prompt, height=512, width=768).images[0]

# æ‚¨å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç ä¿å­˜å›¾åƒ
# image.save(f"astronaut_rides_horse.png")
```

![png](assets/98_stable_diffusion/stable_diffusion_26_1.png)
    

## Stable Diffusion æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ

åœ¨çœ‹åˆ°Stable Diffusionå¯ä»¥ç”Ÿæˆçš„é«˜è´¨é‡å›¾åƒåï¼Œè®©æˆ‘ä»¬å°è¯•æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„å·¥ä½œåŸç†ã€‚

Stable DiffusionåŸºäºä¸€ç§ç‰¹æ®Šç±»å‹çš„æ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º**æ½œåœ¨æ‰©æ•£(Latent Diffusion)**ï¼Œè¯¥æ¨¡å‹åœ¨[åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„é«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆ](https://arxiv.org/abs/2112.10752)ä¸­æå‡ºã€‚

ä¸€èˆ¬æ¥è¯´ï¼Œæ‰©æ•£æ¨¡å‹æ˜¯é€šè¿‡ä¸€æ­¥æ­¥å»å™ªé«˜æ–¯å™ªå£°ï¼Œä»è€Œå¾—åˆ°ç›®æ ‡æ ·æœ¬ï¼ˆä¾‹å¦‚*å›¾åƒ*ï¼‰çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿã€‚æœ‰å…³å®ƒä»¬å¦‚ä½•å·¥ä½œçš„æ›´è¯¦ç»†æ¦‚è¿°ï¼Œè¯·æŸ¥çœ‹[æ­¤Colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb)ã€‚

æ‰©æ•£æ¨¡å‹å·²è¢«è¯æ˜åœ¨ç”Ÿæˆå›¾åƒæ•°æ®æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚ä½†æ‰©æ•£æ¨¡å‹çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯é€†å‘å»å™ªè¿‡ç¨‹éå¸¸æ…¢ï¼Œå› ä¸ºå®ƒæ˜¯é‡å¤çš„ã€åºåˆ—åŒ–çš„ã€‚æ­¤å¤–ï¼Œè¿™äº›æ¨¡å‹æ¶ˆè€—å¤§é‡å†…å­˜ï¼Œå› ä¸ºå®ƒä»¬åœ¨åƒç´ ç©ºé—´ä¸­æ“ä½œï¼Œè€Œåœ¨ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒæ—¶ï¼Œåƒç´ ç©ºé—´å˜å¾—éå¸¸åºå¤§ã€‚å› æ­¤ï¼Œè®­ç»ƒè¿™äº›æ¨¡å‹å’Œè¿›è¡Œæ¨ç†éƒ½éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ã€‚

æ½œåœ¨æ‰©æ•£é€šè¿‡åœ¨ä½ç»´çš„*æ½œåœ¨*ç©ºé—´ä¸Šåº”ç”¨æ‰©æ•£è¿‡ç¨‹æ¥å‡å°‘å†…å­˜å’Œè®¡ç®—å¤æ‚åº¦ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å®é™…çš„åƒç´ ç©ºé—´ã€‚è¿™æ˜¯æ ‡å‡†æ‰©æ•£æ¨¡å‹ä¸æ½œåœ¨æ‰©æ•£æ¨¡å‹ä¹‹é—´çš„å…³é”®åŒºåˆ«ï¼š**åœ¨æ½œåœ¨æ‰©æ•£ä¸­ï¼Œæ¨¡å‹è¢«è®­ç»ƒç”Ÿæˆå›¾åƒçš„æ½œåœ¨ï¼ˆå‹ç¼©ï¼‰è¡¨ç¤ºã€‚**

æ½œåœ¨æ‰©æ•£ä¸­æœ‰ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼š

1. ä¸€ä¸ªè‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ã€‚
2. ä¸€ä¸ª[U-Net](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb#scrollTo=wW8o1Wp0zRkq)ã€‚
3. ä¸€ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼Œä¾‹å¦‚[CLIPçš„æ–‡æœ¬ç¼–ç å™¨](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)ã€‚

**1. è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰**

VAEæ¨¡å‹æœ‰ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€ä¸ªç¼–ç å™¨å’Œä¸€ä¸ªè§£ç å™¨ã€‚ç¼–ç å™¨ç”¨äºå°†å›¾åƒè½¬æ¢ä¸ºä½ç»´çš„æ½œåœ¨è¡¨ç¤ºï¼Œè¿™å°†ä½œä¸º*U-Net*æ¨¡å‹çš„è¾“å…¥ã€‚
è§£ç å™¨åˆ™å°†æ½œåœ¨è¡¨ç¤ºè½¬åŒ–ä¸ºå›¾åƒã€‚

åœ¨æ½œåœ¨æ‰©æ•£*è®­ç»ƒ*æœŸé—´ï¼Œç¼–ç å™¨ç”¨äºè·å–å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºï¼ˆ_æ½œåœ¨å˜é‡_ï¼‰ï¼Œç”¨äºæ­£å‘æ‰©æ•£è¿‡ç¨‹ï¼Œåœ¨æ¯ä¸€æ­¥ä¸­åŠ å…¥æ›´å¤šçš„å™ªå£°ã€‚åœ¨*æ¨ç†*æœŸé—´ï¼Œé€šè¿‡é€†å‘æ‰©æ•£è¿‡ç¨‹ç”Ÿæˆçš„å»å™ªæ½œåœ¨å˜é‡ç”±VAEè§£ç å™¨è½¬æ¢å›å›¾åƒã€‚æ­£å¦‚æˆ‘ä»¬å°†çœ‹åˆ°çš„ï¼Œåœ¨æ¨ç†æœŸé—´æˆ‘ä»¬**åªéœ€è¦VAEè§£ç å™¨**ã€‚

**2. U-Net**

U-Netçš„ç»“æ„åŒ…æ‹¬ä¸€ä¸ªç¼–ç å™¨éƒ¨åˆ†å’Œä¸€ä¸ªè§£ç å™¨éƒ¨åˆ†ï¼Œä¸¤è€…éƒ½ç”±ResNetå—ç»„æˆã€‚
ç¼–ç å™¨å°†å›¾åƒè¡¨ç¤ºå‹ç¼©ä¸ºè¾ƒä½åˆ†è¾¨ç‡çš„å›¾åƒè¡¨ç¤ºï¼Œè€Œè§£ç å™¨å°†è¾ƒä½åˆ†è¾¨ç‡çš„å›¾åƒè¡¨ç¤ºè§£ç å›åŸå§‹çš„è¾ƒé«˜åˆ†è¾¨ç‡å›¾åƒè¡¨ç¤ºï¼Œå‡å®šå…¶å™ªå£°è¾ƒå°‘ã€‚
æ›´å…·ä½“åœ°è¯´ï¼ŒU-Netçš„è¾“å‡ºé¢„æµ‹äº†å¯ä»¥ç”¨æ¥è®¡ç®—é¢„æµ‹çš„å»å™ªå›¾åƒè¡¨ç¤ºçš„å™ªå£°æ®‹å·®ã€‚

ä¸ºäº†é˜²æ­¢U-Netåœ¨ä¸‹é‡‡æ ·æ—¶ä¸¢å¤±é‡è¦ä¿¡æ¯ï¼Œé€šå¸¸ä¼šåœ¨ç¼–ç å™¨çš„ä¸‹é‡‡æ ·ResNetå—å’Œè§£ç å™¨çš„ä¸Šé‡‡æ ·ResNetå—ä¹‹é—´æ·»åŠ æ·å¾„è¿æ¥ã€‚
æ­¤å¤–ï¼ŒStable Diffusionçš„U-Netèƒ½å¤Ÿé€šè¿‡äº¤å‰æ³¨æ„åŠ›å±‚å°†å…¶è¾“å‡ºä¸æ–‡æœ¬åµŒå…¥è¿›è¡Œæ¡ä»¶åŒ–ã€‚äº¤å‰æ³¨æ„åŠ›å±‚é€šå¸¸åœ¨ç¼–ç å™¨å’Œè§£ç å™¨éƒ¨åˆ†çš„ResNetå—ä¹‹é—´æ·»åŠ ã€‚

**3. æ–‡æœ¬ç¼–ç å™¨**

æ–‡æœ¬ç¼–ç å™¨è´Ÿè´£å°†è¾“å…¥æç¤ºï¼Œä¾‹å¦‚"An astronaut riding a horse"è½¬æ¢ä¸ºU-Netå¯ä»¥ç†è§£çš„åµŒå…¥ç©ºé—´ã€‚å®ƒé€šå¸¸æ˜¯ä¸€ä¸ªç®€å•çš„*åŸºäºå˜æ¢å™¨(transformer-based)çš„*ç¼–ç å™¨ï¼Œç”¨äºå°†è¾“å…¥æ ‡è®°åºåˆ—æ˜ å°„ä¸ºä¸€ç³»åˆ—æ½œåœ¨çš„æ–‡æœ¬åµŒå…¥ã€‚

å—[Imagen](https://imagen.research.google/)å¯å‘ï¼ŒStable Diffusionåœ¨è®­ç»ƒæœŸé—´**ä¸ä¼š**è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„CLIPæ–‡æœ¬ç¼–ç å™¨ï¼Œ[CLIPTextModel](https://huggingface.co/docs/transformers/model_doc/clip#transformers.CLIPTextModel)ã€‚

**ä¸ºä»€ä¹ˆæ½œåœ¨æ‰©æ•£å¿«ä¸”é«˜æ•ˆï¼Ÿ**

ç”±äºæ½œåœ¨æ‰©æ•£åœ¨ä½ç»´ç©ºé—´ä¸­æ“ä½œï¼Œç›¸æ¯”äºåƒç´ ç©ºé—´çš„æ‰©æ•£æ¨¡å‹ï¼Œå®ƒæå¤§åœ°å‡å°‘äº†å†…å­˜å’Œè®¡ç®—éœ€æ±‚ã€‚ä¾‹å¦‚ï¼ŒStable Diffusionä¸­ä½¿ç”¨çš„è‡ªç¼–ç å™¨çš„ç¼©å‡å› å­ä¸º8ã€‚è¿™æ„å‘³ç€å½¢çŠ¶ä¸º`(3, 512, 512)`çš„å›¾åƒåœ¨æ½œåœ¨ç©ºé—´ä¸­å˜ä¸º`(4, 64, 64)`ï¼Œè¿™æ„å‘³ç€ç©ºé—´å‹ç¼©æ¯”ä¸º`8 Ã— 8 = 64`ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå³ä½¿åœ¨16GBçš„Colab GPUä¸Šï¼Œä¹Ÿèƒ½å¦‚æ­¤å¿«é€Ÿåœ°ç”Ÿæˆ`512 Ã— 512`çš„å›¾åƒçš„åŸå› ï¼


**æ¨ç†ä¸­çš„ç¨³å®šæ‰©æ•£**

å°†æ‰€æœ‰éƒ¨åˆ†ç»“åˆèµ·æ¥ï¼Œæˆ‘ä»¬ç°åœ¨æ¥ä»”ç»†çœ‹çœ‹æ¨¡å‹åœ¨æ¨ç†ä¸­çš„å·¥ä½œåŸç†ï¼Œå¹¶é€šè¿‡å±•ç¤ºé€»è¾‘æµç¨‹æ¥è¿›è¡Œè¯´æ˜

<p align="center">
<img src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/stable_diffusion.png" alt="sd-pipeline" width="500"/>
</p>

ç¨³å®šæ‰©æ•£æ¨¡å‹åŒæ—¶æ¥å—ä¸€ä¸ªæ½œåœ¨ç§å­å’Œæ–‡æœ¬æç¤ºä½œä¸ºè¾“å…¥ã€‚ç„¶åä½¿ç”¨æ½œåœ¨ç§å­ç”Ÿæˆå¤§å°ä¸º\\( 64 \times 64 \\)çš„éšæœºæ½œåœ¨å›¾åƒè¡¨ç¤ºï¼Œè€Œæ–‡æœ¬æç¤ºåˆ™é€šè¿‡CLIPçš„æ–‡æœ¬ç¼–ç å™¨è½¬æ¢ä¸ºå¤§å°ä¸º\\( 77 \times 768 \\)çš„æ–‡æœ¬åµŒå…¥ã€‚

æ¥ä¸‹æ¥ï¼ŒU-Netæ¨¡å‹åœ¨æ–‡æœ¬åµŒå…¥çš„æ¡ä»¶ä¸‹ï¼Œé€æ­¥å¯¹éšæœºæ½œåœ¨å›¾åƒè¡¨ç¤ºè¿›è¡Œ*å»å™ª*ã€‚U-Netçš„è¾“å‡ºâ€”â€”å³å™ªå£°æ®‹å·®â€”â€”é€šè¿‡è°ƒåº¦ç®—æ³•è®¡ç®—å‡ºå»å™ªåçš„æ½œåœ¨å›¾åƒè¡¨ç¤ºã€‚å¯ä»¥ä½¿ç”¨å¤šç§ä¸åŒçš„è°ƒåº¦ç®—æ³•æ¥è¿›è¡Œæ­¤è®¡ç®—ï¼Œæ¯ç§ç®—æ³•å„æœ‰ä¼˜ç¼ºç‚¹ã€‚å¯¹äºç¨³å®šæ‰©æ•£ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨ä»¥ä¸‹å‡ ç§è°ƒåº¦å™¨ä¹‹ä¸€ï¼š

- [PNDMè°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_pndm.py)ï¼ˆé»˜è®¤ä½¿ç”¨ï¼‰
- [DDIMè°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_ddim.py)
- [K-LMSè°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/main/src/diffusers/schedulers/scheduling_lms_discrete.py)

å…³äºè°ƒåº¦ç®—æ³•å¦‚ä½•å·¥ä½œçš„ç†è®ºè¶…å‡ºäº†æœ¬ç¬”è®°æœ¬çš„èŒƒå›´ï¼Œä½†ç®€è€Œè¨€ä¹‹ï¼Œåº”è¯¥è®°ä½å®ƒä»¬æ˜¯æ ¹æ®å‰ä¸€ä¸ªå™ªå£°è¡¨ç¤ºå’Œé¢„æµ‹çš„å™ªå£°æ®‹å·®æ¥è®¡ç®—é¢„æµ‹çš„å»å™ªå›¾åƒè¡¨ç¤ºçš„ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œæˆ‘ä»¬å»ºè®®å‚è€ƒ[Elucidating the Design Space of Diffusion-Based Generative Models](https://arxiv.org/abs/2206.00364)ã€‚

*å»å™ª*è¿‡ç¨‹é‡å¤*çº¦*50æ¬¡ï¼Œä»¥é€æ­¥è·å¾—æ›´å¥½çš„æ½œåœ¨å›¾åƒè¡¨ç¤ºã€‚
ä¸€æ—¦å®Œæˆï¼Œæ½œåœ¨å›¾åƒè¡¨ç¤ºå°†ç”±å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨çš„è§£ç å™¨éƒ¨åˆ†è¿›è¡Œè§£ç ã€‚

åœ¨å¯¹æ½œåœ¨æ‰©æ•£å’Œç¨³å®šæ‰©æ•£è¿›è¡Œç®€è¦ä»‹ç»åï¼Œæˆ‘ä»¬æ¥çœ‹å¦‚ä½•é«˜çº§ä½¿ç”¨ğŸ¤— Hugging Face `diffusers`åº“ï¼

## ç¼–å†™è‡ªå·±çš„æ¨ç†ç®¡é“

æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºå¦‚ä½•ä½¿ç”¨`diffusers`åˆ›å»ºè‡ªå®šä¹‰çš„æ‰©æ•£ç®¡é“ã€‚
ç¼–å†™è‡ªå®šä¹‰æ¨ç†ç®¡é“æ˜¯`diffusers`åº“çš„é«˜çº§ç”¨æ³•ï¼Œå¯ä»¥ç”¨äºæ›¿æ¢æŸäº›ç»„ä»¶ï¼Œä¾‹å¦‚ä¸Šé¢æåˆ°çš„VAEæˆ–è°ƒåº¦å™¨ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ä¸åŒçš„è°ƒåº¦å™¨ï¼Œå³[Katherine Crowson's](https://github.com/crowsonkb) K-LMSè°ƒåº¦å™¨ï¼Œè¯¥è°ƒåº¦å™¨å·²åœ¨[æ­¤PR](https://github.com/huggingface/diffusers/pull/185)ä¸­æ·»åŠ ã€‚

[é¢„è®­ç»ƒæ¨¡å‹](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/main)åŒ…å«è®¾ç½®å®Œæ•´æ‰©æ•£ç®¡é“æ‰€éœ€çš„æ‰€æœ‰ç»„ä»¶ã€‚å®ƒä»¬å­˜å‚¨åœ¨ä»¥ä¸‹æ–‡ä»¶å¤¹ä¸­ï¼š
- `text_encoder`: ç¨³å®šæ‰©æ•£ä½¿ç”¨CLIPï¼Œä½†å…¶ä»–æ‰©æ•£æ¨¡å‹å¯èƒ½ä½¿ç”¨å…¶ä»–ç¼–ç å™¨ï¼Œå¦‚`BERT`ã€‚
- `tokenizer`: å¿…é¡»ä¸`text_encoder`æ¨¡å‹æ‰€ä½¿ç”¨çš„åˆ†è¯å™¨ç›¸åŒ¹é…ã€‚
- `scheduler`: åœ¨è®­ç»ƒæœŸé—´ç”¨äºé€æ¸å‘å›¾åƒæ·»åŠ å™ªå£°çš„è°ƒåº¦ç®—æ³•ã€‚
- `unet`: ç”¨äºç”Ÿæˆè¾“å…¥çš„æ½œåœ¨è¡¨ç¤ºçš„æ¨¡å‹ã€‚
- `vae`: æˆ‘ä»¬å°†ç”¨æ¥å°†æ½œåœ¨è¡¨ç¤ºè§£ç ä¸ºçœŸå®å›¾åƒçš„è‡ªåŠ¨ç¼–ç å™¨æ¨¡å—ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡å¼•ç”¨ä¿å­˜å®ƒä»¬çš„æ–‡ä»¶å¤¹æ¥åŠ è½½ç»„ä»¶ï¼Œä½¿ç”¨`from_pretrained`ä¸­çš„`subfolder`å‚æ•°ã€‚

```python
from transformers import CLIPTextModel, CLIPTokenizer
from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler

# 1. åŠ è½½è‡ªåŠ¨ç¼–ç å™¨æ¨¡å‹ï¼Œå°†ç”¨æ¥å°†æ½œåœ¨è¡¨ç¤ºè§£ç ä¸ºå›¾åƒç©ºé—´ã€‚
vae = AutoencoderKL.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="vae")

# 2. åŠ è½½åˆ†è¯å™¨å’Œæ–‡æœ¬ç¼–ç å™¨ï¼Œä»¥å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯å’Œç¼–ç ã€‚
tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-large-patch14")
text_encoder = CLIPTextModel.from_pretrained("openai/clip-vit-large-patch14")

# 3. ç”¨äºç”Ÿæˆæ½œåœ¨å˜é‡çš„UNetæ¨¡å‹ã€‚
unet = UNet2DConditionModel.from_pretrained("CompVis/stable-diffusion-v1-4", subfolder="unet")
```

æˆ‘ä»¬åŠ è½½å¸¦æœ‰é€‚é…å‚æ•°çš„[K-LMSè°ƒåº¦å™¨](https://github.com/huggingface/diffusers/blob/71ba8aec55b52a7ba5a1ff1db1265ffdd3c65ea2/src/diffusers/schedulers/scheduling_lms_discrete.py#L26)è€Œä¸æ˜¯åŠ è½½é¢„å®šä¹‰çš„è°ƒåº¦å™¨ã€‚

```python
from diffusers import LMSDiscreteScheduler

scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule="scaled_linear", num_train_timesteps=1000)
```

æ¥ä¸‹æ¥ï¼Œå°†æ¨¡å‹ç§»åŠ¨åˆ°GPUä¸Šã€‚

```python
torch_device = "cuda"
vae.to(torch_device)
text_encoder.to(torch_device)
unet.to(torch_device) 
```

ç°åœ¨æˆ‘ä»¬å®šä¹‰ç”Ÿæˆå›¾åƒæ—¶è¦ä½¿ç”¨çš„å‚æ•°ã€‚

è¯·æ³¨æ„ï¼Œ`guidance_scale`ä¸[Imagenè®ºæ–‡](https://arxiv.org/pdf/2205.11487.pdf)ä¸­çš„æ–¹ç¨‹(2)ä¸­çš„æŒ‡å¯¼æƒé‡`w`ç±»ä¼¼ã€‚`guidance_scale == 1`è¡¨ç¤ºä¸è¿›è¡Œåˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼ã€‚è¿™é‡Œæˆ‘ä»¬å°†å…¶è®¾ç½®ä¸º7.5ï¼Œå°±åƒä¹‹å‰ä¸€æ ·ã€‚

ä¸ä¹‹å‰çš„ä¾‹å­ç›¸æ¯”ï¼Œæˆ‘ä»¬å°†`num_inference_steps`è®¾ç½®ä¸º100ï¼Œä»¥è·å¾—æ›´æ¸…æ™°çš„å›¾åƒã€‚

```python
prompt = ["a photograph of an astronaut riding a horse"]

height = 512 # ç¨³å®šæ‰©æ•£çš„é»˜è®¤é«˜åº¦
width = 512 # ç¨³å®šæ‰©æ•£çš„é»˜è®¤å®½åº¦

num_inference_steps = 100 # å»å™ªæ­¥éª¤æ•°

guidance_scale = 7.5 # åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼çš„æ¯”ä¾‹

generator = torch.manual_seed(0) # ç”¨äºåˆ›å»ºåˆå§‹æ½œåœ¨å™ªå£°çš„ç§å­ç”Ÿæˆå™¨

batch_size = len(prompt)
```

é¦–å…ˆï¼Œæˆ‘ä»¬ä¸ºä¼ é€’çš„æç¤ºè·å–`text_embeddings`ã€‚è¿™äº›åµŒå…¥å°†ç”¨äºæ¡ä»¶UNetæ¨¡å‹ï¼Œå¹¶å¼•å¯¼å›¾åƒç”Ÿæˆæ¥è¿‘è¾“å…¥æç¤ºã€‚

```python
text_input = tokenizer(prompt, padding="max_length", max_length=tokenizer.model_max_length, truncation=True, return_tensors="pt")

text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]
```

æˆ‘ä»¬è¿˜å°†ä¸ºåˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼è·å–æ— æ¡ä»¶çš„æ–‡æœ¬åµŒå…¥ï¼Œå³å¡«å……æ ‡è®°ï¼ˆç©ºæ–‡æœ¬ï¼‰çš„åµŒå…¥ã€‚å®ƒä»¬éœ€è¦å…·æœ‰ä¸æ¡ä»¶`text_embeddings`ç›¸åŒçš„å½¢çŠ¶ï¼ˆ`batch_size`å’Œ`seq_length`ï¼‰ã€‚

```python
max_length = text_input.input_ids.shape[-1]
uncond_input = tokenizer(
    [""] * batch_size, padding="max_length", max_length=max_length, return_tensors="pt"
)
uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]   
```

å¯¹äºåˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼ï¼Œæˆ‘ä»¬éœ€è¦æ‰§è¡Œä¸¤æ¬¡å‰å‘ä¼ é€’ï¼šä¸€æ¬¡ä½¿ç”¨æ¡ä»¶è¾“å…¥ï¼ˆ`text_embeddings`ï¼‰ï¼Œå¦ä¸€æ¬¡ä½¿ç”¨æ— æ¡ä»¶åµŒå…¥ï¼ˆ`uncond_embeddings`ï¼‰ã€‚å®é™…ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸¤è€…è¿æ¥æˆä¸€ä¸ªæ‰¹æ¬¡ï¼Œä»¥é¿å…è¿›è¡Œä¸¤æ¬¡å‰å‘ä¼ é€’ã€‚


```python
text_embeddings = torch.cat([uncond_embeddings, text_embeddings])
```

æ¥ä¸‹æ¥ï¼Œç”Ÿæˆåˆå§‹éšæœºå™ªå£°ã€‚

```python
latents = torch.randn(
    (batch_size, unet.in_channels, height // 8, width // 8),
    generator=generator,
)
latents = latents.to(torch_device)
```

å¦‚æœæ­¤æ—¶æ£€æŸ¥`latents`ï¼Œæˆ‘ä»¬ä¼šå‘ç°å®ƒä»¬çš„å½¢çŠ¶ä¸º`torch.Size([1, 4, 64, 64])`ï¼Œæ¯”æˆ‘ä»¬è¦ç”Ÿæˆçš„å›¾åƒå°å¾—å¤šã€‚ç¨åæ¨¡å‹å°†æŠŠè¿™ç§æ½œåœ¨è¡¨ç¤ºï¼ˆçº¯å™ªå£°ï¼‰è½¬æ¢ä¸º`512 Ã— 512`å›¾åƒã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨æ‰€é€‰çš„`num_inference_steps`åˆå§‹åŒ–è°ƒåº¦å™¨ã€‚
è¿™å°†è®¡ç®—å»å™ªè¿‡ç¨‹ä¸­ä½¿ç”¨çš„`sigma`å’Œç¡®åˆ‡æ—¶é—´æ­¥å€¼ã€‚

```python
scheduler.set_timesteps(num_inference_steps)
```

K-LMSè°ƒåº¦å™¨éœ€è¦å°†`latents`ä¹˜ä»¥å…¶`sigma`å€¼ã€‚è®©æˆ‘ä»¬åœ¨æ­¤è¿›è¡Œæ“ä½œï¼š


```python
latents = latents * scheduler.init_noise_sigma
```

æˆ‘ä»¬å·²å‡†å¤‡å¥½ç¼–å†™å»å™ªå¾ªç¯ã€‚


```python
from tqdm.auto import tqdm

scheduler.set_timesteps(num_inference_steps)

for t in tqdm(scheduler.timesteps):
# å¦‚æœæˆ‘ä»¬æ­£åœ¨è¿›è¡Œåˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼ï¼Œåˆ™æ‰©å±•æ½œåœ¨å˜é‡ï¼Œä»¥é¿å…è¿›è¡Œä¸¤æ¬¡å‰å‘ä¼ é€’ã€‚
latent_model_input = torch.cat([latents] * 2)

latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)

# é¢„æµ‹å™ªå£°æ®‹å·®
with torch.no_grad():
noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample

# è¿›è¡Œåˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼
noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)
noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)

# è®¡ç®—å»å™ªå›¾åƒçš„éšç©ºé—´è¡¨ç¤º
latents = scheduler.step(noise_pred, t, latents).prev_sample 
```

ä»£ç æ‰§è¡Œåï¼Œæ½œåœ¨å˜é‡`latents`åº”è¯¥ä¸å†åªæ˜¯å™ªå£°ï¼Œè€Œæ˜¯å»å™ªåæ½œåœ¨å›¾åƒçš„è¡¨ç¤ºã€‚

åœ¨å»å™ªå¾ªç¯ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä»æ½œåœ¨ç©ºé—´è§£ç å›¾åƒã€‚


```python
# å°†æ½œåœ¨å˜é‡ç¼©æ”¾å›å»ã€‚
latents = 1 / 0.18215 * latents
with torch.no_grad():
    image = vae.decode(latents).sample
```

æœ€åï¼Œå°†è§£ç çš„å›¾åƒè½¬æ¢ä¸ºåƒç´ å€¼ï¼Œå¹¶æ˜¾ç¤ºå®ƒä»¬ã€‚

```python
image = (image / 2 + 0.5).clamp(0, 1)
image = image.detach().cpu().permute(0, 2, 3, 1).numpy()
images = (image * 255).round().astype("uint8")
pil_images = [Image.fromarray(image) for image in images]
pil_images[0]
```

![png](assets/98_stable_diffusion/stable_diffusion_k_lms.png)

æˆ‘ä»¬å·²ç»ä»ä½¿ç”¨ ğŸ¤— Hugging Face Diffusers çš„ Stable Diffusion åŸºç¡€åº”ç”¨ï¼Œé€æ­¥æ·±å…¥åˆ°äº†æ›´é«˜çº§çš„ç”¨æ³•ï¼Œå¹¶å°è¯•ä»‹ç»ç°ä»£æ‰©æ•£ç³»ç»Ÿçš„å„ä¸ªç»„æˆéƒ¨åˆ†ã€‚å¦‚æœä½ å¯¹è¿™ä¸ªä¸»é¢˜æ„Ÿå…´è¶£å¹¶æƒ³äº†è§£æ›´å¤šå†…å®¹ï¼Œæˆ‘ä»¬æ¨èä»¥ä¸‹èµ„æºï¼š

- æˆ‘ä»¬çš„ [Colab notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb) æä¾›äº†æœ‰å…³ Stable Diffusion çš„å®è·µç»ƒä¹ ã€‚
- [Diffusers å…¥é—¨æŒ‡å—](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb) çš„ notebookï¼Œæ¦‚è¿°äº†æ‰©æ•£ç³»ç»Ÿçš„åŸºæœ¬çŸ¥è¯†ã€‚
- [Annotated Diffusion Model](https://huggingface.co/blog/annotated-diffusion) åšå®¢æ–‡ç« ã€‚
- æˆ‘ä»¬çš„ [GitHub ä»£ç ](https://github.com/huggingface/diffusers)ï¼Œå¦‚æœä½ è§‰å¾— `diffusers` å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæˆ‘ä»¬ä¼šå¾ˆé«˜å…´æ”¶åˆ°ä½ çš„ â­ ï¼

### Citation:
```
@article{patil2022stable,
  author = {Patil, Suraj and Cuenca, Pedro and Lambert, Nathan and von Platen, Patrick},
  title = {Stable Diffusion with ğŸ§¨ Diffusers},
  journal = {Hugging Face Blog},
  year = {2022},
  note = {[https://huggingface.co/blog/rlhf](https://huggingface.co/blog/stable_diffusion)},
}
```
