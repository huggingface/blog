---
title: "ä½¿ç”¨ ğŸ¤— Transformers ä¼˜åŒ– Bark" 
thumbnail: /blog/assets/bark_optimization/thumbnail.png
authors:
- user: ylacombe
translators:
- user: MatrixYao
- user: zhongdongy
  proofreader: true
---

# ä½¿ç”¨ ğŸ¤— Transformers ä¼˜åŒ–æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹ Bark


<a target="_blank" href="https://colab.research.google.com/github/ylacombe/notebooks/blob/main/Benchmark_Bark_HuggingFace.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg"/>
</a>

ğŸ¤— Transformers æä¾›äº†è®¸å¤šæœ€æ–°æœ€å…ˆè¿› (state-of-the-artï¼ŒSoTA) çš„æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹æ¨ªè·¨å¤šä¸ªé¢†åŸŸåŠä»»åŠ¡ã€‚ä¸ºäº†ä½¿è¿™äº›æ¨¡å‹èƒ½ä»¥æœ€ä½³æ€§èƒ½è¿è¡Œï¼Œæˆ‘ä»¬éœ€è¦ä¼˜åŒ–å…¶æ¨ç†é€Ÿåº¦åŠå†…å­˜ä½¿ç”¨ã€‚

ğŸ¤— Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸ºæ»¡è¶³ä¸Šè¿°éœ€æ±‚æä¾›äº†ç°æˆä¸”æ˜“äºä½¿ç”¨çš„ä¼˜åŒ–å·¥å…·ï¼Œè¿™äº›å·¥å…·å¯åº”ç”¨äºåº“ä¸­çš„æ‰€æœ‰æ¨¡å‹ã€‚ç”¨æˆ·åªéœ€æ·»åŠ å‡ è¡Œä»£ç å°±å¯ä»¥è½»æ¾ **å‡å°‘å†…å­˜å ç”¨** å¹¶ **æé«˜æ¨ç†é€Ÿåº¦**ã€‚

åœ¨æœ¬å®æˆ˜æ•™ç¨‹ä¸­ï¼Œæˆ‘å°†æ¼”ç¤ºå¦‚ä½•ç”¨ä¸‰ä¸ªç®€å•çš„ä¼˜åŒ–æŠ€å·§æ¥ä¼˜åŒ– [Bark](https://huggingface.co/docs/transformers/main/en/model_doc/bark#overview) æ¨¡å‹ã€‚Bark æ˜¯ğŸ¤— Transformers æ”¯æŒçš„ä¸€ä¸ªæ–‡æœ¬è½¬è¯­éŸ³ (Text-To-Speechï¼ŒTTS) æ¨¡å‹ã€‚æ‰€æœ‰ä¼˜åŒ–ä»…ä¾èµ–äº [Transformers](https://github.com/huggingface/transformers)ã€[Optimum](https://github.com/huggingface/optimum) ä»¥åŠ [Accelerate](https://github.com/huggingface/accelerate) è¿™ä¸‰ä¸ª ğŸ¤— ç”Ÿæ€ç³»ç»Ÿåº“ã€‚

æœ¬æ•™ç¨‹è¿˜æ¼”ç¤ºäº†å¦‚ä½•å¯¹æ¨¡å‹åŠå…¶ä¸åŒçš„ä¼˜åŒ–æ–¹æ¡ˆè¿›è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•ã€‚

æœ¬æ–‡å¯¹åº”çš„ Google Colab åœ¨ [æ­¤](https://colab.research.google.com/github/ylacombe/notebooks/blob/main/Benchmark_Bark_HuggingFace.ipynb)ã€‚

æœ¬æ–‡ç»“æ„å¦‚ä¸‹:

## ç›®å½•

1. Bark æ¨¡å‹ [ç®€ä»‹](#bark-æ¨¡å‹æ¶æ„)
2. ä¸åŒä¼˜åŒ–æŠ€å·§åŠå…¶ä¼˜ç‚¹ [æ¦‚è¿°](#ä¼˜åŒ–æŠ€æœ¯)
3. åŸºå‡†æµ‹è¯•ç»“æœ [å±•ç¤º](#åŸºå‡†æµ‹è¯•ç»“æœ)

# Bark æ¨¡å‹æ¶æ„

**Bark** æ˜¯ Suno AI æå‡ºçš„åŸºäº transformer çš„ TTS æ¨¡å‹ï¼Œå…¶åŸå§‹ä»£ç åº“ä¸º [suno-ai/bark](https://github.com/suno-ai/bark)ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå„ç§éŸ³é¢‘è¾“å‡ºï¼ŒåŒ…æ‹¬è¯­éŸ³ã€éŸ³ä¹ã€èƒŒæ™¯å™ªéŸ³ä»¥åŠç®€å•çš„éŸ³æ•ˆã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¯ä»¥äº§ç”Ÿéè¯­è¨€è¯­éŸ³ï¼Œå¦‚ç¬‘å£°ã€å¹æ¯å£°å’ŒæŠ½æ³£å£°ç­‰ã€‚

è‡ª v4.31.0 èµ·ï¼ŒBark å·²é›†æˆå…¥ ğŸ¤— Transformersï¼

ä½ å¯ä»¥é€šè¿‡ [è¿™ä¸ª notebook](https://colab.research.google.com/github/ylacombe/notebooks/blob/main/Bark_HuggingFace_Demo.ipynb) è¯•è¯• Bark å¹¶æ¢ç´¢å…¶åŠŸèƒ½ã€‚

Bark ä¸»è¦ç”± 4 ä¸ªæ¨¡å‹ç»„æˆ:

- `BarkSemanticModel` (ä¹Ÿç§°ä¸º **æ–‡æœ¬** æ¨¡å‹): ä¸€ä¸ªå› æœè‡ªå›å½’ transformer æ¨¡å‹ï¼Œå…¶è¾“å…¥ä¸ºåˆ†è¯åçš„è¯å…ƒåºåˆ—ï¼Œå¹¶è¾“å‡ºèƒ½æ•è·æ–‡ä¹‰çš„è¯­ä¹‰è¯å…ƒã€‚
- `BarkCoarseModel` (ä¹Ÿç§°ä¸º **ç²—å£°å­¦** æ¨¡å‹): ä¸€ä¸ªå› æœè‡ªå›å½’ transformer æ¨¡å‹ï¼Œå…¶æ¥æ”¶ `BarkSemanticModel` æ¨¡å‹çš„è¾“å‡ºï¼Œå¹¶æ®æ­¤é¢„æµ‹ EnCodec æ‰€éœ€çš„å‰ä¸¤ä¸ªéŸ³é¢‘ç æœ¬ã€‚
- `BarkFineModel` (ä¹Ÿç§°ä¸º **ç»†å£°å­¦** æ¨¡å‹)ï¼Œè¿™æ¬¡æ˜¯ä¸ªéå› æœè‡ªç¼–ç å™¨ transformer æ¨¡å‹ï¼Œå®ƒå¯¹ _å…ˆå‰ç æœ¬çš„åµŒå…¥å’Œ_ è¿›è¡Œè¿­ä»£ï¼Œä»è€Œç”Ÿæˆæœ€åä¸€ä¸ªç æœ¬ã€‚
- åœ¨ [`EncodecModel`](https://huggingface.co/docs/transformers/v4.31.0/model_doc/encodec) çš„ç¼–ç å™¨éƒ¨åˆ†é¢„æµ‹å‡ºæ‰€æœ‰ç æœ¬é€šé“åï¼ŒBark ç»§ç»­ç”¨å…¶è§£ç å™¨æ¥è§£ç å¹¶è¾“å‡ºéŸ³é¢‘åºåˆ—ã€‚

æˆªè‡³æœ¬æ–‡æ’°å†™æ—¶ï¼Œå…±æœ‰ä¸¤ä¸ª Bark checkpoint å¯ç”¨ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯ [å°ç‰ˆ](https://huggingface.co/suno/bark-small)ï¼Œä¸€ä¸ªæ˜¯ [å¤§ç‰ˆ](https://huggingface.co/suno/bark)ã€‚

## åŠ è½½æ¨¡å‹åŠå…¶å¤„ç†å™¨

é¢„è®­ç»ƒçš„ Bark [å° checkpoint](https://huggingface.co/suno/bark-small) å’Œ [å¤§ checkpoint]((https://huggingface.co/suno/bark)) å‡å¯ä» Hugging Face Hub ä¸ŠåŠ è½½ã€‚ä½ å¯æ ¹æ®å®é™…éœ€è¦åŠ è½½ç›¸åº”çš„ repo-idã€‚

ä¸ºäº†ä½¿å®éªŒè¿è¡Œèµ·æ¥å¿«ç‚¹ï¼Œæˆ‘ä»¬é»˜è®¤ä½¿ç”¨å° checkpointï¼Œå³ `â€œsuno/bark-smallâ€` ã€‚ä½†ä½ å¯ä»¥éšæ„æ”¹æˆ `â€œsuno/barkâ€` æ¥å°è¯•å¤§ checkpointã€‚

```python
from transformers import BarkModel

model = BarkModel.from_pretrained("suno/bark-small")
```

å°†æ¨¡å‹æ”¾åˆ°åŠ é€Ÿå™¨ä¸Šä»¥ä¼˜åŒ–å…¶é€Ÿåº¦:

```python
import torch

device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = model.to(device)
```

åŠ è½½å¤„ç†å™¨ï¼Œå®ƒä¸»è¦å¤„ç†åˆ†è¯ä»¥åŠè¯´è¯äººåµŒå…¥ (è‹¥æœ‰)ã€‚

```python
from transformers import AutoProcessor

processor = AutoProcessor.from_pretrained("suno/bark-small")
```

# ä¼˜åŒ–æŠ€å·§

æœ¬èŠ‚ï¼Œæˆ‘ä»¬å°†æ¢ç´¢å¦‚ä½•ä½¿ç”¨ ğŸ¤— Optimum å’Œ ğŸ¤— Accelerate åº“ä¸­çš„ç°æˆåŠŸèƒ½æ¥ä»¥æœ€å°‘çš„ä»£ç æ”¹åŠ¨è¾¾åˆ°ä¼˜åŒ– Bark æ¨¡å‹çš„ç›®çš„ã€‚

## è®¾ç½®å®éªŒç¯å¢ƒ

é¦–å…ˆï¼Œæˆ‘ä»¬å‡†å¤‡ä¸€ä¸ªè¾“å…¥æ–‡æœ¬å¹¶å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æµ‹é‡ Bark ç”Ÿæˆè¿‡ç¨‹çš„å»¶è¿ŸåŠå…¶ GPU æ˜¾å­˜å ç”¨æƒ…å†µã€‚

```python
text_prompt = "Let's try generating speech, with Bark, a text-to-speech model"
inputs = processor(text_prompt).to(device)
```

æµ‹é‡å»¶è¿Ÿå’Œ GPU å†…å­˜å ç”¨éœ€è¦ä½¿ç”¨ç‰¹å®šçš„ CUDA å‡½æ•°ã€‚æˆ‘ä»¬å®ç°äº†ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼Œç”¨äºæµ‹é‡æ¨¡å‹çš„æ¨ç†å»¶è¿ŸåŠ GPU å†…å­˜å ç”¨ã€‚ä¸ºäº†ç¡®ä¿ç»“æœçš„å‡†ç¡®æ€§ï¼Œæ¯æ¬¡æµ‹é‡æˆ‘ä»¬ä¼šè¿è¡Œ `nb_loops` æ¬¡æ±‚å‡å€¼:

```python
import torch
from transformers import set_seed

def measure_latency_and_memory_use(model, inputs, nb_loops = 5):

  # define Events that measure start and end of the generate pass
  start_event = torch.cuda.Event(enable_timing=True)
  end_event = torch.cuda.Event(enable_timing=True)

  # reset cuda memory stats and empty cache
  torch.cuda.reset_peak_memory_stats(device)
  torch.cuda.empty_cache()
  torch.cuda.synchronize()

  # get the start time
  start_event.record()

  # actually generate
  for _ in range(nb_loops):
        # set seed for reproducibility
        set_seed(0)
        output = model.generate(**inputs, do_sample = True, fine_temperature = 0.4, coarse_temperature = 0.8)

  # get the end time
  end_event.record()
  torch.cuda.synchronize()

  # measure memory footprint and elapsed time
  max_memory = torch.cuda.max_memory_allocated(device)
  elapsed_time = start_event.elapsed_time(end_event)* 1.0e-3

  print('Execution time:', elapsed_time/nb_loops, 'seconds')
  print('Max memory footprint', max_memory*1e-9, ' GB')

  return output
```

## åŸºçº¿

åœ¨ä¼˜åŒ–ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæµ‹é‡ä¸‹æ¨¡å‹çš„åŸºçº¿æ€§èƒ½å¹¶å¬ä¸€ä¸‹ç”Ÿæˆçš„éŸ³é¢‘ï¼Œæˆ‘ä»¬æµ‹é‡äº”æ¬¡å¹¶æ±‚å‡å€¼:

```python

with torch.inference_mode():
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)
```

**è¾“å‡º:**

```
Execution time: 9.3841625 seconds
Max memory footprint 1.914612224 GB
```

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥æ’­æ”¾ä¸€ä¸‹è¾“å‡ºéŸ³é¢‘:

```python
from IPython.display import Audio

# now, listen to the output
sampling_rate = model.generation_config.sample_rate
Audio(speech_output[0].cpu().numpy(), rate=sampling_rate)
```

æŒ‰ä¸‹é¢çš„æ’­æ”¾é”®å¬ä¸€ä¸‹å§ ([ä¸‹è½½è¯¥éŸ³é¢‘æ–‡ä»¶](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_base.wav)):

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_base.wav" type="audio/wav">
å½“å‰æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

### é‡è¦è¯´æ˜

ä¸Šä¾‹ä¸­è¿è¡Œæ¬¡æ•°è¾ƒå°‘ã€‚ä¸ºäº†æµ‹é‡å’Œåç»­å¯¹æ¯”çš„å‡†ç¡®æ€§ï¼Œè¿è¡Œæ¬¡æ•°éœ€è¦å¢åŠ åˆ°è‡³å°‘ 100ã€‚

å¢åŠ  `nb_loops` ä¸€ä¸ªä¸»è¦åŸå› æ˜¯ï¼ŒåŒä¸€è¾“å…¥çš„å¤šæ¬¡è¿è¡Œæ‰€ç”Ÿæˆçš„è¯­éŸ³é•¿åº¦å·®å¼‚ä¹Ÿå¾ˆå¤§ã€‚å› æ­¤å½“è¿è¡Œæ¬¡æ•°è¾ƒå°‘æ—¶ï¼Œæœ‰å¯èƒ½é€šè¿‡ `measure_latency_and_memory_use` æµ‹å‡ºçš„å»¶è¿Ÿå¹¶ä¸èƒ½åæ˜ å‡ºä¼˜åŒ–æ–¹æ³•çš„å®é™…æ€§èƒ½ï¼æ–‡æœ«çš„åŸºå‡†æµ‹è¯•å–çš„æ˜¯ 100 æ¬¡è¿è¡Œçš„å‡å€¼ï¼Œç”¨ä»¥é€¼è¿‘æ¨¡å‹çš„çœŸå®æ€§èƒ½ã€‚

## 1. ğŸ¤— Better Transformer

Better Transformer æ˜¯  ğŸ¤— Optimum çš„ä¸€ä¸ªåŠŸèƒ½ï¼Œå®ƒå¯ä»¥å¸®åŠ©åœ¨åå°æ‰§è¡Œç®—å­èåˆã€‚è¿™æ„å‘³ç€æ¨¡å‹çš„æŸäº›æ“ä½œåœ¨ GPU ä¸Šçš„æ€§èƒ½å°†ä¼šå¾—åˆ°è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œä»è€ŒåŠ é€Ÿæ¨¡å‹çš„æœ€ç»ˆè¿è¡Œé€Ÿåº¦ã€‚

å†å…·ä½“ä¸€ç‚¹ï¼ŒğŸ¤— Transformers æ”¯æŒçš„å¤§å¤šæ•°æ¨¡å‹éƒ½ä¾èµ–äºæ³¨æ„åŠ›ï¼Œè¿™ä½¿å¾—æ¨¡å‹åœ¨ç”Ÿæˆè¾“å‡ºæ—¶å¯ä»¥é€‰æ‹©æ€§åœ°å…³æ³¨è¾“å…¥çš„æŸäº›éƒ¨åˆ†ï¼Œå› è€Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†è¿œç¨‹ä¾èµ–å…³ç³»å¹¶æ•è·æ•°æ®ä¸­å¤æ‚çš„ä¸Šä¸‹æ–‡å…³ç³»ã€‚

Dao ç­‰äººäº 2022 å¹´æå‡ºäº†ä¸€é¡¹åä¸º [Flash Attention](https://arxiv.org/abs/2205.14135) çš„æŠ€æœ¯ï¼Œæå¤§åœ°ä¼˜åŒ–äº†æœ´ç´ æ³¨æ„åŠ›çš„æ€§èƒ½ã€‚

Flash Attention æ˜¯ä¸€ç§æ›´å¿«ã€æ›´é«˜æ•ˆçš„æ³¨æ„åŠ›ç®—æ³•ï¼Œå®ƒå·§å¦™åœ°ç»“åˆäº†ä¸€äº›ä¼ ç»Ÿæ–¹æ³• (å¦‚å¹³é“ºå’Œé‡è®¡ç®—)ï¼Œä»¥æœ€å¤§é™åº¦åœ°å‡å°‘å†…å­˜ä½¿ç”¨å¹¶æé«˜é€Ÿåº¦ã€‚ä¸ä¹‹å‰çš„ç®—æ³•ä¸åŒï¼ŒFlash Attention å°†å†…å­˜ä½¿ç”¨é‡ä»ä¸åºåˆ—é•¿åº¦å‘ˆå¹³æ–¹å…³ç³»é™ä½åˆ°çº¿æ€§å…³ç³»ï¼Œè¿™å¯¹å…³æ³¨å†…å­˜æ•ˆç‡çš„åº”ç”¨å°¤å…¶é‡è¦ã€‚

ğŸ¤— Better Transformer å¯ä»¥å¼€ç®±å³ç”¨åœ°æ”¯æŒ Flash Attentionï¼åªéœ€ä¸€è¡Œä»£ç å³å¯å°†æ¨¡å‹å¯¼å‡ºåˆ° ğŸ¤— Better Transformer å¹¶å¯ç”¨ Flash Attention:

```python
model =  model.to_bettertransformer()

with torch.inference_mode():
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)
```

**è¾“å‡º:**

```
Execution time: 5.43284375 seconds
Max memory footprint 1.9151841280000002 GB
```

æŒ‰ä¸‹é¢çš„æ’­æ”¾é”®å¬ä¸€ä¸‹è¾“å‡ºå§ ([ä¸‹è½½è¯¥éŸ³é¢‘æ–‡ä»¶](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_bettertransformer.wav)):

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_bettertransformer.wav" type="audio/wav">
å½“å‰æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

**åˆ©å¼Š**

æ•ˆæœä¸ä¼šä¸‹é™ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥è·å¾—ä¸åŸºçº¿ç‰ˆæœ¬å®Œå…¨ç›¸åŒçš„ç»“æœï¼ŒåŒæ—¶æé€Ÿ 20% åˆ° 30%ï¼æƒ³è¦äº†è§£æ›´å¤šæœ‰å…³ Better Transformer çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æ­¤ [åšæ–‡](https://pytorch.org/blog/out-of-the-box-acceleration/)ã€‚

## 2. åŠç²¾åº¦

å¤§å¤šæ•°äººå·¥æ™ºèƒ½æ¨¡å‹é€šå¸¸ä½¿ç”¨ç§°ä¸ºå•ç²¾åº¦æµ®ç‚¹çš„å­˜å‚¨æ ¼å¼ï¼Œå³ `fp32` ï¼Œè¿™åœ¨å®è·µä¸­æ„å‘³ç€æ¯ä¸ªæ•°éƒ½ç”¨ 32 æ¯”ç‰¹æ¥å­˜å‚¨ã€‚

ä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä½¿ç”¨ 16 æ¯”ç‰¹å¯¹æ¯ä¸ªæ•°è¿›è¡Œç¼–ç ï¼Œå³æ‰€è°“çš„åŠç²¾åº¦æµ®ç‚¹ï¼Œå³ `fp16` (è¯‘è€…æ³¨: æˆ– `bf16` )ï¼Œè¿™æ—¶æ¯ä¸ªæ•°å ç”¨çš„å­˜å‚¨ç©ºé—´å°±å˜æˆäº†åŸæ¥çš„ä¸€åŠï¼é™¤æ­¤ä»¥å¤–ï¼Œä½ è¿˜å¯ä»¥è·å¾—è®¡ç®—ä¸Šçš„åŠ é€Ÿï¼

ä½†å¤©ä¸‹æ²¡æœ‰å…è´¹çš„åˆé¤ï¼ŒåŠç²¾åº¦ä¼šå¸¦æ¥è¾ƒå°çš„æ•ˆæœä¸‹é™ï¼Œå› ä¸ºæ¨¡å‹å†…éƒ¨çš„æ“ä½œä¸å¦‚ `fp32` ç²¾ç¡®äº†ã€‚

ä½ å¯ä»¥é€šè¿‡ç®€å•åœ°åœ¨ `BarkModel.from_pretrained(...)` çš„å…¥å‚ä¸­æ·»åŠ  `torch_dtype=torch.float16` æ¥å°† Transformers æ¨¡å‹åŠ è½½ä¸ºåŠç²¾åº¦ï¼

ä»£ç å¦‚ä¸‹:

```python
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16).to(device)

with torch.inference_mode():
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)
```

**è¾“å‡º:**

```
Execution time: 7.00045390625 seconds
Max memory footprint 2.7436124160000004 GB
```

ç…§ä¾‹ï¼ŒæŒ‰ä¸‹é¢çš„æ’­æ”¾é”®å¬ä¸€ä¸‹è¾“å‡ºå§ ([ä¸‹è½½è¯¥éŸ³é¢‘æ–‡ä»¶](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_fp16.wav)):

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_fp16.wav" type="audio/wav">
å½“å‰æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

**åˆ©å¼Š**

è™½ç„¶æ•ˆæœç•¥æœ‰ä¸‹é™ï¼Œä½†å†…å­˜å ç”¨é‡å‡å°‘äº† 50%ï¼Œé€Ÿåº¦æé«˜äº† 5%ã€‚

## 3. CPU å¸è½½

æ­£å¦‚æœ¬æ–‡ç¬¬ä¸€éƒ¨åˆ†æ‰€è¿°ï¼ŒBark åŒ…å« 4 ä¸ªå­æ¨¡å‹ï¼Œè¿™äº›å­æ¨¡å‹åœ¨éŸ³é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­æŒ‰åºè°ƒç”¨ã€‚ **æ¢å¥è¯è¯´ï¼Œå½“ä¸€ä¸ªå­æ¨¡å‹æ­£åœ¨ä½¿ç”¨æ—¶ï¼Œå…¶ä»–å­æ¨¡å‹å¤„äºç©ºé—²çŠ¶æ€ã€‚**

ä¸ºä»€ä¹ˆè¦è®¨è®ºè¿™ä¸ªé—®é¢˜å‘¢ï¼Ÿ å› ä¸º GPU æ˜¾å­˜åœ¨ AI å·¥ä½œè´Ÿè½½ä¸­éå¸¸å®è´µï¼Œæ˜¾å­˜ä¸­çš„è¿ç®—é€Ÿåº¦æ˜¯æœ€å¿«çš„ï¼Œè€Œå¾ˆå¤šæƒ…å†µä¸‹æ˜¾å­˜ä¸è¶³æ˜¯æ¨ç†é€Ÿåº¦çš„ç“¶é¢ˆã€‚

ä¸€ä¸ªç®€å•çš„è§£å†³æ–¹æ¡ˆæ˜¯å°†ç©ºé—²å­æ¨¡å‹ä» GPU æ˜¾å­˜ä¸­å¸è½½è‡³ CPU å†…å­˜ï¼Œè¯¥æ“ä½œç§°ä¸º CPU å¸è½½ã€‚

**å¥½æ¶ˆæ¯: ** Bark çš„ CPU å¸è½½å·²é›†æˆè‡³ ğŸ¤— Transformers ä¸­ï¼Œåªéœ€ä¸€è¡Œä»£ç å³å¯ä½¿èƒ½ã€‚å”¯ä¸€æ¡ä»¶æ˜¯ï¼Œä»…éœ€ç¡®ä¿å®‰è£…äº† ğŸ¤— Accelerate å³å¯ï¼

```python
model = BarkModel.from_pretrained("suno/bark-small")

# Enable CPU offload
model.enable_cpu_offload()

with torch.inference_mode():
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)
```

**è¾“å‡º:**

```
Execution time: 8.97633828125 seconds
Max memory footprint 1.3231160320000002 GB
```

æŒ‰ä¸‹é¢çš„æ’­æ”¾é”®å¬ä¸€ä¸‹è¾“å‡ºå§ ([ä¸‹è½½è¯¥éŸ³é¢‘æ–‡ä»¶](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_cpu_offload.wav)):
<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_cpu_offload.wav" type="audio/wav">
å½“å‰æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

**åˆ©å¼Š**

é€Ÿåº¦ç•¥æœ‰ä¸‹é™ (10%)ï¼Œæ¢å¾—å†…å­˜å ç”¨çš„å·¨å¤§é™ä½ (60% ğŸ¤¯)ã€‚

å¯ç”¨æ­¤åŠŸèƒ½åï¼Œ `bark-large` å ç”¨ç©ºé—´ä»åŸå…ˆçš„ 5GB é™è‡³ 2GBï¼Œä¸ `bark-small` çš„å†…å­˜å ç”¨ç›¸åŒï¼

å¦‚æœä½ è¿˜æƒ³è¦é™æ›´å¤šçš„è¯ï¼Œå¯ä»¥è¯•è¯•å¯ç”¨ `fp16` ï¼Œå†…å­˜å ç”¨ç”šè‡³å¯ä»¥é™è‡³ 1GBã€‚å…·ä½“å¯ä»¥å‚è§ä¸‹ä¸€èŠ‚çš„æ•°æ®ã€‚

## 4. ç»„åˆä¼˜åŒ–

æˆ‘ä»¬æŠŠä¸Šè¿°æ‰€æœ‰ä¼˜åŒ–ç»„åˆåˆ°ä¸€èµ·ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥åˆå¹¶ CPU å¸è½½ã€åŠç²¾åº¦ä»¥åŠ ğŸ¤— Better Transformer å¸¦æ¥çš„æ”¶ç›Šï¼

```python
# load in fp16
model = BarkModel.from_pretrained("suno/bark-small", torch_dtype=torch.float16).to(device)

# convert to bettertransformer
model = BetterTransformer.transform(model, keep_original_model=False)

# enable CPU offload
model.enable_cpu_offload()

with torch.inference_mode():
  speech_output = measure_latency_and_memory_use(model, inputs, nb_loops = 5)
```

**è¾“å‡º:**

```
Execution time: 7.4496484375000005 seconds
Max memory footprint 0.46871091200000004 GB
```

æŒ‰ä¸‹é¢çš„æ’­æ”¾é”®å¬ä¸€ä¸‹è¾“å‡ºå§ ([ä¸‹è½½è¯¥éŸ³é¢‘æ–‡ä»¶](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_optimized.wav)):

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_optimized.wav" type="audio/wav">
å½“å‰æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

**åˆ©å¼Š**

æœ€ç»ˆï¼Œä½ å°†è·å¾— 23% çš„åŠ é€Ÿå¹¶èŠ‚çº¦ 80% çš„å†…å­˜ï¼

## æ‰¹å¤„ç†

å¾—é™‡æœ›èœ€ï¼Ÿ

åŠ ä¸ªæ‰¹å¤„ç†å§ï¼Œä¸Šè¿° 3 ç§ä¼˜åŒ–æŠ€å·§åŠ ä¸Šæ‰¹å¤„ç†å¯ä»¥è¿›ä¸€æ­¥æå‡é€Ÿåº¦ã€‚æ‰¹å¤„ç†å³å°†å¤šä¸ªæ ·æœ¬ç»„åˆèµ·æ¥ä¸€èµ·æ¨ç†ï¼Œè¿™æ ·ä¼šä½¿è¿™äº›æ ·æœ¬çš„æ€»ç”Ÿæˆæ—¶é—´ä½äºé€æ ·æœ¬ç”Ÿæˆæ—¶çš„æ€»ç”Ÿæˆæ—¶é—´ã€‚

ä¸‹é¢ç»™å‡ºäº†ä¸€ä¸ªæ‰¹å¤„ç†çš„ç®€å•ä»£ç :

```python
text_prompt = [
    "Let's try generating speech, with Bark, a text-to-speech model",
    "Wow, batching is so great!",
    "I love Hugging Face, it's so cool."]

inputs = processor(text_prompt).to(device)

with torch.inference_mode():
  # samples are generated all at once
  speech_output = model.generate(**inputs, do_sample = True, fine_temperature = 0.4, coarse_temperature = 0.8)
```

è¾“å‡ºéŸ³é¢‘å¦‚ä¸‹ (ä¸‹è½½ [ç¬¬ä¸€ä¸ª](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_batch_0.wav)ã€[ç¬¬äºŒä¸ª](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_batch_1.wav) ä»¥åŠ [ç¬¬ä¸‰ä¸ª](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_batch_2.wav) éŸ³é¢‘æ–‡ä»¶):

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_batch_0.wav" type="audio/wav">
å½“å‰æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_batch_1.wav" type="audio/wav">
å½“å‰æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bark_optimization/audio_sample_batch_2.wav" type="audio/wav">
å½“å‰æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

# åŸºå‡†æµ‹è¯•ç»“æœ

ä¸Šæ–‡æˆ‘ä»¬è¿›è¡Œçš„è¿™äº›å°å®éªŒæ›´å¤šæ˜¯æƒ³æ³•éªŒè¯ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶æ‰©å±•ä»¥æ›´å‡†ç¡®åœ°è¡¡é‡æ€§èƒ½ã€‚å¦å¤–ï¼Œåœ¨æ¯æ¬¡æ­£å¼æµ‹é‡æ€§èƒ½ä¹‹å‰ï¼Œè¿˜éœ€è¦å…ˆè·‘å‡ è½®ä»¥é¢„çƒ­ GPUã€‚

ä»¥ä¸‹æ˜¯æ‰©å±•è‡³ 100 ä¸ªæ ·æœ¬çš„åŸºå‡†æµ‹é‡çš„ç»“æœï¼Œä½¿ç”¨çš„æ¨¡å‹ä¸º **å¤§ Bark**ã€‚

è¯¥åŸºå‡†æµ‹è¯•åœ¨ NVIDIA TITAN RTX 24GB ä¸Šè¿è¡Œï¼Œæœ€å¤§è¯å…ƒæ•°ä¸º 256ã€‚

## å¦‚ä½•è§£è¯»ç»“æœï¼Ÿ

### å»¶è¿Ÿ

è¯¥æŒ‡æ ‡ä¸»è¦æµ‹é‡æ¯æ¬¡è°ƒç”¨ç”Ÿæˆå‡½æ•°çš„å¹³å‡æ—¶é—´ï¼Œæ— è®º batch size å¦‚ä½•ã€‚

æ¢å¥è¯è¯´ï¼Œå®ƒç­‰äº $\frac{elapsedTime}{nbLoops}$ã€‚

**å»¶è¿Ÿè¶Šå°è¶Šå¥½ã€‚**

### æœ€å¤§å†…å­˜å ç”¨

å®ƒä¸»è¦æµ‹é‡ç”Ÿæˆå‡½æ•°åœ¨æ¯æ¬¡è°ƒç”¨æœŸé—´ä½¿ç”¨çš„æœ€å¤§å†…å­˜ã€‚

**å†…å­˜å ç”¨è¶Šå°è¶Šå¥½ã€‚**

### ååé‡

å®ƒæµ‹é‡æ¯ç§’ç”Ÿæˆçš„æ ·æœ¬æ•°ã€‚è¿™æ¬¡ï¼Œbatch size çš„å› ç´ å·²è¢«è€ƒè™‘åœ¨å†…ã€‚

æ¢å¥è¯è¯´ï¼Œå®ƒç­‰äº $\frac{nbLoops*batchSize}{elapsedTime}$ã€‚

**ååé‡è¶Šé«˜è¶Šå¥½ã€‚**

## å•æ ·æœ¬æ¨ç†

ä¸‹è¡¨ä¸º `batch_size=1` çš„ç»“æœã€‚

| ç»å¯¹æ€§èƒ½           | å»¶è¿Ÿ | å†…å­˜å ç”¨  |
|-----------------------------|---------|---------|
| æ— ä¼˜åŒ–           |   10.48 | 5025.0M |
| ä»… bettertransformer      |    7.70 | 4974.3M |
| CPU å¸è½½ + bettertransformer |    8.90 | 2040.7M |
| CPU å¸è½½ + bettertransformer + fp16   |    8.10 | 1010.4M |

| ç›¸å¯¹æ€§èƒ½              | å»¶è¿Ÿ | å†…å­˜å ç”¨ |
|-----------------------------|---------|--------|
| æ— ä¼˜åŒ–            |      0% |     0% |
| ä»… bettertransformer      |    -27% |    -1% |
| CPU å¸è½½ + bettertransformer |    -15% |   -59% |
| CPU å¸è½½ + bettertransformer + fp16   |    -23% |   -80% |

### ç‚¹è¯„

ä¸å‡ºæ‰€æ–™ï¼ŒCPU å¸è½½æå¤§åœ°å‡å°‘äº†å†…å­˜å ç”¨ï¼ŒåŒæ—¶ç•¥å¾®å¢åŠ äº†å»¶è¿Ÿã€‚

ç„¶è€Œï¼Œç»“åˆ bettertransformer å’Œ `fp16` ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸¤å…¨å…¶ç¾çš„æ•ˆæœï¼Œå·¨å¤§çš„å»¶è¿Ÿå’Œå†…å­˜é™ä½ï¼

## batch size ä¸º 8

ä»¥ä¸‹æ˜¯ `batch_size=8` æ—¶çš„ååé‡åŸºå‡†æµ‹è¯•ç»“æœã€‚

è¯·æ³¨æ„ï¼Œç”±äº `bettertransformer` æ˜¯ä¸€ç§å…è´¹ä¼˜åŒ–ï¼Œå®ƒæ‰§è¡Œä¸éä¼˜åŒ–æ¨¡å‹å®Œå…¨ç›¸åŒçš„æ“ä½œå¹¶å…·æœ‰ç›¸åŒçš„å†…å­˜å ç”¨ï¼ŒåŒæ—¶é€Ÿåº¦æ›´å¿«ï¼Œå› æ­¤æ‰€æœ‰çš„åŸºå‡†æµ‹è¯•å‡ **é»˜è®¤å¼€å¯æ­¤ä¼˜åŒ–**ã€‚

| ç»å¯¹æ€§èƒ½              | å»¶è¿Ÿ | å†…å­˜å ç”¨  | ååé‡ |
|-------------------------------|---------|---------|-----------|
| åŸºçº¿ (bettertransformer) |   19.26 | 8329.2M |      0.42 |
| + fp16                          |   10.32 | 4198.8M |      0.78 |
| + CPU å¸è½½                       |   20.46 | 5172.1M |      0.39 |
| + CPU å¸è½½ + fp16                |   10.91 | 2619.5M |      0.73 |

| ç›¸å¯¹æ€§èƒ½                | å»¶è¿Ÿ | å†…å­˜å ç”¨ | ååé‡ |
|-------------------------------|---------|--------|------------|
| + åŸºçº¿  (bettertransformer) |      0% |     0% |         0% |
| + fp16                          |    -46% |   -50% |        87% |
| + CPU å¸è½½                        |      6% |   -38% |        -6% |
| + CPU å¸è½½  + fp16                |    -43% |   -69% |       77% |

### ç‚¹è¯„

è¿™é‡Œï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ç»„åˆæ‰€æœ‰ä¸‰ä¸ªä¼˜åŒ–æŠ€å·§åçš„æ€§èƒ½æ½œåŠ›ï¼

`fp16` å¯¹å»¶è¿Ÿçš„å½±å“åœ¨ `batch_size = 1` æ—¶ä¸å¤ªæ˜æ˜¾ï¼Œä½†åœ¨ `batch_size = 1` æ—¶çš„è¡¨ç°éå¸¸æœ‰è¶£ï¼Œå®ƒå¯ä»¥å°†å»¶è¿Ÿå‡å°‘è¿‘ä¸€åŠï¼Œååé‡å‡ ä¹ç¿»å€ï¼

# ç»“æŸè¯­

æœ¬æ–‡å±•ç¤ºäº† ğŸ¤— ç”Ÿæ€ç³»ç»Ÿä¸­çš„ä¸€äº›ç°æˆçš„ã€ç®€å•çš„ä¼˜åŒ–æŠ€å·§ã€‚ä½¿ç”¨è¿™äº›æŠ€å·§ä¸­çš„ä»»ä½•ä¸€ç§æˆ–å…¨éƒ¨ä¸‰ç§éƒ½å¯ä»¥æå¤§åœ°æ”¹å–„ Bark çš„æ¨ç†é€Ÿåº¦å’Œå†…å­˜å ç”¨ã€‚

- **ä½¿ç”¨ğŸ¤— Better Transformer å’Œ CPU å¸è½½**ï¼Œä½ å¯ä»¥å¯¹å¤§ Bark æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œè€Œä¸ä¼šå‡ºç°ä»»ä½•æ€§èƒ½ä¸‹é™ï¼Œå ç”¨ç©ºé—´ä»…ä¸º 2GB (è€Œä¸æ˜¯ 5GB)ï¼ŒåŒæ—¶é€Ÿåº¦æé«˜ 15%ã€‚
- å¦‚æœä½ é’Ÿæƒ…äºé«˜ååï¼Œå¯ä»¥ **æŠŠ batch size æ‰“åˆ° 8ï¼Œå¹¶åˆ©ç”¨ ğŸ¤— Better Transformer å’Œ fp16**ã€‚
- å¦‚æœä½ â€œæ—¢è¦ï¼Œåˆè¦ï¼Œè¿˜è¦â€ï¼Œè¯•è¯• **fp16ã€ğŸ¤— Better Transformer åŠ  CPU å¸è½½** ç»„åˆä¼˜åŒ–å§ï¼