---
title: "ä½¿ç”¨ ğŸ§¨ Diffusers å®ç° ControlNet é«˜é€Ÿæ¨ç†" 
thumbnail: /blog/assets/controlnet/thumbnail.png 
authors:
- user: sayakpaul
- user: yiyixu
- user: patrickvonplaten
translators:
- user: SuSung-boy
---

# ä½¿ç”¨ ğŸ§¨ Diffusers å®ç° ControlNet é«˜é€Ÿæ¨ç†


<a target="_blank" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/controlnet.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a> 

è‡ªä» Stable Diffusion é£é¡å…¨çƒä»¥æ¥ï¼Œäººä»¬ä¸€ç›´åœ¨å¯»æ±‚å¦‚ä½•æ›´å¥½åœ°æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹çš„æ–¹æ³•ã€‚ControlNet æä¾›äº†ä¸€ä¸ªç®€å•çš„è¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œèƒ½å¤Ÿå…è®¸ç”¨æˆ·åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè‡ªå®šä¹‰ç”Ÿæˆè¿‡ç¨‹ã€‚é€šè¿‡ [ControlNet](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/controlnet)ï¼Œç”¨æˆ·å¯ä»¥è½»æ¾åœ°ä½¿ç”¨å¤šç§ç©ºé—´è¯­ä¹‰æ¡ä»¶ä¿¡æ¯ (ä¾‹å¦‚æ·±åº¦å›¾ã€åˆ†å‰²å›¾ã€æ¶‚é¸¦å›¾ã€å…³é”®ç‚¹ç­‰) æ¥æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹ã€‚

å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥å°†å¡é€šç»˜å›¾è½¬åŒ–ä¸ºé€¼çœŸçš„ç…§ç‰‡ï¼ŒåŒæ—¶ä¿æŒæä½³çš„å¸ƒå±€è¿è´¯æ€§ã€‚

<table>
<tr style="text-align: center;">
    <th>Realistic Lofi Girl</th>
</tr>
<tr>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/lofi.jpg" width=300 /></td>
</tr>
</table>

è¿›è¡Œå®¤å†…è®¾è®¡ã€‚

<table>
<tr style="text-align: center;">
    <th>Before</th>
    <th>After</th>
</tr>
<tr>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/house_depth.png" width=300/></td>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/house_after.jpeg" width=300/></td>
</tr>
</table>

å°†æ¶‚é¸¦è‰å›¾å˜æˆè‰ºæœ¯ä½œå“ã€‚

<table>
<tr style="text-align: center;">
    <th>Before</th>
    <th>After</th>
</tr>
<tr>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/drawing_before.png" width=300/></td>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/drawing_after.jpeg" width=300/></td>
</tr>
</table>

ç”šè‡³æ‹ŸäººåŒ–è‘—åçš„ logo å½¢è±¡ã€‚

<table>
<tr style="text-align: center;">
    <th>Before</th>
    <th>After</th>
</tr>
<tr>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/starbucks_logo.jpeg" width=300/></td>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/starbucks_after.png" width=300/></td>
</tr>
</table>

ControlNetï¼Œä½¿ä¸€åˆ‡çš†æœ‰å¯èƒ½ ğŸŒ 

æœ¬æ–‡çš„ä¸»è¦å†…å®¹:
- ä»‹ç» [`StableDiffusionControlNetPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/controlnet)
- å±•ç¤ºå¤šç§æ§åˆ¶æ¡ä»¶æ ·ä¾‹

è®©æˆ‘ä»¬å¼€å¯æ§åˆ¶ä¹‹æ—…ï¼

## ControlNet ç®€è¿°

ControlNet åœ¨ [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543) ä¸€æ–‡ä¸­æè¢«å‡ºï¼Œä½œè€…æ˜¯ Lvmin Zhang å’Œ Maneesh Agrawalaã€‚å®ƒå¼•å…¥äº†ä¸€ä¸ªæ¡†æ¶ï¼Œæ”¯æŒåœ¨æ‰©æ•£æ¨¡å‹ (å¦‚ Stable Diffusion) ä¸Šé™„åŠ é¢å¤–çš„å¤šç§ç©ºé—´è¯­ä¹‰æ¡ä»¶æ¥æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹ã€‚Diffusers å®ç°ä»åŸå§‹ [æºä»£ç ](https://github.com/lllyasviel/ControlNet/) æ¼”åŒ–è€Œæ¥ã€‚

è®­ç»ƒ ControlNet åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤:

1. å…‹éš†æ‰©æ•£æ¨¡å‹çš„é¢„è®­ç»ƒå‚æ•° (æ–‡ä¸­ç§°ä¸º å¯è®­ç»ƒå‰¯æœ¬, trainable copyã€‚å¦‚ Stable Diffusion çš„ latent UNet éƒ¨åˆ†)ï¼ŒåŒæ—¶ä¿ç•™åŸæœ¬çš„é¢„è®­ç»ƒå‚æ•° (æ–‡ä¸­ç§°ä¸º é”å®šå‰¯æœ¬, locked copy)ã€‚è¿™æ ·å¯ä»¥å®ç°: a) è®©é”å®šå‰¯æœ¬ä¿ç•™ä»å¤§å‹æ•°æ®é›†ä¸­å­¦åˆ°çš„ä¸°å¯ŒçŸ¥è¯†ï¼›b) è®©å¯è®­ç»ƒå‰¯æœ¬å­¦ä¹ ç‰¹å®šä»»åŠ¡çš„çŸ¥è¯†ã€‚
2. å¯è®­ç»ƒå‰¯æœ¬å’Œé”å®šå‰¯æœ¬çš„å‚æ•°é€šè¿‡ â€œé›¶å·ç§¯â€ å±‚ (è¯¦è§ [æ­¤å¤„](https://github.com/lllyasviel/ControlNet#controlnet) for more information)) è¿æ¥ã€‚â€œé›¶å·ç§¯â€ å±‚æ˜¯ ControlNet æ¡†æ¶çš„ä¸€éƒ¨åˆ†ï¼Œä¼šåœ¨ç‰¹å®šä»»åŠ¡ä¸­ä¼˜åŒ–å‚æ•°ã€‚è¿™æ˜¯ä¸€ç§è®­ç»ƒæŠ€å·§ï¼Œå¯ä»¥åœ¨æ–°ä»»åŠ¡æ¡ä»¶è®­ç»ƒæ—¶ä¿ç•™å·²å†»ç»“æ¨¡å‹å·²ç»å­¦åˆ°çš„è¯­ä¹‰ä¿¡æ¯ã€‚

è®­ç»ƒ ControlNet çš„è¿‡ç¨‹å¦‚å›¾æ‰€ç¤º:

<p align="center">
    <img src="https://github.com/lllyasviel/ControlNet/raw/main/github_page/sd.png" alt="controlnet-structure"><br>
    <em>The diagram is taken from <a href=https://github.com/lllyasviel/ControlNet/blob/main/github_page/sd.png>here</a>.</em>
</p>

ControlNet è®­ç»ƒé›†ä¸­çš„å…¶ä¸­ä¸€ç§æ ·ä¾‹å¦‚ä¸‹ (é¢å¤–çš„æ§åˆ¶æ¡ä»¶æ˜¯ Canny è¾¹ç¼˜å›¾):

<table>
<tr style="text-align: center;">
    <th>Prompt</th>
    <th>Original Image</th>
    <th>Conditioning</th>
</tr>
<tr style="text-align: center;">
     <td style="vertical-align: middle">"bird"</td>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/controlnet/original_bird.png" width=200/></td>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/controlnet/canny_map.png" width=200/></td>
</tr>
</table>

åŒæ ·åœ°ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨çš„é¢å¤–æ§åˆ¶æ¡ä»¶æ˜¯è¯­ä¹‰åˆ†å‰²å›¾ï¼Œé‚£ä¹ˆ ControlNet è®­ç»ƒé›†çš„æ ·ä¾‹å°±æ˜¯è¿™æ ·:

<table>
<tr style="text-align: center;">
    <th>Prompt</th>
    <th>Original Image</th>
    <th>Conditioning</th>
</tr>
<tr style="text-align: center;">
    <td style="vertical-align: middle">"big house"</td>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/controlnet/original_house.png" width=300/></td>
    <td><img class="mx-auto" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/controlnet/segmentation_map.png" width=300/></td>
</tr>
</table>

æ¯å¯¹ ControlNet æ–½åŠ ä¸€ç§é¢å¤–çš„æ§åˆ¶æ¡ä»¶ï¼Œéƒ½éœ€è¦è®­ç»ƒä¸€ä»½æ–°çš„å¯è®­ç»ƒå‰¯æœ¬å‚æ•°ã€‚è®ºæ–‡ä¸­æå‡ºäº† 8 ç§ä¸åŒçš„æ§åˆ¶æ¡ä»¶ï¼Œå¯¹åº”çš„æ§åˆ¶æ¨¡å‹åœ¨ Diffusers ä¸­ [å‡å·²æ”¯æŒ](https://huggingface.co/lllyasviel?search=controlnet)ï¼

æ¨ç†é˜¶æ®µéœ€è¦åŒæ—¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„é¢„è®­ç»ƒæƒé‡ä»¥åŠè®­ç»ƒè¿‡çš„ ControlNet æƒé‡ã€‚å¦‚è¦ä½¿ç”¨ Stable Diffusion v1-5 ä»¥åŠå…¶ ControlNet æƒé‡æ¨ç†ï¼Œå…¶å‚æ•°é‡è¦æ¯”ä»…ä½¿ç”¨ [Stable Diffusion v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) å¤šå¤§çº¦ 7 äº¿ä¸ªï¼Œå› æ­¤æ¨ç† ControlNet éœ€è¦æ¶ˆè€—æ›´å¤šçš„å†…å­˜ã€‚

ç”±äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ‰©æ•£æ¨¡å‹é¢„è®­ç»ƒå‚æ•°ä¸ºé”å®šå‰¯æœ¬ï¼Œå› æ­¤åœ¨ä½¿ç”¨ä¸åŒçš„æ§åˆ¶æ¡ä»¶è®­ç»ƒæ—¶ï¼Œåªéœ€è¦åˆ‡æ¢ ControlNet å¯è®­ç»ƒå‰¯æœ¬çš„å‚æ•°å³å¯ã€‚è¿™æ ·åœ¨ä¸€ä¸ªåº”ç”¨ç¨‹åºä¸­éƒ¨ç½²å¤šä¸ª ControlNet æƒé‡å°±éå¸¸ç®€å•äº†ï¼Œæœ¬æ–‡ä¼šåœ¨åé¢è¯¦ç»†ä»‹ç»ã€‚

## `StableDiffusionControlNetPipeline`

åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘ä»¬è¦å‘ç¤¾åŒºè´¡çŒ®è€… [Takuma Mori](https://github.com/takuma104) è¡¨ç¤ºå·¨å¤§çš„æ„Ÿè°¢ã€‚å°† ControlNet é›†æˆåˆ° Diffusers ä¸­ï¼Œä»–åŠŸä¸å¯æ²¡ â¤ï¸ã€‚

ç±»ä¼¼ Diffusers ä¸­çš„ [å…¶ä»– Pipeline](https://huggingface.co/docs/diffusers/api/pipelines/overview)ï¼ŒDiffusers åŒæ ·ä¸º ControlNet æä¾›äº† [`StableDiffusionControlNetPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/controlnet) ä¾›ç”¨æˆ·ä½¿ç”¨ã€‚StableDiffusionControlNetPipeline çš„æ ¸å¿ƒæ˜¯ controlnet å‚æ•°ï¼Œå®ƒæ¥æ”¶ç”¨æˆ·æŒ‡å®šçš„è®­ç»ƒè¿‡çš„ [`ControlNetModel`](https://huggingface.co/docs/diffusers/main/en/api/models#diffusers.ControlNetModel) å®ä¾‹ä½œä¸ºè¾“å…¥ï¼ŒåŒæ—¶ä¿æŒæ‰©æ•£æ¨¡å‹çš„é¢„è®­ç»ƒæƒé‡ä¸å˜ã€‚

æœ¬æ–‡å°†ä»‹ç» StableDiffusionControlNetPipeline çš„å¤šä¸ªä¸åŒç”¨ä¾‹ã€‚é¦–å…ˆè¦ä»‹ç»çš„ç¬¬ä¸€ä¸ª ControlNet æ¨¡å‹æ˜¯ [Canny æ¨¡å‹](https://huggingface.co/runwayml/stable-diffusion-v1-5)ï¼Œè¿™æ˜¯ç›®å‰æœ€æµè¡Œçš„ ControlNet æ¨¡å‹ä¹‹ä¸€ï¼Œæ‚¨å¯èƒ½å·²ç»åœ¨ç½‘ä¸Šè§è¯†è¿‡ä¸€äº›å®ƒç”Ÿæˆçš„ç²¾ç¾å›¾ç‰‡ã€‚

åœ¨é˜…è¯»åˆ°å„ä¸ªéƒ¨åˆ†çš„ä»£ç æ—¶ï¼Œä¹Ÿæ¬¢è¿æ‚¨ä½¿ç”¨æ­¤ [Colab ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/controlnet.ipynb) è¿è¡Œç›¸å…³ä»£ç ç‰‡æ®µã€‚

è¿è¡Œä»£ç ä¹‹å‰ï¼Œé¦–å…ˆç¡®ä¿æˆ‘ä»¬å·²ç»å®‰è£…å¥½æ‰€æœ‰å¿…è¦çš„åº“:

```bash
pip install diffusers==0.14.0 transformers xformers git+https://github.com/huggingface/accelerate.git
```

ä¸ºå¤„ç†ä¸åŒ ControlNet å¯¹åº”çš„å¤šç§æ§åˆ¶æ¡ä»¶ï¼Œè¿˜éœ€è¦å®‰è£…ä¸€äº›é¢å¤–çš„ä¾èµ–é¡¹:
- [OpenCV](https://opencv.org/)
- [controlnet-aux](https://github.com/patrickvonplaten/controlnet_aux#controlnet-auxiliary-models) - ControlNet é¢„å¤„ç†æ¨¡å‹åº“

```bash
pip install opencv-contrib-python
pip install controlnet_aux
```

æˆ‘ä»¬å°†ä»¥è‘—åçš„æ²¹ç”»ä½œå“ [ã€Šæˆ´çç è€³ç¯çš„å°‘å¥³ã€‹](https://en.wikipedia.org/wiki/Girl_with_a_Pearl_Earring) ä¸ºä¾‹ï¼Œé¦–å…ˆè®©æˆ‘ä»¬ä¸‹è½½è¿™å¼ å›¾åƒå¹¶æŸ¥çœ‹ä¸€ä¸‹:

```python
from diffusers.utils import load_image

image = load_image(
    "https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/input_image_vermeer.png"
)
image
```

<p align="center">
<img src="https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/blog_post_cell_6_output_0.jpeg" width=600/>
</p>

ç„¶åå°†å›¾åƒè¾“å…¥ç»™ Canny é¢„å¤„ç†å™¨:

```python
import cv2
from PIL import Image
import numpy as np

image = np.array(image)

low_threshold = 100
high_threshold = 200

image = cv2.Canny(image, low_threshold, high_threshold)
image = image[:, :, None]
image = np.concatenate([image, image, image], axis=2)
canny_image = Image.fromarray(image)
canny_image
```

å¦‚å›¾å¯è§ï¼ŒCanny æœ¬è´¨ä¸Šæ˜¯è¾¹ç¼˜æ£€æµ‹å™¨:

<p align="center">
<img src="https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/blog_post_cell_10_output_0.jpeg" width=600/>
</p>

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åŠ è½½ [runwaylml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5) å’Œ [Canny è¾¹ç¼˜ ControlNet æ¨¡å‹](https://huggingface.co/lllyasviel/sd-controlnet-canny)ã€‚è®¾ç½®å‚æ•° torch.dtype=torch.float16 å¯ä»¥æŒ‡å®šæ¨¡å‹ä»¥åŠç²¾åº¦æ¨¡å¼åŠ è½½ï¼Œå¯å®ç°å†…å­˜é«˜æ•ˆå’Œå¿«é€Ÿçš„æ¨ç†ã€‚

```python
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel
import torch

controlnet = ControlNetModel.from_pretrained("lllyasviel/sd-controlnet-canny", torch_dtype=torch.float16)
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16
)
```

è¿™é‡Œæˆ‘ä»¬ä¸ä½¿ç”¨ Stable Diffusion é»˜è®¤çš„ [PNDMScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/pndm) è°ƒåº¦å™¨ï¼Œè€Œä½¿ç”¨æ”¹è¿›çš„ [UniPCMultistepScheduler](https://huggingface.co/docs/diffusers/main/en/api/schedulers/unipc) (ç›®å‰æœ€å¿«çš„æ‰©æ•£æ¨¡å‹è°ƒåº¦å™¨ä¹‹ä¸€)ï¼Œå¯ä»¥æå¤§åœ°åŠ å¿«æ¨ç†é€Ÿåº¦ã€‚ç»æµ‹è¯•ï¼Œåœ¨ä¿è¯ç”Ÿæˆå›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œæˆ‘ä»¬èƒ½å°†æ¨ç†é˜¶æ®µçš„é‡‡æ ·æ­¥æ•°ä» 50 é™åˆ° 20ã€‚æ›´å¤šå…³äºè°ƒåº¦å™¨çš„ä¿¡æ¯å¯ä»¥ç‚¹å‡» [æ­¤å¤„](https://huggingface.co/docs/diffusers/main/en/using-diffusers/schedulers) æŸ¥çœ‹ã€‚

```python
from diffusers import UniPCMultistepScheduler

pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
```

æˆ‘ä»¬é€šè¿‡è°ƒç”¨ [enable_model_cpu_offload å‡½æ•°](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/controlnet#diffusers.StableDiffusionControlNetPipeline.enable_model_cpu_offload)æ¥å¯ç”¨æ™ºèƒ½ CPU å¸è½½ï¼Œè€Œä¸æ˜¯ç›´æ¥å°† pipeline åŠ è½½åˆ° GPU ä¸Šã€‚

æ™ºèƒ½ CPU å¸è½½æ˜¯ä¸€ç§é™ä½æ˜¾å­˜å ç”¨çš„æ–¹æ³•ã€‚æ‰©æ•£æ¨¡å‹ (å¦‚ Stable Diffusion) çš„æ¨ç†å¹¶ä¸æ˜¯è¿è¡Œä¸€ä¸ªå•ç‹¬çš„æ¨¡å‹ï¼Œè€Œæ˜¯å¤šä¸ªæ¨¡å‹ç»„ä»¶çš„ä¸²è¡Œæ¨ç†ã€‚å¦‚åœ¨æ¨ç† ControlNet Stable Diffusion æ—¶ï¼Œéœ€è¦é¦–å…ˆè¿è¡Œ CLIP æ–‡æœ¬ç¼–ç å™¨ï¼Œå…¶æ¬¡æ¨ç†æ‰©æ•£æ¨¡å‹ UNet å’Œ ControlNetï¼Œç„¶åè¿è¡Œ VAE è§£ç å™¨ï¼Œæœ€åè¿è¡Œ safety checker (å®‰å…¨æ£€æŸ¥å™¨ï¼Œä¸»è¦ç”¨äºå®¡æ ¸è¿‡æ»¤è¿è§„å›¾åƒ)ã€‚è€Œåœ¨æ‰©æ•£è¿‡ç¨‹ä¸­å¤§å¤šæ•°ç»„ä»¶ä»…è¿è¡Œä¸€æ¬¡ï¼Œå› æ­¤ä¸éœ€è¦ä¸€ç›´å ç”¨ GPU å†…å­˜ã€‚é€šè¿‡å¯ç”¨æ™ºèƒ½æ¨¡å‹å¸è½½ï¼Œå¯ä»¥ç¡®ä¿æ¯ä¸ªç»„ä»¶åœ¨ä¸éœ€è¦å‚ä¸ GPU è®¡ç®—æ—¶å¸è½½åˆ° CPU ä¸Šï¼Œä»è€Œæ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨ï¼Œå¹¶ä¸”ä¸ä¼šæ˜¾è‘—å¢åŠ æ¨ç†æ—¶é—´ (ä»…å¢åŠ äº†æ¨¡å‹åœ¨ GPU-CPU ä¹‹é—´çš„è½¬ç§»æ—¶é—´)ã€‚

**æ³¨æ„**: å¯ç”¨ `enable_model_cpu_offload` åï¼Œpipeline ä¼šè‡ªåŠ¨è¿›è¡Œ GPU å†…å­˜ç®¡ç†ï¼Œå› æ­¤è¯·ä¸è¦å†ä½¿ç”¨ `.to("cuda")` æ‰‹åŠ¨å°† pipeline è½¬ç§»åˆ° GPUã€‚

```py
pipe.enable_model_cpu_offload()
```

æœ€åï¼Œæˆ‘ä»¬è¦å……åˆ†åˆ©ç”¨ [FlashAttention/xformers](https://github.com/facebookresearch/xformers) è¿›è¡Œæ³¨æ„åŠ›å±‚åŠ é€Ÿã€‚è¿è¡Œä¸‹åˆ—ä»£ç ä»¥å®ç°åŠ é€Ÿï¼Œå¦‚æœè¯¥ä»£ç æ²¡æœ‰èµ·ä½œç”¨ï¼Œé‚£ä¹ˆæ‚¨å¯èƒ½æ²¡æœ‰æ­£ç¡®å®‰è£… `xformers` åº“ï¼Œæ­¤æ—¶æ‚¨å¯ä»¥è·³è¿‡è¯¥ä»£ç ã€‚

```py
pipe.enable_xformers_memory_efficient_attention()
```

åŸºæœ¬æ¡ä»¶å‡†å¤‡å°±ç»ªï¼Œç°åœ¨æ¥è¿è¡Œ ControlNet pipelineï¼

è·Ÿè¿è¡Œ Stable Diffusion image-to-image pipeline ç›¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬ä¹Ÿä½¿ç”¨äº†æ–‡æœ¬æç¤ºè¯­æ¥å¼•å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚ä¸è¿‡æœ‰ä¸€äº›ä¸åŒçš„æ˜¯ï¼ŒControlNet å…è®¸æ–½åŠ æ›´å¤šç§ç±»çš„æ§åˆ¶æ¡ä»¶æ¥æ§åˆ¶å›¾åƒç”Ÿæˆè¿‡ç¨‹ï¼Œæ¯”å¦‚ä½¿ç”¨åˆšæ‰æˆ‘ä»¬åˆ›å»ºçš„ Canny è¾¹ç¼˜å›¾å°±èƒ½æ›´ç²¾ç¡®çš„æ§åˆ¶ç”Ÿæˆå›¾åƒçš„æ„å›¾ã€‚

è®©æˆ‘ä»¬æ¥çœ‹ä¸€äº›æœ‰è¶£çš„ï¼Œå°† 17 ä¸–çºªçš„åä½œã€Šæˆ´çç è€³ç¯çš„å°‘å¥³ã€‹ä¸­çš„å°‘å¥³ä¸€è§’æ¢ä¸ºç°ä»£çš„åäººä¼šæ˜¯ä»€ä¹ˆæ ·ï¼Ÿä½¿ç”¨ ControlNet å°±èƒ½è½»æ¾åšåˆ°ï¼Œåªéœ€è¦åœ¨æç¤ºè¯­ä¸­å†™ä¸Šä»–ä»¬çš„åå­—å³å¯ï¼

é¦–å…ˆåˆ›å»ºä¸€ä¸ªéå¸¸ç®€å•çš„å¸®åŠ©å‡½æ•°æ¥å®ç°ç”Ÿæˆå›¾åƒçš„ç½‘æ ¼å¯è§†åŒ–ã€‚

```python
def image_grid(imgs, rows, cols):
    assert len(imgs) == rows * cols

    w, h = imgs[0].size
    grid = Image.new("RGB", size=(cols * w, rows * h))
    grid_w, grid_h = grid.size

    for i, img in enumerate(imgs):
        grid.paste(img, box=(i % cols * w, i // cols * h))
    return grid
```

ç„¶åè¾“å…¥åå­—æç¤ºè¯­ï¼Œå¹¶è®¾ç½®éšæœºç§å­ä»¥ä¾¿å¤ç°ã€‚

```py
prompt = ", best quality, extremely detailed"
prompt = [t + prompt for t in ["Sandra Oh", "Kim Kardashian", "rihanna", "taylor swift"]] # åˆ†åˆ«ä¸º: å´çŠå“ã€é‡‘Â·å¡æˆ´çŠã€è•¾å“ˆå¨œã€æ³°å‹’Â·æ–¯å¨å¤«ç‰¹
generator = [torch.Generator(device="cpu").manual_seed(2) for i in range(len(prompt))]
```

æœ€åè¿è¡Œ pipelineï¼Œå¹¶å¯è§†åŒ–ç”Ÿæˆçš„å›¾åƒï¼

```py
output = pipe(
    prompt,
    canny_image,
    negative_prompt=["monochrome, lowres, bad anatomy, worst quality, low quality"] * 4,
    num_inference_steps=20,
    generator=generator,
)

image_grid(output.images, 2, 2)
```

<p align="center">
<img src="https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/blog_post_cell_16_output_1.jpeg" width=600/>
</p>

æˆ‘ä»¬è¿˜èƒ½è½»æ¾åœ°å°† ControlNet ä¸å¾®è°ƒç»“åˆä½¿ç”¨ï¼ä¾‹å¦‚ä½¿ç”¨ [DreamBooth](https://huggingface.co/docs/diffusers/main/en/training/dreambooth) å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç„¶åä½¿ç”¨ ControlNet å¢åŠ æ§åˆ¶ä¿¡æ¯ï¼Œå°†å…¶æ¸²æŸ“åˆ°ä¸åŒçš„åœºæ™¯ä¸­ã€‚

æœ¬æ–‡å°†ä»¥æˆ‘ä»¬æœ€çˆ±çš„åœŸè±†å…ˆç”Ÿä¸ºä¾‹ï¼Œæ¥ä»‹ç»æ€æ ·ç»“åˆä½¿ç”¨ ControlNet å’Œ DreamBoothã€‚

ç›¸è¾ƒäºä¸Šæ–‡ï¼Œpipeline ä¸­ä½¿ç”¨çš„ ControlNet éƒ¨åˆ†ä¿æŒä¸å˜ï¼Œä½†æ˜¯ä¸ä½¿ç”¨ Stable Diffusion 1.5ï¼Œè€Œæ˜¯é‡æ–°åŠ è½½ä¸€ä¸ª [åœŸè±†å…ˆç”Ÿ](https://huggingface.co/sd-dreambooth-library/mr-potato-head) æ¨¡å‹ (ä½¿ç”¨ Dreambooth å¾®è°ƒçš„ Stable Diffusion æ¨¡å‹) ğŸ¥”ã€‚

è™½ç„¶ ControlNet æ²¡å˜ï¼Œä½†ä»ç„¶éœ€è¦é‡æ–°åŠ è½½ pipelineã€‚

```python
model_id = "sd-dreambooth-library/mr-potato-head"
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    model_id,
    controlnet=controlnet,
    torch_dtype=torch.float16,
)
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe.enable_model_cpu_offload()
pipe.enable_xformers_memory_efficient_attention()
```

ç°åœ¨æ¥è®©åœŸè±†å…ˆç”Ÿæ‘†ä¸€ä¸ªã€Šæˆ´çç è€³ç¯çš„å°‘å¥³ã€‹çš„å§¿åŠ¿å§ï¼

```python
generator = torch.manual_seed(2)
prompt = "a photo of sks mr potato head, best quality, extremely detailed"
output = pipe(
    prompt,
    canny_image,
    negative_prompt="monochrome, lowres, bad anatomy, worst quality, low quality",
    num_inference_steps=20,
    generator=generator,
)
output.images[0]
```

çœ‹å¾—å‡ºæ¥åœŸè±†å…ˆç”Ÿå°½åŠ›äº†ï¼Œè¿™åœºæ™¯ç€å®ä¸å¤ªé€‚åˆä»–ï¼Œä¸è¿‡ä»–ä»ç„¶æŠ“ä½äº†ç²¾é«“ ğŸŸã€‚

<p align="center">
<img src="https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/blog_post_cell_22_output_0.jpeg" width=600/>
</p>

ControlNet è¿˜æœ‰å¦ä¸€ä¸ªç‹¬ç‰¹åº”ç”¨: ä»å›¾åƒæå–äººä½“å§¿æ€ï¼Œç”¨å§¿æ€ä¿¡æ¯æ§åˆ¶ç”Ÿæˆå…·æœ‰ç›¸åŒå§¿æ€çš„æ–°å›¾åƒã€‚å› æ­¤åœ¨ä¸‹ä¸€ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Open Pose ControlNet](https://huggingface.co/lllyasviel/sd-controlnet-openpose) æ¥æ•™è¶…çº§è‹±é›„å¦‚ä½•åšç‘œä¼½ï¼

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æ”¶é›†ä¸€äº›ç‘œä¼½åŠ¨ä½œå›¾åƒé›†:

```python
urls = "yoga1.jpeg", "yoga2.jpeg", "yoga3.jpeg", "yoga4.jpeg"
imgs = [
    load_image("https://huggingface.co/datasets/YiYiXu/controlnet-testing/resolve/main/" + url) 
    for url in urls
]

image_grid(imgs, 2, 2)
```

<p align="center">
    <img src="https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/blog_post_cell_25_output_0.jpeg" width=600/>
</p>

é€šè¿‡ `controlnet_aux` æä¾›çš„ OpenPose é¢„å¤„ç†å™¨ï¼Œæˆ‘ä»¬å¯ä»¥å¾ˆæ–¹ä¾¿åœ°æå–ç‘œä¼½å§¿æ€ã€‚

```python
from controlnet_aux import OpenposeDetector

model = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")

poses = [model(img) for img in imgs]
image_grid(poses, 2, 2)
```

<p align="center">
    <img src="https://huggingface.co/datasets/YiYiXu/test-doc-assets/resolve/main/blog_post_cell_28_output_0.jpeg" width=600/>
</p>

ç‘œä¼½å§¿æ€æå–å®Œæˆåï¼Œæˆ‘ä»¬æ¥ç€åˆ›å»ºä¸€ä¸ª [Open Pose ControlNet](https://huggingface.co/lllyasviel/sd-controlnet-openpose) pipeline æ¥ç”Ÿæˆä¸€äº›ç›¸åŒå§¿æ€çš„è¶…çº§è‹±é›„å›¾åƒã€‚Let's go ğŸš€

```python
controlnet = ControlNetModel.from_pretrained(
    "fusing/stable-diffusion-v1-5-controlnet-openpose", torch_dtype=torch.float16
)

model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionControlNetPipeline.from_pretrained(
    model_id,
    controlnet=controlnet,
    torch_dtype=torch.float16,
)
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe.enable_model_cpu_offload()
```

è¶…çº§è‹±é›„çš„ç‘œä¼½æ—¶é—´ï¼ 

```python
generator = [torch.Generator(device="cpu").manual_seed(2) for i in range(4)]
prompt = "super-hero character, best quality, extremely detailed"
output = pipe(
    [prompt] * 4,
    poses,
    negative_prompt=["monochrome, lowres, bad anatomy, worst quality, low quality"] * 4,
    generator=generator,
    num_inference_steps=20,
)
image_grid(output.images, 2, 2)
```

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/controlnet/anime_do_yoga.png" width=600/>
</p>

### ç»„åˆå¤šç§æ¡ä»¶

æˆ‘ä»¬å¯ä»¥å°†å¤šä¸ª ControlNet çš„çº¦æŸæ¡ä»¶ç»„åˆèµ·æ¥ä½œç”¨åœ¨åŒä¸€ä¸ªå›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚å°†ä¸€ä¸ª ControlNet æ•°ç»„ä¼ ç»™ pipeline æ„é€ å‡½æ•°ï¼Œä»¥åŠå°†å¯¹åº”çš„æ•°ç»„ä¼ ç»™ `__call__` è°ƒç”¨ã€‚

åœ¨ç»„åˆçº¦æŸæ¡ä»¶æ—¶ï¼Œå¯¹æ¡ä»¶è¿›è¡Œæ©è”½æ“ä½œå¯ä»¥æœ‰æ•ˆé¿å…å…¶ä½œç”¨é‡å ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°† canny map çš„ä¸­é—´éƒ¨åˆ†æ©è”½ï¼Œå› ä¸ºé‚£é‡Œæ˜¯å§¿æ€æ¡ä»¶çš„ä½œç”¨èŒƒå›´ã€‚

å¦å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡å˜åŒ–ä¸åŒçš„ `controlnet_conditioning_scale` å€¼æ¥å®ç°å¯¹ä¸åŒçº¦æŸæ¡ä»¶çš„çªå‡ºå¼ºåŒ–ã€‚

#### Canny çº¦æŸ

åŸå§‹å›¾åƒ

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png" width=600/>
</p>

å‡†å¤‡çº¦æŸæ¡ä»¶

```python
from diffusers.utils import load_image
from PIL import Image
import cv2
import numpy as np
from diffusers.utils import load_image

canny_image = load_image(
    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png"
)
canny_image = np.array(canny_image)

low_threshold = 100
high_threshold = 200

canny_image = cv2.Canny(canny_image, low_threshold, high_threshold)

# zero out middle columns of image where pose will be overlayed
zero_start = canny_image.shape[1] // 4
zero_end = zero_start + canny_image.shape[1] // 2
canny_image[:, zero_start:zero_end] = 0

canny_image = canny_image[:, :, None]
canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2)
canny_image = Image.fromarray(canny_image)
```

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/controlnet/landscape_canny_masked.png" width=600/>
</p>

#### Openpose çº¦æŸ

åŸå§‹å›¾åƒ

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/person.png" width=600/>
</p>

å‡†å¤‡çº¦æŸæ¡ä»¶

```python
from controlnet_aux import OpenposeDetector
from diffusers.utils import load_image

openpose = OpenposeDetector.from_pretrained("lllyasviel/ControlNet")

openpose_image = load_image(
    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/person.png"
)
openpose_image = openpose(openpose_image)
```

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/controlnet/person_pose.png" width=600/>
</p>

#### åœ¨å¤šé‡çº¦æŸä¸‹è¿è¡Œ ControlNet

```python
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
import torch

controlnet = [
    ControlNetModel.from_pretrained("lllyasviel/sd-controlnet-openpose", torch_dtype=torch.float16),
    ControlNetModel.from_pretrained("lllyasviel/sd-controlnet-canny", torch_dtype=torch.float16),
]

pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", controlnet=controlnet, torch_dtype=torch.float16
)
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)

pipe.enable_xformers_memory_efficient_attention()
pipe.enable_model_cpu_offload()

prompt = "a giant standing in a fantasy landscape, best quality"
negative_prompt = "monochrome, lowres, bad anatomy, worst quality, low quality"

generator = torch.Generator(device="cpu").manual_seed(1)

images = [openpose_image, canny_image]

image = pipe(
    prompt,
    images,
    num_inference_steps=20,
    generator=generator,
    negative_prompt=negative_prompt,
    controlnet_conditioning_scale=[1.0, 0.8],
).images[0]

image.save("./multi_controlnet_output.png")
```

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/controlnet/multi_controlnet_output.png" width=600/>
</p>

é€šè¿‡ä»¥ä¸Šç¤ºä¾‹ï¼Œæˆ‘ä»¬å¯¹ [`StableDiffusionControlNetPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/controlnet) çš„å¤šç§ç”¨æ³•æœ‰äº†ç›´è§‚çš„è®¤è¯†ï¼Œä¹Ÿå­¦ä¼šäº†å¦‚ä½•ä½¿ç”¨ Diffusers ç©è½¬ ControlNetã€‚ä¸è¿‡ï¼Œè¿˜æœ‰ä¸€äº› ControlNet æ”¯æŒçš„å…¶ä»–ç±»å‹çš„æ§åˆ¶æ¡ä»¶ç¤ºä¾‹ï¼Œç”±äºç¯‡å¹…åŸå› æœ¬æ–‡ä¸å†å±•å¼€ï¼Œå¦‚æƒ³äº†è§£æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥ç‚¹å‡»ä»¥ä¸‹é“¾æ¥æŸ¥çœ‹ç›¸åº”çš„æ¨¡å‹æ–‡æ¡£é¡µé¢:

* [lllyasviel/sd-controlnet-depth](https://huggingface.co/lllyasviel/sd-controlnet-depth)
* [lllyasviel/sd-controlnet-hed](https://huggingface.co/lllyasviel/sd-controlnet-hed)
* [lllyasviel/sd-controlnet-normal](https://huggingface.co/lllyasviel/sd-controlnet-normal)
* [lllyasviel/sd-controlnet-scribble](https://huggingface.co/lllyasviel/sd-controlnet-scribble)
* [lllyasviel/sd-controlnet-seg](https://huggingface.co/lllyasviel/sd-controlnet-scribble)
* [lllyasviel/sd-controlnet-openpose](https://huggingface.co/lllyasviel/sd-controlnet-openpose)
* [lllyasviel/sd-controlnet-mlsd](https://huggingface.co/lllyasviel/sd-controlnet-mlsd)
* [lllyasviel/sd-controlnet-canny](https://huggingface.co/lllyasviel/sd-controlnet-canny)

æˆ‘ä»¬éå¸¸æ¬¢è¿æ‚¨å°è¯•ç»„åˆä¸åŒçš„æ§åˆ¶ç»„ä»¶æ¥ç”Ÿæˆç²¾ç¾çš„å›¾åƒï¼Œå¹¶åœ¨ Twitter ä¸Šä¸ [@diffuserslib](https://twitter.com/diffuserslib) åˆ†äº«æ‚¨çš„ä½œå“ã€‚å¦‚æœæ‚¨è¿˜æ²¡æœ‰è¿è¡Œä¸Šè¿°ä»£ç æ®µï¼Œè¿™é‡Œå†æ¬¡å»ºè®®æ‚¨æŸ¥çœ‹åˆšæ‰æåˆ°çš„ [Colab ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/controlnet.ipynb)ï¼Œäº²è‡ªè¿è¡Œä»£ç ä½“éªŒç¤ºä¾‹çš„æ•ˆæœï¼

åœ¨ä¸Šæ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†åŠ é€Ÿç”Ÿæˆè¿‡ç¨‹ã€å‡å°‘æ˜¾å­˜å ç”¨çš„ä¸€äº›æŠ€å·§ï¼Œå®ƒä»¬åŒ…æ‹¬: å¿«é€Ÿè°ƒåº¦å™¨ã€æ™ºèƒ½æ¨¡å‹å¸è½½ã€`xformers`ã€‚å¦‚æœç»“åˆä½¿ç”¨è¿™äº›æŠ€å·§ï¼Œå•å¼ å›¾åƒçš„ç”Ÿæˆè¿‡ç¨‹ä»…éœ€è¦: V100 GPU ä¸Šçº¦ 3 ç§’çš„æ¨ç†æ—¶é—´ä»¥åŠçº¦ 4 GB çš„ VRAM å ç”¨ï¼›å…è´¹ GPU æœåŠ¡ (å¦‚ Google Colab çš„ T4) ä¸Šçº¦ 5 ç§’çš„æ¨ç†æ—¶é—´ã€‚å¦‚æœæ²¡æœ‰å®ç°è¿™äº›æŠ€å·§ï¼ŒåŒæ ·çš„ç”Ÿæˆè¿‡ç¨‹å¯è¾¾ 17 ç§’ï¼ç°å·²é›†æˆè‡³ Diffusers å·¥å…·ç®±ï¼Œæ¥ä½¿ç”¨ Diffusers å§ï¼Œå®ƒçœŸçš„éå¸¸å¼ºåŠ›ï¼ğŸ’ª

## ç»“è¯­

æœ¬æ–‡ä»‹ç»äº† [`StableDiffusionControlNetPipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/controlnet) çš„å¤šä¸ªç”¨ä¾‹ï¼Œéå¸¸æœ‰è¶£ï¼æˆ‘ä»¬ä¹Ÿéå¸¸æœŸå¾…çœ‹åˆ°ç¤¾åŒºåœ¨æ­¤ pipeline çš„åŸºç¡€ä¸Šèƒ½æ„å»ºå‡ºä»€ä¹ˆå¥½ç©çš„åº”ç”¨ã€‚å¦‚æœæ‚¨æƒ³äº†è§£æ›´å¤š Diffusers æ”¯æŒçš„å…³äºæ§åˆ¶æ¨¡å‹çš„å…¶ä»– pipeline å’ŒæŠ€æœ¯ç»†èŠ‚ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„ [å®˜æ–¹æ–‡æ¡£](https://huggingface.co/docs/diffusers/main/en/using-diffusers/controlling_generation)ã€‚

å¦‚æœæ‚¨æƒ³ç›´æ¥å°è¯• ControlNet çš„æ§åˆ¶æ•ˆæœï¼Œæˆ‘ä»¬ä¹Ÿèƒ½æ»¡è¶³ï¼åªéœ€ç‚¹å‡»ä»¥ä¸‹ HuggingFace Spaces å³å¯å°è¯•æ§åˆ¶ç”Ÿæˆå›¾åƒ:
- [![Canny ControlNet Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/diffusers/controlnet-canny)
- [![OpenPose ControlNet Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/diffusers/controlnet-openpose)
