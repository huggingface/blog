---
title: ä½¿ç”¨ LoRA è¿›è¡Œ Stable Diffusion çš„é«˜æ•ˆå‚æ•°å¾®è°ƒ
thumbnail: /blog/assets/lora/thumbnail.png
authors:
- user: pcuenq
- user: sayakpaul
translators:
- user: innovation64
- user: zhongdongy
  proofreader: true
---

# ä½¿ç”¨ LoRA è¿›è¡Œ Stable Diffusion çš„é«˜æ•ˆå‚æ•°å¾®è°ƒ


[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) æ˜¯å¾®è½¯ç ”ç©¶å‘˜å¼•å…¥çš„ä¸€é¡¹æ–°æŠ€æœ¯ï¼Œä¸»è¦ç”¨äºå¤„ç†å¤§æ¨¡å‹å¾®è°ƒçš„é—®é¢˜ã€‚ç›®å‰è¶…è¿‡æ•°åäº¿ä»¥ä¸Šå‚æ•°çš„å…·æœ‰å¼ºèƒ½åŠ›çš„å¤§æ¨¡å‹ (ä¾‹å¦‚ GPT-3) é€šå¸¸åœ¨ä¸ºäº†é€‚åº”å…¶ä¸‹æ¸¸ä»»åŠ¡çš„å¾®è°ƒä¸­ä¼šå‘ˆç°å‡ºå·¨å¤§å¼€é”€ã€‚LoRA å»ºè®®å†»ç»“é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡å¹¶åœ¨æ¯ä¸ª Transformer å—ä¸­æ³¨å…¥å¯è®­ç»ƒå±‚ (*ç§©-åˆ†è§£çŸ©é˜µ*)ã€‚å› ä¸ºä¸éœ€è¦ä¸ºå¤§å¤šæ•°æ¨¡å‹æƒé‡è®¡ç®—æ¢¯åº¦ï¼Œæ‰€ä»¥å¤§å¤§å‡å°‘äº†éœ€è¦è®­ç»ƒå‚æ•°çš„æ•°é‡å¹¶ä¸”é™ä½äº† GPU çš„å†…å­˜è¦æ±‚ã€‚ç ”ç©¶äººå‘˜å‘ç°ï¼Œé€šè¿‡èšç„¦å¤§æ¨¡å‹çš„ Transformer æ³¨æ„åŠ›å—ï¼Œä½¿ç”¨ LoRA è¿›è¡Œçš„å¾®è°ƒè´¨é‡ä¸å…¨æ¨¡å‹å¾®è°ƒç›¸å½“ï¼ŒåŒæ—¶é€Ÿåº¦æ›´å¿«ä¸”éœ€è¦æ›´å°‘çš„è®¡ç®—ã€‚

## ç”¨äº Diffusers çš„ LoRA ğŸ§¨

å°½ç®¡ LoRA æœ€åˆæ˜¯ä¸ºå¤§æ¨¡å‹æå‡ºçš„ï¼Œå¹¶åœ¨ transformer å—ä¸Šè¿›è¡Œäº†æ¼”ç¤ºï¼Œä½†è¯¥æŠ€æœ¯ä¹Ÿå¯ä»¥åº”ç”¨äºå…¶ä»–åœ°æ–¹ã€‚åœ¨å¾®è°ƒ Stable Diffusion çš„æƒ…å†µä¸‹ï¼ŒLoRA å¯ä»¥åº”ç”¨äºå°†å›¾åƒè¡¨ç¤ºä¸æè¿°å®ƒä»¬çš„æç¤ºç›¸å…³è”çš„äº¤å‰æ³¨æ„å±‚ã€‚ä¸‹å›¾çš„ç»†èŠ‚ (æ‘˜è‡ª [Stable Diffusion è®ºæ–‡](https://arxiv.org/abs/2112.10752)) å¹¶ä¸é‡è¦ï¼Œåªéœ€è¦æ³¨æ„é»„è‰²å—æ˜¯è´Ÿè´£å»ºç«‹å›¾æ–‡ä¹‹é—´çš„å…³ç³»è¡¨ç¤ºå°±è¡Œã€‚

![Latent Diffusion Architecture](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/lora-assets/latent-diffusion.png)

æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒSimo Ryu ([`@cloneofsimo`](https://github.com/cloneofsimo)) æ˜¯ç¬¬ä¸€ä¸ªæå‡ºé€‚ç”¨äº Stable Diffusion çš„ LoRA å®ç°çš„äººã€‚å¦‚æœæƒ³æŸ¥çœ‹ç›¸å…³ç¤ºä¾‹å’Œè®¸å¤šå…¶ä»–æœ‰è¶£çš„è®¨è®ºå’Œè§è§£ã€‚è¯·ä¸€å®šè¦çœ‹çœ‹ä»–ä»¬çš„ [GitHub é¡¹ç›®](https://github.com/cloneofsimo/lora)ã€‚

ä¸ºäº†å°† LoRA çš„å¯è®­ç»ƒçŸ©é˜µæ³¨å…¥åˆ°ä¸äº¤å‰æ³¨æ„åŠ›å±‚ä¸€æ ·æ·±çš„æ¨¡å‹ä¸­ï¼Œè¿‡å»äººä»¬éœ€è¦ä»¥å¯Œæœ‰æƒ³è±¡åŠ› (ä½†è„†å¼±) çš„æ–¹å¼ç ´è§£ [diffusers](https://github.com/huggingface/diffusers) çš„æºä»£ç ã€‚å¦‚æœ Stable Diffusion å‘æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä»¶äº‹ï¼Œé‚£å°±æ˜¯ç¤¾åŒºæ€»æ˜¯ä¼šæƒ³å‡ºåŠæ³•æ¥æ”¹å˜å’Œè°ƒæ•´æ¨¡å‹ä»¥è¾¾åˆ°åˆ›é€ æ€§ç›®çš„ï¼Œæˆ‘ä»¬å–œæ¬¢è¿™æ ·ï¼ç”±äºè®¸å¤šå…¶ä»–åŸå› ï¼Œæä¾›æ“çºµäº¤å‰æ³¨æ„åŠ›å±‚çš„çµæ´»æ€§å¯èƒ½æ˜¯æœ‰ç›Šçš„ï¼Œä¾‹å¦‚æ›´å®¹æ˜“é‡‡ç”¨ [xFormers](https://github.com/facebookresearch/xformers) ç­‰ä¼˜åŒ–æŠ€æœ¯ã€‚[Prompt-to-Prompt](https://arxiv.org/abs/2208.01626) ç­‰å…¶ä»–åˆ›æ„é¡¹ç›®å¯ä»¥ä½¿ç”¨ä¸€äº›ç®€å•çš„æ–¹æ³•æ¥è®¿é—®è¿™äº›å±‚ï¼Œå› æ­¤æˆ‘ä»¬å†³å®š [ä¸ºç”¨æˆ·æä¾›ä¸€ç§é€šç”¨çš„æ–¹æ³•æ¥åšåˆ°è¿™ä¸€ç‚¹](https://github.com/huggingface/diffusers/pull/1639)ã€‚è‡ª 12 æœˆä¸‹æ—¬ä»¥æ¥ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨æµ‹è¯•ï¼Œå¹¶åœ¨æˆ‘ä»¬çš„ diffusers ä¸­ [æ­£å¼å‘å¸ƒ](https://github.com/huggingface/diffusers/releases/tag/v0.12.0)ã€‚

æˆ‘ä»¬ä¸€ç›´åœ¨ä¸ [`@cloneofsimo`](https://github.com/cloneofsimo) åˆä½œï¼Œä¸º Dreambooth å’Œå…¨å¾®è°ƒæ–¹æ³•æä¾› Diffusions ä¸­çš„ LoRA è®­ç»ƒæ”¯æŒï¼è¿™äº›æŠ€æœ¯æä¾›äº†ä»¥ä¸‹å¥½å¤„ï¼š

- æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦
- è®¡ç®—è¦æ±‚è¾ƒä½ã€‚æˆ‘ä»¬å¯ä»¥åœ¨å…·æœ‰ 11 GB VRAM çš„ 2080 Ti ä¸­åˆ›å»ºä¸€ä¸ªå…¨å¾®è°ƒæ¨¡å‹ï¼
- **å°äº†å¾ˆå¤šçš„è®­ç»ƒæ¨¡å‹**ã€‚ç”±äºåŸå§‹æ¨¡å‹å·²å†»ç»“ï¼Œæˆ‘ä»¬æ³¨å…¥äº†æ–°å±‚è¿›è¡Œè®­ç»ƒï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†æ–°å±‚çš„æƒé‡ä¿å­˜ä¸ºå¤§å°çº¦ä¸º 3 MB çš„å•ä¸ªæ–‡ä»¶ã€‚è¿™æ¯” UNet æ¨¡å‹çš„åŸå§‹å¤§å° *å°ä¸€åƒå€*ã€‚

æˆ‘ä»¬å¯¹æœ€åä¸€ç‚¹ç‰¹åˆ«å…´å¥‹ã€‚ä¸ºäº†è®©ç”¨æˆ·åˆ†äº«ä»–ä»¬å‡ºè‰²çš„å¾®è°ƒæˆ– dreamboothed æ¨¡å‹ï¼Œä»–ä»¬å¿…é¡»åˆ†äº«æœ€ç»ˆæ¨¡å‹çš„å®Œæ•´å‰¯æœ¬ã€‚å…¶ä»–æƒ³è¦è¯•ç”¨å®ƒä»¬çš„ç”¨æˆ·å¿…é¡»åœ¨ä»–ä»¬æœ€å–œæ¬¢çš„ UI ä¸­ä¸‹è½½ç»è¿‡å¾®è°ƒçš„æƒé‡ï¼Œè¿™ä¼šå¢åŠ å¤§é‡å­˜å‚¨å’Œä¸‹è½½æˆæœ¬ã€‚æˆªè‡³ä»Šå¤©ï¼Œ[å¤§çº¦æœ‰ 1000 ä¸ª Dreambooth æ¨¡å‹åœ¨ Dreambooth æ¦‚å¿µåº“ä¸­æ³¨å†Œ](https://huggingface.co/sd-dreambooth-library)ï¼Œå¯èƒ½è¿˜æœ‰æ›´å¤šæœªåœ¨åº“ä¸­æ³¨å†Œã€‚

ä½¿ç”¨ LoRAï¼Œç°åœ¨å¯ä»¥å‘å¸ƒ [å•ä¸ª 3.29 MB æ–‡ä»¶](https://huggingface.co/sayakpaul/sd-model-finetuned-lora-t4/blob/main/pytorch_lora_weights.bin) ä»¥å…è®¸å…¶ä»–äººä½¿ç”¨ä½ çš„å¾®è°ƒæ¨¡å‹ã€‚

*(æ„Ÿè°¢ [`@mishig25`](https://github.com/mishig25)ï¼Œä»–æ˜¯æˆ‘äº†è§£åˆ°çš„é¦–ä¸ªåœ¨å¹³å¸¸å¯¹è¯ä¸­å°† **dreamboothing** ä½œä¸ºåŠ¨è¯çš„äºº)ã€‚*

## LoRA å¾®è°ƒ

Stable Diffusion çš„å…¨æ¨¡å‹å¾®è°ƒè¿‡å»æ—¢ç¼“æ…¢åˆå›°éš¾ï¼Œè¿™ä¹Ÿæ˜¯ Dreambooth æˆ– Textual Inversion ç­‰è½»é‡çº§æ–¹æ³•å˜å¾—å¦‚æ­¤æµè¡Œçš„éƒ¨åˆ†åŸå› ã€‚ä½¿ç”¨ LoRAï¼Œåœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šå¾®è°ƒæ¨¡å‹è¦å®¹æ˜“å¾—å¤šã€‚

Diffusers ç°åœ¨æä¾›äº†ä¸€ä¸ª [LoRA å¾®è°ƒè„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/text_to_image/train_text_to_image_lora.py)ï¼Œå¯ä»¥åœ¨ä½è‡³ 11 GB çš„ GPU RAM ä¸­è¿è¡Œè€Œæ— éœ€å€ŸåŠ©åˆ°è¯¸å¦‚ 8-bit ä¼˜åŒ–å™¨ä¹‹ç±»çš„æŠ€å·§ã€‚è¿™é‡Œå±•ç¤ºäº†æ‚¨å¦‚ä½•å€ŸåŠ©å®ƒæ¥ä½¿ç”¨ [Lambda Labs PokÃ©mon æ•°æ®é›†](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions) å¾®è°ƒæ¨¡å‹ï¼š

```bash
export MODEL_NAME="runwayml/stable-diffusion-v1-5"
export OUTPUT_DIR="/sddata/finetune/lora/pokemon"
export HUB_MODEL_ID="pokemon-lora"
export DATASET_NAME="lambdalabs/pokemon-blip-captions"

accelerate launch --mixed_precision="fp16"  train_text_to_image_lora.py \
  --pretrained_model_name_or_path=$MODEL_NAME \
  --dataset_name=$DATASET_NAME \
  --dataloader_num_workers=8 \
  --resolution=512 --center_crop --random_flip \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --max_train_steps=15000 \
  --learning_rate=1e-04 \
  --max_grad_norm=1 \
  --lr_scheduler="cosine" --lr_warmup_steps=0 \
  --output_dir=${OUTPUT_DIR} \
  --push_to_hub \
  --hub_model_id=${HUB_MODEL_ID} \
  --report_to=wandb \
  --checkpointing_steps=500 \
  --validation_prompt="Totoro" \
  --seed=1337
```

è¿™é‡Œéœ€è¦æ³¨æ„çš„ä¸€ä»¶äº‹æ˜¯å­¦ä¹ ç‡ä¸ºâ€œ1e-4â€ï¼Œè¿œå¤§äºå¸¸è§„å¾®è°ƒçš„é€šå¸¸å­¦ä¹ ç‡ (é€šå¸¸ä¸ºâ€œ~1e-6â€çš„æ•°é‡çº§)ã€‚è¿™æ˜¯ä¸Šæ¬¡è¿è¡Œçš„ [W&B dashboard](https://wandb.ai/pcuenq/text2image-fine-tune/runs/b4k1w0tn?workspace=user-pcuenq)ï¼Œåœ¨ 2080 Ti GPU (11 GB å†…å­˜)ã€‚æˆ‘æ²¡æœ‰å°è¯•ä¼˜åŒ–è¶…å‚æ•°ï¼Œæ‰€ä»¥è¯·è‡ªè¡Œå°è¯•ï¼[Sayak](https://huggingface.co/sayakpaul) åœ¨ T4 (16 GB å†…å­˜) ä¸Šåˆè·‘äº†ä¸€æ¬¡ï¼Œè¯· [åœ¨è¿™é‡Œ](https://huggingface.co/spaces/pcuenq/lora-pokemon) æŸ¥çœ‹ä»–çš„æœ€ç»ˆæ¨¡å‹ï¼Œä»¥åŠä½¿ç”¨è¯¥æ¨¡å‹çš„æ¼”ç¤ºç©ºé—´ã€‚

![Sample outputs from Sayak's LoRA model](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/lora-assets/sayak-pokemon-collage.png)

æœ‰å…³ diffusers ä¸­ LoRA æ”¯æŒçš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [æˆ‘ä»¬çš„æ–‡æ¡£](https://huggingface.co/docs/diffusers/main/en/training/lora) â€”â€”å®ƒå°†å§‹ç»ˆä¸å®ç°ä¿æŒåŒæ­¥ã€‚

## æ¨ç†

æ­£å¦‚æˆ‘ä»¬æ‰€è®¨è®ºçš„ï¼ŒLoRA çš„ä¸»è¦ä¼˜åŠ¿ä¹‹ä¸€æ˜¯æ‚¨å¯ä»¥é€šè¿‡è®­ç»ƒæ¯”åŸå§‹æ¨¡å‹å¤§å°å°‘å‡ ä¸ªæ•°é‡çº§çš„æƒé‡æ¥è·å¾—å‡ºè‰²çš„ç»“æœã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ¨ç†è¿‡ç¨‹ï¼Œå…è®¸åœ¨æœªä¿®æ”¹çš„ Stable Diffusion æ¨¡å‹æƒé‡ä¹‹ä¸ŠåŠ è½½é¢å¤–çš„æƒé‡ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Hub API è‡ªåŠ¨ç¡®å®šç”¨äºå¾®è°ƒ LoRA æ¨¡å‹çš„åŸºæœ¬æ¨¡å‹æ˜¯ä»€ä¹ˆã€‚ä» [Sayak çš„æ¨¡å‹](https://huggingface.co/sayakpaul/sd-model-finetuned-lora-t4) å¼€å§‹ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™æ®µä»£ç ï¼š

```Python
from huggingface_hub import model_info

# LoRA weights ~3 MB
model_path = "sayakpaul/sd-model-finetuned-lora-t4"

info = model_info(model_path)
model_base = info.cardData["base_model"]
print(model_base)   # CompVis/stable-diffusion-v1-4
```
æ­¤ä»£ç æ®µå°†æ‰“å°ä»–ç”¨äºå¾®è°ƒçš„æ¨¡å‹ï¼Œå³ `CompVis/stable-diffusion-v1-4`ã€‚å°±æˆ‘è€Œè¨€ï¼Œæˆ‘ä» Stable Diffusion 1.5 ç‰ˆå¼€å§‹è®­ç»ƒæˆ‘çš„æ¨¡å‹ï¼Œå› æ­¤å¦‚æœæ‚¨ä½¿ç”¨ [æˆ‘çš„ LoRA æ¨¡å‹](https://huggingface.co/pcuenq/pokemon-lora) è¿è¡Œç›¸åŒçš„ä»£ç ï¼Œæ‚¨ä¼šçœ‹åˆ°è¾“å‡ºæ˜¯ runwayml/stable-diffusion-v1-5ã€‚

å¦‚æœæ‚¨ä½¿ç”¨ `--push_to_hub` é€‰é¡¹ï¼Œæˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ä¸­çœ‹åˆ°çš„å¾®è°ƒè„šæœ¬ä¼šè‡ªåŠ¨å¡«å……æœ‰å…³åŸºæœ¬æ¨¡å‹çš„ä¿¡æ¯ã€‚æ­£å¦‚æ‚¨åœ¨ [pokemon-lora çš„ä»‹ç»æ–‡æ¡£](https://huggingface.co/pcuenq/pokemon-lora/blob/main/README.md) ä¸­æ‰€è§ï¼Œè¿™è¢«è®°å½•ä¸ºæ¨¡å‹å­˜å‚¨åº“çš„ `README` æ–‡ä»¶ä¸­çš„å…ƒæ•°æ®æ ‡ç­¾ã€‚

åœ¨æˆ‘ä»¬ç¡®å®šäº†ç”¨äºä½¿ç”¨ LoRA è¿›è¡Œå¾®è°ƒçš„åŸºç¡€æ¨¡å‹ä¹‹åï¼Œæˆ‘ä»¬åŠ è½½äº†ä¸€ä¸ªæ­£å¸¸çš„ç¨³å®šæ‰©æ•£ç®¡é“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ `DPMSolverMultistepScheduler` å¯¹å…¶è¿›è¡Œè‡ªå®šä¹‰ï¼Œä»¥å®ç°éå¸¸å¿«é€Ÿçš„æ¨ç†ï¼š

```Python
import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler

pipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)
pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
```

**ç¥å¥‡çš„åœ°æ–¹æ¥äº†**ã€‚æˆ‘ä»¬ä» hub åŠ è½½ LoRA æƒé‡ *åœ¨å¸¸è§„æ¨¡å‹æƒé‡ä¹‹ä¸Š*ï¼Œå°† pipline ç§»åŠ¨åˆ° cuda è®¾å¤‡å¹¶è¿è¡Œæ¨ç†ï¼š

```Python
pipe.unet.load_attn_procs(model_path)
pipe.to("cuda")

image = pipe("Green pokemon with menacing face", num_inference_steps=25).images[0]
image.save("green_pokemon.png")
```

## ç”¨ LoRA è¿›è¡Œ Dreamboothing

Dreambooth å…è®¸æ‚¨å‘ Stable Diffusion æ¨¡å‹â€œæ•™æˆâ€æ–°æ¦‚å¿µã€‚LoRA ä¸ Dreambooth å…¼å®¹ï¼Œè¿‡ç¨‹ç±»ä¼¼äºå¾®è°ƒï¼Œæœ‰å‡ ä¸ªä¼˜ç‚¹ï¼š

- è®­ç»ƒæ›´å¿«ã€‚
- æˆ‘ä»¬åªéœ€è¦å‡ å¼ æˆ‘ä»¬æƒ³è¦è®­ç»ƒçš„ä¸»é¢˜çš„å›¾åƒ (é€šå¸¸ 5 æˆ– 10 å¼ å°±è¶³å¤Ÿäº†)ã€‚
- å¦‚æœéœ€è¦ï¼Œæˆ‘ä»¬å¯ä»¥è°ƒæ•´æ–‡æœ¬ç¼–ç å™¨ï¼Œä»¥æé«˜å¯¹è®­ç»ƒä¸»ä½“çš„ä¿çœŸåº¦ã€‚

è¦ä½¿ç”¨ LoRA è®­ç»ƒ Dreamboothï¼Œæ‚¨éœ€è¦ä½¿ç”¨ [è¿™ä¸ª diffusers è„šæœ¬](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth_lora.py)ã€‚è¯·çœ‹ä¸€ä¸‹ç›¸å…³çš„é¡¹ç›® [README](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth#training-with-low-rank-adaptation-of-large-language-models-lora)ã€[æ–‡æ¡£](https://huggingface.co/docs/diffusers/main/en/training/lora) å’Œæˆ‘ä»¬çš„ [è¶…å‚æ•°æ¢ç´¢åšæ–‡](https://huggingface.co/blog/dreambooth) äº†è§£è¯¦ç»†ä¿¡æ¯.

å¦‚æœæ‚¨æƒ³ä½“éªŒä¸€ç§å¿«é€Ÿã€ä½æˆæœ¬åˆå®¹æ˜“çš„æ–¹å¼æ¥ç”¨ LoRA è®­ç»ƒæ‚¨çš„ Dreambooth æ¨¡å‹ï¼Œè¯·æŸ¥çœ‹ [`hysts`](https://twitter.com/hysts12321) åˆ›ä½œçš„ è¿™ä¸ª [Hugging Face Space](https://huggingface.co/spaces/lora-library/LoRA-DreamBooth-Training-UI)ã€‚æ‚¨éœ€è¦å…‹éš†å®ƒï¼Œç„¶åä¸ºå®ƒåˆ†é…ä¸€ä¸ª GPUï¼Œè¿™æ ·æ‰èƒ½è¿è¡Œåœ°è¶³å¤Ÿå¿«ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥çœä¸‹æ‚¨ä»å¤´å¼€å§‹é…ç½®è®­ç»ƒç¯å¢ƒçš„åŠŸå¤«ï¼Œæ‚¨å¯ä»¥åœ¨æ•°åˆ†é’Ÿå†…å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼

## å…¶ä»–æ–¹æ³•

å¯¹è½»æ¾å¾®è°ƒçš„è¿½æ±‚å¹¶ä¸æ–°é²œã€‚é™¤äº† Dreambooth ä¹‹å¤–ï¼Œ[_textual inversion_](https://huggingface.co/docs/diffusers/main/en/training/text_inversion) æ˜¯å¦ä¸€ç§æµè¡Œçš„æ–¹æ³•ï¼Œå®ƒè¯•å›¾å‘è®­ç»ƒæœ‰ç´ çš„ç¨³å®šæ‰©æ•£æ¨¡å‹æ•™æˆæ–°æ¦‚å¿µã€‚ä½¿ç”¨ Textual Inversion çš„ä¸»è¦åŸå› ä¹‹ä¸€æ˜¯ç»è¿‡è®­ç»ƒçš„æƒé‡ä¹Ÿå¾ˆå°ä¸”æ˜“äºå…±äº«ã€‚ç„¶è€Œï¼Œå®ƒä»¬åªé€‚ç”¨äºå•ä¸ªä¸»é¢˜ (æˆ–ä¸€å°éƒ¨åˆ†ä¸»é¢˜)ï¼Œè€Œ LoRA å¯ç”¨äºé€šç”¨å¾®è°ƒï¼Œè¿™æ„å‘³ç€å®ƒå¯ä»¥é€‚åº”æ–°çš„é¢†åŸŸæˆ–æ•°æ®é›†ã€‚

[Pivotal Tuning](https://arxiv.org/abs/2106.05744) æ˜¯ä¸€ç§å°è¯•å°† Textual Inversion ä¸ LoRA ç›¸ç»“åˆçš„æ–¹æ³•ã€‚é¦–å…ˆï¼Œæ‚¨ä½¿ç”¨ textual inversion æŠ€æœ¯å‘æ¨¡å‹æ•™æˆä¸€ä¸ªæ–°æ¦‚å¿µï¼Œè·å¾—ä¸€ä¸ªæ–°çš„æ ‡è®°åµŒå…¥æ¥è¡¨ç¤ºå®ƒã€‚ç„¶åï¼Œæ‚¨ä½¿ç”¨ LoRA è®­ç»ƒè¯¥ token åµŒå…¥ä»¥è·å¾—ä¸¤å…¨å…¶ç¾ã€‚

æˆ‘ä»¬è¿˜æ²¡æœ‰ä½¿ç”¨ LoRA æ¢ç´¢è¿‡ Pivotal Tuningã€‚è°æƒ³æ¥æŒ‘æˆ˜ï¼ŸğŸ¤—
