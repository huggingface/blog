---
title: "AudioLDM 2ï¼ŒåŠ é€Ÿâš¡ï¸ï¼" 
thumbnail: /blog/assets/161_audioldm2/thumbnail.png
authors:
- user: sanchit-gandhi
translators:
- user: MatrixYao
- user: zhongdongy
  proofreader: true
---

# AudioLDM 2ï¼ŒåŠ é€Ÿâš¡ï¸ï¼

<!-- {blog_metadata} -->
<!-- {authors} -->

<a target="_blank" href="https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/AudioLDM-2.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt=" åœ¨ Colab ä¸­æ‰“å¼€ "/>
</a>

AudioLDM 2 ç”±åˆ˜æ¿ èµ«ç­‰äººåœ¨ [AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining](https://arxiv.org/abs/2308.05734) ä¸€æ–‡ä¸­æå‡ºã€‚ AudioLDM 2 æ¥å—æ–‡æœ¬æç¤ºä½œä¸ºè¾“å…¥å¹¶è¾“å‡ºå¯¹åº”çš„éŸ³é¢‘ï¼Œå…¶å¯ç”¨äºç”Ÿæˆé€¼çœŸçš„å£°æ•ˆã€äººç±»è¯­éŸ³ä»¥åŠéŸ³ä¹ã€‚

è™½ç„¶ç”Ÿæˆçš„éŸ³é¢‘è´¨é‡å¾ˆé«˜ï¼Œä½†åŸºäºå…¶åŸå§‹å®ç°è¿›è¡Œæ¨ç†çš„é€Ÿåº¦éå¸¸æ…¢: ç”Ÿæˆä¸€ä¸ª 10 ç§’çš„éŸ³é¢‘éœ€è¦ 30 ç§’ä»¥ä¸Šçš„æ—¶é—´ã€‚æ…¢çš„åŸå› æ˜¯å¤šé‡çš„ï¼ŒåŒ…æ‹¬å…¶ä½¿ç”¨äº†å¤šé˜¶æ®µå»ºæ¨¡ã€checkpoint è¾ƒå¤§ä»¥åŠä»£ç å°šæœªä¼˜åŒ–ç­‰ã€‚

æœ¬æ–‡å°†å±•ç¤ºå¦‚ä½•åœ¨ Hugging Face ğŸ§¨ Diffusers åº“ä¸­ä½¿ç”¨ AudioLDM 2ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæ¢ç´¢ä¸€ç³»åˆ—ä»£ç ä¼˜åŒ– (å¦‚åŠç²¾åº¦ã€Flash æ³¨æ„åŠ›ã€å›¾ç¼–è¯‘) ä»¥åŠæ¨¡å‹çº§ä¼˜åŒ– (å¦‚é€‰æ‹©åˆé€‚çš„è°ƒåº¦å™¨åŠåå‘æç¤º)ã€‚æœ€ç»ˆæˆ‘ä»¬å°†æ¨ç†æ—¶é—´é™ä½äº† **10 å€** å¤šï¼Œä¸”å¯¹è¾“å‡ºéŸ³é¢‘è´¨é‡çš„å½±å“æœ€ä½ã€‚æœ¬æ–‡è¿˜é™„æœ‰ä¸€ä¸ªæ›´ç²¾ç®€çš„ [Colab notebook](https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/AudioLDM-2.ipynb)ï¼Œè¿™é‡Œé¢åŒ…å«æ‰€æœ‰ä»£ç ä½†ç²¾ç®€äº†å¾ˆå¤šæ–‡å­—éƒ¨åˆ†ã€‚

æœ€ç»ˆï¼Œæˆ‘ä»¬å¯ä»¥åœ¨çŸ­çŸ­ 1 ç§’å†…ç”Ÿæˆä¸€ä¸ª 10 ç§’çš„éŸ³é¢‘ï¼

## æ¨¡å‹æ¦‚è¿°

å— [Stable Diffusion](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/overview) çš„å¯å‘ï¼ŒAudioLDM 2 æ˜¯ä¸€ç§æ–‡ç”ŸéŸ³é¢‘çš„ _ éšæ‰©æ•£æ¨¡å‹ (latent diffusion modelï¼ŒLDM)_ï¼Œå…¶å¯ä»¥å°†æ–‡æœ¬åµŒå…¥æ˜ å°„æˆè¿ç»­çš„éŸ³é¢‘è¡¨å¾ã€‚

å¤§ä½“çš„ç”Ÿæˆæµç¨‹æ€»ç»“å¦‚ä¸‹:

1. ç»™å®šè¾“å…¥æ–‡æœ¬ $\boldsymbol{x}$ï¼Œä½¿ç”¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨æ¨¡å‹æ¥è®¡ç®—æ–‡æœ¬åµŒå…¥: [CLAP](https://huggingface.co/docs/transformers/main/en/model_doc/clap) çš„æ–‡æœ¬åˆ†æ”¯ï¼Œä»¥åŠ [Flan-T5](https://huggingface.co/docs/transformers/main/en/model_doc/flan-t5) çš„æ–‡æœ¬ç¼–ç å™¨ã€‚

    $$\boldsymbol{E} _{1} = \text{CLAP}\left(\boldsymbol{x} \right); \quad \boldsymbol{E}_ {2} = \text{T5}\left(\boldsymbol{x}\right)
    $$

    CLAP æ–‡æœ¬åµŒå…¥ç»è¿‡è®­ç»ƒï¼Œå¯ä»¥ä¸å¯¹åº”çš„éŸ³é¢‘åµŒå…¥å¯¹é½ï¼Œè€Œ Flan-T5 åµŒå…¥å¯ä»¥æ›´å¥½åœ°è¡¨å¾æ–‡æœ¬çš„è¯­ä¹‰ã€‚

2. è¿™äº›æ–‡æœ¬åµŒå…¥é€šè¿‡å„è‡ªçš„çº¿æ€§å±‚æŠ•å½±åˆ°åŒä¸€ä¸ªåµŒå…¥ç©ºé—´:

    $$\boldsymbol{P} _{1} = \boldsymbol{W}_ {\text{CLAP}} \boldsymbol{E} _{1}; \quad \boldsymbol{P}_ {2} = \boldsymbol{W} _{\text{T5}}\boldsymbol{E}_ {2}
    $$

    åœ¨ `diffusers` å®ç°ä¸­ï¼Œè¿™äº›æŠ•å½±ç”± [AudioLDM2ProjectionModel](https://huggingface.co/docs/diffusers/api/pipelines/audioldm2/AudioLDM2ProjectionModel) å®šä¹‰ã€‚

3. ä½¿ç”¨ [GPT2](https://huggingface.co/docs/transformers/main/en/model_doc/gpt2) è¯­è¨€æ¨¡å‹ (LM) åŸºäº CLAP å’Œ Flan-T5 åµŒå…¥è‡ªå›å½’åœ°ç”Ÿæˆä¸€ä¸ªå«æœ‰ $N$ ä¸ªåµŒå…¥å‘é‡çš„æ–°åºåˆ—:

    $$\tilde{\boldsymbol{E}} _{i} = \text{GPT2}\left(\boldsymbol{P}_ {1}, \boldsymbol{P} _{2}, \tilde{\boldsymbol{E}}_ {1:i-1}\right) \qquad \text{for } i=1,\dots,N$$
    
4. ä»¥ç”Ÿæˆçš„åµŒå…¥å‘é‡ $\tilde{\boldsymbol{E}} _{1:N}$ å’Œ Flan-T5 æ–‡æœ¬åµŒå…¥ $\boldsymbol{E}_ {2}$ ä¸ºæ¡ä»¶ï¼Œé€šè¿‡ LDM çš„åå‘æ‰©æ•£è¿‡ç¨‹å¯¹éšæœºéšå˜é‡è¿›è¡Œ _å»å™ª_ ã€‚LDM åœ¨åå‘æ‰©æ•£è¿‡ç¨‹ä¸­è¿è¡Œ $T$ ä¸ªæ­¥æ¨ç†:

    $$\boldsymbol{z} _{t} = \text{LDM}\left(\boldsymbol{z}_ {t-1} | \tilde{\boldsymbol{E}} _{1:N}, \boldsymbol{E}_ {2}\right) \qquad \text{for } t = 1, \dots, T$$

    å…¶ä¸­åˆå§‹éšå˜é‡ $\boldsymbol{z} _{0}$ æ˜¯ä»æ­£æ€åˆ†å¸ƒ $\mathcal{N} \left(\boldsymbol{0}, \boldsymbol{I} \right )$ ä¸­é‡‡æ ·è€Œå¾—ã€‚ LDM çš„ [UNet](https://huggingface.co/docs/diffusers/api/pipelines/audioldm2/AudioLDM2UNet2DConditionModel) çš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºå®ƒéœ€è¦ **ä¸¤ç»„** äº¤å‰æ³¨æ„åŠ›åµŒå…¥ï¼Œæ¥è‡ª GPT2 è¯­è¨€æ¨¡å‹çš„ $\tilde{\boldsymbol{E}}_ {1:N}$ å’Œæ¥è‡ª Flan-T5 çš„  $\boldsymbol{E}_{2}$ï¼Œè€Œå…¶ä»–å¤§å¤šæ•° LDM åªæœ‰ä¸€ä¸ªäº¤å‰æ³¨æ„åŠ›æ¡ä»¶ã€‚

5. æŠŠæœ€ç»ˆå»å™ªåçš„éšå˜é‡ $\boldsymbol{z}_{T}$ ä¼ ç»™ VAE è§£ç å™¨ä»¥æ¢å¤æ¢…å°”è°±å›¾ $\boldsymbol{s}$:

    $$
    \boldsymbol{s} = \text{VAE} _{\text{dec}} \left(\boldsymbol{z}_ {T}\right)
    $$

6. æ¢…å°”è°±å›¾è¢«ä¼ ç»™å£°ç å™¨ (vocoder) ä»¥è·å¾—è¾“å‡ºéŸ³é¢‘æ³¢å½¢ $\mathbf{y}$:

    $$
    \boldsymbol{y} = \text{Vocoder}\left(\boldsymbol{s}\right)
    $$

ä¸‹å›¾å±•ç¤ºäº†æ–‡æœ¬è¾“å…¥æ˜¯å¦‚ä½•ä½œä¸ºæ¡ä»¶ä¼ é€’ç»™æ¨¡å‹çš„ï¼Œå¯ä»¥çœ‹åˆ°åœ¨ LDM ä¸­ä¸¤ä¸ªæç¤ºåµŒå…¥å‡è¢«ç”¨ä½œäº†äº¤å‰æ³¨æ„åŠ›çš„æ¡ä»¶:

<p align="center">
  <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/161_audioldm2/audioldm2.png?raw=true" width="600"/>
</p>

æœ‰å…³å¦‚ä½•è®­ç»ƒ AudioLDM 2 æ¨¡å‹çš„å®Œæ•´çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯»è€…å¯ä»¥å‚é˜… [AudioLDM 2 è®ºæ–‡](https://arxiv.org/abs/2308.05734)ã€‚

Hugging Face ğŸ§¨ Diffusers æä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¨ç†æµæ°´çº¿ç±» [`AudioLDM2Pipeline`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/audioldm2) ä»¥å°†è¯¥æ¨¡å‹çš„å¤šé˜¶æ®µç”Ÿæˆè¿‡ç¨‹åŒ…è£…åˆ°å•ä¸ªå¯è°ƒç”¨å¯¹è±¡ä¸­ï¼Œè¿™æ ·ç”¨æˆ·åªéœ€å‡ è¡Œä»£ç å³å¯å®Œæˆä»æ–‡æœ¬ç”ŸæˆéŸ³é¢‘çš„è¿‡ç¨‹ã€‚

AudioLDM 2 æœ‰ä¸‰ä¸ªå˜ä½“ã€‚å…¶ä¸­ä¸¤ä¸ª checkpoint é€‚ç”¨äºé€šç”¨çš„æ–‡æœ¬åˆ°éŸ³é¢‘ç”Ÿæˆä»»åŠ¡ï¼Œç¬¬ä¸‰ä¸ª checkpoint ä¸“é—¨é’ˆå¯¹æ–‡æœ¬åˆ°éŸ³ä¹ç”Ÿæˆã€‚ä¸‰ä¸ªå®˜æ–¹ checkpoint çš„è¯¦ç»†ä¿¡æ¯è¯·å‚è§ä¸‹è¡¨ï¼Œè¿™äº› checkpoint éƒ½å¯ä»¥åœ¨ [Hugging Face Hub](https://huggingface.co/models?search=cvssp/audioldm2) ä¸Šæ‰¾åˆ°:

| checkpoint                                                            | ä»»åŠ¡          | æ¨¡å‹å¤§å° | è®­ç»ƒæ•°æ®ï¼ˆå•ä½ï¼šå°æ—¶ï¼‰ |
|-----------------------------------------------------------------------|---------------|------------|-------------------|
| [cvssp/audioldm2](https://huggingface.co/cvssp/audioldm2)             | æ–‡ç”ŸéŸ³é¢‘ | 1.1B       | 1150k             |
| [cvssp/audioldm2-music](https://huggingface.co/cvssp/audioldm2-music) | æ–‡ç”ŸéŸ³ä¹ | 1.1B       | 665k              |
| [cvssp/audioldm2-large](https://huggingface.co/cvssp/audioldm2-large) | æ–‡ç”ŸéŸ³é¢‘ | 1.5B       | 1150k             |

è‡³æ­¤ï¼Œæˆ‘ä»¬å·²ç»å…¨é¢æ¦‚è¿°äº† AudioLDM 2 ç”Ÿæˆçš„å·¥ä½œåŸç†ï¼Œæ¥ä¸‹æ¥è®©æˆ‘ä»¬å°†è¿™ä¸€ç†è®ºä»˜è¯¸å®è·µï¼

## åŠ è½½æµæ°´çº¿

æˆ‘ä»¬ä»¥åŸºç¡€ç‰ˆæ¨¡å‹ [cvssp/audioldm2](https://huggingface.co/cvssp/audioldm2) ä¸ºä¾‹ï¼Œé¦–å…ˆä½¿ç”¨ [`.from_pretrained`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained) æ–¹æ³•æ¥åŠ è½½æ•´ä¸ªç®¡é“ï¼Œè¯¥æ–¹æ³•ä¼šå®ä¾‹åŒ–ç®¡é“å¹¶åŠ è½½é¢„è®­ç»ƒæƒé‡:

```python
from diffusers import AudioLDM2Pipeline

model_id = "cvssp/audioldm2"
pipe = AudioLDM2Pipeline.from_pretrained(model_id)
```

**è¾“å‡º:**

```
Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:01<00:00, 7.62it/s]
```

ä¸ PyTorch ä¸€æ ·ï¼Œä½¿ç”¨ `to` æ–¹æ³•å°†æµæ°´çº¿ç§»è‡³ GPU:

```python
pipe.to("cuda");
```

ç°åœ¨ï¼Œæˆ‘ä»¬æ¥å®šä¹‰ä¸€ä¸ªéšæœºæ•°ç”Ÿæˆå™¨å¹¶å›ºå®šä¸€ä¸ªç§å­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼æ¥å›ºå®š LDM æ¨¡å‹ä¸­çš„èµ·å§‹éšå˜é‡ä»è€Œä¿è¯ç»“æœçš„å¯å¤ç°æ€§ï¼Œå¹¶å¯ä»¥è§‚å¯Ÿä¸åŒæç¤ºå¯¹ç”Ÿæˆè¿‡ç¨‹å’Œç»“æœçš„å½±å“:

```python
import torch

generator = torch.Generator("cuda").manual_seed(0)
```

ç°åœ¨ï¼Œæˆ‘ä»¬å‡†å¤‡å¥½å¼€å§‹ç¬¬ä¸€æ¬¡ç”Ÿæˆäº†ï¼æœ¬æ–‡ä¸­çš„æ‰€æœ‰å®éªŒéƒ½ä¼šä½¿ç”¨å›ºå®šçš„æ–‡æœ¬æç¤ºä»¥åŠç›¸åŒçš„éšæœºç§å­æ¥ç”ŸæˆéŸ³é¢‘ï¼Œå¹¶æ¯”è¾ƒä¸åŒæ–¹æ¡ˆçš„å»¶æ—¶å’Œæ•ˆæœã€‚ [`audio_length_in_s`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/audioldm2#diffusers.AudioLDM2Pipeline.__call__.audio_length_in_s) å‚æ•°ä¸»è¦æ§åˆ¶æ‰€ç”ŸæˆéŸ³é¢‘çš„é•¿åº¦ï¼Œè¿™é‡Œæˆ‘ä»¬å°†å…¶è®¾ç½®ä¸ºé»˜è®¤å€¼ï¼Œå³ LDM è®­ç»ƒæ—¶çš„éŸ³é¢‘é•¿åº¦: 10.24 ç§’:

```python
prompt = "The sound of Brazilian samba drums with waves gently crashing in the background"

audio = pipe(prompt, audio_length_in_s=10.24, generator=generator).audios[0]
```

**è¾“å‡º:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:13<00:00, 15.27it/s]
```

é…·ï¼æˆ‘ä»¬èŠ±äº†å¤§çº¦ 13 ç§’æœ€ç»ˆç”Ÿæˆå‡ºäº†éŸ³é¢‘ã€‚æˆ‘ä»¬æ¥å¬ä¸€ä¸‹:

```python
from IPython.display import Audio

Audio(audio, rate=16000)
```

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/161_audioldm2/sample_1.wav" type="audio/wav">
æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

å¬èµ·æ¥è·Ÿæˆ‘ä»¬çš„æ–‡å­—æç¤ºå¾ˆå»åˆï¼è´¨é‡å¾ˆå¥½ï¼Œä½†æ˜¯æœ‰ä¸€äº›èƒŒæ™¯å™ªéŸ³ã€‚æˆ‘ä»¬å¯ä»¥ä¸ºæµæ°´çº¿æä¾› [_åå‘æç¤º (negative prompt)_](https://huggingface.co/docs/diffusers/main/en/api/pipelines/audioldm2#diffusers.AudioLDM2Pipeline.__call__.negative_prompt)ï¼Œä»¥é˜²æ­¢å…¶ç”Ÿæˆçš„éŸ³é¢‘ä¸­å«æœ‰æŸäº›ä¸æƒ³è¦ç‰¹å¾ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬ç»™æ¨¡å‹ä¸€ä¸ªåå‘æç¤ºï¼Œä»¥é˜²æ­¢æ¨¡å‹ç”Ÿæˆä½è´¨é‡çš„éŸ³é¢‘ã€‚æˆ‘ä»¬ä¸è®¾ `audio_length_in_s` å‚æ•°ä»¥ä½¿ç”¨å…¶é»˜è®¤å€¼:

```python
negative_prompt = "Low quality, average quality."

audio = pipe(prompt, negative_prompt=negative_prompt, generator=generator.manual_seed(0)).audios[0]
```

**è¾“å‡º:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:12<00:00, 16.50it/s]
```

ä½¿ç”¨åå‘æç¤º ${}^1$ æ—¶ï¼Œæ¨ç†æ—¶é—´ä¸å˜; æˆ‘ä»¬åªéœ€å°† LDM çš„æ— æ¡ä»¶è¾“å…¥æ›¿æ¢ä¸ºåå‘æç¤ºå³å¯ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬åœ¨éŸ³é¢‘è´¨é‡æ–¹é¢è·å¾—çš„ä»»ä½•æ”¶ç›Šéƒ½æ˜¯å…è´¹çš„ã€‚

æˆ‘ä»¬å¬ä¸€ä¸‹ç”Ÿæˆçš„éŸ³é¢‘:

```python
Audio(audio, rate=16000)
```

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/161_audioldm2/sample_2.wav" type="audio/wav">
æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

æ˜¾ç„¶ï¼Œæ•´ä½“éŸ³é¢‘è´¨é‡æœ‰æ‰€æ”¹å–„ - å™ªå£°æ›´å°‘ï¼Œå¹¶ä¸”éŸ³é¢‘æ•´ä½“å¬èµ·æ¥æ›´æ¸…æ™°ã€‚

${}^1$ è¯·æ³¨æ„ï¼Œåœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šçœ‹åˆ°ç¬¬äºŒæ¬¡ç”Ÿæˆæ¯”ç¬¬ä¸€æ¬¡ç”Ÿæˆæ‰€éœ€çš„æ¨ç†æ—¶é—´æœ‰æ‰€å‡å°‘ã€‚è¿™æ˜¯ç”±äºæˆ‘ä»¬ç¬¬ä¸€æ¬¡è¿è¡Œè®¡ç®—æ—¶ CUDA è¢«â€œé¢„çƒ­â€äº†ã€‚å› æ­¤ä¸€èˆ¬è¿›è¡ŒåŸºå‡†æµ‹è¯•æ—¶æˆ‘ä»¬ä¼šé€‰æ‹©ç¬¬äºŒæ¬¡æ¨ç†çš„æ—¶é—´ä½œä¸ºç»“æœã€‚

## ä¼˜åŒ– 1: Flash æ³¨æ„åŠ›

PyTorch 2.0 åŠæ›´é«˜ç‰ˆæœ¬åŒ…å«äº†ä¸€ä¸ªä¼˜åŒ–è¿‡çš„å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶çš„å®ç°ï¼Œç”¨æˆ·å¯é€šè¿‡ [`torch.nn.function.scaled_dot_product_attention`](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention) (SDPA) å‡½æ•°æ¥è°ƒç”¨è¯¥ä¼˜åŒ–ã€‚è¯¥å‡½æ•°ä¼šæ ¹æ®è¾“å…¥è‡ªåŠ¨ä½¿èƒ½å¤šä¸ªå†…ç½®ä¼˜åŒ–ï¼Œå› æ­¤æ¯”æ™®é€šçš„æ³¨æ„åŠ›å®ç°è¿è¡Œå¾—æ›´å¿«ã€æ›´èŠ‚çœå†…å­˜ã€‚æ€»ä½“è€Œè¨€ï¼ŒSDPA å‡½æ•°çš„ä¼˜åŒ–ä¸ Dao ç­‰äººåœ¨è®ºæ–‡ [Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2205.14135) ä¸­æ‰€æå‡ºçš„ _flash æ³¨æ„åŠ›_ ç±»ä¼¼ã€‚

å¦‚æœå®‰è£…äº† PyTorch 2.0 ä¸” `torch.nn.function.scaled_dot_product_attention` å¯ç”¨ï¼ŒDiffusers å°†é»˜è®¤å¯ç”¨è¯¥å‡½æ•°ã€‚å› æ­¤ï¼Œä»…éœ€æŒ‰ç…§ [å®˜æ–¹è¯´æ˜](https://pytorch.org/get-started/locally/) å®‰è£… torch 2.0 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œä¸éœ€å¯¹æµæ°´çº¿ğŸš€ä½œä»»ä½•æ”¹åŠ¨ï¼Œå³èƒ½äº«å—æé€Ÿã€‚

```python
audio = pipe(prompt, negative_prompt=negative_prompt, generator=generator.manual_seed(0)).audios[0]
```

**è¾“å‡º:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:12<00:00, 16.60it/s]
```

æœ‰å…³åœ¨ `diffusers` ä¸­ä½¿ç”¨ SDPA çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…ç›¸åº”çš„ [æ–‡æ¡£](https://huggingface.co/docs/diffusers/optimization/torch2.0)ã€‚

## ä¼˜åŒ– 2: åŠç²¾åº¦

é»˜è®¤æƒ…å†µä¸‹ï¼Œ `AudioLDM2Pipeline` ä»¥ float32 (å…¨) ç²¾åº¦æ–¹å¼åŠ è½½æ¨¡å‹æƒé‡ã€‚æ‰€æœ‰æ¨¡å‹è®¡ç®—ä¹Ÿä»¥ float32 ç²¾åº¦æ‰§è¡Œã€‚å¯¹æ¨ç†è€Œè¨€ï¼Œæˆ‘ä»¬å¯ä»¥å®‰å…¨åœ°å°†æ¨¡å‹æƒé‡å’Œè®¡ç®—è½¬æ¢ä¸º float16 (åŠ) ç²¾åº¦ï¼Œè¿™èƒ½æ”¹å–„æ¨ç†æ—¶é—´å’Œ GPU å†…å­˜ï¼ŒåŒæ—¶å¯¹ç”Ÿæˆè´¨é‡çš„å½±å“å¾®ä¹å…¶å¾®ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡å°† `from_pretrained` çš„ [`torch_dtype`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/overview#diffusers.DiffusionPipeline.from_pretrained.torch_dtype) å‚æ•°è®¾ä¸º `torch.float16` æ¥åŠ è½½åŠç²¾åº¦æƒé‡:

```python
pipe = AudioLDM2Pipeline.from_pretrained(model_id, torch_dtype=torch.float16)

pipe.to("cuda");
```

æˆ‘ä»¬è¿è¡Œä¸€ä¸‹ float16 ç²¾åº¦çš„ç”Ÿæˆï¼Œå¹¶å¬ä¸€ä¸‹è¾“å‡º:

```python
audio = pipe(prompt, negative_prompt=negative_prompt, generator=generator.manual_seed(0)).audios[0]

Audio(audio, rate=16000)
```

**è¾“å‡º:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:09<00:00, 20.94it/s]
```

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/161_audioldm2/sample_3.wav" type="audio/wav">
æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

éŸ³é¢‘è´¨é‡ä¸å…¨ç²¾åº¦ç”ŸæˆåŸºæœ¬æ²¡æœ‰å˜åŒ–ï¼Œæ¨ç†åŠ é€Ÿäº†å¤§çº¦ 2 ç§’ã€‚æ ¹æ®æˆ‘ä»¬çš„ç»éªŒï¼Œä½¿ç”¨å…·æœ‰ float16 ç²¾åº¦çš„ `diffusers` æµæ°´çº¿ï¼Œæˆ‘ä»¬å¯ä»¥è·å¾—æ˜¾è‘—çš„æ¨ç†åŠ é€Ÿè€Œæ— æ˜æ˜¾çš„éŸ³é¢‘è´¨é‡ä¸‹é™ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å»ºè®®é»˜è®¤ä½¿ç”¨ float16 ç²¾åº¦ã€‚

## ä¼˜åŒ– 3: Torch Compile

ä¸ºäº†è·å¾—é¢å¤–çš„åŠ é€Ÿï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨æ–°çš„ `torch.compile` åŠŸèƒ½ã€‚ç”±äºåœ¨æµæ°´çº¿ä¸­ UNet é€šå¸¸è®¡ç®—æˆæœ¬æœ€é«˜ï¼Œå› æ­¤æˆ‘ä»¬ç”¨ `torch.compile` ç¼–è¯‘ä¸€ä¸‹ UNetï¼Œå…¶ä½™å­æ¨¡å‹ (æ–‡æœ¬ç¼–ç å™¨å’Œ VAE) ä¿æŒä¸å˜:

```python
pipe.unet = torch.compile(pipe.unet, mode="reduce-overhead", fullgraph=True)
```

ç”¨ `torch.compile` åŒ…è£… UNet åï¼Œç”±äºç¼–è¯‘ UNet çš„å¼€é”€ï¼Œæˆ‘ä»¬è¿è¡Œç¬¬ä¸€æ­¥æ¨ç†æ—¶é€šå¸¸ä¼šå¾ˆæ…¢ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å…ˆè¿è¡Œä¸€æ­¥æµæ°´çº¿é¢„çƒ­ï¼Œè¿™æ ·åé¢çœŸæ­£è¿è¡Œçš„æ—¶å€™å°±å¿«äº†ã€‚è¯·æ³¨æ„ï¼Œç¬¬ä¸€æ¬¡æ¨ç†çš„ç¼–è¯‘æ—¶é—´å¯èƒ½é•¿è¾¾ 2 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼

```python
audio = pipe(prompt, negative_prompt=negative_prompt, generator=generator.manual_seed(0)).audios[0]
```

**è¾“å‡º:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:23<00:00, 2.39it/s]
```

å¾ˆæ£’ï¼ç°åœ¨ UNet å·²ç¼–è¯‘å®Œæ¯•ï¼Œç°åœ¨å¯ä»¥ä»¥æ›´å¿«çš„é€Ÿåº¦è¿è¡Œå®Œæ•´çš„æ‰©æ•£è¿‡ç¨‹äº†:

```python
audio = pipe(prompt, negative_prompt=negative_prompt, generator=generator.manual_seed(0)).audios[0]
```

**è¾“å‡º:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:04<00:00, 48.98it/s]
```

åªéœ€ 4 ç§’å³å¯ç”Ÿæˆï¼åœ¨å®è·µä¸­ï¼Œä½ åªéœ€ç¼–è¯‘ UNet ä¸€æ¬¡ï¼Œç„¶åå°±å¯ä»¥ä¸ºåé¢çš„æ‰€æœ‰ç”Ÿæˆèµ¢å¾—ä¸€ä¸ªæ›´å¿«çš„æ¨ç†ã€‚è¿™æ„å‘³ç€ç¼–è¯‘æ¨¡å‹æ‰€èŠ±è´¹çš„æ—¶é—´å¯ä»¥ç”±åç»­æ¨ç†æ—¶é—´çš„æ”¶ç›Šæ‰€å‡æ‘Šã€‚æœ‰å…³ `torch.compile` çš„æ›´å¤šä¿¡æ¯åŠé€‰é¡¹ï¼Œè¯·å‚é˜… [torch compile](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html) æ–‡æ¡£ã€‚

## ä¼˜åŒ– 4: è°ƒåº¦å™¨

è¿˜æœ‰ä¸€ä¸ªé€‰é¡¹æ˜¯å‡å°‘æ¨ç†æ­¥æ•°ã€‚é€‰æ‹©æ›´é«˜æ•ˆçš„è°ƒåº¦å™¨å¯ä»¥å¸®åŠ©å‡å°‘æ­¥æ•°ï¼Œè€Œä¸ä¼šç‰ºç‰²è¾“å‡ºéŸ³é¢‘è´¨é‡ã€‚ä½ å¯ä»¥è°ƒç”¨ [`schedulers.compatibles`](https://huggingface.co/docs/diffusers/v0.20.0/en/api/schedulers/overview#diffusers.SchedulerMixin) å±æ€§æ¥æŸ¥çœ‹å“ªäº›è°ƒåº¦å™¨ä¸ `AudioLDM2Pipeline` å…¼å®¹:

```python
pipe.scheduler.compatibles
```

**è¾“å‡º:**

```
[diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,
 diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,
 diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,
 diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler,
 diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,
 diffusers.schedulers.scheduling_pndm.PNDMScheduler,
 diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,
 diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler,
 diffusers.schedulers.scheduling_ddpm.DDPMScheduler,
 diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,
 diffusers.utils.dummy_torch_and_torchsde_objects.DPMSolverSDEScheduler,
 diffusers.schedulers.scheduling_ddim.DDIMScheduler,
 diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler,
 diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler]
```

å¥½ï¼ç°åœ¨æˆ‘ä»¬æœ‰ä¸€é•¿ä¸²çš„è°ƒåº¦å™¨å¤‡é€‰ğŸ“ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒAudioLDM 2 ä½¿ç”¨ [`DDIMScheduler`](https://huggingface.co/docs/diffusers/api/schedulers/ddim)ï¼Œå…¶éœ€è¦ 200 ä¸ªæ¨ç†æ­¥æ‰èƒ½ç”Ÿæˆé«˜è´¨é‡çš„éŸ³é¢‘ã€‚ä½†æ˜¯ï¼Œæ€§èƒ½æ›´é«˜çš„è°ƒåº¦ç¨‹åºï¼Œä¾‹å¦‚ [`DPMSolverMultistepScheduler`](https://huggingface.co/docs/diffusers/main/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler)ï¼Œ
åªéœ€ **20-25 ä¸ªæ¨ç†æ­¥** å³å¯è·å¾—ç±»ä¼¼çš„ç»“æœã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å°† AudioLDM 2 è°ƒåº¦å™¨ä» `DDIM` åˆ‡æ¢åˆ° `DPM Multistep` ã€‚æˆ‘ä»¬éœ€è¦ä½¿ç”¨ [`ConfigMixin.from_config()`](https://huggingface.co/docs/diffusers/main/en/api/configuration#diffusers.ConfigMixin.from_config) æ–¹æ³•ä»¥ç”¨åŸå§‹ [`DDIMScheduler`](https://huggingface.co/docs/diffusers/api/schedulers/ddim) çš„é…ç½®æ¥åŠ è½½ [`DPMSolverMultistepScheduler`](https://huggingface.co/docs/diffusers/main/en/api/schedulers/multistep_dpm_solver#diffusers.DPMSolverMultistepScheduler):

```python
from diffusers import DPMSolverMultistepScheduler

pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
```

è®©æˆ‘ä»¬å°†æ¨ç†æ­¥æ•°è®¾ä¸º 20ï¼Œå¹¶ä½¿ç”¨æ–°çš„è°ƒåº¦å™¨é‡æ–°ç”Ÿæˆã€‚ç”±äº LDM éšå˜é‡çš„å½¢çŠ¶æœªæ›´æ”¹ï¼Œå› æ­¤æˆ‘ä»¬ä¸å¿…é‡ç¼–è¯‘:

```python
audio = pipe(prompt, negative_prompt=negative_prompt, num_inference_steps=20, generator=generator.manual_seed(0)).audios[0]
```

**è¾“å‡º:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 49.14it/s]
```

è¿™æ¬¡åªç”¨äº†ä¸åˆ° **1 ç§’** å°±ç”Ÿæˆäº†éŸ³é¢‘ï¼æˆ‘ä»¬å¬ä¸‹å®ƒçš„ç”Ÿæˆ:

```python
Audio(audio, rate=16000)
```

<audio controls>
  <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/161_audioldm2/sample_4.wav" type="audio/wav">
æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å…ƒç´ ã€‚
</audio>

ç”Ÿæˆè´¨é‡ä¸åŸæ¥çš„åŸºæœ¬ç›¸åŒï¼Œä½†åªèŠ±äº†åŸæ¥æ—¶é—´çš„ä¸€å°éƒ¨åˆ†ï¼ ğŸ§¨ Diffusers æµæ°´çº¿æ˜¯â€œå¯ç»„åˆâ€çš„ï¼Œè¿™ä¸ªè®¾è®¡å…è®¸ä½ è½»æ¾åœ°æ›¿æ¢è°ƒåº¦å™¨æˆ–å…¶ä»–ç»„ä»¶ä»¥è·å¾—æ›´é«˜æ€§èƒ½ã€‚

## å†…å­˜æ¶ˆè€—å¦‚ä½•ï¼Ÿ

æˆ‘ä»¬æƒ³è¦ç”Ÿæˆçš„éŸ³é¢‘çš„é•¿åº¦å†³å®šäº† LDM ä¸­å¾…å»å™ªçš„éšå˜é‡çš„ _å®½åº¦_ ã€‚ç”±äº UNet ä¸­äº¤å‰æ³¨æ„åŠ›å±‚çš„å†…å­˜éšåºåˆ—é•¿åº¦ (å®½åº¦) çš„å¹³æ–¹è€Œå˜åŒ–ï¼Œå› æ­¤ç”Ÿæˆéå¸¸é•¿çš„éŸ³é¢‘å¯èƒ½ä¼šå¯¼è‡´å†…å­˜ä¸è¶³é”™è¯¯ã€‚æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡ batch size æ¥æ§åˆ¶ç”Ÿæˆçš„æ ·æœ¬æ•°ï¼Œè¿›è€Œæ§åˆ¶å†…å­˜ä½¿ç”¨ã€‚

å¦‚å‰æ‰€è¿°ï¼Œä»¥ float16 åŠç²¾åº¦åŠ è½½æ¨¡å‹å¯ä»¥èŠ‚çœå¤§é‡å†…å­˜ã€‚ä½¿ç”¨ PyTorch 2.0 SDPA ä¹Ÿå¯ä»¥æ”¹å–„å†…å­˜å ç”¨ï¼Œä½†è¿™éƒ¨åˆ†æ”¹å–„å¯¹è¶…é•¿åºåˆ—é•¿åº¦æ¥è®²å¯èƒ½ä¸å¤Ÿã€‚

æˆ‘ä»¬æ¥è¯•ç€ç”Ÿæˆä¸€ä¸ª 2.5 åˆ†é’Ÿ (150 ç§’) çš„éŸ³é¢‘ã€‚æˆ‘ä»¬é€šè¿‡è®¾ç½® [`num_waveforms_per_prompt`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/audioldm2#diffusers.AudioLDM2Pipeline.__call__.num_waveforms_per_prompt) `=4` æ¥ç”Ÿæˆ 4 ä¸ªå€™é€‰éŸ³é¢‘ã€‚ä¸€æ—¦ [`num_waveforms_per_prompt`](https://huggingface.co/docs/diffusers/main/en/api/pipelines/audioldm2#diffusers.AudioLDM2Pipeline.__call__.num_waveforms_per_prompt) `>1` ï¼Œåœ¨ç”Ÿæˆçš„éŸ³é¢‘å’Œæ–‡æœ¬æç¤ºä¹‹é—´ä¼šæœ‰ä¸€ä¸ªè‡ªåŠ¨è¯„åˆ†æœºåˆ¶: å°†éŸ³é¢‘å’Œæ–‡æœ¬æç¤ºåµŒå…¥åˆ° CLAP éŸ³é¢‘æ–‡æœ¬åµŒå…¥ç©ºé—´ä¸­ï¼Œç„¶åæ ¹æ®å®ƒä»¬çš„ä½™å¼¦ç›¸ä¼¼åº¦å¾—åˆ†è¿›è¡Œæ’åã€‚ç”Ÿæˆçš„éŸ³é¢‘ä¸­ç¬¬ `0` ä¸ªéŸ³é¢‘å°±æ˜¯åˆ†æ•°â€œæœ€é«˜â€çš„éŸ³é¢‘ã€‚

ç”±äºæˆ‘ä»¬æ›´æ”¹äº† UNet ä¸­éšå˜é‡çš„å®½åº¦ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»ä½¿ç”¨æ–°çš„éšå˜é‡å½¢çŠ¶å†æ‰§è¡Œä¸€æ¬¡ torch ç¼–è¯‘ã€‚ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œæˆ‘ä»¬å°±ä¸ç¼–è¯‘äº†ï¼Œç›´æ¥é‡æ–°åŠ è½½ç®¡é“:

```python
pipe = AudioLDM2Pipeline.from_pretrained(model_id, torch_dtype=torch.float16)

pipe.to("cuda")

audio = pipe(prompt, negative_prompt=negative_prompt, num_waveforms_per_prompt=4, audio_length_in_s=150, num_inference_steps=20, generator=generator.manual_seed(0)).audios[0]
```

**è¾“å‡º:**

```
---------------------------------------------------------------------------
OutOfMemoryError Traceback (most recent call last)
<ipython-input-33-c4cae6410ff5> in <cell line: 5>()
      3 pipe.to("cuda")
      4
----> 5 audio = pipe(prompt, negative_prompt=negative_prompt, num_waveforms_per_prompt=4, audio_length_in_s=150, num_inference_steps=20, generator=generator.manual_seed(0)).audios[0]

23 frames
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py in forward(self, input)
    112
    113 def forward(self, input: Tensor) -> Tensor:
--> 114 return F.linear(input, self.weight, self.bias)
    115
    116 def extra_repr(self) -> str:

OutOfMemoryError: CUDA out of memory. Tried to allocate 1.95 GiB. GPU 0 has a total capacty of 14.75 GiB of which 1.66 GiB is free. Process 414660 has 13.09 GiB memory in use. Of the allocated memory 10.09 GiB is allocated by PyTorch, and 1.92 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
```

é™¤éä½ çš„ GPU æ˜¾å­˜å¾ˆå¤§ï¼Œå¦åˆ™ä¸Šé¢çš„ä»£ç å¯èƒ½ä¼šè¿”å› OOM é”™è¯¯ã€‚è™½ç„¶ AudioLDM 2 æµæ°´çº¿æ¶‰åŠå¤šä¸ªç»„ä»¶ï¼Œä½†ä»»ä½•æ—¶å€™åªæœ‰å½“å‰æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹å¿…é¡»åœ¨ GPU ä¸Šã€‚å…¶ä½™æ¨¡å—å‡å¯ä»¥å¸è½½åˆ° CPUã€‚è¯¥æŠ€æœ¯ç§°ä¸ºâ€œCPU å¸è½½â€ï¼Œå¯å¤§å¤§å‡å°‘æ˜¾å­˜ä½¿ç”¨ï¼Œä¸”å¯¹æ¨ç†æ—¶é—´çš„å½±å“å¾ˆå°ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‡½æ•° [enable_model_cpu_offload()](https://huggingface.co/docs/diffusers/main/en/api/pipelines/audioldm2#diffusers.AudioLDM2Pipeline.enable_model_cpu_offload) åœ¨æµæ°´çº¿ä¸Šå¯ç”¨ CPU å¸è½½:

```python
pipe.enable_model_cpu_offload()
```

è°ƒç”¨ API ç”ŸæˆéŸ³é¢‘çš„æ–¹å¼ä¸ä»¥å‰ç›¸åŒ:

```python
audio = pipe(prompt, negative_prompt=negative_prompt, num_waveforms_per_prompt=4, audio_length_in_s=150, num_inference_steps=20, generator=generator.manual_seed(0)).audios[0]
```

**è¾“å‡º:**

```
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:36<00:00, 1.82s/it]
```

è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”Ÿæˆ 4 ä¸ªå„ä¸º 150 ç§’çš„æ ·æœ¬ï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨ä¸€æ¬¡æµæ°´çº¿è°ƒç”¨ä¸­å®Œæˆï¼å¤§ç‰ˆçš„ AudioLDM 2 checkpoint æ¯”åŸºç¡€ç‰ˆçš„ checkpoint æ€»å†…å­˜ä½¿ç”¨é‡æ›´é«˜ï¼Œå› ä¸º UNet çš„å¤§å°ç›¸å·®ä¸¤å€å¤š (750M å‚æ•°ä¸ 350M å‚æ•°ç›¸æ¯”)ï¼Œå› æ­¤è¿™ç§èŠ‚çœå†…å­˜çš„æŠ€å·§å¯¹å¤§ç‰ˆçš„ checkpoint ç‰¹åˆ«æœ‰ç”¨ã€‚

## æ€»ç»“

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº† ğŸ§¨ Diffusers å¼€ç®±å³ç”¨çš„å››ç§ä¼˜åŒ–æ–¹æ³•ï¼Œå¹¶å°† AudioLDM 2 çš„ç”Ÿæˆæ—¶é—´ä» 14 ç§’ç¼©çŸ­åˆ°ä¸åˆ° 1 ç§’ã€‚æˆ‘ä»¬è¿˜é‡ç‚¹ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨å†…å­˜èŠ‚çœæŠ€å·§ (ä¾‹å¦‚åŠç²¾åº¦å’Œ CPU å¸è½½) æ¥å‡å°‘é•¿éŸ³é¢‘æ ·æœ¬æˆ–å¤§ checkpoint åœºæ™¯ä¸‹çš„å³°å€¼æ˜¾å­˜ä½¿ç”¨é‡ã€‚

æœ¬æ–‡ä½œè€… [Sanchit Gandhi](https://huggingface.co/sanchit-gandhi) éå¸¸æ„Ÿè°¢ [Vaibhav Srivastav](https://huggingface.co/reach-vb) å’Œ [Sayak Paul](https://huggingface.co/sayakpaul) çš„å»ºè®¾æ€§æ„è§ã€‚é¢‘è°±å›¾å›¾åƒæ¥è‡ªäº [Getting to Know the Mel Spectrogram](https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0) ä¸€æ–‡ï¼Œæ³¢å½¢å›¾æ¥è‡ªäº [Aalto Speech Processing](https://speechprocessingbook.aalto.fi/Representations/Waveform.html) ä¸€æ–‡ã€‚