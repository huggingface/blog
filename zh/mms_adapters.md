---
title: "å¾®è°ƒç”¨äºå¤šè¯­è¨€ ASR çš„ MMS é€‚é…å™¨æ¨¡å‹"
thumbnail: /blog/assets/151_mms/mms_map.png
authors:
- user: patrickvonplaten
translators:
- user: innovation64
- user: zhongdongy
  proofreader: true
---

# **å¾®è°ƒç”¨äºå¤šè¯­è¨€ ASR çš„ MMS é€‚é…å™¨æ¨¡å‹**


<a target="_blank" href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_Tune_MMS_on_Common_Voice.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

**æ–°å†…å®¹ (06/2023)**: è¿™ç¯‡åšæ–‡å—åˆ° [â€œåœ¨å¤šè¯­è¨€ ASR ä¸Šå¾®è°ƒ XLS-Râ€](https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2) çš„å¼ºçƒˆå¯å‘ï¼Œå¯ä»¥çœ‹ä½œæ˜¯å®ƒçš„æ”¹è¿›ç‰ˆæœ¬ã€‚

**Wav2Vec2** æ˜¯è‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR) çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç”± _Alexei Baevskiã€Michael Auli_ å’Œ _Alex Conneau_ äº [2020 å¹´ 9 æœˆ](https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/) å‘å¸ƒã€‚å…¶åœ¨æœ€æµè¡Œçš„ ASR è‹±è¯­æ•°æ®é›†ä¹‹ä¸€ [LibriSpeech](https://huggingface.co/datasets/librispeech_asr) ä¸Šå±•ç¤ºäº† Wav2Vec2 çš„å¼ºå¤§æ€§èƒ½åä¸ä¹…ï¼Œ _Facebook AI_ å°±æ¨å‡ºäº† Wav2Vec2 çš„ä¸¤ä¸ªå¤šè¯­è¨€ç‰ˆæœ¬ï¼Œç§°ä¸º [XLSR](https://arxiv.org/abs/2006.13979) å’Œ [XLM-R](https://ai.facebook.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/)ï¼Œèƒ½å¤Ÿè¯†åˆ«å¤šè¾¾ 128 ç§è¯­è¨€çš„è¯­éŸ³ã€‚XLSR ä»£è¡¨ _è·¨è¯­è¨€è¯­éŸ³è¡¨ç¤º_ ï¼ŒæŒ‡çš„æ˜¯æ¨¡å‹å­¦ä¹ è·¨å¤šç§è¯­è¨€æœ‰ç”¨çš„è¯­éŸ³è¡¨ç¤ºçš„èƒ½åŠ›ã€‚

Meta AI çš„æœ€æ–°ç‰ˆæœ¬ï¼Œ[**å¤§è§„æ¨¡å¤šè¯­è¨€è¯­éŸ³ (MMS)**](https://ai.facebook.com/blog/multilingual-model-speech-recognition/)ï¼Œç”± _Vineel Pratapã€Andros Tjandraã€Bowen Shi_ ç­‰äººç¼–å†™ã€‚å°†å¤šè¯­è¨€è¯­éŸ³è¡¨ç¤ºæå‡åˆ°ä¸€ä¸ªæ–°çš„æ°´å¹³ã€‚é€šè¿‡å‘å¸ƒçš„å„ç§ [è¯­è¨€è¯†åˆ«ã€è¯­éŸ³è¯†åˆ«å’Œæ–‡æœ¬è½¬è¯­éŸ³æ£€æŸ¥ç‚¹](https://huggingface.co/models?other=mms)ï¼Œå¯ä»¥è¯†åˆ«ã€è½¬å½•å’Œç”Ÿæˆè¶…è¿‡ 1,100 å¤šç§å£è¯­ã€‚

åœ¨è¿™ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº† MMS çš„é€‚é…å™¨è®­ç»ƒå¦‚ä½•åœ¨çŸ­çŸ­ 10-20 åˆ†é’Ÿçš„å¾®è°ƒåå®ç°æƒŠäººçš„ä½å•è¯é”™è¯¯ç‡ã€‚

å¯¹äºèµ„æºåŒ®ä¹çš„è¯­è¨€ï¼Œæˆ‘ä»¬ **å¼ºçƒˆ** å»ºè®®ä½¿ç”¨ MMS çš„é€‚é…å™¨è®­ç»ƒï¼Œè€Œä¸æ˜¯åƒ [â€œåœ¨å¤šè¯­è¨€ ASR ä¸Šå¾®è°ƒ XLS-Râ€](https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2) ä¸­é‚£æ ·å¾®è°ƒæ•´ä¸ªæ¨¡å‹ã€‚

åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼ŒMMS çš„é€‚é…å™¨è®­ç»ƒä¸ä»…å†…å­˜æ•ˆç‡æ›´é«˜ã€æ›´ç¨³å¥ï¼Œè€Œä¸”å¯¹äºä½èµ„æºè¯­è¨€ä¹Ÿèƒ½äº§ç”Ÿæ›´å¥½çš„æ€§èƒ½ã€‚å¯¹äºä¸­åˆ°é«˜èµ„æºè¯­è¨€ï¼Œå¾®è°ƒæ•´ä¸ªæ£€æŸ¥ç‚¹è€Œä¸æ˜¯ä½¿ç”¨é€‚é…å™¨å±‚ä»ç„¶æ˜¯æœ‰åˆ©çš„ã€‚

![wav2vec2_structure](/blog/assets/151_mms/mms_map.png)

## **ä¿æŠ¤ä¸–ç•Œè¯­è¨€å¤šæ ·æ€§**

æ ¹æ® https://www.ethnologue.com/ çš„æ•°æ®ï¼Œå¤§çº¦ 3000 ç§è¯­è¨€ (å³æ‰€æœ‰â€œç°å­˜â€è¯­è¨€çš„ 40%) ç”±äºæ¯è¯­äººå£«è¶Šæ¥è¶Šå°‘è€Œæ¿’ä¸´ç­ç»ã€‚è¿™ç§è¶‹åŠ¿åªä¼šåœ¨æ—¥ç›Šå…¨çƒåŒ–çš„ä¸–ç•Œä¸­æŒç»­ä¸‹å»ã€‚

**MMS** èƒ½å¤Ÿè½¬å½•è®¸å¤šæ¿’ä¸´ç­ç»çš„è¯­è¨€ï¼Œä¾‹å¦‚ _Ari_ æˆ– _Kaivi_ ã€‚æœªæ¥ï¼ŒMMS å¯ä»¥é€šè¿‡å¸®åŠ©å‰©ä½™çš„ä½¿ç”¨è€…åˆ›å»ºä¹¦é¢è®°å½•å¹¶ç”¨æ¯è¯­è¿›è¡Œäº¤æµï¼Œè¿™åœ¨ä¿æŒè¯­è¨€æ´»åŠ›æ–¹é¢å‘æŒ¥è‡³å…³é‡è¦çš„ä½œç”¨ã€‚

ä¸ºäº†é€‚åº” 1000 å¤šä¸ªä¸åŒçš„è¯æ±‡è¡¨ï¼Œ**MMS** ä½¿ç”¨é€‚é…å™¨ (Adapters) - ä¸€ç§ä»…è®­ç»ƒä¸€å°éƒ¨åˆ†æ¨¡å‹æƒé‡çš„è®­ç»ƒæ–¹æ³•ã€‚

é€‚é…å™¨å±‚å°±åƒè¯­è¨€æ¡¥æ¢ä¸€æ ·ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨è§£è¯»å¦ä¸€ç§è¯­è¨€æ—¶åˆ©ç”¨ä¸€ç§è¯­è¨€çš„çŸ¥è¯†ã€‚

## **å¾®è°ƒ MMS**

**MMS** æ— ç›‘ç£æ£€æŸ¥ç‚¹ä½¿ç”¨ **1,400** å¤šç§è¯­è¨€çš„è¶…è¿‡ **50 ä¸‡** å°æ—¶çš„éŸ³é¢‘è¿›è¡Œäº†é¢„è®­ç»ƒï¼Œå‚æ•°èŒƒå›´ä» 3 äº¿åˆ° 10 äº¿ä¸ç­‰ã€‚

ä½ å¯ä»¥åœ¨ ğŸ¤— Hub ä¸Šæ‰¾åˆ° 3 äº¿ä¸ªå‚æ•° (300M) å’Œ 10 äº¿ä¸ªå‚æ•° (1B) æ¨¡å‹å¤§å°çš„ä»…é¢„è®­ç»ƒæ£€æŸ¥ç‚¹:

- [**`mms-300m`**](https://huggingface.co/facebook/mms-300m)
- [**`mms-1b`**](https://huggingface.co/facebook/mms-1b)

_æ³¨æ„_ : å¦‚æœä½ æƒ³å¾®è°ƒåŸºæœ¬æ¨¡å‹ï¼Œå¯ä»¥æŒ‰ç…§ [â€œåœ¨å¤šè¯­è¨€ ASR ä¸Šå¾®è°ƒ XLS-Râ€](https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2) ä¸­æ‰€ç¤ºçš„å®Œå…¨ç›¸åŒçš„æ–¹å¼è¿›è¡Œæ“ä½œã€‚

ä¸ [BERT çš„æ©ç è¯­è¨€å»ºæ¨¡ç›®æ ‡](http://jalammar.github.io/illustrated-bert/) ç±»ä¼¼ï¼ŒMMS é€šè¿‡éšæœºé®è”½ç‰¹å¾å‘é‡æ¥å­¦ä¹ ä¸Šä¸‹æ–‡è¯­éŸ³è¡¨ç¤ºï¼Œç„¶ååœ¨è‡ªç›‘ç£é¢„è®­ç»ƒæœŸé—´å°†å…¶ä¼ é€’åˆ° Transformer ç½‘ç»œã€‚

å¯¹äº ASRï¼Œé¢„è®­ç»ƒ [MMS-1B æ£€æŸ¥ç‚¹](https://huggingface.co/facebook/mms-1b) é€šè¿‡è”åˆè¯æ±‡è¾“å‡ºå±‚ä»¥ç›‘ç£æ–¹å¼å¯¹ 1000 å¤šç§è¯­è¨€è¿›è¡Œäº†è¿›ä¸€æ­¥å¾®è°ƒã€‚æœ€åä¸€æ­¥ï¼Œè”åˆè¯æ±‡è¾“å‡ºå±‚è¢«ä¸¢å¼ƒï¼Œå¹¶ä¿ç•™ç‰¹å®šäºè¯­è¨€çš„é€‚é…å™¨å±‚ã€‚æ¯ä¸ªé€‚é…å™¨å±‚ **ä»…** åŒ…å«çº¦ 2.5M æƒé‡ï¼Œç”±æ¯ä¸ªæ³¨æ„åŠ›å—çš„å°å‹çº¿æ€§æŠ•å½±å±‚ä»¥åŠç‰¹å®šäºè¯­è¨€çš„è¯æ±‡è¾“å‡ºå±‚ç»„æˆã€‚

å·²å‘å¸ƒé’ˆå¯¹è¯­éŸ³è¯†åˆ« (ASR) è¿›è¡Œå¾®è°ƒçš„ä¸‰ä¸ª **MMS** æ£€æŸ¥ç‚¹ã€‚å®ƒä»¬åˆ†åˆ«åŒ…æ‹¬ 102ã€1107 å’Œ 1162 ä¸ªé€‚é…å™¨æƒé‡ (æ¯ç§è¯­è¨€ä¸€ä¸ª):

- [**`mms-1b-fl102`**](https://huggingface.co/facebook/mms-1b-fl102)
- [**`mms-1b-l1107`**](https://huggingface.co/facebook/mms-1b-l1107)
- [**`mms-1b-all`**](https://huggingface.co/facebook/mms-1b-all)

ä½ å¯ä»¥çœ‹åˆ°åŸºæœ¬æ¨¡å‹ (åƒå¾€å¸¸ä¸€æ ·) ä¿å­˜ä¸ºæ–‡ä»¶ [`model.safetensors`](https://huggingface.co/facebook/mms-1b-all/blob/main/model.safetensors)ï¼Œä½†æ­¤å¤–è¿™äº›å­˜å‚¨åº“è¿˜å­˜å‚¨äº†è®¸å¤šé€‚é…å™¨æƒé‡ï¼Œ _ä¾‹å¦‚_ é’ˆå¯¹æ³•å›½çš„ [`adapter.fra.safetensors`](https://huggingface.co/facebook/mms-1b-all/blob/main/adapter.fra.safetensors)ã€‚

Hugging Face æ–‡æ¡£å¾ˆå¥½åœ° [è§£é‡Šäº†å¦‚ä½•ä½¿ç”¨æ­¤ç±»æ£€æŸ¥ç‚¹è¿›è¡Œæ¨ç†](https://huggingface.co/docs/transformers/main/en/model_doc/mms#loading)ï¼Œå› æ­¤åœ¨è¿™ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å­¦ä¹ å¦‚ä½•åŸºäºä»»ä½•å·²å‘å¸ƒçš„ ASR æ£€æŸ¥ç‚¹æœ‰æ•ˆåœ°è®­ç»ƒé«˜æ€§èƒ½é€‚é…å™¨æ¨¡å‹ã€‚

## è®­ç»ƒè‡ªé€‚åº”æƒé‡

åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œé€‚é…å™¨æ˜¯ä¸€ç§ç”¨äºå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹åŒæ—¶ä¿æŒåŸå§‹æ¨¡å‹å‚æ•°ä¸å˜çš„æ–¹æ³•ã€‚ä»–ä»¬é€šè¿‡åœ¨æ¨¡å‹çš„ç°æœ‰å±‚ä¹‹é—´æ’å…¥å°å‹å¯è®­ç»ƒæ¨¡å— (ç§°ä¸º [é€‚é…å™¨å±‚](https://arxiv.org/pdf/1902.00751.pdf)) æ¥å®ç°æ­¤ç›®çš„ï¼Œç„¶åä½¿æ¨¡å‹é€‚åº”ç‰¹å®šä»»åŠ¡ï¼Œè€Œæ— éœ€è¿›è¡Œå¤§é‡çš„é‡æ–°è®­ç»ƒã€‚

é€‚é…å™¨åœ¨è¯­éŸ³è¯†åˆ«ï¼Œå°¤å…¶æ˜¯ **è¯´è¯äººè¯†åˆ«** æ–¹é¢æœ‰ç€æ‚ ä¹…çš„å†å²ã€‚åœ¨è¯´è¯äººè¯†åˆ«ä¸­ï¼Œé€‚é…å™¨å·²è¢«æœ‰æ•ˆåœ°ç”¨äºè°ƒæ•´é¢„å…ˆå­˜åœ¨çš„æ¨¡å‹ï¼Œä»¥è¯†åˆ«å•ä¸ªè¯´è¯äººçš„ç‰¹è´¨ï¼Œæ­£å¦‚ [Gales å’Œ Woodland (1996)](https://www.isca-speech.org/archive_v0/archive_papers/icslp_1996/i96_1832.pdf) ä»¥åŠ [Miao ç­‰äºº (2014)](https://www.cs.cmu.edu/~ymiao/pub/tasl_sat.pdf) çš„å·¥ä½œä¸­æ‰€å¼ºè°ƒçš„é‚£æ ·ã€‚ä¸è®­ç»ƒå®Œæ•´æ¨¡å‹ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•ä¸ä»…å¤§å¤§é™ä½äº†è®¡ç®—è¦æ±‚ï¼Œè€Œä¸”ä½¿å¾—ç‰¹å®šäºè¯´è¯è€…çš„è°ƒæ•´æ›´å¥½ã€æ›´çµæ´»ã€‚

**MMS** ä¸­å®Œæˆçš„å·¥ä½œåˆ©ç”¨äº†è·¨ä¸åŒè¯­è¨€çš„è¯­éŸ³è¯†åˆ«é€‚é…å™¨çš„æƒ³æ³•ã€‚å¯¹å°‘é‡é€‚é…å™¨æƒé‡è¿›è¡Œäº†å¾®è°ƒï¼Œä»¥æŒæ¡æ¯ç§ç›®æ ‡è¯­è¨€ç‹¬ç‰¹çš„è¯­éŸ³å’Œè¯­æ³•ç‰¹å¾ã€‚å› æ­¤ï¼ŒMMS ä½¿å•ä¸ªå¤§å‹åŸºç¡€æ¨¡å‹ (_ä¾‹å¦‚_ [**mms-1b-all**](https://huggingface.co/facebook/mms-1b-all) æ¨¡å‹æ£€æŸ¥ç‚¹) å’Œ 1000 å¤šä¸ªå°å‹é€‚é…å™¨å±‚ (æ¯ä¸ª 2.5M æƒé‡ **mms-1b-all**) èƒ½å¤Ÿç†è§£å’Œè½¬å½•å¤šç§è¯­è¨€ã€‚è¿™æå¤§åœ°å‡å°‘äº†ä¸ºæ¯ç§è¯­è¨€å¼€å‘ä¸åŒæ¨¡å‹çš„è®¡ç®—éœ€æ±‚ã€‚

æ£’æäº†ï¼ç°åœ¨æˆ‘ä»¬äº†è§£å…¶åŠ¨æœºå’Œç†è®ºï¼Œä¸‹é¢è®©æˆ‘ä»¬ç ”ç©¶ä¸€ä¸‹ **mms-1b-all** ğŸ”¥çš„é€‚é…å™¨æƒé‡å¾®è°ƒ

## Notebook è®¾ç½®

æ­£å¦‚ä¹‹å‰åœ¨ [â€œå¤šè¯­è¨€ ASR ä¸Šå¾®è°ƒ XLS-Râ€](https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2) åšå®¢æ–‡ç« ä¸­æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬åœ¨ [Common Voice](https://huggingface.co/datasets/common_voice) çš„ä½èµ„æº ASR æ•°æ®é›†ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œè¯¥æ•°æ®é›†ä»…åŒ…å« _ca._ 4 å°æ—¶ç»è¿‡éªŒè¯çš„è®­ç»ƒæ•°æ®ã€‚

å°±åƒ Wav2Vec2 æˆ– XLS-R ä¸€æ ·ï¼ŒMMS ä½¿ç”¨è¿æ¥æ—¶åºåˆ†ç±» (CTC) è¿›è¡Œå¾®è°ƒï¼ŒCTC æ˜¯ä¸€ç§ç”¨äºè®­ç»ƒç¥ç»ç½‘ç»œè§£å†³åºåˆ—åˆ°åºåˆ—é—®é¢˜ (ä¾‹å¦‚ ASR å’Œæ‰‹å†™è¯†åˆ«) çš„ç®—æ³•ã€‚

æœ‰å…³ CTC ç®—æ³•çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œæˆ‘å¼ºçƒˆå»ºè®®é˜…è¯» Awni Hannun çš„å†™å¾—å¾ˆå¥½çš„ä¸€ç¯‡åšå®¢æ–‡ç«  [_Sequence Modeling with CTC (2017)_](https://distill.pub/2017/ctc/)ã€‚

åœ¨æˆ‘ä»¬å¼€å§‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å®‰è£… `datasets` å’Œ `transformers`ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬éœ€è¦ `torchaudio` æ¥åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼Œä»¥åŠä½¿ç”¨ [å­—é”™è¯¯ç‡ (WER)](https://huggingface.co/metrics/wer) æŒ‡æ ‡ \( {}^1 \) è¯„ä¼°æˆ‘ä»¬å¾®è°ƒåçš„æ¨¡å‹ï¼Œå› æ­¤ä¹Ÿéœ€è¦å®‰è£… `jiwer`ã€‚

```bash
%%capture
!pip install --upgrade pip
!pip install datasets[audio]
!pip install evaluate
!pip install git+https://github.com/huggingface/transformers.git
!pip install jiwer
!pip install accelerate
```

æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½ åœ¨è®­ç»ƒæ—¶å°†è®­ç»ƒæ£€æŸ¥ç‚¹ç›´æ¥ä¸Šä¼ åˆ° [ğŸ¤— Hub](https://huggingface.co/)ã€‚Hub å­˜å‚¨åº“å†…ç½®äº†ç‰ˆæœ¬æ§åˆ¶ï¼Œå› æ­¤ä½ å¯ä»¥ç¡®ä¿åœ¨è®­ç»ƒæœŸé—´ä¸ä¼šä¸¢å¤±ä»»ä½•æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚

ä¸ºæ­¤ï¼Œä½ å¿…é¡»å­˜å‚¨æ¥è‡ª Hugging Face ç½‘ç«™çš„èº«ä»½éªŒè¯ä»¤ç‰Œ (å¦‚æœä½ è¿˜æ²¡æœ‰æ³¨å†Œï¼Œè¯·åœ¨ [æ­¤å¤„](https://huggingface.co/join) æ³¨å†Œï¼)

```python
from huggingface_hub import notebook_login

notebook_login()
```

## å‡†å¤‡æ•°æ®ã€åˆ†è¯å™¨ã€ç‰¹å¾æå–å™¨

ASR æ¨¡å‹å°†è¯­éŸ³è½¬å½•ä¸ºæ–‡æœ¬ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå°†è¯­éŸ³ä¿¡å·å¤„ç†ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼ (ä¾‹å¦‚ç‰¹å¾å‘é‡) çš„ç‰¹å¾æå–å™¨ï¼Œä»¥åŠä¸€ä¸ªå°†æ¨¡å‹è¾“å‡ºæ ¼å¼å¤„ç†ä¸ºæ–‡æœ¬çš„åˆ†è¯å™¨ã€‚

åœ¨ğŸ¤— Transformers ä¸­ï¼ŒMMS æ¨¡å‹åŒæ—¶ä¼´éšç€ä¸€ä¸ªåä¸º [Wav2Vec2FeatureExtractor](https://huggingface.co/transformers/master/model_doc/wav2vec2.html#wav2vec2featureextractor) çš„ç‰¹å¾æå–å™¨å’Œä¸€ä¸ªåä¸º [Wav2Vec2CTCTokenizer](https://huggingface.co/transformers/master/model_doc/wav2vec2.html#wav2vec2ctctokenizer) çš„åˆ†è¯å™¨ã€‚

æˆ‘ä»¬é¦–å…ˆåˆ›å»ºæ ‡è®°ç”Ÿæˆå™¨ï¼Œå°†é¢„æµ‹çš„è¾“å‡ºç±»è§£ç ä¸ºè¾“å‡ºè½¬å½•ã€‚

### åˆ›å»º `Wav2Vec2CTCTokenizer`

å¾®è°ƒçš„ MMS æ¨¡å‹ï¼Œä¾‹å¦‚ [**mms-1b-all**](https://huggingface.co/facebook/mms-1b-all) å·²ç»æœ‰ä¸€ä¸ªä¼´éšæ¨¡å‹æ£€æŸ¥ç‚¹çš„ [åˆ†è¯å™¨](https://huggingface.co/facebook/mms-1b-all/blob/main/tokenizer_config.json)ã€‚ç„¶è€Œï¼Œç”±äºæˆ‘ä»¬æƒ³è¦åœ¨æŸç§è¯­è¨€çš„ç‰¹å®šä½èµ„æºæ•°æ®ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œå› æ­¤å»ºè®®å®Œå…¨åˆ é™¤åˆ†è¯å™¨å’Œè¯æ±‡è¾“å‡ºå±‚ï¼Œå¹¶æ ¹æ®è®­ç»ƒæ•°æ®æœ¬èº«åˆ›å»ºæ–°çš„ã€‚

åœ¨ CTC ä¸Šå¾®è°ƒçš„ç±»ä¼¼ Wav2Vec2 çš„æ¨¡å‹é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ é€’æ¥è½¬å½•éŸ³é¢‘æ–‡ä»¶ï¼Œé¦–å…ˆå°†éŸ³é¢‘è¾“å…¥å¤„ç†ä¸ºä¸€ç³»åˆ—ç»è¿‡å¤„ç†çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨æœ€ç»ˆçš„è¯æ±‡è¾“å‡ºå±‚å°†æ¯ä¸ªä¸Šä¸‹æ–‡è¡¨ç¤ºåˆ†ç±»ä¸ºè¡¨ç¤ºè¯¥å­—ç¬¦çš„å­—ç¬¦è½¬å½•ã€‚

è¯¥å±‚çš„è¾“å‡ºå¤§å°å¯¹åº”äºè¯æ±‡è¡¨ä¸­çš„æ ‡è®°æ•°é‡ï¼Œæˆ‘ä»¬å°†ä»ç”¨äºå¾®è°ƒçš„æ ‡è®°æ•°æ®é›†ä¸­æå–è¯¥è¯æ±‡è¡¨ã€‚å› æ­¤ï¼Œç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬å°†æŸ¥çœ‹æ‰€é€‰çš„ Common Voice æ•°æ®é›†ï¼Œå¹¶æ ¹æ®è½¬å½•å®šä¹‰è¯æ±‡è¡¨ã€‚

å¯¹äºæœ¬ notebookï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Common Voice](https://huggingface.co/datasets/mozilla-foundation/common_voice_6_1) çš„ 6.1 åœŸè€³å…¶è¯­æ•°æ®é›†ã€‚åœŸè€³å…¶è¯­å¯¹åº”äºè¯­è¨€ä»£ç  `"tr"`ã€‚

å¤ªå¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ ğŸ¤— Datasets çš„ç®€å• API æ¥ä¸‹è½½æ•°æ®äº†ã€‚æ•°æ®é›†åç§°æ˜¯ `"mozilla-foundation/common_voice_6_1"`ï¼Œé…ç½®åç§°å¯¹åº”äºè¯­è¨€ä»£ç ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ `"tr"`ã€‚

**æ³¨æ„**: åœ¨ä¸‹è½½æ•°æ®é›†ä¹‹å‰ï¼Œä½ å¿…é¡»ç™»å½•ä½ çš„ Hugging Face å¸æˆ·ï¼Œè¿›å…¥ [æ•°æ®é›†å­˜å‚¨åº“é¡µ](https://huggingface.co/datasets/mozilla-foundation/common_voice_6_1) é¢å¹¶å•å‡»â€œåŒæ„å¹¶è®¿é—®å­˜å‚¨åº“â€æ¥è®¿é—®å®ƒ

Common Voice æœ‰è®¸å¤šä¸åŒçš„åˆ†å‰²ï¼Œå…¶ä¸­åŒ…æ‹¬ `invalidated`ï¼Œå®ƒæŒ‡çš„æ˜¯æœªè¢«è¯„ä¸ºâ€œè¶³å¤Ÿå¹²å‡€â€è€Œè¢«è®¤ä¸ºæœ‰ç”¨çš„æ•°æ®ã€‚åœ¨æ­¤ notebook ä¸­ï¼Œæˆ‘ä»¬å°†ä»…ä½¿ç”¨æ‹†åˆ†çš„ `"train"`, `"validation"` å’Œ `"test"` ã€‚

```python
from datasets import load_dataset, load_metric, Audio

common_voice_train = load_dataset("mozilla-foundation/common_voice_6_1", "tr", split="train+validation", use_auth_token=True)
common_voice_test = load_dataset("mozilla-foundation/common_voice_6_1", "tr", split="test", use_auth_token=True)
```

è®¸å¤š ASR æ•°æ®é›†ä»…æä¾›æ¯ä¸ªéŸ³é¢‘æ•°ç»„ (`'audio'`) å’Œæ–‡ä»¶ (`'path'`) çš„ç›®æ ‡æ–‡æœ¬ (`'sentence'`)ã€‚å®é™…ä¸Šï¼ŒCommon Voice æä¾›äº†å…³äºæ¯ä¸ªéŸ³é¢‘æ–‡ä»¶çš„æ›´å¤šä¿¡æ¯ï¼Œä¾‹å¦‚ `'accent'` ç­‰ã€‚ä¸ºäº†ä½¿ notebook å°½å¯èƒ½é€šç”¨ï¼Œæˆ‘ä»¬ä»…è€ƒè™‘ç”¨äºå¾®è°ƒçš„è½¬å½•æ–‡æœ¬ã€‚

```python
common_voice_train = common_voice_train.remove_columns(["accent", "age", "client_id", "down_votes", "gender", "locale", "segment", "up_votes"])
common_voice_test = common_voice_test.remove_columns(["accent", "age", "client_id", "down_votes", "gender", "locale", "segment", "up_votes"])
```

è®©æˆ‘ä»¬ç¼–å†™ä¸€ä¸ªç®€çŸ­çš„å‡½æ•°æ¥æ˜¾ç¤ºæ•°æ®é›†çš„ä¸€äº›éšæœºæ ·æœ¬ï¼Œå¹¶è¿è¡Œå®ƒå‡ æ¬¡ä»¥äº†è§£è½¬å½•çš„æ„Ÿè§‰ã€‚

```python
from datasets import ClassLabel
import random
import pandas as pd
from IPython.display import display, HTML

def show_random_elements(dataset, num_examples=10):
    assert num_examples <= len(dataset), "Can't pick more elements than there are in the dataset."
    picks = []
    for _ in range(num_examples):
        pick = random.randint(0, len(dataset)-1)
        while pick in picks:
            pick = random.randint(0, len(dataset)-1)
        picks.append(pick)

    df = pd.DataFrame(dataset[picks])
    display(HTML(df.to_html()))
```

```python
show_random_elements(common_voice_train.remove_columns(["path", "audio"]), num_examples=10)
```

```bash
Oylar teker teker elle sayÄ±lacak.
Son olaylar endiÅŸe seviyesini yÃ¼kseltti.
Tek bir kart hepsinin kapÄ±larÄ±nÄ± aÃ§Ä±yor.
Blogcular da tam bundan bahsetmek istiyor.
Bu AralÄ±k iki bin onda oldu.
FiyatÄ±n altmÄ±ÅŸ altÄ± milyon avro olduÄŸu bildirildi.
ArdÄ±ndan da silahlÄ± Ã§atÄ±ÅŸmalar Ã§Ä±ktÄ±.
"Romanya'da kurumlar gelir vergisi oranÄ± yÃ¼zde on altÄ±."
Bu konuda neden bu kadar az ÅŸey sÃ¶ylendiÄŸini aÃ§Ä±klayabilir misiniz?
```

å¥½å§ï¼è½¬å½•çœ‹èµ·æ¥ç›¸å½“å¹²å‡€ã€‚ç¿»è¯‘å®Œè½¬å½•çš„å¥å­åï¼Œè¿™ç§è¯­è¨€ä¼¼ä¹æ›´å¤šåœ°å¯¹åº”äºä¹¦é¢æ–‡æœ¬ï¼Œè€Œä¸æ˜¯å˜ˆæ‚çš„å¯¹è¯ã€‚è€ƒè™‘åˆ° [Common Voice](https://huggingface.co/datasets/common_voice) æ˜¯ä¸€ä¸ªä¼—åŒ…é˜…è¯»è¯­éŸ³è¯­æ–™åº“ï¼Œè¿™ä¹Ÿè§£é‡Šçš„é€šã€‚

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œè½¬å½•æ–‡æœ¬ä¸­åŒ…å«ä¸€äº›ç‰¹æ®Šå­—ç¬¦ï¼Œå¦‚ `,.?!;:`ã€‚æ²¡æœ‰è¯­è¨€æ¨¡å‹ï¼Œè¦å°†è¯­éŸ³å—åˆ†ç±»ä¸ºè¿™äº›ç‰¹æ®Šå­—ç¬¦å°±æ›´éš¾äº†ï¼Œå› ä¸ºå®ƒä»¬å¹¶ä¸çœŸæ­£å¯¹åº”äºä¸€ä¸ªç‰¹å¾æ€§çš„å£°éŸ³å•å…ƒã€‚ä¾‹å¦‚ï¼Œå­—æ¯ `"s"` æœ‰ä¸€ä¸ªæˆ–å¤šæˆ–å°‘æ¸…æ™°çš„å£°éŸ³ï¼Œè€Œç‰¹æ®Šå­—ç¬¦ `"."` åˆ™æ²¡æœ‰ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç†è§£è¯­éŸ³ä¿¡å·çš„å«ä¹‰ï¼Œé€šå¸¸ä¸éœ€è¦åœ¨è½¬å½•ä¸­åŒ…å«ç‰¹æ®Šå­—ç¬¦ã€‚

è®©æˆ‘ä»¬ç®€å•åœ°åˆ é™¤æ‰€æœ‰å¯¹å•è¯çš„å«ä¹‰æ²¡æœ‰è´¡çŒ®å¹¶ä¸”ä¸èƒ½çœŸæ­£ç”¨å£°éŸ³è¡¨ç¤ºçš„å­—ç¬¦ï¼Œå¹¶å¯¹æ–‡æœ¬è¿›è¡Œè§„èŒƒåŒ–ã€‚

```python
import re
chars_to_remove_regex = '[\,\?\.\!\-\;\:\"\â€œ\%\â€˜\â€\ï¿½\']'

def remove_special_characters(batch):
    batch["sentence"] = re.sub(chars_to_remove_regex, '', batch["sentence"]).lower()
    return batch
```

```python
common_voice_train = common_voice_train.map(remove_special_characters)
common_voice_test = common_voice_test.map(remove_special_characters)
```

æˆ‘ä»¬å†çœ‹çœ‹å¤„ç†åçš„æ–‡æœ¬æ ‡ç­¾ã€‚

```python
show_random_elements(common_voice_train.remove_columns(["path","audio"]))
```

```bash
iÌ‡kinci tur mÃ¼zakereler eylÃ¼l ayÄ±nda baÅŸlayacak
jani ve babasÄ± bu dÃ¼ÅŸÃ¼ncelerinde yalnÄ±z deÄŸil
onurun gÃ¶zlerindeki bÃ¼yÃ¼
bandiÃ§ oylarÄ±n yÃ¼zde kÄ±rk sekiz virgÃ¼l elli dÃ¶rdÃ¼nÃ¼ topladÄ±
bu imkansÄ±z
bu konu aÃ§Ä±k deÄŸildir
cinayet kamuoyunu ÅŸiddetle sarstÄ±
kentin sokaklarÄ± iki metre su altÄ±nda kaldÄ±
muhalefet partileri hÃ¼kÃ¼mete karÅŸÄ± ciddi bir mÃ¼cadele ortaya koyabiliyorlar mÄ±
festivale tÃ¼m dÃ¼nyadan elli film katÄ±lÄ±yor
```

å¥½ï¼è¿™çœ‹èµ·æ¥æ›´å¥½äº†ã€‚æˆ‘ä»¬å·²ç»ä»è½¬å½•ä¸­åˆ é™¤äº†å¤§å¤šæ•°ç‰¹æ®Šå­—ç¬¦ï¼Œå¹¶å°†å®ƒä»¬è§„èŒƒåŒ–ä¸ºä»…å°å†™ã€‚

åœ¨å®Œæˆé¢„å¤„ç†ä¹‹å‰ï¼Œå’¨è¯¢ç›®æ ‡è¯­è¨€çš„æ¯è¯­äººå£«æ€»æ˜¯æœ‰ç›Šçš„ï¼Œä»¥æŸ¥çœ‹æ–‡æœ¬æ˜¯å¦å¯ä»¥è¿›ä¸€æ­¥ç®€åŒ–ã€‚
å¯¹äºè¿™ç¯‡åšå®¢æ–‡ç« ï¼Œ[Merve](https://twitter.com/mervenoyann) å¾ˆå‹å¥½åœ°å¿«é€ŸæŸ¥çœ‹äº†ä¸€ä¸‹ï¼Œå¹¶æŒ‡å‡ºå¸¦å¸½å­çš„å­—ç¬¦ (å¦‚ `Ã¢`) åœ¨åœŸè€³å…¶è¯­ä¸­å·²ç»ä¸å†ä½¿ç”¨ï¼Œå¯ä»¥ç”¨å®ƒä»¬çš„æ— å¸½å­ç­‰æ•ˆç‰© (ä¾‹å¦‚ `a`) æ›¿æ¢ã€‚

è¿™æ„å‘³ç€æˆ‘ä»¬åº”è¯¥å°†åƒ `"yargÄ± sistemi hÃ¢lÃ¢ saÄŸlÄ±ksÄ±z"` è¿™æ ·çš„å¥å­æ›¿æ¢ä¸º `"yargÄ± sistemi hala saÄŸlÄ±ksÄ±z"`ã€‚

è®©æˆ‘ä»¬å†å†™ä¸€ä¸ªç®€çŸ­çš„æ˜ å°„å‡½æ•°æ¥è¿›ä¸€æ­¥ç®€åŒ–æ–‡æœ¬æ ‡ç­¾ã€‚è®°ä½ - æ–‡æœ¬æ ‡ç­¾è¶Šç®€å•ï¼Œæ¨¡å‹å­¦ä¹ é¢„æµ‹è¿™äº›æ ‡ç­¾å°±è¶Šå®¹æ˜“ã€‚

```python
def replace_hatted_characters(batch):
    batch["sentence"] = re.sub('[Ã¢]', 'a', batch["sentence"])
    batch["sentence"] = re.sub('[Ã®]', 'i', batch["sentence"])
    batch["sentence"] = re.sub('[Ã´]', 'o', batch["sentence"])
    batch["sentence"] = re.sub('[Ã»]', 'u', batch["sentence"])
    return batch
```

```python
common_voice_train = common_voice_train.map(replace_hatted_characters)
common_voice_test = common_voice_test.map(replace_hatted_characters)
```

åœ¨ CTC ä¸­ï¼Œå°†è¯­éŸ³å—åˆ†ç±»ä¸ºå­—æ¯æ˜¯å¾ˆå¸¸è§çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨è¿™é‡Œä¹ŸåšåŒæ ·çš„äº‹æƒ…ã€‚è®©æˆ‘ä»¬æå–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¸­æ‰€æœ‰ä¸åŒçš„å­—æ¯ï¼Œå¹¶ä»è¿™ç»„å­—æ¯ä¸­æ„å»ºæˆ‘ä»¬çš„è¯æ±‡è¡¨ã€‚

æˆ‘ä»¬ç¼–å†™ä¸€ä¸ªæ˜ å°„å‡½æ•°ï¼Œå°†æ‰€æœ‰è½¬å½•è¿æ¥æˆä¸€ä¸ªé•¿è½¬å½•ï¼Œç„¶åå°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºä¸€ç»„å­—ç¬¦ã€‚å°†å‚æ•°ä¼ é€’ `batched=True` ç»™ `map(...)` å‡½æ•°éå¸¸é‡è¦ï¼Œä»¥ä¾¿æ˜ å°„å‡½æ•°å¯ä»¥ç«‹å³è®¿é—®æ‰€æœ‰è½¬å½•ã€‚

```python
def extract_all_chars(batch):
  all_text = " ".join(batch["sentence"])
  vocab = list(set(all_text))
  return {"vocab": [vocab], "all_text": [all_text]}
```

```python
vocab_train = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train.column_names)
vocab_test = common_voice_test.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_test.column_names)
```

ç°åœ¨ï¼Œæˆ‘ä»¬åˆ›å»ºè®­ç»ƒæ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†ä¸­æ‰€æœ‰ä¸åŒå­—æ¯çš„å¹¶é›†ï¼Œå¹¶å°†ç»“æœåˆ—è¡¨è½¬æ¢ä¸ºæšä¸¾å­—å…¸ã€‚

```python
vocab_list = list(set(vocab_train["vocab"][0]) | set(vocab_test["vocab"][0]))
```

```python
vocab_dict = {v: k for k, v in enumerate(sorted(vocab_list))}
vocab_dict
```

```bash
    {' ': 0,
     'a': 1,
     'b': 2,
     'c': 3,
     'd': 4,
     'e': 5,
     'f': 6,
     'g': 7,
     'h': 8,
     'i': 9,
     'j': 10,
     'k': 11,
     'l': 12,
     'm': 13,
     'n': 14,
     'o': 15,
     'p': 16,
     'q': 17,
     'r': 18,
     's': 19,
     't': 20,
     'u': 21,
     'v': 22,
     'w': 23,
     'x': 24,
     'y': 25,
     'z': 26,
     'Ã§': 27,
     'Ã«': 28,
     'Ã¶': 29,
     'Ã¼': 30,
     'ÄŸ': 31,
     'Ä±': 32,
     'ÅŸ': 33,
     'Ì‡': 34}
```

å¾ˆé…·ï¼Œæˆ‘ä»¬çœ‹åˆ°å­—æ¯è¡¨ä¸­çš„æ‰€æœ‰å­—æ¯éƒ½å‡ºç°åœ¨æ•°æ®é›†ä¸­ (è¿™å¹¶ä¸ä»¤äººæƒŠè®¶)ï¼Œæˆ‘ä»¬è¿˜æå–äº†ç‰¹æ®Šå­—ç¬¦ `""` å’Œ  `'`ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬æ²¡æœ‰æ’é™¤è¿™äº›ç‰¹æ®Šå­—ç¬¦ï¼Œå› ä¸ºæ¨¡å‹å¿…é¡»å­¦ä¼šé¢„æµ‹å•è¯ä½•æ—¶ç»“æŸï¼Œå¦åˆ™é¢„æµ‹å°†å§‹ç»ˆæ˜¯ä¸€ç³»åˆ—å­—æ¯ï¼Œè¿™å°†ä½¿å¾—ä¸å¯èƒ½å°†å•è¯å½¼æ­¤åˆ†å¼€ã€‚

äººä»¬åº”è¯¥å§‹ç»ˆè®°ä½ï¼Œåœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œé¢„å¤„ç†æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„æ­¥éª¤ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä¸å¸Œæœ›æˆ‘ä»¬çš„æ¨¡å‹ä»…ä»…å› ä¸ºæˆ‘ä»¬å¿˜è®°è§„èŒƒåŒ–æ•°æ®è€ŒåŒºåˆ† `a` å’Œ `A`ã€‚`a` å’Œ `A` ä¹‹é—´çš„åŒºåˆ«æ ¹æœ¬ä¸å–å†³äºå­—æ¯çš„â€œå£°éŸ³â€ï¼Œè€Œæ›´å¤šåœ°å–å†³äºè¯­æ³•è§„åˆ™ - ä¾‹å¦‚ï¼Œåœ¨å¥å­å¼€å¤´ä½¿ç”¨å¤§å†™å­—æ¯ã€‚å› æ­¤ï¼Œåˆ é™¤å¤§å†™å­—æ¯å’Œéå¤§å†™å­—æ¯ä¹‹é—´çš„å·®å¼‚æ˜¯æ˜æ™ºçš„ï¼Œè¿™æ ·æ¨¡å‹åœ¨å­¦ä¹ è½¬å½•è¯­éŸ³æ—¶å°±æ›´å®¹æ˜“äº†ã€‚

ä¸ºäº†æ›´æ¸…æ¥šåœ°è¡¨æ˜ `" "` å…·æœ‰è‡ªå·±çš„æ ‡è®°ç±»åˆ«ï¼Œæˆ‘ä»¬ç»™å®ƒä¸€ä¸ªæ›´æ˜æ˜¾çš„å­—ç¬¦ `|`ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ·»åŠ äº†ä¸€ä¸ªâ€œæœªçŸ¥â€æ ‡è®°ï¼Œä»¥ä¾¿æ¨¡å‹ä»¥åèƒ½å¤Ÿå¤„ç† Common Voice è®­ç»ƒé›†ä¸­æœªé‡åˆ°çš„å­—ç¬¦ã€‚

```python
vocab_dict["|"] = vocab_dict[" "]
del vocab_dict[" "]
```

æœ€åï¼Œæˆ‘ä»¬è¿˜æ·»åŠ äº†ä¸€ä¸ªå¯¹åº”äº CTC çš„â€œç©ºç™½æ ‡è®°â€çš„å¡«å……æ ‡è®°ã€‚ â€œç©ºç™½æ ‡è®°â€æ˜¯ CTC ç®—æ³•çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ã€‚æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ [æ­¤å¤„](https://distill.pub/2017/ctc/) çš„â€œå¯¹é½â€éƒ¨åˆ†ã€‚

```python
vocab_dict["[UNK]"] = len(vocab_dict)
vocab_dict["[PAD]"] = len(vocab_dict)
len(vocab_dict)
```

```bash
    37
```

å¾ˆé…·ï¼Œç°åœ¨æˆ‘ä»¬çš„è¯æ±‡è¡¨å·²ç»å®Œæˆï¼ŒåŒ…å« 37 ä¸ªæ ‡è®°ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å°†ä½œä¸ºé€‚é…å™¨æƒé‡çš„ä¸€éƒ¨åˆ†æ·»åŠ åœ¨é¢„è®­ç»ƒçš„ MMS æ£€æŸ¥ç‚¹é¡¶éƒ¨çš„çº¿æ€§å±‚å°†å…·æœ‰ 37 çš„è¾“å‡ºç»´åº¦ã€‚

ç”±äºå•ä¸ª MMS æ£€æŸ¥ç‚¹å¯ä»¥ä¸ºå¤šç§è¯­è¨€æä¾›å®šåˆ¶æƒé‡ï¼Œå› æ­¤åˆ†è¯å™¨ä¹Ÿå¯ä»¥åŒ…å«å¤šä¸ªè¯æ±‡è¡¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åµŒå¥—æˆ‘ä»¬çš„ `vocab_dict`ï¼Œä»¥ä¾¿å°†æ¥å¯èƒ½å‘è¯æ±‡è¡¨ä¸­æ·»åŠ æ›´å¤šè¯­è¨€ã€‚å­—å…¸åº”è¯¥åµŒå¥—ä½¿ç”¨é€‚é…å™¨æƒé‡çš„åç§°ï¼Œå¹¶åœ¨åˆ†è¯å™¨é…ç½®ä¸­ä»¥ [`target_lang`](https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer.target_lang) çš„åç§°ä¿å­˜ã€‚

è®©æˆ‘ä»¬åƒåŸå§‹çš„ [**`mms-1b-all`**](https://huggingface.co/facebook/mms-1b-all) æ£€æŸ¥ç‚¹ä¸€æ ·ä½¿ç”¨ ISO-639-3 è¯­è¨€ä»£ç ã€‚

```python
target_lang = "tur"
```

è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç©ºå­—å…¸ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨å…¶ä¸­æ·»åŠ åˆšåˆšåˆ›å»ºçš„è¯æ±‡è¡¨

```python
new_vocab_dict = {target_lang: vocab_dict}
```

**æ³¨æ„**: å¦‚æœä½ æƒ³ä½¿ç”¨æ­¤ notebook å°†æ–°çš„é€‚é…å™¨å±‚æ·»åŠ åˆ° _ç°æœ‰æ¨¡å‹ä»“åº“_ ï¼Œè¯·ç¡®ä¿ **ä¸è¦** åˆ›å»ºä¸€ä¸ªç©ºçš„æ–°è¯æ±‡è¡¨ï¼Œè€Œæ˜¯é‡ç”¨å·²ç»å­˜åœ¨çš„è¯æ±‡è¡¨ã€‚ä¸ºæ­¤ï¼Œä½ åº”è¯¥å–æ¶ˆæ³¨é‡Šä»¥ä¸‹å•å…ƒæ ¼ï¼Œå¹¶å°† `"patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab"` æ›¿æ¢ä¸ºä½ è¦æ·»åŠ é€‚é…å™¨æƒé‡çš„æ¨¡å‹ä»“åº“ IDã€‚

```python
# from transformers import Wav2Vec2CTCTokenizer

# mms_adapter_repo = "patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab" # make sure to replace this path with a repo to which you want to add your new adapter weights

# tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(mms_adapter_repo)
# new_vocab = tokenizer.vocab

# new_vocab[target_lang] = vocab_dict
```

ç°åœ¨è®©æˆ‘ä»¬å°†è¯æ±‡è¡¨ä¿å­˜ä¸º json æ–‡ä»¶ã€‚

```python
import json
with open('vocab.json', 'w') as vocab_file:
    json.dump(new_vocab_dict, vocab_file)
```

æœ€åä¸€æ­¥ï¼Œæˆ‘ä»¬ä½¿ç”¨ json æ–‡ä»¶å°†è¯æ±‡è¡¨åŠ è½½åˆ°ç±»çš„å®ä¾‹ä¸­ `Wav2Vec2CTCTokenizer`ã€‚

```python
from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer.from_pretrained("./", unk_token="[UNK]", pad_token="[PAD]", word_delimiter_token="|", target_lang=target_lang)
```

å¦‚æœæƒ³è¦åœ¨æœ¬ notebook çš„å¾®è°ƒæ¨¡å‹ä¸­é‡ç”¨åˆšåˆšåˆ›å»ºçš„åˆ†è¯å™¨ï¼Œå¼ºçƒˆå»ºè®®å°† `tokenizer` ä¸Šä¼ åˆ° [ğŸ¤— Hub](https://huggingface.co/)ã€‚è®©æˆ‘ä»¬å°†ä¸Šä¼ æ–‡ä»¶çš„ä»“åº“å‘½åä¸º `"wav2vec2-large-mms-1b-turkish-colab"`:

```python
repo_name = "wav2vec2-large-mms-1b-turkish-colab"
```

å¹¶å°†åˆ†è¯å™¨ä¸Šä¼ åˆ° [ğŸ¤— Hub](https://huggingface.co/)ã€‚

```python
tokenizer.push_to_hub(repo_name)
```

```bash
    CommitInfo(commit_url='https://huggingface.co/patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab/commit/48cccbfd6059aa6ce655e9d94b8358ba39536cb7', commit_message='Upload tokenizer', commit_description='', oid='48cccbfd6059aa6ce655e9d94b8358ba39536cb7', pr_url=None, pr_revision=None, pr_num=None)
```

å¤ªå¥½äº†ï¼Œä½ å¯ä»¥åœ¨ä¸‹é¢çœ‹åˆ°åˆšåˆšåˆ›å»ºçš„å­˜å‚¨åº“ `https://huggingface.co/<your-username>/wav2vec2-large-mms-1b-tr-colab`

### åˆ›å»º `Wav2Vec2FeatureExtractor`

è¯­éŸ³æ˜¯ä¸€ä¸ªè¿ç»­çš„ä¿¡å·ï¼Œè¦è¢«è®¡ç®—æœºå¤„ç†ï¼Œé¦–å…ˆå¿…é¡»ç¦»æ•£åŒ–ï¼Œè¿™é€šå¸¸è¢«ç§°ä¸º **é‡‡æ ·**ã€‚é‡‡æ ·ç‡åœ¨è¿™é‡Œèµ·ç€é‡è¦çš„ä½œç”¨ï¼Œå®ƒå®šä¹‰äº†æ¯ç§’æµ‹é‡è¯­éŸ³ä¿¡å·çš„æ•°æ®ç‚¹æ•°ã€‚å› æ­¤ï¼Œé‡‡ç”¨æ›´é«˜çš„é‡‡æ ·ç‡é‡‡æ ·ä¼šæ›´å¥½åœ°è¿‘ä¼¼ _çœŸå®_ è¯­éŸ³ä¿¡å·ï¼Œä½†ä¹Ÿéœ€è¦æ¯ç§’æ›´å¤šçš„å€¼ã€‚

é¢„è®­ç»ƒæ£€æŸ¥ç‚¹æœŸæœ›å…¶è¾“å…¥æ•°æ®ä¸å…¶è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒå¤§è‡´ç›¸åŒã€‚ä¸¤ä¸ªä¸åŒé‡‡æ ·ç‡é‡‡æ ·çš„ç›¸åŒè¯­éŸ³ä¿¡å·å…·æœ‰éå¸¸ä¸åŒçš„åˆ†å¸ƒï¼Œä¾‹å¦‚ï¼Œå°†é‡‡æ ·ç‡åŠ å€ä¼šå¯¼è‡´æ•°æ®ç‚¹æ•°é‡åŠ å€ã€‚å› æ­¤ï¼Œåœ¨å¾®è°ƒ ASR æ¨¡å‹çš„é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ä¹‹å‰ï¼Œå¿…é¡»éªŒè¯ç”¨äºé¢„è®­ç»ƒæ¨¡å‹çš„æ•°æ®çš„é‡‡æ ·ç‡ä¸ç”¨äºå¾®è°ƒæ¨¡å‹çš„æ•°æ®é›†çš„é‡‡æ ·ç‡æ˜¯å¦åŒ¹é…ã€‚ `Wav2Vec2FeatureExtractor` å¯¹è±¡éœ€è¦ä»¥ä¸‹å‚æ•°æ‰èƒ½å®ä¾‹åŒ–:

- `feature_size`: è¯­éŸ³æ¨¡å‹ä»¥ç‰¹å¾å‘é‡åºåˆ—ä½œä¸ºè¾“å…¥ã€‚è™½ç„¶è¿™ä¸ªåºåˆ—çš„é•¿åº¦æ˜¾ç„¶ä¼šå˜åŒ–ï¼Œä½†ç‰¹å¾å¤§å°ä¸åº”è¯¥å˜åŒ–ã€‚åœ¨ Wav2Vec2 çš„æƒ…å†µä¸‹ï¼Œç‰¹å¾å¤§å°ä¸º 1ï¼Œå› ä¸ºè¯¥æ¨¡å‹æ˜¯åœ¨åŸå§‹è¯­éŸ³ä¿¡å·ä¸Šè®­ç»ƒçš„ \( {}^2 \)ã€‚
- `sampling_rate`: æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„é‡‡æ ·ç‡ã€‚
- `padding_value`: å¯¹äºæ‰¹é‡æ¨ç†ï¼Œè¾ƒçŸ­çš„è¾“å…¥éœ€è¦ç”¨ç‰¹å®šå€¼å¡«å……
- `do_normalize`: è¾“å…¥æ˜¯å¦åº”è¯¥è¿›è¡Œ _é›¶å‡å€¼å•ä½æ–¹å·®_ å½’ä¸€åŒ–ã€‚é€šå¸¸ï¼Œè¯­éŸ³æ¨¡å‹åœ¨å½’ä¸€åŒ–è¾“å…¥æ—¶è¡¨ç°æ›´å¥½
- `return_attention_mask`: æ¨¡å‹æ˜¯å¦åº”è¯¥ä½¿ç”¨ `attention_mask` è¿›è¡Œæ‰¹é‡æ¨ç†ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼ŒXLS-R æ¨¡å‹æ£€æŸ¥ç‚¹åº”è¯¥ **å§‹ç»ˆ** ä½¿ç”¨ `attention_mask`

```python
from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)
```

å¤ªå¥½äº†ï¼ŒMMS çš„ç‰¹å¾æå–ç®¡é“å·²ç»å®Œå…¨å®šä¹‰ï¼

ä¸ºäº†æé«˜ç”¨æˆ·å‹å¥½æ€§ï¼Œç‰¹å¾æå–å™¨å’Œåˆ†è¯å™¨è¢« _å°è£…_ åˆ°ä¸€ä¸ª `Wav2Vec2Processor` ç±»ä¸­ï¼Œè¿™æ ·åªéœ€è¦ä¸€ä¸ª `model` å’Œ  `processor` å¯¹è±¡ã€‚

```python
from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å‡†å¤‡æ•°æ®é›†ã€‚

### é¢„å¤„ç†æ•°æ®

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰çœ‹è¿‡è¯­éŸ³ä¿¡å·çš„å®é™…å€¼ï¼Œåªçœ‹è¿‡è½¬å½•ã€‚é™¤äº† `sentence`ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†è¿˜åŒ…æ‹¬å¦å¤–ä¸¤ä¸ªåˆ—å `path` å’Œ  `audio`ã€‚ `path` è¡¨ç¤ºéŸ³é¢‘æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼Œ `audio` è¡¨ç¤ºå·²ç»åŠ è½½çš„éŸ³é¢‘æ•°æ®ã€‚MMS æœŸæœ›è¾“å…¥æ ¼å¼ä¸º 16kHz çš„ä¸€ç»´æ•°ç»„ã€‚è¿™æ„å‘³ç€éŸ³é¢‘æ–‡ä»¶å¿…é¡»åŠ è½½å¹¶é‡æ–°é‡‡æ ·ã€‚

å€¼å¾—åº†å¹¸çš„æ˜¯ï¼Œå½“åˆ—åä¸º `audio` æ—¶ï¼Œ `datasets` ä¼šè‡ªåŠ¨å®Œæˆè¿™ä¸€æ“ä½œã€‚è®©æˆ‘ä»¬è¯•è¯•ã€‚

```python
common_voice_train[0]["audio"]
```

```bash
    {'path': '/root/.cache/huggingface/datasets/downloads/extracted/71ba9bd154da9d8c769b736301417178729d2b87b9e00cda59f6450f742ed778/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_17346025.mp3',
     'array': array([ 0.00000000e+00, -2.98378618e-13, -1.59835903e-13, ...,
            -2.01663317e-12, -1.87991593e-12, -1.17969588e-12]),
     'sampling_rate': 48000}
```

åœ¨ä¸Šé¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°éŸ³é¢‘æ•°æ®ä»¥ 48kHz çš„é‡‡æ ·ç‡åŠ è½½ï¼Œè€Œæ¨¡å‹æœŸæœ›çš„æ˜¯ 16kHzï¼Œæ­£å¦‚æˆ‘ä»¬æ‰€è§ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨ [`cast_column`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=cast_column#datasets.DatasetDict.cast_column) å°†éŸ³é¢‘ç‰¹å¾è®¾ç½®ä¸ºæ­£ç¡®çš„é‡‡æ ·ç‡:

```python
common_voice_train = common_voice_train.cast_column("audio", Audio(sampling_rate=16_000))
common_voice_test = common_voice_test.cast_column("audio", Audio(sampling_rate=16_000))
```

æˆ‘ä»¬å†æ¥çœ‹ä¸€ä¸‹ `"audio"`ã€‚

```python
common_voice_train[0]["audio"]
```

```
{'path': '/root/.cache/huggingface/datasets/downloads/extracted/71ba9bd154da9d8c769b736301417178729d2b87b9e00cda59f6450f742ed778/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_17346025.mp3',
 'array': array([ 9.09494702e-13, -6.13908924e-12, -1.09139364e-11, ...,
         1.81898940e-12, 4.54747351e-13, 3.63797881e-12]),
 'sampling_rate': 16000}
```

è¿™ä¼¼ä¹å¥æ•ˆäº†ï¼è®©æˆ‘ä»¬é€šè¿‡æ‰“å°è¯­éŸ³è¾“å…¥çš„å½¢çŠ¶ã€è½¬å½•å†…å®¹å’Œç›¸åº”çš„é‡‡æ ·ç‡æ¥æœ€åæ£€æŸ¥æ•°æ®æ˜¯å¦å‡†å¤‡æ­£ç¡®ã€‚

```python
rand_int = random.randint(0, len(common_voice_train)-1)

print("Target text:", common_voice_train[rand_int]["sentence"])
print("Input array shape:", common_voice_train[rand_int]["audio"]["array"].shape)
print("Sampling rate:", common_voice_train[rand_int]["audio"]["sampling_rate"])
```

```bash
    Target text: baÄŸÄ±ÅŸ anlaÅŸmasÄ± bir aÄŸustosta imzalandÄ±
    Input array shape:(70656,)
    Sampling rate: 16000
```

å¾ˆå¥½ï¼ä¸€åˆ‡çœ‹èµ·æ¥éƒ½å¾ˆæ£’ - æ•°æ®æ˜¯ä¸€ç»´æ•°ç»„ï¼Œé‡‡æ ·ç‡å§‹ç»ˆå¯¹åº”äº 16kHzï¼Œå¹¶ä¸”ç›®æ ‡æ–‡æœ¬å·²æ ‡å‡†åŒ–ã€‚

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨ `Wav2Vec2Processor` å°†æ•°æ®å¤„ç†æˆ `Wav2Vec2ForCTC` è®­ç»ƒæ‰€éœ€çš„æ ¼å¼ã€‚ä¸ºæ­¤ï¼Œè®©æˆ‘ä»¬åˆ©ç”¨ Dataset çš„ [`map(...)`](https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=map#datasets.DatasetDict.map) å‡½æ•°ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡è°ƒç”¨ `batch["audio"]` æ¥åŠ è½½å¹¶é‡æ–°é‡‡æ ·éŸ³é¢‘æ•°æ®ã€‚  
å…¶æ¬¡ï¼Œæˆ‘ä»¬ä»åŠ è½½çš„éŸ³é¢‘æ–‡ä»¶ä¸­æå– `input_values`ã€‚åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œ `Wav2Vec2Processor` åªè§„èŒƒåŒ–æ•°æ®ã€‚ç„¶è€Œï¼Œå¯¹äºå…¶ä»–è¯­éŸ³æ¨¡å‹ï¼Œè¿™ä¸€æ­¥å¯èƒ½åŒ…æ‹¬æ›´å¤æ‚çš„ç‰¹å¾æå–ï¼Œä¾‹å¦‚ [Log-Mel ç‰¹å¾æå–](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)ã€‚  
ç¬¬ä¸‰ï¼Œæˆ‘ä»¬å°†è½¬å½•ç¼–ç ä¸ºæ ‡ç­¾ idã€‚

**æ³¨æ„**: è¿™ä¸ªæ˜ å°„å‡½æ•°æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œè¯´æ˜äº†å¦‚ä½•ä½¿ç”¨ `Wav2Vec2Processor` ç±»ã€‚åœ¨â€œæ­£å¸¸â€æƒ…å†µä¸‹ï¼Œè°ƒç”¨ `processor(...)` ä¼šé‡å®šå‘åˆ° `Wav2Vec2FeatureExtractor` çš„è°ƒç”¨æ–¹æ³•ã€‚ç„¶è€Œï¼Œå½“å°†å¤„ç†å™¨å°è£…åˆ° `as_target_processor` ä¸Šä¸‹æ–‡ä¸­æ—¶ï¼ŒåŒä¸€ä¸ªæ–¹æ³•ä¼šé‡å®šå‘åˆ° `Wav2Vec2CTCTokenizer` çš„è°ƒç”¨æ–¹æ³•ã€‚
æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ [æ–‡æ¡£](https://huggingface.co/transformers/master/model_doc/wav2vec2.html#transformers.Wav2Vec2Processor.__call__)ã€‚

```python
def prepare_dataset(batch):
    audio = batch["audio"]

    # batched output is "un-batched"
    batch["input_values"] = processor(audio["array"], sampling_rate=audio["sampling_rate"]).input_values[0]
    batch["input_length"] = len(batch["input_values"])

    batch["labels"] = processor(text=batch["sentence"]).input_ids
    return batch
```

è®©æˆ‘ä»¬å°†æ•°æ®å‡†å¤‡åŠŸèƒ½åº”ç”¨åˆ°æ‰€æœ‰ç¤ºä¾‹ä¸­ã€‚

```python
common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names)
common_voice_test = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names)
```

**æ³¨æ„**: `datasets` è‡ªåŠ¨å¤„ç†éŸ³é¢‘åŠ è½½å’Œé‡æ–°é‡‡æ ·ã€‚å¦‚æœä½ å¸Œæœ›å®ç°è‡ªå·±çš„å®šåˆ¶æ•°æ®åŠ è½½/é‡‡æ ·ï¼Œè¯·éšæ„ä½¿ç”¨è¯¥ `"path"` åˆ—å¹¶å¿½ç•¥è¯¥ `"audio"` åˆ—ã€‚

å¤ªæ£’äº†ï¼Œç°åœ¨æˆ‘ä»¬å‡†å¤‡å¼€å§‹è®­ç»ƒäº†ï¼

## è®­ç»ƒ

æ•°æ®å·²ç»å¤„ç†å¥½ï¼Œæˆ‘ä»¬å‡†å¤‡å¼€å§‹è®¾ç½®è®­ç»ƒæµç¨‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ ğŸ¤— çš„ [Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer)ï¼Œä¸ºæ­¤æˆ‘ä»¬åŸºæœ¬ä¸Šéœ€è¦åšä»¥ä¸‹å‡ ä»¶äº‹:

- å®šä¹‰ä¸€ä¸ªæ•°æ®æ•´ç†å™¨ã€‚ä¸å¤§å¤šæ•° NLP æ¨¡å‹ä¸åŒï¼ŒMMS çš„è¾“å…¥é•¿åº¦æ¯”è¾“å‡ºé•¿åº¦å¤§å¾—å¤šã€‚ä¾‹å¦‚ï¼Œè¾“å…¥é•¿åº¦ä¸º 50000 çš„æ ·æœ¬çš„è¾“å‡ºé•¿åº¦ä¸è¶…è¿‡ 100ã€‚é‰´äºè¾“å…¥å¤§å°è¾ƒå¤§ï¼ŒåŠ¨æ€å¡«å……è®­ç»ƒæ‰¹æ¬¡æ›´ä¸ºé«˜æ•ˆï¼Œè¿™æ„å‘³ç€æ‰€æœ‰è®­ç»ƒæ ·æœ¬åªåº”å¡«å……åˆ°å…¶æ‰¹æ¬¡ä¸­æœ€é•¿çš„æ ·æœ¬ï¼Œè€Œä¸æ˜¯æ•´ä½“æœ€é•¿çš„æ ·æœ¬ã€‚å› æ­¤ï¼Œå¾®è°ƒ MMS éœ€è¦ä¸€ä¸ªç‰¹æ®Šçš„å¡«å……æ•°æ®æ•´ç†å™¨ï¼Œæˆ‘ä»¬å°†åœ¨ä¸‹é¢å®šä¹‰å®ƒ
- è¯„ä¼°æŒ‡æ ‡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹åº”è¯¥æ ¹æ®å­—é”™è¯¯ç‡è¿›è¡Œè¯„ä¼°ã€‚æˆ‘ä»¬åº”è¯¥ç›¸åº”åœ°å®šä¹‰ä¸€ä¸ª `compute_metrics` å‡½æ•°
- åŠ è½½é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚æˆ‘ä»¬éœ€è¦åŠ è½½é¢„è®­ç»ƒæ£€æŸ¥ç‚¹å¹¶æ­£ç¡®é…ç½®å®ƒè¿›è¡Œè®­ç»ƒã€‚
- å®šä¹‰è®­ç»ƒé…ç½®ã€‚

åœ¨å¾®è°ƒæ¨¡å‹ä¹‹åï¼Œæˆ‘ä»¬å°†æ­£ç¡®åœ°åœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°å®ƒï¼Œå¹¶éªŒè¯å®ƒæ˜¯å¦ç¡®å®å­¦ä¼šäº†æ­£ç¡®è½¬å½•è¯­éŸ³ã€‚

### è®¾ç½® Trainer

è®©æˆ‘ä»¬ä»å®šä¹‰æ•°æ®æ•´ç†å™¨å¼€å§‹ã€‚æ•°æ®æ•´ç†å™¨çš„ä»£ç æ˜¯ä» [è¿™ä¸ªç¤ºä¾‹](https://github.com/huggingface/transformers/blob/7e61d56a45c19284cfda0cee8995fb552f6b1f4e/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py#L219) ä¸­å¤åˆ¶çš„ã€‚

ä¸è¯¦ç»†è®²è¿°ï¼Œä¸å¸¸è§çš„æ•°æ®æ•´ç†å™¨ä¸åŒï¼Œè¿™ä¸ªæ•°æ®æ•´ç†å™¨åˆ†åˆ«å¯¹å¾… `input_values` å’Œ  `labels`ï¼Œå› æ­¤å¯¹å®ƒä»¬åº”ç”¨ä¸¤ä¸ªå•ç‹¬çš„å¡«å……å‡½æ•° (å†æ¬¡åˆ©ç”¨ MMS å¤„ç†å™¨çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨)ã€‚è¿™æ˜¯å¿…è¦çš„ï¼Œå› ä¸ºåœ¨è¯­éŸ³è¯†åˆ«ä¸­ï¼Œè¾“å…¥å’Œè¾“å‡ºå±äºä¸åŒçš„æ¨¡æ€ï¼Œå› æ­¤å®ƒä»¬ä¸åº”è¯¥è¢«ç›¸åŒçš„å¡«å……å‡½æ•°å¤„ç†ã€‚
ä¸å¸¸è§çš„æ•°æ®æ•´ç†å™¨ç±»ä¼¼ï¼Œæ ‡ç­¾ä¸­çš„å¡«å……æ ‡è®°ç”¨ `-100` å¡«å……ï¼Œä»¥ä¾¿åœ¨è®¡ç®—æŸå¤±æ—¶ **ä¸** è€ƒè™‘è¿™äº›æ ‡è®°ã€‚

```python
import torch

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Union

@dataclass
class DataCollatorCTCWithPadding:
    """
    Data collator that will dynamically pad the inputs received.
    Args:
        processor (:class:`~transformers.Wav2Vec2Processor`)
            The processor used for proccessing the data.
        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):
            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)
            among:
            *:obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single
              sequence if provided).
            *:obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the
              maximum acceptable input length for the model if that argument is not provided.
            *:obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of
              different lengths).
    """

    processor: Wav2Vec2Processor
    padding: Union[bool, str] = True

    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
        # split inputs and labels since they have to be of different lenghts and need
        # different padding methods
        input_features = [{"input_values": feature["input_values"]} for feature in features]
        label_features = [{"input_ids": feature["labels"]} for feature in features]

        batch = self.processor.pad(
            input_features,
            padding=self.padding,
            return_tensors="pt",
        )

        labels_batch = self.processor.pad(
            labels=label_features,
            padding=self.padding,
            return_tensors="pt",
        )

        # replace padding with -100 to ignore loss correctly
        labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)

        batch["labels"] = labels

        return batch
```

```python
data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)
```

æ¥ä¸‹æ¥ï¼Œå®šä¹‰è¯„ä¼°æŒ‡æ ‡ã€‚å¦‚å‰æ‰€è¿°ï¼ŒASR ä¸­çš„ä¸»è¦æŒ‡æ ‡æ˜¯å•è¯é”™è¯¯ç‡ (WER)ï¼Œå› æ­¤æˆ‘ä»¬ä¹Ÿå°†åœ¨æœ¬ notebook ä¸­ä½¿ç”¨å®ƒã€‚

```python
from evaluate import load

wer_metric = load("wer")
```

æ¨¡å‹å°†è¿”å›ä¸€ç³»åˆ— logit å‘é‡:
\( \mathbf{y}_1, \ldots, \mathbf{y}_m \) å…¶ä¸­ \( \mathbf{y} _1 = f_{\theta}(x_1, \ldots, x_n)[0] \) ä¸”  \( n >> m \)ã€‚

logit å‘é‡ \( \mathbf{y}_1 \) åŒ…å«æˆ‘ä»¬å‰é¢å®šä¹‰çš„è¯æ±‡è¡¨ä¸­æ¯ä¸ªå•è¯çš„å¯¹æ•°å‡ ç‡ï¼Œå› æ­¤ \( \text{len}(\mathbf{y}_i) = \) `config.vocab_size`ã€‚æˆ‘ä»¬å¯¹æ¨¡å‹æœ€å¯èƒ½çš„é¢„æµ‹æ„Ÿå…´è¶£ï¼Œå› æ­¤å– logits çš„  `argmax(...)`ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å°† `-100` æ›¿æ¢ä¸º `pad_token_id` å¹¶è§£ç  idï¼ŒåŒæ—¶ç¡®ä¿è¿ç»­æ ‡è®° **ä¸** ä»¥ CTC é£æ ¼åˆ†ç»„åˆ°åŒä¸€æ ‡è®° \( {}^1 \)ï¼Œå°†ç¼–ç åçš„æ ‡ç­¾è½¬æ¢å›åŸå§‹å­—ç¬¦ä¸²ã€‚

```python
def compute_metrics(pred):
    pred_logits = pred.predictions
    pred_ids = np.argmax(pred_logits, axis=-1)

    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id

    pred_str = processor.batch_decode(pred_ids)
    # we do not want to group tokens when computing the metrics
    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)

    wer = wer_metric.compute(predictions=pred_str, references=label_str)

    return {"wer": wer}
```

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥åŠ è½½é¢„è®­ç»ƒçš„ [`mms-1b-all`](https://huggingface.co/facebook/mms-1b-all) æ£€æŸ¥ç‚¹ã€‚åˆ†è¯å™¨çš„ `pad_token_id` å¿…é¡»å®šä¹‰æ¨¡å‹çš„ `pad_token_id`ï¼Œæˆ–è€…åœ¨ `Wav2Vec2ForCTC` çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯ CTC çš„ _ç©ºç™½æ ‡è®°_ \( {}^2 \)ã€‚

ç”±äºæˆ‘ä»¬åªè®­ç»ƒä¸€å°éƒ¨åˆ†æƒé‡ï¼Œæ¨¡å‹ä¸å®¹æ˜“è¿‡æ‹Ÿåˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬ç¡®ä¿ç¦ç”¨æ‰€æœ‰ dropout å±‚ã€‚

**æ³¨æ„**: å½“ä½¿ç”¨æœ¬ç¬”è®°æœ¬åœ¨ Common Voice çš„å¦ä¸€ç§è¯­è¨€ä¸Šè®­ç»ƒ MMS æ—¶ï¼Œè¿™äº›è¶…å‚æ•°è®¾ç½®å¯èƒ½ä¸ä¼šå¾ˆå¥½åœ°å·¥ä½œã€‚æ ¹æ®ä½ çš„ç”¨ä¾‹ï¼Œéšæ„è°ƒæ•´è¿™äº›è®¾ç½®ã€‚

```python
from transformers import Wav2Vec2ForCTC

model = Wav2Vec2ForCTC.from_pretrained(
    "facebook/mms-1b-all",
    attention_dropout=0.0,
    hidden_dropout=0.0,
    feat_proj_dropout=0.0,
    layerdrop=0.0,
    ctc_loss_reduction="mean",
    pad_token_id=processor.tokenizer.pad_token_id,
    vocab_size=len(processor.tokenizer),
    ignore_mismatched_sizes=True,
)
```

```bash
    Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/mms-1b-all and are newly initialized because the shapes did not match:
    - lm_head.bias: found shape torch.Size([154]) in the checkpoint and torch.Size([39]) in the model instantiated
    - lm_head.weight: found shape torch.Size([154, 1280]) in the checkpoint and torch.Size([39, 1280]) in the model instantiated
    You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```

**æ³¨æ„**: é¢„è®¡ä¸€äº›æƒé‡å°†è¢«é‡æ–°åˆå§‹åŒ–ã€‚è¿™äº›æƒé‡å¯¹åº”äºæ–°åˆå§‹åŒ–çš„è¯æ±‡è¾“å‡ºå±‚ã€‚

æˆ‘ä»¬ç°åœ¨å¸Œæœ›ç¡®ä¿åªæœ‰é€‚é…å™¨æƒé‡å°†è¢«è®­ç»ƒï¼Œè€Œæ¨¡å‹çš„å…¶ä½™éƒ¨åˆ†ä¿æŒå†»ç»“ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬é‡æ–°åˆå§‹åŒ–æ‰€æœ‰é€‚é…å™¨æƒé‡ï¼Œè¿™å¯ä»¥é€šè¿‡æ–¹ä¾¿çš„ `init_adapter_layers` æ–¹æ³•å®Œæˆã€‚ä¹Ÿå¯ä»¥ä¸é‡æ–°åˆå§‹åŒ–é€‚é…å™¨æƒé‡å¹¶ç»§ç»­å¾®è°ƒï¼Œä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåœ¨è®­ç»ƒä¹‹å‰åº”è¯¥é€šè¿‡ [`load_adapter(...)` æ–¹æ³•](https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC.load_adapter) åŠ è½½åˆé€‚çš„é€‚é…å™¨æƒé‡ã€‚ç„¶è€Œï¼Œè¯æ±‡è¡¨é€šå¸¸ä»ç„¶ä¸ä¼šå¾ˆå¥½åœ°åŒ¹é…è‡ªå®šä¹‰è®­ç»ƒæ•°æ®ï¼Œå› æ­¤é€šå¸¸æ›´å®¹æ˜“é‡æ–°åˆå§‹åŒ–æ‰€æœ‰é€‚é…å™¨å±‚ï¼Œä»¥ä¾¿å®ƒä»¬å¯ä»¥è½»æ¾åœ°è¿›è¡Œå¾®è°ƒã€‚

```python
model.init_adapter_layers()
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å†»ç»“ **é™¤** é€‚é…å™¨å±‚ä¹‹å¤–çš„æ‰€æœ‰æƒé‡ã€‚

```python
model.freeze_base_model()

adapter_weights = model._get_adapters()
for param in adapter_weights.values():
    param.requires_grad = True
```

æœ€åä¸€æ­¥ï¼Œæˆ‘ä»¬å®šä¹‰ä¸è®­ç»ƒç›¸å…³çš„æ‰€æœ‰å‚æ•°ã€‚
å¯¹ä¸€äº›å‚æ•°è¿›è¡Œæ›´å¤šè§£é‡Š:

- `group_by_length` é€šè¿‡å°†è¾“å…¥é•¿åº¦ç›¸ä¼¼çš„è®­ç»ƒæ ·æœ¬åˆ†ç»„åˆ°ä¸€ä¸ªæ‰¹æ¬¡ä¸­ï¼Œä½¿è®­ç»ƒæ›´åŠ é«˜æ•ˆã€‚è¿™å¯ä»¥é€šè¿‡å¤§å¤§å‡å°‘é€šè¿‡æ¨¡å‹ä¼ é€’çš„æ— ç”¨å¡«å……æ ‡è®°çš„æ€»æ•°ï¼Œä»è€Œæ˜¾è‘—åŠ å¿«è®­ç»ƒæ—¶é—´
- `learning_rate` è¢«é€‰æ‹©ä¸º 1e-3ï¼Œè¿™æ˜¯ä½¿ç”¨ Adam è®­ç»ƒçš„å¸¸ç”¨é»˜è®¤å€¼ã€‚å…¶ä»–å­¦ä¹ ç‡å¯èƒ½åŒæ ·æœ‰æ•ˆã€‚

æœ‰å…³å…¶ä»–å‚æ•°çš„æ›´å¤šè§£é‡Šï¼Œå¯ä»¥æŸ¥çœ‹ [æ–‡æ¡£](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer#trainingarguments)ã€‚ä¸ºäº†èŠ‚çœ GPU å†…å­˜ï¼Œæˆ‘ä»¬å¯ç”¨ PyTorch çš„ [æ¢¯åº¦æ£€æŸ¥ç‚¹](https://pytorch.org/docs/stable/checkpoint.html)ï¼Œå¹¶å°†æŸå¤±å‡å°‘è®¾ç½®ä¸ºâ€œ _mean_ â€ã€‚MMS é€‚é…å™¨å¾®è°ƒéå¸¸å¿«åœ°æ”¶æ•›åˆ°éå¸¸å¥½çš„æ€§èƒ½ï¼Œå› æ­¤å³ä½¿å¯¹äºåƒ 4 å°æ—¶è¿™æ ·å°çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬ä¹Ÿåªä¼šè®­ç»ƒ 4 ä¸ªå‘¨æœŸã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ 200 ä¸ªè®­ç»ƒæ­¥éª¤å°†å¼‚æ­¥ä¸Šä¼ ä¸€ä¸ªæ£€æŸ¥ç‚¹åˆ° hubã€‚å®ƒå…è®¸ä½ åœ¨æ¨¡å‹ä»åœ¨è®­ç»ƒæ—¶ä¹Ÿå¯ä»¥ä½¿ç”¨æ¼”ç¤ºå°éƒ¨ä»¶ç©è€ã€‚

**æ³¨æ„**: å¦‚æœä¸æƒ³å°†æ¨¡å‹æ£€æŸ¥ç‚¹ä¸Šä¼ åˆ° hubï¼Œåªéœ€å°† `push_to_hub=False` å³å¯ã€‚

```python
from transformers import TrainingArguments

training_args = TrainingArguments(
  output_dir=repo_name,
  group_by_length=True,
  per_device_train_batch_size=32,
  evaluation_strategy="steps",
  num_train_epochs=4,
  gradient_checkpointing=True,
  fp16=True,
  save_steps=200,
  eval_steps=100,
  logging_steps=100,
  learning_rate=1e-3,
  warmup_steps=100,
  save_total_limit=2,
  push_to_hub=True,
)
```

ç°åœ¨ï¼Œæ‰€æœ‰å®ä¾‹éƒ½å¯ä»¥ä¼ é€’ç»™ Trainerï¼Œæˆ‘ä»¬å‡†å¤‡å¼€å§‹è®­ç»ƒï¼

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    data_collator=data_collator,
    args=training_args,
    compute_metrics=compute_metrics,
    train_dataset=common_voice_train,
    eval_dataset=common_voice_test,
    tokenizer=processor.feature_extractor,
)
```

---

\( {}^1 \) ä¸ºäº†ä½¿æ¨¡å‹ç‹¬ç«‹äºè¯´è¯äººé€Ÿç‡ï¼Œåœ¨ CTC ä¸­ï¼Œç›¸åŒçš„è¿ç»­æ ‡è®°ç®€å•åœ°åˆ†ç»„ä¸ºå•ä¸ªæ ‡è®°ã€‚ç„¶è€Œï¼Œåœ¨è§£ç æ—¶ä¸åº”è¯¥å¯¹ç¼–ç çš„æ ‡ç­¾è¿›è¡Œåˆ†ç»„ï¼Œå› ä¸ºå®ƒä»¬ä¸å¯¹åº”äºæ¨¡å‹çš„é¢„æµ‹æ ‡è®°ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆå¿…é¡»ä¼ é€’ `group_tokens=False` å‚æ•°ã€‚å¦‚æœæˆ‘ä»¬ä¸ä¼ é€’è¿™ä¸ªå‚æ•°ï¼Œåƒ `"hello"` è¿™æ ·çš„å•è¯ä¼šè¢«é”™è¯¯åœ°ç¼–ç ï¼Œå¹¶è§£ç ä¸º `"helo"`ã€‚

\( {}^2 \) ç©ºç™½æ ‡è®°å…è®¸æ¨¡å‹é€šè¿‡å¼ºåˆ¶åœ¨ä¸¤ä¸ª l ä¹‹é—´æ’å…¥ç©ºç™½æ ‡è®°æ¥é¢„æµ‹ä¸€ä¸ªè¯ï¼Œä¾‹å¦‚ `"hello"`ã€‚æˆ‘ä»¬æ¨¡å‹çš„ CTC ç¬¦åˆé¢„æµ‹ `"hello"` å°†æ˜¯ `[PAD] [PAD]"h" "e" "e" "l" "l" [PAD]"l" "o" "o" [PAD]`ã€‚

### è®­ç»ƒ

è®­ç»ƒæ—¶é—´åº”è¯¥å°‘äº 30 åˆ†é’Ÿï¼Œå…·ä½“å–å†³äºæ‰€ä½¿ç”¨çš„ GPUã€‚

```python
trainer.train()
```

| è®­ç»ƒæŸå¤± | è®­ç»ƒæ­¥æ•° | éªŒè¯æŸå¤± | Wer |
| :-: | :-: | :-: | :-: |
| 4.905 | 100 | 0.215 | 0.280 |
| 0.290 | 200 | 0.167 | 0.232 |
| 0.2659 | 300 | 0.161 | 0.229 |
| 0.2398 | 400 | 0.156 | 0.223 |

è®­ç»ƒæŸå¤±å’ŒéªŒè¯ WER éƒ½å¾ˆå¥½åœ°ä¸‹é™ã€‚

æˆ‘ä»¬çœ‹åˆ°ï¼Œä»…å¾®è°ƒ `mms-1b-all` çš„é€‚é…å™¨å±‚ 100 æ­¥å°±å¤§å¤§è¶…è¿‡äº† [è¿™é‡Œ](https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2#training-1) æ˜¾ç¤ºçš„å¾®è°ƒæ•´ä¸ª `xls-r-300m` æ£€æŸ¥ç‚¹ã€‚

ä» [å®˜æ–¹è®ºæ–‡](https://scontent-cdg4-3.xx.fbcdn.net/v/t39.8562-6/348827959_6967534189927933_6819186233244071998_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ad8a9d&_nc_ohc=fSo3qQ7uxr0AX8EWnWl&_nc_ht=scontent-cdg4-3.xx&oh=00_AfBL34K0MAAPb0CgnthjbHfiB6pSnnwbn5esj9DZVPvyoA&oe=6495E802) å’Œè¿™ä¸ªå¿«é€Ÿæ¯”è¾ƒä¸­å¯ä»¥æ¸…æ¥šåœ°çœ‹å‡ºï¼Œ `mms-1b-all` å…·æœ‰æ›´é«˜çš„å°†çŸ¥è¯†è½¬ç§»åˆ°ä½èµ„æºè¯­è¨€çš„èƒ½åŠ›ï¼Œåº”è¯¥ä¼˜å…ˆäº `xls-r-300m`ã€‚æ­¤å¤–ï¼Œè®­ç»ƒä¹Ÿæ›´èŠ‚çœå†…å­˜ï¼Œå› ä¸ºåªè®­ç»ƒäº†ä¸€å°éƒ¨åˆ†å±‚ã€‚

é€‚é…å™¨æƒé‡å°†ä½œä¸ºæ¨¡å‹æ£€æŸ¥ç‚¹çš„ä¸€éƒ¨åˆ†ä¸Šä¼ ï¼Œä½†æˆ‘ä»¬ä¹Ÿå¸Œæœ›ç¡®ä¿å•ç‹¬ä¿å­˜å®ƒä»¬ï¼Œä»¥ä¾¿å®ƒä»¬å¯ä»¥è½»æ¾åœ°ä¸Šä¸‹çº¿ã€‚

è®©æˆ‘ä»¬å°†æ‰€æœ‰é€‚é…å™¨å±‚ä¿å­˜åˆ°è®­ç»ƒè¾“å‡ºç›®å½•ä¸­ï¼Œä»¥ä¾¿å®ƒèƒ½å¤Ÿæ­£ç¡®ä¸Šä¼ åˆ° Hubã€‚

```python
from safetensors.torch import save_file as safe_save_file
from transformers.models.wav2vec2.modeling_wav2vec2 import WAV2VEC2_ADAPTER_SAFE_FILE
import os

adapter_file = WAV2VEC2_ADAPTER_SAFE_FILE.format(target_lang)
adapter_file = os.path.join(training_args.output_dir, adapter_file)

safe_save_file(model._get_adapters(), adapter_file, metadata={"format": "pt"})
```

æœ€åï¼Œä½ å¯ä»¥å°†è®­ç»ƒç»“æœä¸Šä¼ åˆ°ğŸ¤— Hubã€‚

```python
trainer.push_to_hub()
```

é€‚é…å™¨æƒé‡è®­ç»ƒçš„ä¸»è¦ä¼˜ç‚¹ä¹‹ä¸€æ˜¯â€œåŸºç¡€â€æ¨¡å‹ (çº¦å æ¨¡å‹æƒé‡çš„ 99%) ä¿æŒä¸å˜ï¼Œåªéœ€å…±äº«ä¸€ä¸ªå°çš„ [2.5M é€‚é…å™¨æ£€æŸ¥ç‚¹](https://huggingface.co/patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab/blob/main/adapter.tur.safetensors) å³å¯ä½¿ç”¨è®­ç»ƒå¥½çš„æ£€æŸ¥ç‚¹ã€‚

è¿™ä½¿å¾—è®­ç»ƒé¢å¤–çš„é€‚é…å™¨å±‚å¹¶å°†å®ƒä»¬æ·»åŠ åˆ°ä½ çš„ä»“åº“å˜å¾—éå¸¸ç®€å•ã€‚

ä½ å¯ä»¥é€šè¿‡ç®€å•åœ°é‡æ–°è¿è¡Œæ­¤è„šæœ¬å¹¶å°†ä½ æƒ³è¦è®­ç»ƒçš„è¯­è¨€æ›´æ”¹ä¸ºå¦ä¸€ç§è¯­è¨€æ¥è½»æ¾å®ç°ï¼Œä¾‹å¦‚ `swe` è¡¨ç¤ºç‘å…¸è¯­ã€‚æ­¤å¤–ï¼Œä½ åº”è¯¥ç¡®ä¿è¯æ±‡è¡¨ä¸ä¼šè¢«å®Œå…¨è¦†ç›–ï¼Œè€Œæ˜¯æ–°è¯­è¨€è¯æ±‡è¡¨åº”è¯¥åƒä¸Šé¢æ³¨é‡Šæ‰çš„å•å…ƒæ ¼ä¸­æ‰€è¿°é‚£æ · **é™„åŠ ** åˆ°ç°æœ‰è¯æ±‡è¡¨ä¸­ã€‚

ä¸ºäº†æ¼”ç¤ºå¦‚ä½•åŠ è½½ä¸åŒçš„é€‚é…å™¨å±‚ï¼Œæˆ‘è¿˜è®­ç»ƒå¹¶ä¸Šä¼ äº†ä¸€ä¸ªç‘å…¸è¯­é€‚é…å™¨å±‚ï¼Œå…¶ iso è¯­è¨€ä»£ç ä¸º `swe`ï¼Œå¦‚ [æ­¤å¤„](https://huggingface.co/patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab/blob/main/adapter.swe.safetensors) æ‰€ç¤º

ä½ å¯ä»¥åƒå¾€å¸¸ä¸€æ ·ä½¿ç”¨ `from_pretrained(...)` åŠ è½½å¾®è°ƒåçš„æ£€æŸ¥ç‚¹ï¼Œä½†åº”ç¡®ä¿åœ¨æ–¹æ³•ä¸­æ·»åŠ  `target_lang="<your-lang-code>"`ï¼Œä»¥ä¾¿åŠ è½½æ­£ç¡®çš„é€‚é…å™¨ã€‚ä½ è¿˜åº”è¯¥ä¸ºåˆ†è¯å™¨æ­£ç¡®è®¾ç½®ç›®æ ‡è¯­è¨€ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•é¦–å…ˆåŠ è½½åœŸè€³å…¶æ£€æŸ¥ç‚¹ã€‚

```python
model_id = "patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab"

model = Wav2Vec2ForCTC.from_pretrained(model_id, target_lang="tur").to("cuda")
processor = Wav2Vec2Processor.from_pretrained(model_id)

processor.tokenizer.set_target_lang("tur")
```

è®©æˆ‘ä»¬æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ä»¥æ­£ç¡®è½¬å½•åœŸè€³å…¶è¯­

```python
from datasets import Audio

common_voice_test_tr = load_dataset("mozilla-foundation/common_voice_6_1", "tr", data_dir="./cv-corpus-6.1-2020-12-11", split="test", use_auth_token=True)
common_voice_test_tr = common_voice_test_tr.cast_column("audio", Audio(sampling_rate=16_000))
```

è®©æˆ‘ä»¬å¤„ç†éŸ³é¢‘ï¼Œè¿è¡Œå‰å‘ä¼ é€’å¹¶é¢„æµ‹ ids

```python
input_dict = processor(common_voice_test_tr[0]["audio"]["array"], sampling_rate=16_000, return_tensors="pt", padding=True)

logits = model(input_dict.input_values.to("cuda")).logits

pred_ids = torch.argmax(logits, dim=-1)[0]
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥è§£ç è¯¥ç¤ºä¾‹ã€‚

```python
print("Prediction:")
print(processor.decode(pred_ids))

print("\nReference:")
print(common_voice_test_tr[0]["sentence"].lower())
```

**è¾“å‡º**:

```bash
    Prediction:
    pekÃ§oÄŸuda roman toplumundan geliyor

    Reference:
    pek Ã§oÄŸu da roman toplumundan geliyor.
```

è¿™çœ‹èµ·æ¥å‡ ä¹å®Œå…¨æ­£ç¡®ï¼Œåªæ˜¯ç¬¬ä¸€ä¸ªå•è¯ä¸­åº”è¯¥æ·»åŠ ä¸¤ä¸ªç©ºæ ¼ã€‚
ç°åœ¨ï¼Œé€šè¿‡è°ƒç”¨ [`model.load_adapter(...)`](mozilla-foundation/common_voice_6_1) å¹¶å°†åˆ†è¯å™¨æ›´æ”¹ä¸ºç‘å…¸è¯­ï¼Œå¯ä»¥éå¸¸ç®€å•åœ°å°†é€‚é…å™¨æ›´æ”¹ä¸ºç‘å…¸è¯­ã€‚

```python
model.load_adapter("swe")
processor.tokenizer.set_target_lang("swe")
```

æˆ‘ä»¬å†æ¬¡ä»æ™®é€šè¯­éŸ³åŠ è½½ç‘å…¸è¯­æµ‹è¯•é›†

```python
common_voice_test_swe = load_dataset("mozilla-foundation/common_voice_6_1", "sv-SE", data_dir="./cv-corpus-6.1-2020-12-11", split="test", use_auth_token=True)
common_voice_test_swe = common_voice_test_swe.cast_column("audio", Audio(sampling_rate=16_000))
```

å¹¶è½¬å½•ä¸€ä¸ªæ ·æœ¬:

```python
input_dict = processor(common_voice_test_swe[0]["audio"]["array"], sampling_rate=16_000, return_tensors="pt", padding=True)

logits = model(input_dict.input_values.to("cuda")).logits

pred_ids = torch.argmax(logits, dim=-1)[0]

print("Prediction:")
print(processor.decode(pred_ids))

print("\nReference:")
print(common_voice_test_swe[0]["sentence"].lower())
```

**è¾“å‡º**:

```bash
    Prediction:
    jag lÃ¤mnade grovjobbet Ã¥t honom

    Reference:
    jag lÃ¤mnade grovjobbet Ã¥t honom.
```

å¤ªå¥½äº†ï¼Œè¿™çœ‹èµ·æ¥åƒæ˜¯ä¸€ä¸ªå®Œç¾çš„è½¬å½•ï¼

æˆ‘ä»¬åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­å±•ç¤ºäº† MMS é€‚é…å™¨æƒé‡å¾®è°ƒä¸ä»…åœ¨ä½èµ„æºè¯­è¨€ä¸Šæä¾›äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè€Œä¸”è¿˜æ˜¾è‘—ç¼©çŸ­äº†è®­ç»ƒæ—¶é—´ï¼Œå¹¶å…è®¸è½»æ¾æ„å»ºå®šåˆ¶çš„é€‚é…å™¨æƒé‡é›†åˆã€‚

_ç›¸å…³å¸–å­å’Œé™„åŠ é“¾æ¥åˆ—åœ¨è¿™é‡Œ:_

- [**å®˜æ–¹è®ºæ–‡**](https://huggingface.co/papers/2305.13516)
- [**åŸå§‹ cobebase**](https://github.com/facebookresearch/fairseq/tree/main/examples/mms/asr)
- [**å®˜æ–¹æ¼”ç¤º**](https://huggingface.co/spaces/facebook/MMS)
- [**Transformers æ–‡æ¡£**](https://huggingface.co/docs/transformers/index)
- [**ç›¸å…³ XLS-R åšå®¢æ–‡ç« **](https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2)
- [**Hub ä¸Šçš„æ¨¡å‹**](https://huggingface.co/models?other=mms)