---
title: "æ¬¢è¿ Gemma: Google æœ€æ–°æ¨å‡ºå¼€æ”¾å¤§è¯­è¨€æ¨¡å‹"
thumbnail: /blog/assets/gemma/thumbnail.jpg
authors:
- user: philschmid
- user: osanseviero
- user: pcuenq
translators:
- user: chenglu
---

# æ¬¢è¿ Gemma: Google æœ€æ–°æ¨å‡ºå¼€æ”¾å¤§è¯­è¨€æ¨¡å‹

ä»Šå¤©ï¼ŒGoogle å‘å¸ƒäº†ä¸€ç³»åˆ—æœ€æ–°çš„å¼€æ”¾å¼å¤§å‹è¯­è¨€æ¨¡å‹ â€”â€” Gemmaï¼Google æ­£åœ¨åŠ å¼ºå…¶å¯¹å¼€æºäººå·¥æ™ºèƒ½çš„æ”¯æŒï¼Œæˆ‘ä»¬ä¹Ÿéå¸¸æœ‰å¹¸èƒ½å¤Ÿå¸®åŠ©å…¨åŠ›æ”¯æŒè¿™æ¬¡å‘å¸ƒï¼Œå¹¶ä¸ Hugging Face ç”Ÿæ€å®Œç¾é›†æˆã€‚

Gemma æä¾›ä¸¤ç§è§„æ¨¡çš„æ¨¡å‹ï¼š7B å‚æ•°æ¨¡å‹ï¼Œé’ˆå¯¹æ¶ˆè´¹çº§ GPU å’Œ TPU è®¾è®¡ï¼Œç¡®ä¿é«˜æ•ˆéƒ¨ç½²å’Œå¼€å‘ï¼›2B å‚æ•°æ¨¡å‹åˆ™é€‚ç”¨äº CPU å’Œç§»åŠ¨è®¾å¤‡ã€‚æ¯ç§è§„æ¨¡çš„æ¨¡å‹éƒ½åŒ…å«åŸºç¡€ç‰ˆæœ¬å’Œç»è¿‡æŒ‡ä»¤è°ƒä¼˜çš„ç‰ˆæœ¬ã€‚

æˆ‘ä»¬ä¸ Google ç´§å¯†åˆä½œï¼Œç¡®ä¿ Gemma èƒ½å¤Ÿæ— ç¼é›†æˆåˆ° Hugging Face çš„ç”Ÿæ€ç³»ç»Ÿä¸­ã€‚åœ¨ Hub ä¸Šï¼Œä½ å¯ä»¥æ‰¾åˆ°è¿™å››ä¸ªå…¬å¼€å¯è®¿é—®çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ä¸¤ä¸ªåŸºç¡€æ¨¡å‹å’Œä¸¤ä¸ªç»è¿‡è°ƒä¼˜çš„æ¨¡å‹ï¼‰ã€‚æ­¤æ¬¡å‘å¸ƒçš„äº®ç‚¹åŒ…æ‹¬ï¼š

- [Hub ä¸Šçš„æ¨¡å‹](https://huggingface.co/models?search=google/gemma)ï¼ŒåŒ…æ‹¬æ¨¡å‹è¯´æ˜å’Œæˆæƒä¿¡æ¯
- [ğŸ¤— Transformers çš„é›†æˆ](https://github.com/huggingface/transformers/releases/tag/v4.38.0)
- ä¸ Google Cloud çš„æ·±åº¦é›†æˆ
- ä¸æ¨ç†ç«¯ç‚¹ (Inference Endpoints) çš„é›†æˆ
- ä½¿ç”¨ ğŸ¤— TRL åœ¨å•ä¸ª GPU ä¸Šå¯¹ Gemma è¿›è¡Œå¾®è°ƒçš„ç¤ºä¾‹

## ç›®å½•

- [Gemma æ˜¯ä»€ä¹ˆï¼Ÿ](#what-is-gemma)
  - [æç¤ºæ ¼å¼](#prompt-format)
  - [æ¢ç´¢æœªçŸ¥](#exploring-the-unknowns)
- [æ¼”ç¤º](#demo)
  - [ä½¿ç”¨ ğŸ¤— Transformers](#using-ğŸ¤—-transformers)
  - [JAX æƒé‡](#jax-weights)
- [ä¸ Google Cloud çš„é›†æˆ](#integration-with-google-cloud)
- [ä¸æ¨ç†ç«¯ç‚¹çš„é›†æˆ](#integration-with-inference-endpoints)
- [ä½¿ç”¨ ğŸ¤— TRL è¿›è¡Œå¾®è°ƒ](#fine-tuning-with-ğŸ¤—-trl)
- [é¢å¤–èµ„æº](#additional-resources)
- [è‡´è°¢](#acknowledgments)

## Gemma æ˜¯ä»€ä¹ˆï¼Ÿ

Gemma æ˜¯ Google åŸºäº Gemini æŠ€æœ¯æ¨å‡ºçš„å››æ¬¾æ–°å‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œæä¾›äº† 2B å’Œ 7B ä¸¤ç§ä¸åŒè§„æ¨¡çš„ç‰ˆæœ¬ï¼Œæ¯ç§éƒ½åŒ…å«äº†é¢„è®­ç»ƒåŸºç¡€ç‰ˆæœ¬å’Œç»è¿‡æŒ‡ä»¤ä¼˜åŒ–çš„ç‰ˆæœ¬ã€‚æ‰€æœ‰ç‰ˆæœ¬å‡å¯åœ¨å„ç±»æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿è¡Œï¼Œæ— éœ€æ•°æ®é‡åŒ–å¤„ç†ï¼Œæ‹¥æœ‰é«˜è¾¾ 8K tokens çš„å¤„ç†èƒ½åŠ›ï¼š

- [gemma-7b](https://huggingface.co/google/gemma-7b)ï¼š7B å‚æ•°çš„åŸºç¡€æ¨¡å‹ã€‚
- [gemma-7b-it](https://huggingface.co/google/gemma-7b-it)ï¼š7B å‚æ•°çš„æŒ‡ä»¤ä¼˜åŒ–ç‰ˆæœ¬ã€‚
- [gemma-2b](https://huggingface.co/google/gemma-2b)ï¼š2B å‚æ•°çš„åŸºç¡€æ¨¡å‹ã€‚
- [gemma-2b-it](https://huggingface.co/google/gemma-2b-it)ï¼š2B å‚æ•°çš„æŒ‡ä»¤ä¼˜åŒ–ç‰ˆæœ¬ã€‚

<div class="flex items-center justify-center">
<img src="/blog/assets/gemma/Gemma-logo-small.png" alt="Gemma logo">
</div>

Gemma æ¨¡å‹çš„æ€§èƒ½å¦‚ä½•ï¼Ÿä»¥ä¸‹æ˜¯å…¶åŸºç¡€ç‰ˆæœ¬ä¸å…¶ä»–å¼€æ”¾æ¨¡å‹åœ¨ [LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) ä¸Šçš„æ¯”è¾ƒï¼ˆå¾—åˆ†è¶Šé«˜è¶Šå¥½ï¼‰ï¼š

| æ¨¡å‹                                                                            | è®¸å¯è¯         | å•†ä¸šä½¿ç”¨ | é¢„è®­ç»ƒå¤§å° [tokens] | æ’è¡Œæ¦œåˆ†æ•° â¬‡ï¸ |
| -------------------------------------------------------------------------------- | --------------- | --------------- | ------------------------- | -------------------- |
| [LLama 2 70B Chat (å‚è€ƒ)](https://huggingface.co/meta-llama/Llama-2-70b-hf) | Llama 2 è®¸å¯è¯ | âœ…               | 2T                        | 67.87                |
| [Gemma-7B](https://huggingface.co/google/gemma-7b)                               | Gemma è®¸å¯è¯   | âœ…               | 6T                        | 63.75                |
| [DeciLM-7B](https://huggingface.co/Deci/DeciLM-7B)                               | Apache 2.0      | âœ…               | æœªçŸ¥                   | 61.55                |
| [PHI-2 (2.7B)](https://huggingface.co/microsoft/phi-2)                           | MIT             | âœ…               | 1.4T                      | 61.33                |
| [Mistral-7B-v0.1](https://huggingface.co/mistralai/Mistral-7B-v0.1)              | Apache 2.0      | âœ…               | æœªçŸ¥                   | 60.97                |
| [Llama 2 7B](https://huggingface.co/meta-llama/Llama-2-7b-hf)                    | Llama 2 è®¸å¯è¯ | âœ…               | 2T                        | 54.32                |
| [Gemma 2B](https://huggingface.co/google/gemma-2b)                               | Gemma è®¸å¯è¯   | âœ…               | 2T                        | 46.51                |

åœ¨ 7B å‚æ•°çº§åˆ«ï¼ŒGemma è¡¨ç°å‡ºè‰²ï¼Œä¸å¸‚åœºä¸Šæœ€ä½³æ¨¡å‹å¦‚ Mistral 7B ä¸ç›¸ä¸Šä¸‹ã€‚è€Œ 2B ç‰ˆæœ¬çš„ Gemma è™½ç„¶è§„æ¨¡è¾ƒå°ï¼Œä½†åœ¨å…¶ç±»åˆ«ä¸­çš„è¡¨ç°ä¹Ÿé¢‡å…·ç«äº‰åŠ›ï¼Œå°½ç®¡åœ¨æ’è¡Œæ¦œä¸Šçš„å¾—åˆ†å¹¶æœªè¶…è¶Šç±»ä¼¼è§„æ¨¡çš„é¡¶å°–æ¨¡å‹ï¼Œä¾‹å¦‚ Phi 2ã€‚æˆ‘ä»¬æœŸå¾…ç¤¾åŒºå¯¹è¿™äº›æ¨¡å‹çš„çœŸå®ä½¿ç”¨åé¦ˆï¼Œä»¥è¿›ä¸€æ­¥ä¼˜åŒ–å’Œè°ƒæ•´ã€‚

éœ€è¦æµ…æµ…å†å¼ºè°ƒä¸€ä¸‹ï¼šLLM æ’è¡Œæ¦œç‰¹åˆ«é€‚ç”¨äºè¡¡é‡é¢„è®­ç»ƒæ¨¡å‹çš„è´¨é‡ï¼Œè€Œä¸å¤ªé€‚ç”¨äºèŠå¤©æ¨¡å‹ã€‚æˆ‘ä»¬é¼“åŠ±å¯¹èŠå¤©æ¨¡å‹è¿è¡Œå…¶ä»–åŸºå‡†æµ‹è¯•ï¼Œå¦‚ MT Benchã€EQ Bench å’Œ lmsys Arenaã€‚

### Prompt æç¤ºè¯æ ¼å¼

Gemma çš„åŸºç¡€æ¨¡å‹ä¸é™å®šç‰¹å®šçš„æç¤ºæ ¼å¼ã€‚å¦‚åŒå…¶ä»–åŸºç¡€æ¨¡å‹ï¼Œå®ƒä»¬èƒ½å¤Ÿæ ¹æ®è¾“å…¥åºåˆ—ç”Ÿæˆä¸€ä¸ªåˆç†çš„ç»­æ¥å†…å®¹ï¼Œé€‚ç”¨äºé›¶æ ·æœ¬æˆ–å°‘æ ·æœ¬çš„æ¨ç†ä»»åŠ¡ã€‚è¿™äº›æ¨¡å‹ä¹Ÿä¸ºé’ˆå¯¹ç‰¹å®šåº”ç”¨åœºæ™¯çš„å¾®è°ƒæä¾›äº†åšå®çš„åŸºç¡€ã€‚æŒ‡ä»¤ä¼˜åŒ–ç‰ˆæœ¬åˆ™é‡‡ç”¨äº†ä¸€ç§æå…¶ç®€æ´çš„å¯¹è¯ç»“æ„ï¼š

```xml
<start_of_turn>user
knock knock<end_of_turn>
<start_of_turn>model
who is there<end_of_turn>
<start_of_turn>user
LaMDA<end_of_turn>
<start_of_turn>model
LaMDA who?<end_of_turn>
```

è¦æœ‰æ•ˆåˆ©ç”¨è¿™ä¸€æ ¼å¼ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°ç»“æ„è¿›è¡Œå¯¹è¯ã€‚æˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•åˆ©ç”¨ `transformers` åº“ä¸­æä¾›çš„èŠå¤©æ¨¡æ¿ç®€åŒ–è¿™ä¸€è¿‡ç¨‹ã€‚

### æ¢ç´¢æœªçŸ¥é¢†åŸŸ

å°½ç®¡æŠ€æœ¯æŠ¥å‘Šæä¾›äº†å…³äºåŸºç¡€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°è¿‡ç¨‹çš„ä¿¡æ¯ï¼Œä½†å…³äºæ•°æ®é›†æ„æˆå’Œé¢„å¤„ç†çš„å…·ä½“ç»†èŠ‚åˆ™è¾ƒä¸ºæ¬ ç¼ºã€‚æ®æ‚‰ï¼Œè¿™äº›æ¨¡å‹æ˜¯åŸºäºæ¥è‡ªäº’è”ç½‘æ–‡æ¡£ã€ç¼–ç¨‹ä»£ç å’Œæ•°å­¦æ–‡æœ¬ç­‰å¤šç§æ•°æ®æºè®­ç»ƒè€Œæˆï¼Œç»è¿‡ä¸¥æ ¼ç­›é€‰ï¼Œä»¥æ’é™¤å«æœ‰æ•æ„Ÿä¿¡æ¯å’Œä¸é€‚å†…å®¹çš„æ•°æ®ã€‚

å¯¹äº Gemma çš„æŒ‡ä»¤ä¼˜åŒ–æ¨¡å‹ï¼Œå…³äºå¾®è°ƒæ•°æ®é›†ä»¥åŠä¸é¡ºåºå¾®è°ƒæŠ€æœ¯ï¼ˆSFTï¼‰å’Œ [åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰](https://huggingface.co/blog/rlhf)ç›¸å…³çš„è¶…å‚æ•°è®¾ç½®ï¼Œç»†èŠ‚åŒæ ·æœªå…¬å¼€ã€‚

## æ¼”ç¤º

ç°åœ¨ï¼Œä½ å¯ä»¥åœ¨ Hugging Chat ä¸Šä½“éªŒä¸ Gemma æŒ‡ä»¤æ¨¡å‹çš„äº’åŠ¨å¯¹è¯ï¼ç‚¹å‡»æ­¤å¤„è®¿é—®ï¼š[https://huggingface.co/chat?model=google/gemma-7b-it](https://huggingface.co/chat?model=google/gemma-7b-it)

### ä½¿ç”¨ ğŸ¤— Transformers

å€ŸåŠ© Transformers çš„ [4.38 ç‰ˆæœ¬](https://github.com/huggingface/transformers/releases/tag/v4.38.0)ï¼Œä½ å¯ä»¥è½»æ¾åœ°ä½¿ç”¨ Gemma æ¨¡å‹ï¼Œå¹¶å……åˆ†åˆ©ç”¨ Hugging Face ç”Ÿæ€ç³»ç»Ÿå†…çš„å·¥å…·ï¼ŒåŒ…æ‹¬ï¼š

- è®­ç»ƒå’Œæ¨ç†è„šæœ¬åŠç¤ºä¾‹
- å®‰å…¨æ–‡ä»¶æ ¼å¼ï¼ˆ`safetensors`ï¼‰
- é›†æˆäº†è¯¸å¦‚ bitsandbytesï¼ˆ4ä½é‡åŒ–ï¼‰ã€PEFTï¼ˆå‚æ•°æ•ˆç‡å¾®è°ƒï¼‰å’Œ Flash Attention 2 ç­‰å·¥å…·
- è¾…åŠ©å·¥å…·å’Œå¸®åŠ©å™¨ï¼Œä»¥ä¾¿ä½¿ç”¨æ¨¡å‹è¿›è¡Œç”Ÿæˆ
- å¯¼å‡ºæ¨¡å‹ä»¥ä¾¿éƒ¨ç½²çš„æœºåˆ¶

å¦å¤–ï¼ŒGemma æ¨¡å‹æ”¯æŒ `torch.compile()` ä¸ CUDA å›¾çš„ç»“åˆä½¿ç”¨ï¼Œåœ¨æ¨ç†æ—¶å¯å®ç°çº¦ 4 å€çš„é€Ÿåº¦æå‡ï¼

ç¡®ä¿ä½ ä½¿ç”¨çš„æ˜¯æœ€æ–°ç‰ˆæœ¬çš„ `transformers`ï¼š

```jsx
pip install -U "transformers==4.38.0" --upgrade
```

ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†å¦‚ä½•ç»“åˆ transformers ä½¿ç”¨ `gemma-7b-it`ã€‚è¿è¡Œæ­¤ä»£ç éœ€å¤§çº¦ 18 GB çš„ RAMï¼Œé€‚ç”¨äºåŒ…æ‹¬ 3090 æˆ– 4090 åœ¨å†…çš„æ¶ˆè´¹çº§ GPUã€‚

```python
from transformers import AutoTokenizer, pipeline
import torch

model = "google/gemma-7b-it"

tokenizer = AutoTokenizer.from_pretrained(model)
pipeline = pipeline(
    "text-generation",
    model=model,
    model_kwargs={"torch_dtype": torch.bfloat16},
    device="cuda",
)

messages = [
        {"role": "user", "content": "Who are you? Please, answer in pirate-speak."},
]
prompt = pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
outputs = pipeline(
    prompt,
    max_new_tokens=256,
    add_special_tokens=True,
    do_sample=True,
    temperature=0.7,
    top_k=50,
    top_p=0.95
)
print(outputs[0]["generated_text"][len(prompt):])
```

> Avast me, me hearty. I am a pirate of the high seas, ready to pillage and plunder. Prepare for a tale of adventure and booty!
> 

ç®€å•ä»‹ç»ä¸€ä¸‹è¿™æ®µä»£ç :

- ä»£ç æ®µå±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨ `bfloat16` æ•°æ®ç±»å‹è¿›è¡Œæ¨¡å‹æ¨ç†ï¼Œè¯¥æ•°æ®ç±»å‹æ˜¯æ‰€æœ‰è¯„ä¼°ä¸­ä½¿ç”¨çš„å‚è€ƒç²¾åº¦ã€‚å¦‚æœä½ çš„ç¡¬ä»¶æ”¯æŒï¼Œä½¿ç”¨ `float16` å¯èƒ½ä¼šæ›´å¿«ã€‚
- ä½ è¿˜å¯ä»¥å°†æ¨¡å‹è‡ªåŠ¨é‡åŒ–ï¼Œä»¥ 8 ä½æˆ– 4 ä½æ¨¡å¼åŠ è½½ã€‚ä»¥ 4 ä½æ¨¡å¼åŠ è½½æ¨¡å‹å¤§çº¦éœ€è¦ 9 GB çš„å†…å­˜ï¼Œä½¿å…¶é€‚ç”¨äºå¤šç§æ¶ˆè´¹çº§æ˜¾å¡ï¼ŒåŒ…æ‹¬ Google Colab ä¸Šçš„æ‰€æœ‰ GPUã€‚ä»¥ä¸‹æ˜¯ä»¥ 4 ä½åŠ è½½ç”Ÿæˆ pipeline çš„æ–¹æ³•ï¼š

```jsx
pipeline = pipeline(
    "text-generation",
    model=model,
    model_kwargs={
        "torch_dtype": torch.float16,
        "quantization_config": {"load_in_4bit": True}
    },
)
```

æ›´å¤šå…³äºå¦‚ä½•ä½¿ç”¨ transformers å’Œæ¨¡å‹çš„è¯¦æƒ…ï¼Œè¯·å‚é˜… [æ¨¡å‹å¡ç‰‡](https://huggingface.co/google/gemma-7b)ã€‚

### JAX æƒé‡

æ‰€æœ‰ Gemma æ¨¡å‹å˜ç§éƒ½å¯ä»¥ç”¨ PyTorch æˆ– JAX / Flax ä½¿ç”¨ã€‚è‹¥è¦åŠ è½½ Flax æƒé‡ï¼Œä½ éœ€è¦æŒ‰ç…§ä»¥ä¸‹æ–¹å¼ä½¿ç”¨ä»“åº“ä¸­çš„ `flax` ä¿®è®¢ç‰ˆæœ¬ï¼š

```python
import jax.numpy as jnp
from transformers import AutoTokenizer, FlaxGemmaForCausalLM

model_id = "google/gemma-2b"

tokenizer = AutoTokenizer.from_pretrained(model_id)
tokenizer.padding_side = "left"

model, params = FlaxGemmaForCausalLM.from_pretrained(
        model_id,
        dtype=jnp.bfloat16,
        revision="flax",
        _do_init=False,
)

inputs = tokenizer("Valencia and MÃ¡laga are", return_tensors="np", padding=True)
output = model.generate(inputs, params=params, max_new_tokens=20, do_sample=False)
output_text = tokenizer.batch_decode(output.sequences, skip_special_tokens=True)
```

> `['Valencia and MÃ¡laga are two of the most popular tourist destinations in Spain. Both cities boast a rich history, vibrant culture,']`
> 

å¦‚æœä½ åœ¨ TPU æˆ–å¤šä¸ª GPU è®¾å¤‡ä¸Šè¿è¡Œï¼Œå¯ä»¥åˆ©ç”¨ `jit` å’Œ `pmap` æ¥ç¼–è¯‘å’Œå¹¶è¡Œæ‰§è¡Œæ¨ç†ä»»åŠ¡ã€‚

## ä¸ Google Cloud é›†æˆ

ä½ å¯ä»¥é€šè¿‡ Vertex AI æˆ– Google Kubernetes Engine (GKE) åœ¨ Google Cloud ä¸Šéƒ¨ç½²å’Œè®­ç»ƒ Gemmaï¼Œåˆ©ç”¨ [æ–‡æœ¬ç”Ÿæˆæ¨ç†](https://huggingface.co/docs/text-generation-inference/index) å’Œ Transformers å®ç°ã€‚

è¦ä» Hugging Face éƒ¨ç½² Gemma æ¨¡å‹ï¼Œè¯·è®¿é—®[æ¨¡å‹é¡µé¢](https://huggingface.co/google/gemma-7b-it)å¹¶ç‚¹å‡»[éƒ¨ç½² -> Google Cloud](https://huggingface.co/google/gemma-7b-it)ã€‚è¿™å°†å¼•å¯¼ä½ è¿›å…¥ Google Cloud Consoleï¼Œåœ¨é‚£é‡Œä½ å¯ä»¥é€šè¿‡ Vertex AI æˆ– GKE ä¸€é”®éƒ¨ç½² Gemmaã€‚æ–‡æœ¬ç”Ÿæˆæ¨ç†ä¸º Gemma åœ¨ Google Cloud ä¸Šçš„éƒ¨ç½²æä¾›æ”¯æŒï¼Œè¿™æ˜¯æˆ‘ä»¬[ä¸ Google Cloud åˆä½œä¼™ä¼´å…³ç³»çš„åˆæ­¥æˆæœ](https://huggingface.co/blog/gcp-partnership)ã€‚

![åœ¨ GCP ä¸Šéƒ¨ç½²](/blog/assets/gemma/gcp-deploy.png)

ä½ ä¹Ÿå¯ä»¥é€šè¿‡ Vertex AI Model Garden ç›´æ¥è®¿é—® Gemmaã€‚

è¦åœ¨ Hugging Face ä¸Šå¾®è°ƒ Gemma æ¨¡å‹ï¼Œè¯·è®¿é—® [æ¨¡å‹é¡µé¢](https://huggingface.co/google/gemma-7b-it) å¹¶ç‚¹å‡» [è®­ç»ƒ -> Google Cloud](https://huggingface.co/google/gemma-7b-it)ã€‚è¿™å°†å¼•å¯¼ä½ è¿›å…¥ Google Cloud Consoleï¼Œåœ¨é‚£é‡Œä½ å¯ä»¥åœ¨ Vertex AI æˆ– GKE ä¸Šè®¿é—®ç¬”è®°æœ¬ï¼Œä»¥åœ¨è¿™äº›å¹³å°ä¸Šå¾®è°ƒ Gemmaã€‚

![åœ¨ GCP ä¸Šè®­ç»ƒ](/blog/assets/gemma/gcp-train-gemma.png)

è¿™äº›é›†æˆæ˜¯æˆ‘ä»¬ [ä¸ Google åˆä½œä¼™ä¼´å…³ç³»æˆæœçš„ä¸€éƒ¨åˆ†](https://huggingface.co/blog/gcp-partnership)ï¼Œæœªæ¥è¿˜ä¼šæœ‰æ›´å¤šç²¾å½©å†…å®¹å‘å¸ƒï¼Œæ•¬è¯·æœŸå¾…ï¼

## ä¸æ¨ç†ç«¯ç‚¹é›†æˆ

ä½ å¯ä»¥åœ¨ Hugging Face çš„ [æ¨ç†ç«¯ç‚¹](https://ui.endpoints.huggingface.co/new?repository=google%2Fgemma-7b-it) ä¸Šéƒ¨ç½² Gemmaï¼Œè¯¥ç«¯ç‚¹ä½¿ç”¨æ–‡æœ¬ç”Ÿæˆæ¨ç†ä½œä¸ºåç«¯ã€‚[æ–‡æœ¬ç”Ÿæˆæ¨ç†](https://github.com/huggingface/text-generation-inference) æ˜¯ç”± Hugging Face å¼€å‘çš„å¯ç”¨äºç”Ÿäº§ç¯å¢ƒçš„æ¨ç†å®¹å™¨ï¼Œæ—¨åœ¨ç®€åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²ã€‚å®ƒæ”¯æŒè¿ç»­æ‰¹å¤„ç†ã€ä»¤ç‰Œæµå¼ä¼ è¾“ã€å¤š GPU å¼ é‡å¹¶è¡ŒåŠ é€Ÿæ¨ç†ï¼Œå¹¶æä¾›ç”Ÿäº§å°±ç»ªçš„æ—¥å¿—è®°å½•å’Œè·Ÿè¸ªåŠŸèƒ½ã€‚

è¦éƒ¨ç½² Gemma æ¨¡å‹ï¼Œè¯·è®¿é—® HF Hub [æ¨¡å‹é¡µé¢](https://huggingface.co/google/gemma-7b-it) å¹¶ç‚¹å‡» [éƒ¨ç½² -> æ¨ç†ç«¯ç‚¹](https://ui.endpoints.huggingface.co/new?repository=google%2Fgemma-7b-it)ã€‚æœ‰å…³ [ä½¿ç”¨ Hugging Face æ¨ç†ç«¯ç‚¹éƒ¨ç½² LLM](https://huggingface.co/blog/inference-endpoints-llm)çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æˆ‘ä»¬ä¹‹å‰çš„åšå®¢æ–‡ç« ã€‚æ¨ç†ç«¯ç‚¹é€šè¿‡æ–‡æœ¬ç”Ÿæˆæ¨ç†æ”¯æŒ [æ¶ˆæ¯ API](https://huggingface.co/blog/tgi-messages-api)ï¼Œä½¿ä½ å¯ä»¥é€šè¿‡ç®€å•åœ°æ›´æ¢ URL ä»å…¶ä»–å°é—­æ¨¡å‹åˆ‡æ¢åˆ°å¼€æ”¾æ¨¡å‹ã€‚

```bash
from openai import OpenAI

# initialize the client but point it to TGI
client = OpenAI(
    base_url="<ENDPOINT_URL>" + "/v1/",  # replace with your endpoint url
    api_key="<HF_API_TOKEN>",  # replace with your token
)
chat_completion = client.chat.completions.create(
    model="tgi",
    messages=[
        {"role": "user", "content": "Why is open-source software important?"},
    ],
    stream=True,
    max_tokens=500
)

# iterate and print stream
for message in chat_completion:
    print(message.choices[0].delta.content, end="")
```

## ä½¿ç”¨ ğŸ¤— TRL è¿›è¡Œå¾®è°ƒ

åœ¨æ¶ˆè´¹çº§ GPU ä¸Šè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹æ—¢æ˜¯æŠ€æœ¯ä¸Šçš„æŒ‘æˆ˜ï¼Œä¹Ÿæ˜¯è®¡ç®—ä¸Šçš„æŒ‘æˆ˜ã€‚æœ¬èŠ‚å°†ä»‹ç» Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­å¯ç”¨çš„å·¥å…·ï¼Œè¿™äº›å·¥å…·å¯ä»¥å¸®åŠ©ä½ é«˜æ•ˆåœ°åœ¨æ¶ˆè´¹çº§ GPU ä¸Šè®­ç»ƒ Gemmaã€‚

ä¸€ä¸ªå¾®è°ƒ Gemma çš„ç¤ºä¾‹å‘½ä»¤å¦‚ä¸‹ã€‚æˆ‘ä»¬åˆ©ç”¨ 4 ä½é‡åŒ–å’Œ QLoRAï¼ˆä¸€ç§å‚æ•°æ•ˆç‡å¾®è°ƒæŠ€æœ¯ï¼‰æ¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œç›®æ ‡æ˜¯æ‰€æœ‰æ³¨æ„åŠ›å—çš„çº¿æ€§å±‚ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸å¯†é›†å‹ Transformer ä¸åŒï¼ŒMLP å±‚ï¼ˆå¤šå±‚æ„ŸçŸ¥å™¨å±‚ï¼‰å› å…¶ç¨€ç–æ€§ä¸é€‚åˆä¸ PEFTï¼ˆå‚æ•°æ•ˆç‡å¾®è°ƒï¼‰æŠ€æœ¯ç»“åˆä½¿ç”¨ã€‚

é¦–å…ˆï¼Œå®‰è£… ğŸ¤— TRL çš„æœ€æ–°ç‰ˆæœ¬å¹¶å…‹éš†ä»“åº“ä»¥è·å– [è®­ç»ƒè„šæœ¬](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)ï¼š

```jsx
pip install -U transformers
pip install git+https://github.com/huggingface/trl
git clone https://github.com/huggingface/trl
cd trl
```

ç„¶åè¿è¡Œè„šæœ¬ï¼š

```jsx
accelerate launch --config_file examples/accelerate_configs/multi_gpu.yaml --num_processes=1 \
    examples/scripts/sft.py \
    --model_name google/gemma-7b \
    --dataset_name OpenAssistant/oasst_top1_2023-08-25 \
    --batch_size 2 \
    --gradient_accumulation_steps 1 \
    --learning_rate 2e-4 \
    --save_steps 20_000 \
    --use_peft \
    --peft_lora_r 16 --peft_lora_alpha 32 \
    --target_modules q_proj k_proj v_proj o_proj \
    --load_in_4bit
```

åœ¨å•ä¸ª A10G GPU ä¸Šï¼Œè¿™ä¸ªè®­ç»ƒè¿‡ç¨‹å¤§çº¦éœ€è¦ 9 å°æ—¶ã€‚é€šè¿‡è°ƒæ•´ `--num_processes` å‚æ•°ä¸ºä½ å¯ç”¨çš„ GPU æ•°é‡ï¼Œå¯ä»¥å®ç°å¹¶è¡ŒåŒ–è®­ç»ƒï¼Œä»è€Œç¼©çŸ­è®­ç»ƒæ—¶é—´ã€‚

## é¢å¤–èµ„æº

- [Hub ä¸Šçš„æ¨¡å‹](https://huggingface.co/models?other=gemma)
- å¼€æ”¾ LLM [æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [Hugging Chat ä¸Šçš„èŠå¤©æ¼”ç¤º](https://huggingface.co/chat?model=google/gemma-7b-it)
- [Gemma å®˜æ–¹åšå®¢](https://blog.google/technology/developers/gemma-open-models/)
- [Gemma äº§å“é¡µé¢](https://ai.google.dev/gemma)
- [Vertex AI æ¨¡å‹èŠ±å›­é“¾æ¥](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335)
- Google Notebook æ•™ç¨‹

## è‡´è°¢

æ­¤æ¬¡å‘å¸ƒå’Œåœ¨ç”Ÿæ€ç³»ç»Ÿä¸­çš„é›†æˆæ˜¯ç”±åŒ…æ‹¬ [ClÃ©mentine](https://huggingface.co/clefourrier)ã€[Eleuther è¯„ä¼°å·¥å…·](https://github.com/EleutherAI/lm-evaluation-harness)ï¼ˆLLM è¯„ä¼°ï¼‰ã€[Olivier](https://huggingface.co/olivierdehaene)ã€[David](https://huggingface.co/drbh)ï¼ˆæ–‡æœ¬ç”Ÿæˆæ¨ç†æ”¯æŒï¼‰ã€[Simon](https://huggingface.co/sbrandeis)ï¼ˆåœ¨ Hugging Face ä¸Šå¼€å‘æ–°çš„è®¿é—®æ§åˆ¶ç‰¹æ€§ï¼‰ã€[Arthur](https://huggingface.co/ArthurZ)ã€[Younes](https://huggingface.co/ybelkada)ã€[Sanchit](https://huggingface.co/sanchit-gandhi)ï¼ˆå°† Gemma é›†æˆåˆ° transformers ä¸­ï¼‰ã€[Morgan](https://huggingface.co/mfuntowicz)ï¼ˆå°† Gemma é›†æˆåˆ° optimum-nvidiaï¼Œå³å°†æ¨å‡ºï¼‰ã€[Nathan](https://huggingface.co/nsarrazin)ã€[Victor](https://huggingface.co/victor)ã€[Mishig](https://huggingface.co/mishig)ï¼ˆä½¿ Gemma åœ¨ Hugging Chat ä¸Šå¯ç”¨ï¼‰ç­‰ä¼—å¤šç¤¾åŒºæˆå‘˜çš„å…±åŒåŠªåŠ›è€Œæˆã€‚

æˆ‘ä»¬ç‰¹åˆ«æ„Ÿè°¢ Google å›¢é˜Ÿå‘å¸ƒ Gemma å¹¶ä½¿å…¶åœ¨å¼€æº AI ç¤¾åŒºä¸­å¯ç”¨ï¼Œä¸ºæ¨åŠ¨å¼€æ”¾å¼äººå·¥æ™ºèƒ½å‘å±•åšå‡ºäº†é‡è¦è´¡çŒ®ã€‚
