---
title: "PaliGemma æ­£å¼å‘å¸ƒ â€” Google æœ€æ–°å‘å¸ƒçš„å‰æ²¿å¼€æ”¾è§†è§‰è¯­è¨€æ¨¡å‹"
thumbnail: /blog/assets/paligemma/Paligemma.png
authors:
- user: merve
- user: andsteing
  guest: true
  org: google
- user: pcuenq
translators:
- user: chenglu
---

# PaliGemma æ­£å¼å‘å¸ƒ â€” Google æœ€æ–°å‘å¸ƒçš„å‰æ²¿å¼€æ”¾è§†è§‰è¯­è¨€æ¨¡å‹

PaliGemma æ˜¯ Google æ¨å‡ºçš„æ–°ä¸€ä»£è§†è§‰è¯­è¨€æ¨¡å‹å®¶æ—ï¼Œèƒ½å¤Ÿæ¥æ”¶å›¾åƒä¸æ–‡æœ¬è¾“å…¥å¹¶ç”Ÿæˆæ–‡æœ¬è¾“å‡ºã€‚

Google å›¢é˜Ÿå·²æ¨å‡ºä¸‰ç§ç±»å‹çš„æ¨¡å‹ï¼šé¢„è®­ç»ƒï¼ˆPTï¼‰æ¨¡å‹ã€æ··åˆæ¨¡å‹å’Œå¾®è°ƒï¼ˆFTï¼‰æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åˆ†è¾¨ç‡å„å¼‚ï¼Œæä¾›å¤šç§ç²¾åº¦ä»¥ä¾¿ä½¿ç”¨ã€‚

æ‰€æœ‰æ¨¡å‹å‡åœ¨ Hugging Face Hub çš„æ¨¡å‹åº“ä¸­å‘å¸ƒï¼Œé…å¤‡äº†æ¨¡å‹è¯´æ˜å’Œè®¸å¯è¯ï¼Œå¹¶ä¸”æ”¯æŒ transformers é›†æˆã€‚

## PaliGemma æ˜¯ä»€ä¹ˆ?

PaliGemmaï¼ˆ[Github](https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/README.md)ï¼‰æ˜¯ä¸€ç³»åˆ—å…·æœ‰è§†è§‰å’Œè¯­è¨€å¤„ç†èƒ½åŠ›çš„æ¨¡å‹ï¼Œç”± [SigLIP-So400m](https://huggingface.co/google/siglip-so400m-patch14-384) ä½œä¸ºå›¾åƒç¼–ç å™¨å’Œ [Gemma-2B](https://huggingface.co/google/gemma-2b) ä½œä¸ºæ–‡æœ¬è§£ç å™¨æ„æˆã€‚SigLIP æ˜¯ä¸€ä¸ªé¡¶å°–çš„æ¨¡å‹ï¼Œå¯ä»¥åŒæ—¶è§£æå›¾åƒå’Œæ–‡æœ¬ã€‚å®ƒçš„å·¥ä½œæ–¹å¼ç±»ä¼¼äº CLIPï¼ŒåŒ…æ‹¬å›¾åƒå’Œæ–‡æœ¬ç¼–ç å™¨çš„è”åˆè®­ç»ƒã€‚ä¸ [PaLI-3](https://arxiv.org/abs/2310.09199)ç›¸ä¼¼ï¼ŒPaliGemma æ¨¡å‹åœ¨å›¾åƒ-æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒåï¼Œå¯è½»æ¾é’ˆå¯¹ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚å›¾åƒæ ‡é¢˜ç”Ÿæˆæˆ–æŒ‡ä»£åˆ†å‰²ï¼‰è¿›è¡Œå¾®è°ƒã€‚[Gemma](https://huggingface.co/blog/gemma)æ˜¯ä¸€ä¸ªä¸“ä¸ºæ–‡æœ¬ç”Ÿæˆè®¾è®¡çš„è§£ç å™¨æ¨¡å‹ã€‚é€šè¿‡çº¿æ€§é€‚é…å™¨å°† SigLIP çš„å›¾åƒç¼–ç åŠŸèƒ½ä¸ Gemma ç»“åˆï¼Œä½¿ PaliGemma æˆä¸ºä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„è§†è§‰è¯­è¨€æ¨¡å‹ã€‚

![Architecture](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/paligemma_arch.png)

PaliGemma çš„å‘å¸ƒåŒ…æ‹¬ä¸‰ç§æ¨¡å‹ç±»å‹ï¼š

- PT æ£€æŸ¥ç‚¹ï¼šé¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„å¾®è°ƒï¼›
- æ··åˆæ£€æŸ¥ç‚¹ï¼šå·²é’ˆå¯¹ä»»åŠ¡æ··åˆè¿›è¡Œå¾®è°ƒçš„PTæ¨¡å‹ï¼Œé€‚åˆä½¿ç”¨è‡ªç”±æ–‡æœ¬æç¤ºè¿›è¡Œé€šç”¨æ¨ç†ï¼Œä»…é™ç ”ç©¶ä½¿ç”¨ï¼›
- FT æ£€æŸ¥ç‚¹ï¼šé’ˆå¯¹ä¸åŒå­¦æœ¯åŸºå‡†è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ï¼Œæä¾›å¤šç§åˆ†è¾¨ç‡ï¼Œä»…é™ç ”ç©¶ä½¿ç”¨ã€‚

è¿™äº›æ¨¡å‹æä¾›ä¸‰ç§åˆ†è¾¨ç‡ï¼ˆ`224x224`ã€`448x448`ã€`896x896`ï¼‰å’Œä¸‰ç§ç²¾åº¦ï¼ˆ`bfloat16`ã€`float16`ã€`float32`ï¼‰ã€‚æ¯ä¸ªç‰ˆæœ¬éƒ½åŒ…å«ç»™å®šåˆ†è¾¨ç‡å’Œä»»åŠ¡çš„æ£€æŸ¥ç‚¹ï¼Œæ¯ç§ç²¾åº¦æœ‰ä¸‰ä¸ªç‰ˆæœ¬ã€‚æ¯ä¸ªç‰ˆæœ¬çš„`main`åˆ†æ”¯åŒ…å«`float32`æ£€æŸ¥ç‚¹ï¼Œè€Œ`bfloat16`å’Œ`float16`ç‰ˆæœ¬åˆ™åŒ…å«ç›¸åº”ç²¾åº¦çš„æ£€æŸ¥ç‚¹ã€‚åŒæ—¶æä¾›äº†ä¸ transformers å…¼å®¹çš„æ¨¡å‹ï¼Œä»¥åŠåŸå§‹ JAX å®ç°çš„ç‰ˆæœ¬ã€‚

æ­£å¦‚åç»­è¯¦ç»†è¯´æ˜çš„ï¼Œé«˜åˆ†è¾¨ç‡æ¨¡å‹å› è¾“å…¥åºåˆ—è¾ƒé•¿è€Œéœ€è¦æ›´å¤šå†…å­˜ã€‚è™½ç„¶å®ƒä»¬å¯èƒ½æœ‰åŠ©äºæ‰§è¡Œç»†ç²’åº¦ä»»åŠ¡ï¼Œå¦‚ OCRï¼Œä½†å¯¹å¤§å¤šæ•°ä»»åŠ¡çš„è´¨é‡æå‡è¾ƒå°ã€‚224 ç‰ˆæœ¬å·²è¶³å¤Ÿåº”å¯¹å¤§å¤šæ•°åœºæ™¯ã€‚

ä½ å¯ä»¥åœ¨è¿™ä¸ª Hugging Face [åˆé›†](https://huggingface.co/collections/google/paligemma-release-6643a9ffbf57de2ae0448dda) ä¸­æ‰¾åˆ°æ‰€æœ‰ç›¸å…³æ¨¡å‹å’Œ Space åº”ç”¨ã€‚

## æ¨¡å‹åŠŸèƒ½

PaliGemma æ˜¯ä¸€ä¸ªå•è½®è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œä¸é€‚ç”¨äºå¯¹è¯åœºæ™¯ï¼Œæœ€ä½³åº”ç”¨æ˜¯é’ˆå¯¹ç‰¹å®šç”¨ä¾‹è¿›è¡Œå¾®è°ƒã€‚

ä½ å¯ä»¥é€šè¿‡è®¾ç½®ä»»åŠ¡å‰ç¼€ï¼Œå¦‚â€œdetectâ€æˆ–â€œsegmentâ€ï¼Œæ¥é…ç½®æ¨¡å‹è§£å†³çš„ä»»åŠ¡ã€‚é¢„è®­ç»ƒæ¨¡å‹å³æ˜¯é€šè¿‡è¿™ç§æ–¹å¼è®­ç»ƒçš„ï¼Œèµ‹äºˆå…¶ä¸°å¯Œçš„åŠŸèƒ½ï¼ˆé—®é¢˜å›ç­”ã€å›¾åƒæ ‡é¢˜ç”Ÿæˆã€å›¾åƒåˆ†å‰²ç­‰ï¼‰ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å¹¶éè®¾è®¡ä¸ºç›´æ¥ä½¿ç”¨ï¼Œè€Œæ˜¯é€šè¿‡å¾®è°ƒä»¥é€‚åº”ç‰¹å®šä»»åŠ¡ï¼Œä½¿ç”¨ç±»ä¼¼çš„æç¤ºç»“æ„ã€‚å¯¹äºäº¤äº’å¼æµ‹è¯•ï¼Œä½ å¯ä»¥ä½¿ç”¨å·²å¯¹å¤šä»»åŠ¡è¿›è¡Œå¾®è°ƒçš„â€œmixâ€ç³»åˆ—æ¨¡å‹ã€‚

ä»¥ä¸‹æ˜¯ä½¿ç”¨æ··åˆæ£€æŸ¥ç‚¹å±•ç¤ºçš„ä¸€äº›åŠŸèƒ½ç¤ºä¾‹ã€‚

### å›¾åƒæ ‡é¢˜ç”Ÿæˆ

å½“è¢«æç¤ºæ—¶ï¼ŒPaliGemma èƒ½å¤Ÿä¸ºå›¾åƒç”Ÿæˆæ ‡é¢˜ã€‚ä½ å¯ä»¥å°è¯•ä½¿ç”¨æ··åˆæ£€æŸ¥ç‚¹è¿›è¡Œå„ç§æ ‡é¢˜ç”Ÿæˆæç¤ºï¼Œçœ‹çœ‹å®ƒä»¬å¦‚ä½•ååº”ã€‚

![Captioning](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/captioning.png)

### è§†è§‰é—®é¢˜å›ç­”

PaliGemma èƒ½å¤Ÿå›ç­”å…³äºå›¾åƒçš„é—®é¢˜ï¼Œåªéœ€å°†ä½ çš„é—®é¢˜è¿åŒå›¾åƒä¸€èµ·ä¼ å…¥å³å¯ã€‚

![VQA](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/vqa.png)

### æ£€æµ‹

PaliGemma å¯ä»¥ä½¿ç”¨`detect [entity]`æç¤ºæ¥æ£€æµ‹å›¾åƒä¸­çš„å®ä½“ã€‚å®ƒä¼šä»¥ç‰¹æ®Šçš„`<loc[value]>`ä»¤ç‰Œå½¢å¼è¾“å‡ºè¾¹ç•Œæ¡†åæ ‡çš„ä½ç½®ï¼Œå…¶ä¸­`value`æ˜¯ä¸€ä¸ªè¡¨ç¤ºå½’ä¸€åŒ–åæ ‡çš„æ•°å­—ã€‚æ¯æ¬¡æ£€æµ‹éƒ½ç”±å››ä¸ªä½ç½®åæ ‡ä»£è¡¨â€”â€”_y_min, x_min, y_max, x_max_ï¼Œåè·Ÿæ£€æµ‹åˆ°çš„æ¡†ä¸­çš„æ ‡ç­¾ã€‚è¦å°†è¿™äº›å€¼è½¬æ¢ä¸ºåæ ‡ï¼Œä½ éœ€è¦é¦–å…ˆå°†æ•°å­—é™¤ä»¥1024ï¼Œç„¶åå°†`y`ä¹˜ä»¥å›¾åƒé«˜åº¦ï¼Œ`x`ä¹˜ä»¥å®½åº¦ã€‚è¿™å°†ç»™ä½ æä¾›ç›¸å¯¹äºåŸå§‹å›¾åƒå¤§å°çš„è¾¹ç•Œæ¡†åæ ‡ã€‚

![Detection](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/detect.png)

### æŒ‡ä»£è¡¨è¾¾åˆ†å‰²

PaliGemma æ··åˆæ£€æŸ¥ç‚¹ä¹Ÿèƒ½å¤Ÿåœ¨ç»™å®š`segment [entity]`æç¤ºæ—¶å¯¹å›¾åƒä¸­çš„å®ä½“è¿›è¡Œåˆ†å‰²ã€‚è¿™ç§°ä¸ºæŒ‡ä»£è¡¨è¾¾åˆ†å‰²ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°æ¥å¼•ç”¨æ„Ÿå…´è¶£çš„å®ä½“ã€‚è¾“å‡ºæ˜¯ä½ç½®å’Œåˆ†å‰²æ ‡è®°çš„åºåˆ—ã€‚ä½ç½®æ ‡è®°ä»£è¡¨å¦‚ä¸Šæ‰€è¿°çš„ä¸€ä¸ªè¾¹ç•Œæ¡†ã€‚åˆ†å‰²æ ‡è®°å¯ä»¥è¿›ä¸€æ­¥å¤„ç†ï¼Œç”Ÿæˆåˆ†å‰²æ©æ¨¡ã€‚

![Segmentation](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/segment.png)

### æ–‡æ¡£ç†è§£

PaliGemma æ··åˆæ£€æŸ¥ç‚¹å…·å¤‡å‡ºè‰²çš„æ–‡æ¡£ç†è§£ä¸æ¨ç†èƒ½åŠ›ã€‚

![ocrqa](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/ocrqa.png)

### æ··åˆåŸºå‡†

ä»¥ä¸‹æ˜¯æ··åˆæ£€æŸ¥ç‚¹çš„å¾—åˆ†æ•°æ®ã€‚

| æ¨¡å‹     | MMVPå‡†ç¡®ç‡ | POPEå‡†ç¡®ç‡ï¼ˆéšæœº/æµè¡Œ/å¯¹æŠ—ï¼‰ |
|---------|-------------|----------------------------|
| mix-224 | 46.00       | 88.00 86.63 85.67          |
| mix-448 | 45.33       | 89.37 88.40 87.47          |

## å¾®è°ƒæ£€æŸ¥ç‚¹

é™¤äº†é¢„è®­ç»ƒå’Œæ··åˆæ¨¡å‹ä¹‹å¤–ï¼ŒGoogle è¿˜å‘å¸ƒäº†å·²é’ˆå¯¹å„ç§ä»»åŠ¡è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹å¯¹åº”äºç ”ç©¶ç¤¾åŒºå¯ç”¨äºæ¯”è¾ƒæ€§èƒ½çš„å­¦æœ¯åŸºå‡†ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›é€‰å®šçš„æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹ä¹Ÿæä¾›äº†ä¸åŒçš„åˆ†è¾¨ç‡ã€‚ä½ å¯ä»¥æŸ¥çœ‹ä»»ä½•ä¸€ä¸ªæ¨¡å‹çš„æ¨¡å‹å¡ä»¥è·å–æ‰€æœ‰åº¦é‡æŒ‡æ ‡ã€‚

| æ¨¡å‹åç§°                                         | æ•°æ®é›†/ä»»åŠ¡                                    | è½¬ç§»ä»»åŠ¡ä¸­çš„å¾—åˆ†                           |
|------------------------------------------------|---------------------------------------------|----------------------------------------|
| [paligemma-3b-ft-vqav2-448](https://hf.co/google/paligemma-3b-ft-vqav2-448)| å›¾è§£ç†è§£                                    | åœ¨ VQAV2 ä¸Šçš„å‡†ç¡®ç‡ä¸º 85.64               |
| [paligemma-3b-ft-cococap-448](https://hf.co/google/paligemma-3b-ft-cococap-448)| COCO æ ‡é¢˜                                   | CIDEr ä¸º 144.6                           |
| [paligemma-3b-ft-science-qa-448](https://hf.co/google/paligemma-3b-ft-science-qa-448)| ç§‘å­¦é—®é¢˜å›ç­”                                | åœ¨æ²¡æœ‰ CoT çš„ ScienceQA Img å­é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º 95.93 |
| [paligemma-3b-ft-refcoco-seg-896](https://hf.co/google/paligemma-3b-ft-refcoco-seg-896)| å›¾åƒä¸­ç‰¹å®šå¯¹è±¡çš„ç†è§£                        | åœ¨ refcoco ä¸Šçš„å¹³å‡ IoU ä¸º 76.94ï¼Œåœ¨ refcoco+ ä¸Šä¸º 72.18ï¼Œåœ¨ refcocog ä¸Šä¸º 72.22 |
| [paligemma-3b-ft-rsvqa-hr-224](https://hf.co/google/paligemma-3b-ft-rsvqa-hr-224)| é¥æ„Ÿè§†è§‰é—®é¢˜å›ç­”                            | åœ¨ test ä¸Šçš„å‡†ç¡®ç‡ä¸º 92.61ï¼Œåœ¨ test2 ä¸Šä¸º 90.58   |

## æ¼”ç¤º

ä½œä¸ºæ­¤æ¬¡å‘å¸ƒçš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ª [Space åº”ç”¨](https://huggingface.co/spaces/google/paligemma)ï¼Œç›´æ¥ç”¨ [big_vision ä»“åº“](https://github.com/google-research/big_vision) ä¸­çš„å‚è€ƒå®ç°ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªç®€ä¾¿çš„æ–¹å¼æ¥ä½¿ç”¨æ··åˆæ¨¡å‹ã€‚

æˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªä¸ Transformers å…¼å®¹çš„[æ¼”ç¤ºç‰ˆæœ¬](https://huggingface.co/spaces/google/paligemma-hf)ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ PaliGemma transformers APIã€‚

<figure class="image flex flex-col items-center text-center m-0 w-full">
  <video alt="paligemma.mp4" autoplay loop autobuffer muted playsinline>
    <source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/paligemma/paligemma.mp4" type="video/mp4">
  </video>
  <figcaption></figcaption>
</figure>

## å¦‚ä½•è¿è¡Œæ¨ç†

è¦è·å– PaliGemma æ¨¡å‹çš„è®¿é—®æƒé™ï¼Œä½ éœ€è¦æ¥å— Gemma è®¸å¯æ¡æ¬¾å’Œæ¡ä»¶ã€‚å¦‚æœä½ å·²ç»å¯ä»¥è®¿é—® Hugging Face ä¸­çš„å…¶ä»– Gemma æ¨¡å‹ï¼Œé‚£ä¹ˆä½ å·²ç»å‡†å¤‡å¥½äº†ã€‚å¦åˆ™ï¼Œè¯·è®¿é—®ä»»ä½•ä¸€ä¸ª PaliGemma æ¨¡å‹ï¼Œå¹¶åœ¨ä½ åŒæ„è®¸å¯æ—¶æ¥å—å®ƒã€‚ä¸€æ—¦ä½ è·å¾—äº†è®¿é—®æƒé™ï¼Œä½ éœ€è¦é€šè¿‡ [notebook_login](https://huggingface.co/docs/huggingface_hub/v0.21.2/en/package_reference/login#huggingface_hub.notebook_login) æˆ– [huggingface-cli login](https://huggingface.co/docs/huggingface_hub/en/guides/cli#huggingface-cli-login) è¿›è¡Œè®¤è¯ã€‚ç™»å½•åï¼Œä½ å°±å¯ä»¥å¼€å§‹äº†ï¼

ä½ è¿˜å¯ä»¥ç«‹å³åœ¨ [æ­¤notebook](https://colab.research.google.com/drive/1gOhRCFyt9yIoasJkd4VoaHcIqJPdJnlg?usp=sharing) ä¸­å°è¯•è¿è¡Œæ¨ç†ã€‚

### ä½¿ç”¨ Transformers

ä½ å¯ä»¥ä½¿ç”¨`PaliGemmaForConditionalGeneration`ç±»æ¥æ¨æ–­ä»»ä½•å·²å‘å¸ƒçš„æ¨¡å‹ã€‚åªéœ€ä½¿ç”¨å†…ç½®çš„å¤„ç†å™¨é¢„å¤„ç†æç¤ºå’Œå›¾åƒï¼Œç„¶åä¼ é€’é¢„å¤„ç†è¾“å…¥è¿›è¡Œç”Ÿæˆã€‚

```python
from transformers import AutoProcessor, PaliGemmaForConditionalGeneration

model_id = "google/paligemma-3b-mix-224"
model = PaliGemmaForConditionalGeneration.from_pretrained(model_id)
processor = AutoProcessor.from_pretrained(model_id)

prompt = "What is on the flower?"
image_file = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg?download=true"
raw_image = Image.open(requests.get(image_file, stream=True).raw)
inputs = processor(prompt, raw_image, return_tensors="pt")
output = model.generate(**inputs, max_new_tokens=20)

print(processor.decode(output[0], skip_special_tokens=True)[len(prompt):])
# bee
```

ä½ è¿˜å¯ä»¥æŒ‰ä»¥ä¸‹æ–¹å¼åŠ è½½ 4 ä½æ¨¡å‹ã€‚

```python
from transformers import BitsAndBytesConfig

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16
)
model = PaligemmaForConditionalGeneration.from_pretrained(
    model_id,
    quantization_config=bnb_config,
    device_map={"":0}
)
```

é™¤äº† 4 ä½ï¼ˆæˆ– 8 ä½ï¼‰åŠ è½½ï¼Œtransformers é›†æˆè¿˜å…è®¸ä½ åˆ©ç”¨ Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­çš„å…¶ä»–å·¥å…·ï¼Œä¾‹å¦‚ï¼š
- è®­ç»ƒå’Œæ¨ç†è„šæœ¬ä»¥åŠç¤ºä¾‹
- åºåˆ—åŒ–åˆ°å®‰å…¨æ–‡ä»¶ï¼ˆ[safetensors](https://huggingface.co/docs/safetensors/en/index)ï¼‰
- ä¸å·¥å…·é›†æˆï¼Œå¦‚ [PEFTï¼ˆå‚æ•°æ•ˆç‡å¾®è°ƒï¼‰](https://huggingface.co/docs/peft/en/index)
- [å®ç”¨å·¥å…·å’ŒåŠ©æ‰‹](https://huggingface.co/docs/transformers/v4.34.0/en/internal/generation_utils)æ¥è¿è¡Œæ¨¡å‹ç”Ÿæˆ

## è¯¦ç»†æ¨ç†è¿‡ç¨‹

å¦‚æœä½ æƒ³ç¼–å†™è‡ªå·±çš„é¢„å¤„ç†æˆ–è®­ç»ƒä»£ç ï¼Œæˆ–æƒ³æ›´è¯¦ç»†åœ°äº†è§£ PaliGemma å¦‚ä½•å·¥ä½œï¼Œä»¥ä¸‹æ˜¯è¾“å…¥å›¾åƒå’Œæ–‡æœ¬çš„å¤„ç†æ­¥éª¤ï¼š

è¾“å…¥æ–‡æœ¬ä¼šæ­£å¸¸è¿›è¡Œæ ‡è®°åŒ–ã€‚ä¼šåœ¨å¼€å¤´æ·»åŠ ä¸€ä¸ª`<bos>`æ ‡è®°ï¼Œå¹¶é™„åŠ ä¸€ä¸ªé¢å¤–çš„æ¢è¡Œæ ‡è®°ï¼ˆ`\n`ï¼‰ã€‚è¿™ä¸ªæ¢è¡Œæ ‡è®°æ˜¯æ¨¡å‹è®­ç»ƒä¸­è¾“å…¥æç¤ºçš„é‡è¦éƒ¨åˆ†ï¼Œå› æ­¤æ˜ç¡®æ·»åŠ å®ƒä»¥ç¡®ä¿å®ƒå§‹ç»ˆå­˜åœ¨ã€‚æ ‡è®°åŒ–çš„æ–‡æœ¬è¿˜ä»¥å›ºå®šæ•°é‡çš„`<image>`æ ‡è®°ä¸ºå‰ç¼€ã€‚éœ€è¦å¤šå°‘ä¸ªï¼Ÿè¿™å–å†³äºè¾“å…¥å›¾åƒçš„åˆ†è¾¨ç‡å’Œ SigLIP æ¨¡å‹ä½¿ç”¨çš„è´´ç‰‡å¤§å°ã€‚PaliGemma æ¨¡å‹é¢„å…ˆè®­ç»ƒåœ¨ä¸‰ç§æ­£æ–¹å½¢å¤§å°ï¼ˆ224x224ã€448x448 æˆ– 896x896ï¼‰ä¹‹ä¸€ï¼Œå¹¶å§‹ç»ˆä½¿ç”¨ 14 çš„è´´ç‰‡å¤§å°ã€‚å› æ­¤ï¼Œè¦æ·»åŠ çš„`<image>`æ ‡è®°æ•°é‡æ˜¯ 224 æ¨¡å‹çš„ 256ï¼ˆ`224/14 * 224/14`ï¼‰ï¼Œ448 æ¨¡å‹çš„ 1024ï¼Œ896 æ¨¡å‹çš„ 4096ã€‚

æ›´å¤§çš„å›¾åƒå¯¼è‡´è¾“å…¥åºåˆ—æ˜¾è‘—å¢é•¿ï¼Œå› æ­¤éœ€è¦æ›´å¤šçš„å†…å­˜ã€‚åœ¨è€ƒè™‘ä½¿ç”¨å“ªç§æ¨¡å‹æ—¶ï¼Œè¯·è®°ä½è¿™ä¸€ç‚¹ã€‚å¯¹äºç»†ç²’åº¦ä»»åŠ¡ï¼Œå¦‚ OCRï¼Œä½¿ç”¨è¾ƒå¤§å›¾åƒå¯èƒ½æœ‰åŠ©äºå®ç°æ›´å¥½çš„ç»“æœï¼Œä½†å¯¹äºå¤§å¤šæ•°ä»»åŠ¡ï¼Œè´¨é‡æå‡ä¸å¤§ã€‚åœ¨å†³å®šå‡çº§åˆ°æ›´é«˜åˆ†è¾¨ç‡ä¹‹å‰ï¼Œè¯·å…ˆåœ¨ä½ çš„ä»»åŠ¡ä¸Šè¿›è¡Œæµ‹è¯•ï¼

è¿™ä¸ªå®Œæ•´çš„â€œæç¤ºâ€é€šè¿‡è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬åµŒå…¥å±‚ï¼Œå¹¶ç”Ÿæˆæ¯ä¸ªæ ‡è®°2048ç»´çš„æ ‡è®°åµŒå…¥ã€‚

ä¸æ­¤åŒæ—¶ï¼Œè¾“å…¥å›¾åƒç»è¿‡è°ƒæ•´å¤§å°ï¼Œä½¿ç”¨åŒä¸‰æ¬¡é‡é‡‡æ ·è‡³æ‰€éœ€çš„è¾“å…¥å¤§å°ï¼ˆå¯¹äºæœ€å°åˆ†è¾¨ç‡æ¨¡å‹ä¸º 224x224ï¼‰ã€‚ç„¶åï¼Œå®ƒé€šè¿‡ SigLIP å›¾åƒç¼–ç å™¨ç”Ÿæˆæ¯ä¸ªè´´ç‰‡ 1152 ç»´çš„å›¾åƒåµŒå…¥ã€‚è¿™é‡Œçº¿æ€§æŠ•å½±å™¨å‘æŒ¥ä½œç”¨ï¼šå°†å›¾åƒåµŒå…¥æŠ•å½±ä»¥è·å– 2048 ç»´æ¯è´´ç‰‡çš„è¡¨ç¤ºï¼Œä¸æ–‡æœ¬æ ‡è®°è·å¾—çš„è¡¨ç¤ºç›¸åŒã€‚æœ€ç»ˆçš„å›¾åƒåµŒå…¥ç„¶åä¸`<image>`æ–‡æœ¬åµŒå…¥åˆå¹¶ï¼Œè¿™æ˜¯ç”¨äºè‡ªå›å½’æ–‡æœ¬ç”Ÿæˆçš„æœ€ç»ˆè¾“å…¥ã€‚ç”Ÿæˆåœ¨è‡ªå›å½’æ¨¡å¼ä¸‹æ­£å¸¸å·¥ä½œï¼Œå¯¹æ•´ä¸ªè¾“å…¥ï¼ˆ`image + bos + prompt + \n`ï¼‰ä½¿ç”¨å®Œæ•´å—æ³¨æ„åŠ›ï¼Œå¹¶å¯¹ç”Ÿæˆçš„æ–‡æœ¬ä½¿ç”¨å› æœæ³¨æ„åŠ›æ©ç ã€‚

æ‰€æœ‰è¿™äº›ç»†èŠ‚éƒ½åœ¨å¤„ç†å™¨å’Œæ¨¡å‹ç±»ä¸­è‡ªåŠ¨å¤„ç†ï¼Œå› æ­¤å¯ä»¥ä½¿ç”¨å‰é¢ç¤ºä¾‹ä¸­æ‰€ç¤ºçš„ç†Ÿæ‚‰çš„é«˜çº§ transformers API è¿›è¡Œæ¨ç†ã€‚

## å¾®è°ƒ

### ä½¿ç”¨ big_vision

PaliGemma æ˜¯åœ¨ [big_vision](https://github.com/google-research/big_vision)ä»£ç åº“ä¸­è®­ç»ƒçš„ã€‚è¯¥ä»£ç åº“å·²ç”¨äºå¼€å‘å¦‚ BiTã€åŸå§‹ ViTã€LiTã€CapPaã€SigLIP ç­‰æ¨¡å‹ã€‚

é¡¹ç›®é…ç½®æ–‡ä»¶å¤¹ [configs/proj/paligemma/](https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/)åŒ…å«ä¸€ä¸ª`README.md`ã€‚é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥é€šè¿‡è¿è¡Œ [transfers/](https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/transfers/) å­æ–‡ä»¶å¤¹ä¸­çš„é…ç½®æ–‡ä»¶è¿›è¡Œè½¬ç§»ï¼Œæˆ‘ä»¬çš„æ‰€æœ‰è½¬ç§»ç»“æœéƒ½æ˜¯é€šè¿‡è¿è¡Œå…¶ä¸­æä¾›çš„é…ç½®æ–‡ä»¶è·å¾—çš„ã€‚å¦‚æœä½ æƒ³è½¬ç§»è‡ªå·±çš„æ¨¡å‹ï¼Œå¯ä»¥å¤åˆ¶ç¤ºä¾‹é…ç½® [transfers/forkme.py](https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/transfers/forkme.py) å¹¶æŒ‰ç…§æ³¨é‡Šä¸­çš„è¯´æ˜è°ƒæ•´å®ƒä»¥é€‚åº”ä½ çš„ç”¨ä¾‹ã€‚

è¿˜æœ‰ä¸€ä¸ª Colab: [`finetune_paligemma.ipynb`](https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb)ï¼Œå®ƒè¿è¡Œä¸€ä¸ª**ç®€åŒ–çš„å¾®è°ƒ**ï¼Œå¯åœ¨å…è´¹ T4 GPU è¿è¡Œæ—¶ä¸Šè¿è¡Œã€‚ä¸ºäº†é€‚åº”æœ‰é™çš„ä¸»æœºå’Œ GPU å†…å­˜ï¼ŒColab ä¸­çš„ä»£ç ä»…æ›´æ–°æ³¨æ„åŠ›å±‚ä¸­çš„æƒé‡ï¼ˆ170M å‚æ•°ï¼‰ï¼Œå¹¶ä½¿ç”¨ SGDï¼ˆè€Œä¸æ˜¯ Adamï¼‰ã€‚

### ä½¿ç”¨ transformers

é€šè¿‡ transformers è¿›è¡Œ PaliGemma çš„å¾®è°ƒéå¸¸ç®€å•ï¼Œä¹Ÿè¿˜å¯ä»¥è¿›è¡Œ QLoRA æˆ– LoRA å¾®è°ƒã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ç®€è¦å¾®è°ƒè§£ç å™¨ï¼Œç„¶åå±•ç¤ºå¦‚ä½•åˆ‡æ¢åˆ° QLoRA å¾®è°ƒã€‚
æˆ‘ä»¬å°†å®‰è£… transformers åº“çš„æœ€æ–°ç‰ˆæœ¬ã€‚

```bash
pip install git+https://github.com/huggingface/transformers.git
```

å°±åƒåœ¨æ¨ç†éƒ¨åˆ†ä¸€æ ·ï¼Œæˆ‘ä»¬å°†è¿›è¡Œèº«ä»½éªŒè¯ä»¥è®¿é—®æ¨¡å‹ï¼Œä½¿ç”¨`notebook_login()`ã€‚

```python
from huggingface_hub import notebook_login
notebook_login()
```

å¯¹äºè¿™ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ VQAv2 æ•°æ®é›†ï¼Œå¹¶å¾®è°ƒæ¨¡å‹ä»¥å›ç­”æœ‰å…³å›¾åƒçš„é—®é¢˜ã€‚è®©æˆ‘ä»¬åŠ è½½æ•°æ®é›†ã€‚æˆ‘ä»¬åªä¼šä½¿ç”¨ questionã€multiple_choice_answer å’Œ image åˆ—ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬åˆ é™¤å…¶ä»–åˆ—ã€‚æˆ‘ä»¬è¿˜å°†æ‹†åˆ†æ•°æ®é›†ã€‚

```python
from datasets import load_dataset 
ds = load_dataset('HuggingFaceM4/VQAv2', split="train") 
cols_remove = ["question_type", "answers", "answer_type", "image_id", "question_id"] 
ds = ds.remove_columns(cols_remove)
ds = ds.train_test_split(test_size=0.1)
train_ds = ds["train"]
val_ds = ds["test"]
```

æˆ‘ä»¬ç°åœ¨å°†åŠ è½½å¤„ç†å™¨ï¼Œå…¶ä¸­åŒ…å«å›¾åƒå¤„ç†å’Œæ ‡è®°åŒ–éƒ¨åˆ†ï¼Œå¹¶é¢„å¤„ç†æˆ‘ä»¬çš„æ•°æ®é›†ã€‚ 

```python
from transformers import PaliGemmaProcessor 
model_id = "google/paligemma-3b-pt-224"
processor = PaliGemmaProcessor(model_id)
```

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œä»¥è°ƒæ•´ PaliGemma å›ç­”è§†è§‰é—®é¢˜ã€‚ç”±äºæ ‡è®°å™¨å¡«å……è¾“å…¥ï¼Œæˆ‘ä»¬éœ€è¦å°†æˆ‘ä»¬æ ‡ç­¾ä¸­çš„å¡«å……è®¾ç½®ä¸ºä¸æ ‡è®°å™¨ä¸­çš„å¡«å……æ ‡è®°ä¸åŒï¼Œä»¥åŠå›¾åƒæ ‡è®°ã€‚

æ³¨æ„ï¼šåœ¨æ ‡è®°åŒ–éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä¼ é€’ä¸€ä¸ª`tokenize_newline_separately`æ ‡å¿—ï¼Œå› ä¸ºæ¢è¡Œç”¨äºæç¤ºæ¡ä»¶ï¼Œå¿…é¡»å•ç‹¬æ ‡è®°åŒ–ã€‚åœ¨æ¨ç†æœŸé—´ï¼Œé»˜è®¤ä¸º`True`ã€‚

```python
device = "cuda"

image_token = processor.tokenizer.convert_tokens_to_ids("<image>")
def collate_fn(examples):
  texts = ["answer " + example["question"] + "\n" + example['multiple_choice_answer'] for example in examples]
  images = [example["image"].convert("RGB") for example in examples]
  tokens = processor(text=texts, images=images,
                    return_tensors="pt", padding="longest",
                    tokenize_newline_separately=False)
  labels = tokens["input_ids"].clone()
  labels[labels == processor.tokenizer.pad_token_id] = -100
  labels[labels == image_token] = -100
  tokens["labels"] = labels
  tokens = tokens.to(torch.bfloat16).to(device)
  return tokens
```

ä½ å¯ä»¥ç›´æ¥åŠ è½½æ¨¡å‹ï¼Œæˆ–è€…ä¸º QLoRA åŠ è½½ 4 ä½æ¨¡å‹ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•ç›´æ¥åŠ è½½æ¨¡å‹ã€‚æˆ‘ä»¬å°†åŠ è½½æ¨¡å‹ï¼Œå¹¶å†»ç»“å›¾åƒç¼–ç å™¨å’ŒæŠ•å½±å™¨ï¼Œä»…å¾®è°ƒè§£ç å™¨ã€‚å¦‚æœä½ çš„å›¾åƒå±äºç‰¹å®šé¢†åŸŸï¼Œè¿™äº›é¢†åŸŸå¯èƒ½ä¸åœ¨æ¨¡å‹é¢„è®­ç»ƒçš„æ•°æ®é›†ä¸­ï¼Œä½ å¯èƒ½æƒ³è·³è¿‡

å†»ç»“å›¾åƒç¼–ç å™¨ã€‚

```python
model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(device)

for param in model.vision_tower.parameters():
    param.requires_grad = False

for param in model.multi_modal_projector.parameters():
    param.requires_grad = True
```

å¦‚æœä½ æƒ³ä¸º QLoRA åŠ è½½ 4 ä½æ¨¡å‹ï¼Œä½ å¯ä»¥æ·»åŠ ä»¥ä¸‹æ›´æ”¹ï¼š

```python
from transformers import BitsAndBytesConfig
from peft import get_peft_model, LoraConfig

bnb_config = BitsAndBytesConfig(
		load_in_4bit=True,
		bnb_4bit_quant_type="nf4",
		bnb_4bit_compute_type=torch.bfloat16
)

lora_config = LoraConfig(
	r=8, 
	target_modules=["q_proj", "o_proj", "k_proj", "v_proj", "gate_proj", "up_proj", "down_proj"],
	task_type="CAUSAL_LM",
)
model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, quantization_config=bnb_config, device_map={"":0})
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()
#trainable params: 11,298,816 || all params: 2,934,634,224 || trainable%: 0.38501616002417344
```

æˆ‘ä»¬å°†åˆå§‹åŒ– Trainer å’Œ TrainingArgumentsã€‚å¦‚æœä½ å°†è¿›è¡Œ QLoRA å¾®è°ƒï¼Œè¯·å°†ä¼˜åŒ–å™¨è®¾ç½®ä¸º`paged_adamw_8bit`ã€‚


```python
from transformers import TrainingArguments
args=TrainingArguments(
            num_train_epochs=2,
            remove_unused_columns=False,
            per_device_train_batch_size=16,
            gradient_accumulation_steps=4,
            warmup_steps=2,
            learning_rate=2e-5,
            weight_decay=1e-6,
            adam_beta2=0.999,
            logging_steps=100,
            optim="adamw_hf",
            save_strategy="steps",
            save_steps=1000,
            push_to_hub=True,
            save_total_limit=1,
            bf16=True,
            report_to=["tensorboard"],
            dataloader_pin_memory=False
        )
```

åˆå§‹åŒ–`Trainer`ï¼Œä¼ å…¥æ•°æ®é›†ã€æ•°æ®æ•´åˆå‡½æ•°å’Œè®­ç»ƒå‚æ•°ï¼Œå¹¶è°ƒç”¨`train()`å¼€å§‹è®­ç»ƒã€‚

```python
from transformers import Trainer
trainer = Trainer(
        model=model,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        data_collator=collate_fn,
        args=args
        )
trainer.train()
```

## é¢å¤–èµ„æº

- [è§†è§‰è¯­è¨€æ¨¡å‹è§£æ](https://huggingface.co/blog/vlms)
- [æ¨¡å‹æ–‡æ¡£](https://huggingface.co/docs/transformers/model_doc/paligemma)
- [æ¨ç†ç¬”è®°æœ¬](https://colab.research.google.com/drive/1gOhRCFyt9yIoasJkd4VoaHcIqJPdJnlg?usp=sharing)
- [Big vision PaliGemma æ¼”ç¤º](https://huggingface.co/spaces/google/paligemma)
- [ğŸ¤— transformers PaliGemma æ¼”ç¤º](https://huggingface.co/spaces/google/paligemma-hf)
- [æ‰€æœ‰ PaliGemma æ¨¡å‹çš„é›†åˆ](https://huggingface.co/collections/google/paligemma-release-6643a9ffbf57de2ae0448dda)
- [æ‰€æœ‰ PaliGemma å¾®è°ƒæ¨¡å‹çš„é›†åˆ](https://huggingface.co/collections/google/paligemma-ft-models-6643b03efb769dad650d2dda)
- [åŸå§‹å®ç°](https://github.com/google-research/big_vision/blob/main/big_vision/models/proj/paligemma/paligemma.py)

æ„Ÿè°¢ [Omar Sanseviero](osanseviero)ã€[Lucas Beyer](https://huggingface.co/giffmana)ã€[Xiaohua Zhai](https://huggingface.co/xiaohuazhai)å’Œ [Matthias Minderer](https://huggingface.co/mjlm) å¯¹æœ¬åšå®¢æ–‡ç« çš„å…¨é¢å®¡æ ¡ã€‚
