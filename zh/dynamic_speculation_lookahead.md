---
title: "Faster Assisted Generation with Dynamic Speculation"
thumbnail: /blog/assets/optimum_intel/intel_thumbnail.png
authors:
- user: jmamou
  guest: true
  org: Intel
- user: orenpereg
  guest: true
  org: Intel
- user: joaogante
- user: lewtun
- user: danielkorat
  guest: true
  org: Intel
- user: Nadav-Timor
  guest: true
  org: weizmannscience
- user: moshew
  guest: true
  org: Intel
translators:
- user: Zipxuan
---

â­ åœ¨è¿™ç¯‡åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨*åŠ¨æ€æ¨æµ‹è§£ç *â€”â€”è¿™æ˜¯ç”±è‹±ç‰¹å°”å®éªŒå®¤å’ŒHugging Faceå¼€å‘çš„ä¸€ç§æ–°æ–¹æ³•ï¼Œå¯ä»¥åŠ é€Ÿæ–‡æœ¬ç”Ÿæˆé«˜è¾¾2.7å€ï¼Œå…·ä½“å–å†³äºä»»åŠ¡ã€‚ä»[TransformersğŸ¤—](https://github.com/huggingface/transformers)å‘å¸ƒçš„ç‰ˆæœ¬[4.45.0](https://github.com/huggingface/transformers/releases/tag/v4.45.0)å¼€å§‹ï¼Œè¿™ç§æ–¹æ³•æ˜¯è¾…åŠ©ç”Ÿæˆçš„é»˜è®¤æ¨¡å¼â­

## æ¨æµ‹è§£ç 
[æ¨æµ‹è§£ç ](https://arxiv.org/abs/2211.17192)æŠ€æœ¯ååˆ†æµè¡Œï¼Œå…¶ç”¨äºåŠ é€Ÿå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œä¸æ­¤åŒæ—¶ä¿æŒå…¶å‡†ç¡®æ€§ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¨æµ‹è§£ç é€šè¿‡å°†ç”Ÿæˆè¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µæ¥å·¥ä½œã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œä¸€ä¸ªå¿«é€Ÿä½†å‡†ç¡®æ€§è¾ƒä½çš„*è‰ç¨¿*æ¨¡å‹ï¼ˆDraftï¼Œä¹Ÿç§°ä¸ºåŠ©æ‰‹ï¼‰è‡ªå›å½’åœ°ç”Ÿæˆä¸€ç³»åˆ—æ ‡è®°ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œä¸€ä¸ªå¤§å‹ä½†æ›´å‡†ç¡®çš„*ç›®æ ‡*æ¨¡å‹ï¼ˆTargetï¼‰å¯¹ç”Ÿæˆçš„è‰ç¨¿æ ‡è®°è¿›è¡Œå¹¶è¡ŒéªŒè¯ã€‚è¿™ä¸ªè¿‡ç¨‹å…è®¸ç›®æ ‡æ¨¡å‹åœ¨å•ä¸ªå‰å‘ä¼ é€’ä¸­ç”Ÿæˆå¤šä¸ªæ ‡è®°ï¼Œä»è€ŒåŠ é€Ÿè‡ªå›å½’è§£ç ã€‚æ¨æµ‹è§£ç çš„æˆåŠŸåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äº*æ¨æµ‹å‰ç»*ï¼ˆSpeculative Lookaheadï¼Œä¸‹æ–‡ç”¨SLè¡¨ç¤ºï¼‰ï¼Œå³è‰ç¨¿æ¨¡å‹åœ¨æ¯æ¬¡è¿­ä»£ä¸­ç”Ÿæˆçš„æ ‡è®°æ•°é‡ã€‚åœ¨å®è·µä¸­ï¼ŒSLè¦ä¹ˆæ˜¯ä¸€ä¸ªé™æ€å€¼ï¼Œè¦ä¹ˆåŸºäºå¯å‘å¼æ–¹æ³•ï¼Œè¿™ä¸¤è€…éƒ½ä¸æ˜¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­å‘æŒ¥æœ€å¤§æ€§èƒ½çš„æœ€ä¼˜é€‰æ‹©ã€‚

<p align="center">
  <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/dynamic_speculation_lookahead/spec_dec_diagram.png" width="250"><br>
<em>æ¨æµ‹è§£ç çš„å•æ¬¡è¿­ä»£</em>
</figure>

## åŠ¨æ€æ¨æµ‹è§£ç 
[TransformersğŸ¤—](https://github.com/huggingface/transformers) åº“æä¾›äº†ä¸¤ç§ä¸åŒçš„æ–¹æ³•æ¥ç¡®å®šåœ¨æ¨ç†è¿‡ç¨‹ä¸­è°ƒæ•´è‰ç¨¿ï¼ˆåŠ©æ‰‹ï¼‰æ ‡è®°æ•°é‡çš„è®¡åˆ’ã€‚åŸºäº[Leviathanç­‰äºº](https://arxiv.org/pdf/2211.17192)çš„ç›´æ¥æ–¹æ³•ä½¿ç”¨æ¨æµ‹å‰ç»çš„é™æ€å€¼ï¼Œå¹¶æ¶‰åŠåœ¨æ¯ä¸ªæ¨æµ‹è¿­ä»£ä¸­ç”Ÿæˆæ’å®šæ•°é‡çš„å€™é€‰æ ‡è®°ã€‚å¦ä¸€ç§[åŸºäºå¯å‘å¼æ–¹æ³•çš„æ–¹æ³•](https://huggingface.co/blog/assisted-generation)æ ¹æ®å½“å‰è¿­ä»£çš„æ¥å—ç‡è°ƒæ•´ä¸‹ä¸€æ¬¡è¿­ä»£çš„å€™é€‰æ ‡è®°æ•°é‡ã€‚å¦‚æœæ‰€æœ‰æ¨æµ‹æ ‡è®°éƒ½æ˜¯æ­£ç¡®çš„ï¼Œåˆ™å€™é€‰æ ‡è®°çš„æ•°é‡å¢åŠ ï¼›å¦åˆ™ï¼Œæ•°é‡å‡å°‘ã€‚

æˆ‘ä»¬é¢„è®¡ï¼Œé€šè¿‡å¢å¼ºä¼˜åŒ–ç­–ç•¥æ¥ç®¡ç†ç”Ÿæˆçš„è‰ç¨¿æ ‡è®°æ•°é‡ï¼Œå¯ä»¥è¿›ä¸€æ­¥å‡å°‘å»¶è¿Ÿã€‚ä¸ºäº†æµ‹è¯•è¿™ä¸ªè®ºç‚¹ï¼Œæˆ‘ä»¬åˆ©ç”¨ä¸€ä¸ªé¢„æµ‹å™¨æ¥ç¡®å®šæ¯ä¸ªæ¨æµ‹è¿­ä»£çš„æœ€ä½³æ¨æµ‹å‰ç»å€¼ï¼ˆSLï¼‰ã€‚è¯¥é¢„æµ‹å™¨åˆ©ç”¨è‰ç¨¿æ¨¡å‹è‡ªå›å½’çš„ç”Ÿæˆæ ‡è®°ï¼Œç›´åˆ°è‰ç¨¿æ¨¡å‹å’Œç›®æ ‡æ¨¡å‹ä¹‹é—´çš„é¢„æµ‹æ ‡è®°å‡ºç°ä¸ä¸€è‡´ã€‚è¯¥è¿‡ç¨‹åœ¨æ¯ä¸ªæ¨æµ‹è¿­ä»£ä¸­é‡å¤è¿›è¡Œï¼Œæœ€ç»ˆç¡®å®šæ¯æ¬¡è¿­ä»£æ¥å—çš„è‰ç¨¿æ ‡è®°çš„æœ€ä½³ï¼ˆæœ€å¤§ï¼‰æ•°é‡ã€‚è‰ç¨¿/ç›®æ ‡æ ‡è®°ä¸åŒ¹é…æ˜¯é€šè¿‡åœ¨é›¶æ¸©åº¦ä¸‹Leviathanç­‰äººæå‡ºçš„æ‹’ç»æŠ½æ ·ç®—æ³•ï¼ˆrejection sampling algorithmï¼‰æ¥è¯†åˆ«çš„ã€‚è¯¥é¢„æµ‹å™¨é€šè¿‡åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæœ€å¤§æ•°é‡çš„æœ‰æ•ˆè‰ç¨¿æ ‡è®°ï¼Œå¹¶æœ€å°åŒ–å¯¹è‰ç¨¿å’Œç›®æ ‡æ¨¡å‹çš„è°ƒç”¨æ¬¡æ•°ï¼Œå®ç°äº†æ¨æµ‹è§£ç çš„å…¨éƒ¨æ½œåŠ›ã€‚æˆ‘ä»¬ç§°ä½¿ç”¨è¯¥é¢„æµ‹å™¨å¾—åˆ°SLå€¼çš„æ¨æµ‹è§£ç è¿‡ç¨‹ä¸ºé¢„çŸ¥ï¼ˆorcaleï¼‰çš„æ¨æµ‹è§£ç ã€‚

ä¸‹é¢çš„å·¦å›¾å±•ç¤ºäº†æ¥è‡ª[MBPP](https://huggingface.co/datasets/google-research-datasets/mbpp)æ•°æ®é›†çš„ä»£ç ç”Ÿæˆç¤ºä¾‹ä¸­çš„é¢„çŸ¥å’Œé™æ€æ¨æµ‹å‰ç»å€¼åœ¨æ¨æµ‹è¿­ä»£ä¸­çš„å˜åŒ–ã€‚å¯ä»¥è§‚å¯Ÿåˆ°é¢„çŸ¥çš„SLå€¼ï¼ˆæ©™è‰²æ¡ï¼‰å­˜åœ¨å¾ˆé«˜çš„å˜åŒ–ã€‚
é™æ€SLå€¼ï¼ˆè“è‰²æ¡ï¼‰ä¸­ï¼Œç”Ÿæˆçš„è‰ç¨¿æ ‡è®°æ•°é‡å›ºå®šä¸º5ï¼Œæ‰§è¡Œäº†38æ¬¡ç›®æ ‡å‰å‘ä¼ æ’­å’Œ192æ¬¡è‰ç¨¿å‰å‘ä¼ æ’­ï¼Œè€Œé¢„çŸ¥çš„SLå€¼åªæ‰§è¡Œäº†27æ¬¡ç›®æ ‡å‰å‘ä¼ æ’­å’Œ129æ¬¡è‰ç¨¿å‰å‘ä¼ æ’­ - å‡å°‘äº†å¾ˆå¤šã€‚å³å›¾å±•ç¤ºäº†æ•´ä¸ª[Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca)æ•°æ®é›†ä¸­çš„é¢„çŸ¥å’Œé™æ€æ¨æµ‹å‰ç»å€¼ã€‚

<p align="center">
  <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/dynamic_speculation_lookahead/oracle_K_2.png" style="width: 400px; height: auto;"><br>
  <em>åœ¨MBPPçš„ä¸€ä¸ªä¾‹å­ä¸Šçš„é¢„çŸ¥å’Œé™æ€æ¨æµ‹å‰ç»å€¼ï¼ˆSLï¼‰ã€‚</em>
</p>

<p align="center">
  <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/dynamic_speculation_lookahead/Alpaca.png" style="width: 400px; height: auto;"><br>
  <em>åœ¨æ•´ä¸ªAlpacaæ•°æ®é›†ä¸Šå¹³å‡çš„é¢„çŸ¥SLå€¼ã€‚</em>
  
ä¸Šé¢çš„ä¸¤ä¸ªå›¾è¡¨å±•ç¤ºäº†é¢„çŸ¥æ¨æµ‹å‰ç»å€¼çš„å¤šå˜æ€§ï¼Œè¿™è¯´æ˜é™æ€çš„æ¨æµ‹è§£ç å¯èƒ½ä½¿æ¬¡ä¼˜çš„ã€‚

ä¸ºäº†æ›´æ¥è¿‘é¢„çŸ¥çš„æ¨æµ‹è§£ç å¹¶è·å¾—é¢å¤–çš„åŠ é€Ÿï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç®€å•çš„æ–¹æ³•æ¥åœ¨æ¯æ¬¡è¿­ä»£ä¸­åŠ¨æ€è°ƒæ•´æ¨æµ‹å‰ç»å€¼ã€‚åœ¨ç”Ÿæˆæ¯ä¸ªè‰ç¨¿ä»¤ç‰Œåï¼Œæˆ‘ä»¬ç¡®å®šè‰ç¨¿æ¨¡å‹æ˜¯å¦åº”ç»§ç»­ç”Ÿæˆä¸‹ä¸€ä¸ªä»¤ç‰Œæˆ–åˆ‡æ¢åˆ°ç›®æ ‡æ¨¡å‹è¿›è¡ŒéªŒè¯ã€‚è¿™ä¸ªå†³å®šåŸºäºè‰ç¨¿æ¨¡å‹å¯¹å…¶é¢„æµ‹çš„ä¿¡å¿ƒï¼Œé€šè¿‡logitsçš„softmaxä¼°è®¡ã€‚å¦‚æœè‰ç¨¿æ¨¡å‹å¯¹å½“å‰ä»¤ç‰Œé¢„æµ‹çš„ä¿¡å¿ƒä½äºé¢„å®šä¹‰çš„é˜ˆå€¼ï¼Œå³`assistant_confidence_threshold`ï¼Œå®ƒå°†åœ¨è¯¥è¿­ä»£ä¸­åœæ­¢ä»¤ç‰Œç”Ÿæˆè¿‡ç¨‹ï¼Œå³ä½¿å°šæœªè¾¾åˆ°æœ€å¤§æ¨æµ‹ä»¤ç‰Œæ•°`num_assistant_tokens`ã€‚ä¸€æ—¦åœæ­¢ï¼Œå½“å‰è¿­ä»£ä¸­ç”Ÿæˆçš„è‰ç¨¿ä»¤ç‰Œå°†è¢«å‘é€åˆ°ç›®æ ‡æ¨¡å‹è¿›è¡ŒéªŒè¯ã€‚

## åŸºå‡†æµ‹è¯•

æˆ‘ä»¬åœ¨ä¸€ç³»åˆ—ä»»åŠ¡å’Œæ¨¡å‹ç»„åˆä¸­å¯¹åŠ¨æ€æ–¹æ³•ä¸å¯å‘å¼æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚åŠ¨æ€æ–¹æ³•åœ¨æ‰€æœ‰æµ‹è¯•ä¸­è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚
å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä½¿ç”¨åŠ¨æ€æ–¹æ³•å°† `Llama3.2-1B` ä½œä¸º `Llama3.1-8B` çš„åŠ©æ‰‹æ—¶ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°é€Ÿåº¦æå‡é«˜è¾¾ 1.52 å€ï¼Œè€Œä½¿ç”¨ç›¸åŒè®¾ç½®çš„å¯å‘å¼æ–¹æ³•åˆ™æ²¡æœ‰æ˜¾è‘—çš„é€Ÿåº¦æå‡ã€‚å¦ä¸€ä¸ªè§‚å¯Ÿç»“æœæ˜¯ï¼Œ`codegen-6B-mono` åœ¨ä½¿ç”¨å¯å‘å¼æ–¹æ³•æ—¶è¡¨ç°å‡ºé€Ÿåº¦ä¸‹é™ï¼Œè€Œä½¿ç”¨åŠ¨æ€æ–¹æ³•åˆ™è¡¨ç°å‡ºé€Ÿåº¦æå‡ã€‚

| ç›®æ ‡æ¨¡å‹ | è‰ç¨¿æ¨¡å‹ | ä»»åŠ¡ç±»å‹ | åŠ é€Ÿæ¯” - å¯å‘å¼ç­–ç•¥ | åŠ é€Ÿæ¯” - åŠ¨æ€ç­–ç•¥ |
|----------------------|---------------------|---------------------------|---------------------------|---------------------------|
| `facebook/opt-6.7b` | `facebook/opt-125m` |	summarization | 1.82x |	**2.71x** |
| `facebook/opt-6.7b` | `facebook/opt-125m` |	open-ended generation |	1.23x |	**1.59x** |
| `Salesforce/codegen-6B-mono` | `Salesforce/codegen-350M-mono` |	code generation (python) | 0.89x |	**1.09x** |
| `google/flan-t5-xl` | `google/flan-t5-small` | summarization |	1.18x |	**1.31x** |
| `meta-llama/Llama-3.1-8B` | `meta-llama/Llama-3.2-1B` |	summarization |	1.00x |	**1.52x** |
| `meta-llama/Llama-3.1-8B` | `meta-llama/Llama-3.2-1B` |	open-ended generation |	1.00x |	**1.18x** |
| `meta-llama/Llama-3.1-8B` | `meta-llama/Llama-3.2-1B` |	code generation (python) |	1.09x |	**1.15x** |

* è¡¨æ ¼ä¸­çš„ç»“æœåæ˜ äº†è´ªå©ªè§£ç ï¼ˆtemperature = 0ï¼‰ã€‚åœ¨ä½¿ç”¨é‡‡æ ·ï¼ˆtemperature > 0ï¼‰æ—¶ä¹Ÿè§‚å¯Ÿåˆ°äº†ç±»ä¼¼çš„è¶‹åŠ¿ã€‚

* æ‰€æœ‰æµ‹è¯•å‡åœ¨RTX 4090ä¸Šè¿›è¡Œã€‚

* æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•æ˜¯å…¬å¼€çš„ï¼Œå…è®¸ä»»ä½•äººè¯„ä¼°è¿›ä¸€æ­¥çš„æ”¹è¿›ï¼šhttps://github.com/gante/huggingface-demos/tree/main/experiments/faster_generation

## ä»£ç 

åŠ¨æ€æ¨æµ‹å·²ç»æ•´åˆåˆ°Hugging Face Transformersåº“çš„4.45.0ç‰ˆæœ¬ä¸­ï¼Œå¹¶ä¸”ç°åœ¨ä½œä¸ºè¾…åŠ©è§£ç çš„é»˜è®¤æ“ä½œæ¨¡å¼ã€‚è¦ä½¿ç”¨å¸¦æœ‰åŠ¨æ€æ¨æµ‹çš„è¾…åŠ©ç”Ÿæˆï¼Œæ— éœ€è¿›è¡Œä»»ä½•ä»£ç æ›´æ”¹ï¼Œåªéœ€åƒå¹³å¸¸ä¸€æ ·æ‰§è¡Œä»£ç å³å¯ï¼š

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

prompt = "Alice and Bob"
checkpoint = "EleutherAI/pythia-1.4b-deduped"
assistant_checkpoint = "EleutherAI/pythia-160m-deduped"
device = "cuda" if torch.cuda.is_available() else "cpu"

tokenizer = AutoTokenizer.from_pretrained(checkpoint)
inputs = tokenizer(prompt, return_tensors="pt").to(device)

model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)
assistant_model = AutoModelForCausalLM.from_pretrained(assistant_checkpoint).to(device)

outputs = model.generate(**inputs, assistant_model=assistant_model)
```

é»˜è®¤çš„åŠ¨æ€æ¨æµ‹å‰ç»çš„å‚æ•°ååº”äº†æœ€ä¼˜çš„å€¼ï¼Œä½†æ˜¯å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç è¿›è¡Œè°ƒæ•´æ¥åœ¨ç‰¹å®šæ¨¡å‹å’Œæ•°æ®ä¸Šè·å¾—æ›´å¥½çš„æ€§èƒ½ï¼š

```python
# confidence threshold
assistant_model.generation_config.assistant_confidence_threshold=0.4

# 'constant' means that num_assistant_tokens stays unchanged during generation
assistant_model.generation_config.num_assistant_tokens_schedule='constant'

# the maximum number of tokens generated by the assistant model.
# after 20 tokens the draft halts even if the confidence is above the threshold
assistant_model.generation_config.num_assistant_tokens=20
```

è¦æ¢å¤åˆ°**å¯å‘å¼**æˆ–**é™æ€**æ–¹æ³•ï¼ˆå¦‚[Leviathanç­‰äºº](https://arxiv.org/pdf/2211.17192)ä¸­æ‰€è¿°ï¼‰ï¼Œåªéœ€åˆ†åˆ«å°†`num_assistant_tokens_schedule`è®¾ç½®ä¸º`'heuristic'`æˆ–`'constant'`ï¼Œå°†`assistant_confidence_threshold=0`å’Œ`num_assistant_tokens=5`è®¾ç½®å¦‚ä¸‹ï¼š

```python
# Use 'heuristic' or 'constant' or 'dynamic'
assistant_model.generation_config.num_assistant_tokens_schedule='heuristic'
assistant_model.generation_config.assistant_confidence_threshold=0
assistant_model.generation_config.num_assistant_tokens=5
```

## æ¥ä¸‹æ¥æ˜¯ä»€ä¹ˆï¼Ÿ

æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ›´å¿«çš„è¾…åŠ©ç”Ÿæˆç­–ç•¥ï¼Œåä¸ºåŠ¨æ€æ¨æµ‹è§£ç ï¼Œå®ƒä¼˜äºå¯å‘å¼æ–¹æ³•ä»¥åŠå›ºå®šæ•°é‡å€™é€‰æ ‡è®°çš„æ–¹æ³•ã€‚

åœ¨å³å°†å‘å¸ƒçš„åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºä¸€ç§æ–°çš„è¾…åŠ©ç”Ÿæˆæ–¹æ³•ï¼šå°†ä»»ä½•ç›®æ ‡æ¨¡å‹ä¸ä»»ä½•åŠ©æ‰‹æ¨¡å‹ç»“åˆèµ·æ¥ï¼è¿™å°†ä¸ºåœ¨ Hugging Face Hub ä¸ŠåŠ é€Ÿæ— æ³•è·å¾—è¶³å¤Ÿå°çš„åŠ©æ‰‹å˜ä½“çš„æ— æ•°æ¨¡å‹æ‰“å¼€å¤§é—¨ã€‚ä¾‹å¦‚ï¼Œ`Phi 3`ã€`Gemma 2`ã€`CodeLlama`ç­‰ç­‰éƒ½å°†æœ‰èµ„æ ¼è¿›è¡Œæ¨æµ‹è§£ç ã€‚æ•¬è¯·å…³æ³¨ï¼

## å‚è€ƒèµ„æ–™
- [Dynamic Speculation Lookahead Accelerates Speculative Decoding of Large Language Models](https://arxiv.org/abs/2405.04304)ã€‚
åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† DISCOï¼Œä¸€ç§åŠ¨æ€æ¨æµ‹å‰ç»ä¼˜åŒ–æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†ç±»å™¨å†³å®šè‰ç¨¿æ¨¡å‹æ˜¯å¦åº”è¯¥ç»§ç»­ç”Ÿæˆä¸‹ä¸€ä¸ªæ ‡è®°ï¼Œè¿˜æ˜¯æš‚åœï¼Œå¹¶åˆ‡æ¢åˆ°ç›®æ ‡æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼Œè€Œä¸æ˜¯ä»…ä»…ä½¿ç”¨å¯¹é¢„æµ‹æ¦‚ç‡çš„ç®€å•é˜ˆå€¼ã€‚
- [Assisted Generation: a new direction toward low-latency text generation](https://huggingface.co/blog/assisted-generation)
- [Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/pdf/2211.17192)

