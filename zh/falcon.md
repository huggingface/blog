---
title: "Falcon ç™»é™† Hugging Face ç”Ÿæ€" 
thumbnail: /blog/assets/147_falcon/falcon_thumbnail.jpg
authors:
- user: lvwerra
- user: ybelkada
- user: smangrul
- user: lewtun
- user: olivierdehaene
- user: pcuenq
- user: philschmid
translators:
- user: MatrixYao
- user: zhongdongy
---

# Falcon ç™»é™† Hugging Face ç”Ÿæ€


## å¼•è¨€

Falcon æ˜¯ç”±ä½äºé˜¿å¸ƒæ‰æ¯”çš„ [æŠ€æœ¯åˆ›æ–°ç ”ç©¶é™¢ (Technology Innovation Instituteï¼ŒTII) ](https://www.tii.ae/) åˆ›å»ºçš„ä¸€ç³»åˆ—çš„æ–°è¯­è¨€æ¨¡å‹ï¼Œå…¶åŸºäº Apache 2.0 è®¸å¯å‘å¸ƒã€‚ **å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ[Falcon-40B](https://huggingface.co/tiiuae/falcon-40b) æ˜¯é¦–ä¸ªâ€œçœŸæ­£å¼€æ”¾â€çš„æ¨¡å‹ï¼Œå…¶èƒ½åŠ›å¯ä¸å½“å‰è®¸å¤šé—­æºæ¨¡å‹ç›¸åª²ç¾**ã€‚è¿™å¯¹ä»ä¸šè€…ã€çˆ±å¥½è€…å’Œè¡Œä¸šæ¥è¯´éƒ½æ˜¯ä¸ªå¥½æ¶ˆæ¯ï¼Œå› ä¸ºâ€œçœŸå¼€æºâ€ä½¿å¤§å®¶å¯ä»¥æ¯«æ— é¡¾å¿Œåœ°åŸºäºå®ƒä»¬æ¢ç´¢ç™¾èŠ±é½æ”¾çš„åº”ç”¨ã€‚

æœ¬æ–‡ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨ Falcon æ¨¡å‹: é¦–å…ˆæ¢è®¨å®ƒä»¬çš„ç‹¬ç‰¹ä¹‹å¤„ï¼Œç„¶å **å±•ç¤ºå¦‚ä½•åŸºäº Hugging Face ç”Ÿæ€æä¾›çš„å·¥å…·è½»æ¾æ„å»ºåŸºäº Falcon æ¨¡å‹çš„å¤šç§åº”ç”¨ (å¦‚æ¨ç†ã€é‡åŒ–ã€å¾®è°ƒç­‰)**ã€‚

## ç›®å½•

- [Falcon æ¨¡å‹](#Falcon-æ¨¡å‹)
- [æ¼”ç¤º](#æ¼”ç¤º)
- [æ¨ç†](#æ¨ç†)
- [è¯„ä¼°](#è¯„ä¼°)
- [ç”¨ PEFT å¾®è°ƒæ¨¡å‹](#ç”¨-PEFT-å¾®è°ƒæ¨¡å‹)
- [æ€»ç»“](#æ€»ç»“)

## Falcon æ¨¡å‹

Falcon å®¶æ—æœ‰ä¸¤ä¸ªåŸºç¡€æ¨¡å‹: [Falcon-40B](https://huggingface.co/tiiuae/falcon-40b) åŠå…¶å°å…„å¼Ÿ [Falcon-7B](https://huggingface.co/tiiuae/falcon-7b)ã€‚ **40B å‚æ•°æ¨¡å‹ç›®å‰åœ¨ [Open LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) ä¸­ååˆ—å‰èŒ…ï¼Œè€Œ 7B æ¨¡å‹åœ¨åŒç­‰å‚æ•°é‡çš„æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³**ã€‚

è¿è¡Œ Falcon-40B éœ€è¦çº¦ 90GB çš„ GPU æ˜¾å­˜ â€”â€” è™½ç„¶è¿˜æ˜¯æŒºå¤šçš„ï¼Œä½†æ¯” LLaMA-65B å°‘äº†ä¸å°‘ï¼Œå†µä¸” Falcon-40B çš„æ€§èƒ½è¿˜ä¼˜äº LLaMA-65Bã€‚è€Œ Falcon-7B åªéœ€è¦çº¦ 15GB æ˜¾å­˜ï¼Œå³ä½¿åœ¨æ¶ˆè´¹ç±»ç¡¬ä»¶ä¸Šä¹Ÿå¯ä»¥è¿›è¡Œæ¨ç†å’Œå¾®è°ƒã€‚ _(æˆ‘ä»¬å°†åœ¨åæ–‡è®¨è®ºå¦‚ä½•ä½¿ç”¨é‡åŒ–æŠ€æœ¯åœ¨ä¾¿å®œçš„ GPU ä¸Šä½¿ç”¨ Falcon-40Bï¼)_

TII è¿˜æä¾›äº†ç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„æ¨¡å‹: [Falcon-7B-Instruct](https://huggingface.co/tiiuae/falcon-7b-instruct) ä»¥åŠ [Falcon-40B-Instruct](https://huggingface.co/tiiuae/falcon-40b-instruct)ã€‚è¿™ä¸¤ä¸ªå®éªŒæ€§çš„æ¨¡å‹å˜ä½“ç»ç”±æŒ‡ä»¤å’Œå¯¹è¯æ•°æ®å¾®è°ƒè€Œå¾—ï¼Œå› æ­¤æ›´é€‚åˆå½“å‰æµè¡Œçš„åŠ©ç†å¼ä»»åŠ¡ã€‚ **å¦‚æœä½ åªæ˜¯æƒ³æŠŠ Falcon æ¨¡å‹å¿«é€Ÿç”¨èµ·æ¥ï¼Œè¿™ä¸¤ä¸ªæ¨¡å‹æ˜¯æœ€ä½³é€‰æ‹©ã€‚** å½“ç„¶ä½ ä¹Ÿå¯ä»¥åŸºäºç¤¾åŒºæ„å»ºçš„å¤§é‡æ•°æ®é›†å¾®è°ƒä¸€ä¸ªè‡ªå·±çš„æ¨¡å‹ â€”â€” åæ–‡ä¼šç»™å‡ºå¾®è°ƒæ­¥éª¤ï¼

Falcon-7B å’Œ Falcon-40B åˆ†åˆ«åŸºäº 1.5 ä¸‡äº¿å’Œ 1 ä¸‡äº¿è¯å…ƒæ•°æ®è®­ç»ƒè€Œå¾—ï¼Œå…¶æ¶æ„åœ¨è®¾è®¡æ—¶å°±å……åˆ†è€ƒè™‘äº†æ¨ç†ä¼˜åŒ–ã€‚ **Falcon æ¨¡å‹è´¨é‡è¾ƒé«˜çš„å…³é”®åœ¨äºè®­ç»ƒæ•°æ®ï¼Œå…¶ 80% ä»¥ä¸Šçš„è®­ç»ƒæ•°æ®æ¥è‡ªäº [RefinedWeb](https://arxiv.org/abs/2306.01116) â€”â€” ä¸€ä¸ªæ–°çš„åŸºäº CommonCrawl çš„ç½‘ç»œæ•°æ®é›†**ã€‚ TII é€‰æ‹©ä¸å»æ”¶é›†åˆ†æ•£çš„ç²¾é€‰æ•°æ®ï¼Œè€Œæ˜¯ä¸“æ³¨äºæ‰©å±•å¹¶æé«˜ Web æ•°æ®çš„è´¨é‡ï¼Œé€šè¿‡å¤§é‡çš„å»é‡å’Œä¸¥æ ¼è¿‡æ»¤ä½¿æ‰€å¾—è¯­æ–™åº“ä¸å…¶ä»–ç²¾é€‰çš„è¯­æ–™åº“è´¨é‡ç›¸å½“ã€‚ åœ¨è®­ç»ƒ Falcon æ¨¡å‹æ—¶ï¼Œè™½ç„¶ä»ç„¶åŒ…å«äº†ä¸€äº›ç²¾é€‰æ•°æ® (ä¾‹å¦‚æ¥è‡ª Reddit çš„å¯¹è¯æ•°æ®)ï¼Œä½†ä¸ GPT-3 æˆ– PaLM ç­‰æœ€å…ˆè¿›çš„ LLM ç›¸æ¯”ï¼Œç²¾é€‰æ•°æ®çš„ä½¿ç”¨é‡è¦å°‘å¾—å¤šã€‚ä½ çŸ¥é“æœ€å¦™çš„æ˜¯ä»€ä¹ˆå—ï¼Ÿ TII å…¬å¸ƒäº†ä» [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb) ä¸­æå–å‡ºçš„å«æœ‰ 6000 äº¿è¯å…ƒçš„æ•°æ®é›†ï¼Œä»¥ä¾›ç¤¾åŒºåœ¨è‡ªå·±çš„ LLM ä¸­ä½¿ç”¨ï¼

Falcon æ¨¡å‹çš„å¦ä¸€ä¸ªæœ‰è¶£çš„ç‰¹æ€§æ˜¯å…¶ä½¿ç”¨äº† [**å¤šæŸ¥è¯¢æ³¨æ„åŠ› (multiquery attention)**](https://arxiv.org/abs/1911.02150)ã€‚åŸå§‹å¤šå¤´ (head) æ³¨æ„åŠ›æ–¹æ¡ˆæ¯ä¸ªå¤´éƒ½åˆ†åˆ«æœ‰ä¸€ä¸ªæŸ¥è¯¢ (query) ã€é”® (key) ä»¥åŠå€¼ (value)ï¼Œè€Œå¤šæŸ¥è¯¢æ³¨æ„åŠ›æ–¹æ¡ˆæ”¹ä¸ºåœ¨æ‰€æœ‰å¤´ä¸Šå…±äº«åŒä¸€ä¸ªé”®å’Œå€¼ã€‚

| ![mqa](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/147_falcon/multi-query-attention.png) |
|:--:|
| <b>å¤šæŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶åœ¨æ³¨æ„åŠ›å¤´ä¹‹é—´å…±äº«åŒä¸€ä¸ªé”®åµŒå…¥å’Œå€¼åµŒå…¥ã€‚å›¾ç‰‡ç”± Harm de Vries æä¾›ã€‚</b>|

è¿™ä¸ªæŠ€å·§å¯¹é¢„è®­ç»ƒå½±å“ä¸å¤§ï¼Œä½†å®ƒæå¤§åœ° [æé«˜äº†æ¨ç†çš„å¯æ‰©å±•æ€§](https://arxiv.org/abs/2211.05102): äº‹å®ä¸Šï¼Œ **è¯¥æŠ€å·§å¤§å¤§å‡å°‘äº†è‡ªå›å½’è§£ç æœŸé—´ K,V ç¼“å­˜çš„å†…å­˜å ç”¨ï¼Œå°†å…¶å‡å°‘äº† 10-100 å€** (å…·ä½“æ•°å€¼å–å†³äºæ¨¡å‹æ¶æ„çš„é…ç½®)ï¼Œè¿™å¤§å¤§é™ä½äº†æ¨¡å‹æ¨ç†çš„å†…å­˜å¼€é”€ã€‚è€Œå†…å­˜å¼€é”€çš„å‡å°‘ä¸ºè§£é”æ–°çš„ä¼˜åŒ–å¸¦æ¥äº†å¯èƒ½ï¼Œå¦‚çœä¸‹æ¥çš„å†…å­˜å¯ä»¥ç”¨æ¥å­˜å‚¨å†å²å¯¹è¯ï¼Œä»è€Œä½¿å¾—æœ‰çŠ¶æ€æ¨ç†æˆä¸ºå¯èƒ½ã€‚

| æ¨¡å‹ | è®¸å¯ | èƒ½å¦å•†ç”¨ï¼Ÿ | é¢„è®­ç»ƒè¯å…ƒæ•° | é¢„è®­ç»ƒç®—åŠ› [PF-å¤©] | æ’è¡Œæ¦œå¾—åˆ† | K,V ç¼“å­˜å¤§å° (ä¸Šä¸‹æ–‡é•¿åº¦ä¸º 2048) |
| --- | --- | --- | --- | --- | --- | --- |
| StableLM-Alpha-7B | CC-BY-SA-4.0 | âœ… | 1,500B | 700 | 38.3* | 800MB |
| LLaMA-7B | LLaMA license | âŒ | 1,000B | 500 | 47.6 | 1,100MB |
| MPT-7B | Apache 2.0 | âœ… | 1,000B | 500 | 48.6 | 1,100MB |
| Falcon-7B | Apache 2.0 | âœ… | 1,500B | 700 | 48.8 | 20MB |
| LLaMA-33B | LLaMA license | âŒ | 1,500B | 3200 | 56.9 | 3,300MB |
| LLaMA-65B | LLaMA license | âŒ | 1,500B | 6300 | 58.3 | 5,400MB |
| Falcon-40B | Apache 2.0 | âœ… | 1,000B | 2800 | 60.4 | 240MB |

* _ä¸Šè¡¨ä¸­å¾—åˆ†å‡ä¸ºç»è¿‡å¾®è°ƒçš„æ¨¡å‹çš„å¾—åˆ†_

# æ¼”ç¤º

é€šè¿‡ [è¿™ä¸ª Space](https://huggingface.co/spaces/HuggingFaceH4/falcon-chat) æˆ–ä¸‹é¢çš„åº”ç”¨ï¼Œä½ å¯ä»¥å¾ˆè½»æ¾åœ°è¯•ç”¨ä¸€ä¸‹å¤§çš„ Falcon æ¨¡å‹ (400 äº¿å‚æ•°ï¼):

<script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.32.0/gradio.js"> </script>
<gradio-app theme_mode="light" space="HuggingFaceH4/falcon-chat-demo-for-blog"></gradio-app>

ä¸Šé¢çš„åº”ç”¨ä½¿ç”¨äº† Hugging Face çš„ [Text Generation Inference](https://github.com/huggingface/text-generation-inference) æŠ€æœ¯ï¼Œå®ƒæ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„ã€å¿«é€Ÿé«˜æ•ˆçš„æ–‡æœ¬ç”ŸæˆæœåŠ¡ï¼Œä½¿ç”¨äº† Rustã€Python ä»¥åŠ gRPC ç­‰æŠ€æœ¯ã€‚[HuggingChat](https://huggingface.co/chat/) ä¹Ÿä½¿ç”¨äº†ç›¸åŒçš„æŠ€æœ¯ã€‚

æˆ‘ä»¬è¿˜æ„å»ºäº†ä¸€ä¸ª Core ML ç‰ˆæœ¬çš„ `falcon-7b-instruct` æ¨¡å‹ï¼Œä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å°†å…¶è¿è¡Œè‡³ M1 MacBook Pro:

<video controls title="Falcon 7B Instruct running on an M1 MacBook Pro with Core ML">
<source src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/147_falcon/falcon-7b.mp4" type="video/mp4">
è§†é¢‘: åœ¨å®‰è£…äº† Core ML çš„ M1 MacBook Pro ä¸Šè¿è¡Œ Falcon 7B Instruct æ¨¡å‹ã€‚
</video>

è¯¥è§†é¢‘å±•ç¤ºäº†ä¸€ä¸ªè½»é‡çº§åº”ç”¨ç¨‹åºï¼Œè¯¥åº”ç”¨ç¨‹åºåˆ©ç”¨ä¸€ä¸ª Swift åº“å®Œæˆäº†åŒ…æ‹¬åŠ è½½æ¨¡å‹ã€åˆ†è¯ã€å‡†å¤‡è¾“å…¥æ•°æ®ã€ç”Ÿæˆæ–‡æœ¬ä»¥åŠè§£ç åœ¨å†…çš„å¾ˆå¤šç¹é‡çš„æ“ä½œã€‚æˆ‘ä»¬æ­£åœ¨å¿«é©¬åŠ é­æ„å»ºè¿™ä¸ªåº“ï¼Œè¿™æ ·å¼€å‘äººå‘˜å°±èƒ½åŸºäºå®ƒå°†å¼ºå¤§çš„ LLM é›†æˆåˆ°å„ç§åº”ç”¨ç¨‹åºä¸­ï¼Œè€Œæ— éœ€é‡æ–°å‘æ˜è½®å­ã€‚ç›®å‰å®ƒè¿˜æœ‰ç‚¹ç²—ç³™ï¼Œä½†æˆ‘ä»¬è¿«ä¸åŠå¾…åœ°æƒ³è®©å®ƒæ—©ç‚¹é¢ä¸–ã€‚åŒæ—¶ï¼Œä½ ä¹Ÿå¯ä»¥ä¸‹è½½ [Core ML çš„æƒé‡æ–‡ä»¶](https://huggingface.co/tiiuae/falcon-7b-instruct/tree/main/coreml/text-generation) è‡ªå·±æ¢ç´¢ï¼

# æ¨ç†

åœ¨ä½¿ç”¨ç†Ÿæ‚‰çš„ transformers API åœ¨ä½ è‡ªå·±çš„ç¡¬ä»¶ä¸Šè¿è¡Œ Falcon æ¨¡å‹æ—¶ï¼Œä½ éœ€è¦æ³¨æ„å‡ ä¸ªä»¥ä¸‹ç»†èŠ‚:

- ç°æœ‰çš„æ¨¡å‹æ˜¯ç”¨ `bfloat16` æ•°æ®ç±»å‹è®­ç»ƒçš„ï¼Œå› æ­¤å»ºè®®ä½ ä¹Ÿä½¿ç”¨ç›¸åŒçš„æ•°æ®ç±»å‹æ¥æ¨ç†ã€‚ä½¿ç”¨ `bfloat16` éœ€è¦ä½ å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ CUDAï¼Œè€Œä¸” `bfloat16` åœ¨æœ€æ–°çš„å¡ (å¦‚ A100) ä¸Šæ•ˆæœæœ€å¥½ã€‚ä½ ä¹Ÿå¯ä»¥å°è¯•ä½¿ç”¨ `float16` è¿›è¡Œæ¨ç†ï¼Œä½†è¯·è®°ä½ï¼Œç›®å‰æˆ‘ä»¬åˆ†äº«çš„æ¨¡å‹æ•ˆæœæ•°æ®éƒ½æ˜¯åŸºäº `bfloat16` çš„ã€‚
- ä½ éœ€è¦å…è®¸è¿œç¨‹ä»£ç æ‰§è¡Œã€‚è¿™æ˜¯å› ä¸º `transformers` å°šæœªé›†æˆ Falcon æ¨¡å‹æ¶æ„ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨æ¨¡å‹ä½œè€…åœ¨å…¶ä»£ç åº“ä¸­æä¾›çš„ä»£ç æ¥è¿è¡Œã€‚ä»¥ `falcon-7b-instruct` ä¸ºä¾‹ï¼Œå¦‚æœä½ å…è®¸è¿œç¨‹æ‰§è¡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸‹åˆ—æ–‡ä»¶é‡Œçš„ä»£ç æ¥è¿è¡Œæ¨¡å‹: [configuration_RW.py](https://huggingface.co/tiiuae/falcon-7b-instruct/blob/main/configuration_RW.py)ï¼Œ[modelling_RW.py](https://huggingface.co/tiiuae/falcon-7b-instruct/blob/main/modelling_RW.py)ã€‚

ç»¼ä¸Šï¼Œä½ å¯ä»¥å‚è€ƒå¦‚ä¸‹ä»£ç æ¥ä½¿ç”¨ transformers çš„ `pipeline` API åŠ è½½ `falcon-7b-instruct` æ¨¡å‹:

```python
from transformers import AutoTokenizer
import transformers
import torch

model = "tiiuae/falcon-7b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model)
pipeline = transformers.pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    device_map="auto",
)

```

ç„¶åï¼Œå†ç”¨å¦‚ä¸‹ä»£ç ç”Ÿæˆæ–‡æœ¬:

```python
sequences = pipeline(
   "Write a poem about Valencia.",
    max_length=200,
    do_sample=True,
    top_k=10,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
)
for seq in sequences:
    print(f"Result: {seq['generated_text']}")

```

æœ€åï¼Œä½ å¯èƒ½ä¼šå¾—åˆ°å¦‚ä¸‹è¾“å‡º:

```
Valencia, city of the sun
The city that glitters like a star
A city of a thousand colors
Where the night is illuminated by stars
Valencia, the city of my heart
Where the past is kept in a golden chest

```

### å¯¹ Falcon 40B è¿›è¡Œæ¨ç†

å› ä¸º 40B æ¨¡å‹å°ºå¯¸æ¯”è¾ƒå¤§ï¼Œæ‰€ä»¥è¦æŠŠå®ƒè¿è¡Œèµ·æ¥è¿˜æ˜¯æŒºæœ‰æŒ‘æˆ˜æ€§çš„ï¼Œå•ä¸ªæ˜¾å­˜ä¸º 80GB çš„ A100 éƒ½æ”¾ä¸ä¸‹å®ƒã€‚å¦‚æœç”¨ 8 æ¯”ç‰¹æ¨¡å‹çš„è¯ï¼Œéœ€è¦å¤§çº¦ 45GB çš„ç©ºé—´ï¼Œæ­¤æ—¶ A6000 (48GB) èƒ½æ”¾ä¸‹ä½† 40GB çš„ A100 è¿˜æ˜¯æ”¾ä¸ä¸‹ã€‚ç›¸åº”çš„æ¨ç†ä»£ç å¦‚ä¸‹:

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import transformers
import torch

model_id = "tiiuae/falcon-40b-instruct"

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    trust_remote_code=True,
    load_in_8bit=True,
    device_map="auto",
)

pipeline = transformers.pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
)
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒINT8 æ··åˆç²¾åº¦æ¨ç†ä½¿ç”¨çš„æµ®ç‚¹ç²¾åº¦æ˜¯ `torch.float16` è€Œä¸æ˜¯ `torch.bfloat16`ï¼Œå› æ­¤è¯·åŠ¡å¿…è¯¦å°½åœ°å¯¹ç»“æœè¿›è¡Œæµ‹è¯•ã€‚

å¦‚æœä½ æœ‰å¤šå¼  GPU å¡å¹¶å®‰è£…äº† `accelerate`ï¼Œä½ è¿˜å¯ä»¥ç”¨ `device_map="auto"` å°†æ¨¡å‹çš„å„å±‚è‡ªåŠ¨åˆ†å¸ƒåˆ°å¤šå¼ å¡ä¸Šè¿è¡Œã€‚å¦‚æœ‰å¿…è¦ï¼Œç”šè‡³å¯ä»¥å°†æŸäº›å±‚å¸è½½åˆ° CPUï¼Œä½†è¿™ä¼šå½±å“æ¨ç†é€Ÿåº¦ã€‚

åœ¨æœ€æ–°ç‰ˆæœ¬çš„ `bitsandbytes`ã€`transformers` ä»¥åŠ `accelerate` ä¸­æˆ‘ä»¬è¿˜æ”¯æŒäº† [4 æ¯”ç‰¹åŠ è½½](https://huggingface.co/blog/4bit-transformers-bitsandbytes)ã€‚æ­¤æ—¶ï¼Œ40B æ¨¡å‹ä»…éœ€çº¦ 27GB çš„æ˜¾å­˜å°±èƒ½è¿è¡Œã€‚è™½ç„¶è¿™ä¸ªéœ€æ±‚è¿˜æ˜¯æ¯” 3090 æˆ– 4090 è¿™äº›å¡æ‰€èƒ½æä¾›çš„æ˜¾å­˜å¤§ï¼Œä½†å·²ç»è¶³ä»¥åœ¨æ˜¾å­˜ä¸º 30GB æˆ– 40GB çš„å¡ä¸Šè¿è¡Œäº†ã€‚

### Text Generation Inference

[Text Generation Inference](https://github.com/huggingface/text-generation-inference) æ˜¯ Hugging Face å¼€å‘çš„ä¸€ä¸ªå¯ç”¨äºç”Ÿäº§çš„æ¨ç†å®¹å™¨ã€‚æœ‰äº†å®ƒï¼Œç”¨æˆ·å¯ä»¥è½»æ¾éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹ã€‚

å…¶ä¸»è¦ç‰¹ç‚¹æœ‰:

- å¯¹è¾“å…¥è¿›è¡Œæµå¼ batch ç»„è£… (batching)
- æµå¼ç”Ÿæˆè¯ï¼Œä¸»è¦åŸºäº SSE åè®® (Server-Sent Eventsï¼ŒSSE)
- æ¨ç†æ—¶æ”¯æŒå¤š GPU å¼ é‡å¹¶è¡Œ (Tensor Parallelism )ï¼Œæ¨ç†é€Ÿåº¦æ›´å¿«
- transformers æ¨¡å‹ä»£ç ç”±å®šåˆ¶ CUDA æ ¸å‡½æ•°æ·±åº¦ä¼˜åŒ–
- åŸºäº Prometheus å’Œ Open Telemetry çš„äº§å“çº§æ—¥å¿—è®°å½•ã€ç›‘æ§å’Œè·Ÿè¸ªæœºåˆ¶

ä» v0.8.2 èµ·ï¼ŒText Generation Inference åŸç”Ÿæ”¯æŒ Falcon 7b å’Œ 40b æ¨¡å‹ï¼Œè€Œæ— éœ€ä¾èµ– transformers çš„ `â€œä¿¡ä»»è¿œç¨‹ä»£ç  (trust remote code)â€` åŠŸèƒ½ã€‚å› æ­¤ï¼ŒText Generation Inference å¯ä»¥æ”¯æŒå¯†é—­éƒ¨ç½²åŠå®‰å…¨å®¡è®¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ Falcon æ¨¡å‹çš„å®ç°ä¸­åŠ å…¥äº†å®šåˆ¶ CUDA æ ¸å‡½æ•°ä¼˜åŒ–ï¼Œè¿™å¯æ˜¾è‘—é™ä½æ¨ç†çš„ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚

| ![tgi-hfe-screenshot.png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/147_falcon/tgi-hfe.png) |
|:--:|
| <b> Hugging Face Inference Endpoint ç°å·²æ”¯æŒ Text Generation Inferenceã€‚ä½ å¯ä»¥åœ¨å•å¼  A100 ä¸Šè½»æ¾éƒ¨ç½² `falcon-40b-instruct` çš„ Int8 é‡åŒ–æ¨¡å‹ã€‚</b>|

Text Generation Inference ç°å·²é›†æˆè‡³ Hugging Face çš„ [Inference Endpoint](https://huggingface.co/inference-endpoints)ã€‚æƒ³è¦éƒ¨ç½² Falcon æ¨¡å‹ï¼Œå¯è‡³ [æ¨¡å‹é¡µé¢](https://huggingface.co/tiiuae/falcon-7b-instruct) å¹¶ç‚¹å‡» [Deploy -> Inference Endpoints](https://ui.endpoints.huggingface.co/new?repository=tiiuae/falcon-7b-instruct) æŒ‰é’®ã€‚

å¦‚éœ€éƒ¨ç½² 7B æ¨¡å‹ï¼Œå»ºè®®é€‰æ‹© â€œGPU [medium] - 1x Nvidia A10Gâ€ã€‚

å¦‚éœ€éƒ¨ç½² 40B æ¨¡å‹ï¼Œä½ éœ€è¦åœ¨ â€œGPU [xlarge] - 1x Nvidia A100â€ ä¸Šéƒ¨ç½²ä¸”éœ€è¦å¼€å¯é‡åŒ–åŠŸèƒ½ï¼Œè·¯å¾„å¦‚ä¸‹:  
`Advanced configuration -> Serving Container -> Int-8 Quantization`

_æ³¨æ„: åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œå¦‚æœä½ éœ€è¦å‡çº§é…é¢ï¼Œå¯ç›´æ¥å‘ç”µå­é‚®ä»¶è‡³ api-enterprise@huggingface.co ç”³è¯·ã€‚_

## è¯„ä¼°

é‚£ä¹ˆ Falcon æ¨¡å‹ç©¶ç«Ÿæ•ˆæœå¦‚ä½•ï¼Ÿ Falcon çš„ä½œè€…ä»¬é©¬ä¸Šå°†ä¼šå‘å¸ƒä¸€ä¸ªæ·±å…¥çš„è¯„ä¼°æ•°æ®ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬ä»…åœ¨æˆ‘ä»¬çš„ [Open LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) ä¸Šå¯¹ Falcon åŸºç¡€æ¨¡å‹å’ŒæŒ‡ä»¤æ¨¡å‹è¿›è¡Œä¸€ä¸ªåˆæ­¥è¯„ä¼°ã€‚ `Open LLM æ’è¡Œæ¦œ`ä¸»è¦è¡¡é‡ LLM çš„æ¨ç†èƒ½åŠ›åŠå…¶å›ç­”ä»¥ä¸‹å‡ ä¸ªé¢†åŸŸçš„é—®é¢˜çš„èƒ½åŠ›:

- [AI2 æ¨ç†æŒ‘æˆ˜](https://allenai.org/data/arc) (ARC): å°å­¦ç¨‹åº¦æœ‰å…³ç§‘å­¦çš„é€‰æ‹©é¢˜ã€‚
- [HellaSwag](https://arxiv.org/abs/1905.07830): å›´ç»•æ—¥å¸¸äº‹ä»¶çš„å¸¸è¯†æ€§é—®é¢˜ã€‚
- [MMLU](https://github.com/hendrycks/test): 57 ä¸ªç§‘ç›® (åŒ…å«èŒä¸šç§‘ç›®åŠå­¦æœ¯ç§‘ç›®) çš„é€‰æ‹©é¢˜ã€‚
- [TruthfulQA](https://arxiv.org/abs/2109.07958): æµ‹è¯•æ¨¡å‹ä»ä¸€ç»„é”™è¯¯é™ˆè¿°ä¸­æ‰¾å‡ºäº‹å®æ€§é™ˆè¿°çš„èƒ½åŠ›ã€‚

ç»“æœæ˜¾ç¤ºï¼Œ40B åŸºç¡€æ¨¡å‹å’ŒæŒ‡ä»¤æ¨¡å‹éƒ½éå¸¸å¼ºï¼Œç›®å‰åœ¨ [Open LLM æ’è¡Œæ¦œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) ä¸Šåˆ†åˆ—ç¬¬ä¸€å’Œç¬¬äºŒğŸ†ï¼

![leaderboard.png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/147_falcon/leaderboard.png)

æ­£å¦‚ [Thomas Wolf](https://www.linkedin.com/posts/thom-wolf_open-llm-leaderboard-a-hugging-face-space-activity-7070334210116329472-x6ek?utm_source=share&utm_medium=member_desktop) æ‰€è¿°ï¼Œæˆ‘ä»¬æƒŠå–œåœ°å‘ç°ï¼Œç›®å‰é¢„è®­ç»ƒ 40B æ¨¡å‹æ‰€ç”¨çš„è®¡ç®—é‡å¤§çº¦åªæœ‰ LLaMa 65B æ‰€ç”¨è®¡ç®—é‡çš„ä¸€åŠ (Falcon 40B ç”¨äº† 2800 petaflop- å¤©ï¼Œè€Œ LLaMa 65B ç”¨äº† 6300 petaflop- å¤©)ï¼Œè¿™è¡¨æ˜è¯¥æ¨¡å‹ç”šè‡³å°šæœªå®Œå…¨é¢„è®­ç»ƒè‡³ LLM çš„â€œæœ€ä½³â€æé™ã€‚

å¯¹ 7B æ¨¡å‹è€Œè¨€ï¼Œæˆ‘ä»¬å‘ç°å…¶åŸºç¡€æ¨¡å‹è¡¨ç°ä¼˜äº `llama-7b`ï¼Œå¹¶è¶…â€‹â€‹è¿‡äº† MosaicML çš„ `mpt-7b`ï¼Œæˆä¸ºå½“å‰è¯¥è§„æ¨¡ä¸Šæœ€å¥½çš„é¢„è®­ç»ƒ LLMã€‚ä¸‹é¢æ‘˜å½•äº†æ’è¡Œæ¦œä¸­ä¸€äº›çƒ­é—¨æ¨¡å‹çš„æ’åæƒ…å†µï¼Œä»¥ä¾›æ¯”è¾ƒ:

| æ¨¡å‹ | ç±»å‹ | æ’è¡Œæ¦œå¹³å‡å¾—åˆ† |
| :-: | :-: | :-: |
| [tiiuae/falcon-40b-instruct](https://huggingface.co/tiiuae/falcon-40b-instruct) | instruct | 63.2 |
| [tiiuae/falcon-40b](https://huggingface.co/tiiuae/falcon-40b) | base | 60.4 |
| [llama-65b](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) | base | 58.3 |
| [TheBloke/dromedary-65b-lora-HF](https://huggingface.co/TheBloke/dromedary-65b-lora-HF) | instruct | 57 |
| [stable-vicuna-13b](https://huggingface.co/CarperAI/stable-vicuna-13b-delta) | rlhf | 52.4 |
| [llama-13b](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) | base | 51.8 |
| [TheBloke/wizardLM-7B-HF](https://huggingface.co/TheBloke/wizardLM-7B-HF) | instruct | 50.1 |
| [tiiuae/falcon-7b](https://huggingface.co/tiiuae/falcon-7b) | base | 48.8 |
| [mosaicml/mpt-7b](https://huggingface.co/mosaicml/mpt-7b) | base | 48.6 |
| [tiiuae/falcon-7b-instruct](https://huggingface.co/tiiuae/falcon-7b-instruct) | instruct | 48.4 |
| [llama-7b](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) | base | 47.6 |

å°½ç®¡ `Open LLM æ’è¡Œæ¦œ` ä¸èƒ½è¡¡é‡èŠå¤©èƒ½åŠ› (è¿™æ–¹é¢ç›®å‰ä¸»è¦è¿˜æ˜¯ä¾èµ–äººç±»è¯„ä¼°)ï¼Œä½†æˆªè‡³ç›®å‰ Falcon æ¨¡å‹è¡¨ç°å‡ºçš„è¿™äº›åˆæ­¥æ•ˆæœä¾ç„¶éå¸¸é¼“èˆäººå¿ƒï¼

ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•å¾®è°ƒä¸€ä¸ªä½ è‡ªå·±çš„ Falcon æ¨¡å‹ â€”â€” æˆ–è®¸ä½ å¾®è°ƒå‡ºæ¥çš„æŸä¸€ä¸ªæ¨¡å‹æœ€ç»ˆä¼šç™»ä¸Šæ¦œé¦–ğŸ¤—ã€‚

## ç”¨ PEFT å¾®è°ƒ

è®­ç»ƒ 10B+ å¤§å°çš„æ¨¡å‹åœ¨æŠ€æœ¯å’Œè®¡ç®—ä¸Šéƒ½é¢‡å…·æŒ‘æˆ˜ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£å¦‚ä½•ä½¿ç”¨ Hugging Face ç”Ÿæ€ä¸­è½¯ä»¶å·¥å…·åœ¨ç®€å•çš„ç¡¬ä»¶ä¸Šé«˜æ•ˆåœ°å¾®è°ƒè¶…å¤§æ¨¡å‹ï¼Œå¹¶å±•ç¤ºå¦‚ä½•åœ¨å•å¼ è‹±ä¼Ÿè¾¾ T4 å¡ (16GB - Google Colab) ä¸Šå¾®è°ƒ `falcon-7b`ã€‚

æˆ‘ä»¬ä»¥åœ¨ [Guanaco æ•°æ®é›†](https://huggingface.co/datasets/timdettmers/openassistant-guanaco) ä¸Šå¾®è°ƒ Falcon ä¸ºä¾‹ã€‚Guanaco æ•°æ®é›†æ˜¯ [Open Assistant æ•°æ®é›†](https://huggingface.co/datasets/OpenAssistant/oasst1) çš„ä¸€ä¸ªé«˜è´¨é‡å­é›†ï¼Œå…¶ä¸­åŒ…å«å¤§çº¦ 1 ä¸‡ä¸ªå¯¹è¯ã€‚é€šè¿‡ [PEFT åº“](https://github.com/huggingface/peft)ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœ€æ–°çš„ [QLoRA](https://arxiv.org/abs/2305.14314) æ–¹æ³•ç”¨ 4 æ¯”ç‰¹æ¥è¡¨ç¤ºæ¨¡å‹ï¼Œå¹¶å†»ç»“å®ƒï¼Œå†åœ¨å…¶ä¸ŠåŠ ä¸€ä¸ªé€‚é…å­æ¨¡å‹ (adapter)ï¼Œå¹¶å¾®è°ƒè¯¥é€‚é…å­æ¨¡å‹ã€‚ä½ å¯ä»¥ [ä»è¿™ç¯‡åšæ–‡ä¸­](https://huggingface.co/blog/4bit-transformers-bitsandbytes) äº†è§£æœ‰å…³ 4 æ¯”ç‰¹é‡åŒ–æ¨¡å‹çš„æ›´å¤šä¿¡æ¯ã€‚

å› ä¸ºåœ¨ä½¿ç”¨ä½é˜¶é€‚é…å™¨ (Low Rank Adaptersï¼ŒLoRA) æ—¶åªæœ‰ä¸€å°éƒ¨åˆ†æ¨¡å‹æƒé‡æ˜¯å¯è®­ç»ƒçš„ï¼Œæ‰€ä»¥å¯è®­ç»ƒå‚æ•°çš„æ•°é‡å’Œè®­å¾—æ¨¡å‹çš„å°ºå¯¸éƒ½ä¼šæ˜¾è‘—å‡å°ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæœ€ç»ˆçš„è®­ç»ƒäº§ç‰© (trained artifact) ä¸åŸå§‹çš„ 7B æ¨¡å‹ (æ•°æ®ç±»å‹ä¸º bfloat16 æ—¶å  15GB å­˜å‚¨ç©ºé—´) ç›¸æ¯”ï¼Œåªå  65MB å­˜å‚¨ç©ºé—´ã€‚

| ![repo-screenshot.png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/147_falcon/adapter-screenshot.png) |
|:--:|
| <b>ä¸å¤§çº¦ 15GB çš„åŸå§‹æ¨¡å‹ï¼ˆåŠç²¾åº¦ï¼‰ç›¸æ¯”ï¼Œæœ€ç»ˆçš„è®­ç»ƒäº§ç‰©åªéœ€å­˜å‚¨ 65MB çš„æƒé‡ </b>|

æ›´å…·ä½“åœ°è¯´ï¼Œåœ¨é€‰å®šéœ€è¦å¾®è°ƒçš„æ¨¡å— (å³æ³¨æ„åŠ›æ¨¡å—çš„æŸ¥è¯¢æ˜ å°„å±‚å’Œé”®æ˜ å°„å±‚) ä¹‹åï¼Œæˆ‘ä»¬åœ¨æ¯ä¸ªç›®æ ‡æ¨¡å—æ—è¾¹æ·»åŠ ä¸¤ä¸ªå°çš„å¯è®­ç»ƒçº¿æ€§å±‚ (å¦‚ä¸‹å›¾æ‰€ç¤º) ä½œä¸ºé€‚é…å­æ¨¡å‹ã€‚ç„¶åï¼Œå°†é€‚é…å­æ¨¡å‹è¾“å‡ºçš„éšå«çŠ¶æ€ä¸åŸå§‹æ¨¡å‹çš„éšå«çŠ¶æ€ç›¸åŠ ä»¥è·å¾—æœ€ç»ˆéšå«çŠ¶æ€ã€‚

| ![lora-gif](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/133_trl_peft/lora-animated.gif) |
|:--:|
| <b> ç”¨ç”±æƒé‡çŸ©é˜µ A å’Œ B ç»„æˆçš„ä½ç§©é€‚é…å™¨ï¼ˆå³ï¼‰çš„è¾“å‡ºæ¿€æ´»æ¥å¢å¼ºåŸå§‹ï¼ˆå†»ç»“ï¼‰é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå·¦ï¼‰çš„è¾“å‡ºæ¿€æ´»ã€‚</b>|

ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œæ— é¡»ä¿å­˜æ•´ä¸ªæ¨¡å‹ï¼Œå› ä¸ºåŸºç¡€æ¨¡å‹ä¸€ç›´å¤„äºå†»ç»“çŠ¶æ€ã€‚æ­¤å¤–ï¼ŒåŸå§‹æ¨¡å‹å¯ä»¥è¡¨ç¤ºä¸ºä»»æ„æ•°æ®ç±»å‹ (int8ã€fp4ã€fp16 ç­‰)ï¼Œåªè¦åœ¨ä¸é€‚é…å™¨çš„è¾“å‡ºéšå«çŠ¶æ€ç›¸åŠ å‰ï¼Œå°†å…¶è¾“å‡ºéšå«çŠ¶æ€çš„æ•°æ®ç±»å‹è½¬æ¢æˆä¸é€‚é…å™¨ç›¸åŒçš„æ•°æ®ç±»å‹å³å¯ â€”â€” bitsandbytes çš„æ¨¡å— ( `Linear8bitLt` å’Œ  `Linear4bit` ) å°±æ˜¯è¿™ä¹ˆåšçš„ï¼Œ `Linear8bitLt` å’Œ  `Linear4bit` è¿™ä¸¤ä¸ªæ¨¡å—çš„è¾“å‡ºæ•°æ®ç±»å‹ä¸åŸæœªé‡åŒ–æ¨¡å‹çš„è¾“å‡ºæ•°æ®ç±»å‹ç›¸åŒã€‚

æˆ‘ä»¬åœ¨ Guanaco æ•°æ®é›†ä¸Šå¾®è°ƒäº† Falcon æ¨¡å‹çš„ä¸¤ä¸ªå˜ä½“ (7B å’Œ 40B)ã€‚å…¶ä¸­ï¼Œ7B æ¨¡å‹æ˜¯åœ¨å• NVIDIA-T4 16GB ä¸Šå¾®è°ƒçš„ï¼Œè€Œ 40B æ¨¡å‹æ˜¯åœ¨å• NVIDIA A100 80GB ä¸Šå¾®è°ƒçš„ã€‚åœ¨å¾®è°ƒæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† 4 æ¯”ç‰¹é‡åŒ–çš„åŸºç¡€æ¨¡å‹ä»¥åŠ QLoRA æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨äº† [æ¥è‡ª TRL åº“çš„æœ€æ–°çš„ `SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer)ã€‚

[æ­¤å¤„](https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14) æä¾›äº†ä½¿ç”¨ PEFT é‡ç°æˆ‘ä»¬å®éªŒçš„å®Œæ•´è„šæœ¬ã€‚ä½†æ˜¯å¦‚æœä½ æƒ³å¿«é€Ÿè¿è¡Œ `SFTTrainer` (è€Œæ— éœ€ PEFT) çš„è¯ï¼Œåªéœ€ä¸‹é¢å‡ è¡Œä»£ç å³å¯:

```python
from datasets import load_dataset
from trl import SFTTrainer
from transformers import AutoTokenizer, AutoModelForCausalLM

dataset = load_dataset("imdb", split="train")

model_id = "tiiuae/falcon-7b"

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True)

trainer = SFTTrainer(
    model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    dataset_text_field="text",
    max_seq_length=512,
)
trainer.train()
```

ä½ è¿˜å¯ä»¥æŸ¥çœ‹ [åŸå§‹ QLoRA ä»£ç åº“](https://github.com/artidoro/qlora/)ï¼Œä»¥äº†è§£æœ‰å…³å¦‚ä½•è¯„ä¼°è®­ç»ƒæ¨¡å‹çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚

### å…³äºå¾®è°ƒçš„èµ„æº

- **[ä½¿ç”¨ 4 æ¯”ç‰¹é‡åŒ–å’Œ PEFT åœ¨ Guanaco æ•°æ®é›†ä¸Šå¾®è°ƒ Falcon-7B çš„ Colab notebook](https://colab.research.google.com/drive/1BiQiw31DT7-cDp1-0ySXvvhzqomTdI-o?usp=sharing)**
- **[è®­ç»ƒä»£ç ](https://gist.github.com/pacman100/1731b41f7a90a87b457e8c5415ff1c14)**
- **[40B æ¨¡å‹çš„ LoRA æ¨¡å‹](https://huggingface.co/smangrul/falcon-40B-int4-peft-lora-sfttrainer)** ([æ—¥å¿—](https://wandb.ai/smangrul/huggingface/runs/3hpqq08s/workspace?workspace=user-younesbelkada))
- **[7B æ¨¡å‹çš„ LoRA æ¨¡å‹](https://huggingface.co/ybelkada/falcon-7b-guanaco-lora)** ([æ—¥å¿—](https://wandb.ai/younesbelkada/huggingface/runs/2x4zi72j?workspace=user-younesbelkada))

## æ€»ç»“

Falcon æ˜¯æœ€æ–°çš„ã€ä»¤äººå…´å¥‹çš„ã€å¯å•†ç”¨çš„å¤§è¯­è¨€æ¨¡å‹ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº† Falcon æ¨¡å‹çš„åŠŸèƒ½ã€å¦‚ä½•åœ¨ä½ è‡ªå·±çš„ç¯å¢ƒä¸­è¿è¡Œ Falcon æ¨¡å‹ä»¥åŠåœ¨ Hugging Face ç”Ÿæ€ä¸­å¦‚ä½•è½»æ¾åœ°ç”¨è‡ªæœ‰æ•°æ®å¾®è°ƒå®ƒä»¬ã€‚æˆ‘ä»¬æœŸå¾…çœ‹åˆ°ç¤¾åŒºå¦‚ä½•ä½¿ç”¨ Falcon æ¨¡å‹ï¼
