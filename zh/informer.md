---
title: "ä½¿ç”¨ Informer è¿›è¡Œå¤šå…ƒæ¦‚ç‡æ—¶é—´åºåˆ—é¢„æµ‹" 
thumbnail: /blog/assets/134_informer/thumbnail.png
authors:
- user: elisim
  guest: true
- user: nielsr
- user: kashif
translators:
- user: innovation64
---

# ä½¿ç”¨ Informer è¿›è¡Œå¤šå…ƒæ¦‚ç‡æ—¶é—´åºåˆ—é¢„æµ‹

<script async defer src="https://unpkg.com/medium-zoom-element@0/dist/medium-zoom-element.min.js"></script>

<a target="_blank" href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multivariate_informer.ipynb">
    <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

## ä»‹ç»
å‡ ä¸ªæœˆå‰ï¼Œæˆ‘ä»¬ä»‹ç»äº† [Time Series Transformer](https://huggingface.co/blog/time-series-transformers)ï¼Œå®ƒæ˜¯ Vanilla Transformer ([Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)) åº”ç”¨äºé¢„æµ‹çš„æ¨¡å‹ï¼Œå¹¶å±•ç¤ºäº†**å•å˜é‡**æ¦‚ç‡é¢„æµ‹ä»»åŠ¡çš„ç¤ºä¾‹ï¼ˆå³å•ç‹¬é¢„æµ‹æ¯ä¸ªæ—¶é—´åºåˆ—çš„ 1-d åˆ†å¸ƒï¼‰ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº† _Informer_ æ¨¡å‹ ([Zhou, Haoyi, et al., 2021](https://arxiv.org/abs/2012.07436))ï¼ŒAAAI21æœ€ä½³è®ºæ–‡ï¼Œç°åœ¨åœ¨ğŸ¤— Transformers ä¸­ [å¯ç”¨](https://huggingface.co/docs/transformers/main/en/model_doc/informer)ã€‚æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Informer æ¨¡å‹è¿›è¡Œ **å¤šå…ƒ** æ¦‚ç‡æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ï¼Œå³é¢„æµ‹æœªæ¥æ—¶é—´åºåˆ—ç›®æ ‡å€¼çš„ **å‘é‡** çš„åˆ†å¸ƒã€‚è¯·æ³¨æ„ï¼Œè¿™ä¹Ÿé€‚ç”¨äºåŸå§‹æ—¶é—´åºåˆ— Transformer æ¨¡å‹ã€‚

##  å¤šå…ƒæ¦‚ç‡æ—¶é—´åºåˆ—é¢„æµ‹

å°±æ¦‚ç‡é¢„æµ‹çš„å»ºæ¨¡æ–¹é¢è€Œè¨€ï¼Œå½“å¤„ç†å¤šå…ƒæ—¶é—´åºåˆ—æ—¶ï¼ŒTransformer/Informer ä¸éœ€è¦è¿›è¡Œä»»ä½•æ›´æ”¹ã€‚åœ¨å•å˜é‡å’Œå¤šå˜é‡è®¾ç½®ä¸­ï¼Œæ¨¡å‹å°†æ¥æ”¶ä¸€ç³»åˆ—å‘é‡ï¼Œå› æ­¤å”¯ä¸€çš„æ›´æ”¹åœ¨äºæœ€ç»ˆè¾“å‡ºæˆ–æ¨¡å‹è¾“å‡ºã€‚

å¯¹é«˜ç»´æ•°æ®çš„å®Œæ•´è”åˆæ¡ä»¶åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡å¯èƒ½ä¼šä½¿å¾—è®¡ç®—å˜å¾—éå¸¸æ˜‚è´µï¼Œå› æ­¤ä¼šé‡‡ç”¨æŸäº›åˆ†å¸ƒçš„è¿‘ä¼¼æ–¹æ³•ï¼Œæœ€ç®€å•çš„æ˜¯å°†æ•°æ®å»ºæ¨¡ä¸ºæ¥è‡ªç›¸åŒæ—çš„ç‹¬ç«‹åˆ†å¸ƒï¼Œæˆ–è€…æ˜¯å¯¹å®Œæ•´åæ–¹å·®çš„æŸäº›ä½ç§©è¿‘ä¼¼ç­‰ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åªä½¿ç”¨ç‹¬ç«‹ï¼ˆæˆ–å¯¹è§’çº¿ï¼‰æ¨¡å‹è¾“å‡ºï¼Œè¿™äº›æ¨¡å‹è¾“å‡ºå—åˆ°æˆ‘ä»¬[å·²å®ç°](https://huggingface.co/docs/transformers/main/en/internal/time_series_utils)çš„åˆ†å¸ƒæ—æ”¯æŒã€‚

## Informer - åŸç†

åŸºäºåŸå§‹ Transformerï¼ˆ[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)ï¼‰ï¼ŒInformer é‡‡ç”¨äº†ä¸¤ä¸ªä¸»è¦æ”¹è¿›ã€‚ä¸ºäº†ç†è§£è¿™äº›æ”¹è¿›ï¼Œè®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹åŸå§‹ Transformer çš„ç¼ºç‚¹ï¼š

1. **è§„èŒƒè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„äºŒæ¬¡è®¡ç®—ï¼š** åŸå§‹ Transformer çš„è®¡ç®—å¤æ‚åº¦ä¸º \\(O(T^2 D)\\) ï¼Œå…¶ä¸­ \\(T\\) æ˜¯æ—¶é—´åºåˆ—é•¿åº¦ï¼Œ\\(D\\) æ˜¯éšè—çŠ¶æ€çš„ç»´åº¦ã€‚å¯¹äºé•¿åºåˆ—æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆä¹Ÿç§°ä¸º _LSTF é—®é¢˜_ ï¼‰ï¼Œå¯èƒ½éå¸¸è€—è´¹è®¡ç®—èµ„æºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒInformer é‡‡ç”¨äº†ä¸€ç§æ–°çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œç§°ä¸º _ç¨€ç–æ¦‚ç‡_ è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå…¶æ—¶é—´å’Œç©ºé—´å¤æ‚åº¦ä¸º \\(O(T \log T)\\)ã€‚
2. **å †å å±‚æ—¶çš„å†…å­˜ç“¶é¢ˆï¼š**å½“å †å  \\(N\\) ä¸ªç¼–ç å™¨/è§£ç å™¨å±‚æ—¶ï¼ŒåŸå§‹ Transformer çš„å†…å­˜ä½¿ç”¨é‡ä¸º \\(O(N T^2)\\)ï¼Œè¿™é™åˆ¶äº†æ¨¡å‹å¯¹é•¿åºåˆ—çš„å®¹é‡ã€‚Informer ä½¿ç”¨äº†ä¸€ç§ç§°ä¸º _è’¸é¦_ æ“ä½œçš„æ–¹æ³•ï¼Œå°†å±‚ä¹‹é—´çš„è¾“å…¥å¤§å°ç¼©å°åˆ°å…¶ä¸€åŠåˆ‡ç‰‡ã€‚é€šè¿‡è¿™æ ·åšï¼Œå®ƒå°†æ•´ä¸ªå†…å­˜ä½¿ç”¨é‡å‡å°‘åˆ° \\(O(N\cdot T \log T)\\)ã€‚

æ­£å¦‚æ‚¨æ‰€çœ‹åˆ°çš„ï¼ŒInformer æ¨¡å‹çš„åŸç†ç±»ä¼¼äº Longformerï¼ˆ[Beltagy et el., 2020](https://arxiv.org/abs/2004.05150)ï¼‰ï¼ŒSparse Transformerï¼ˆ[Child et al., 2019](https://arxiv.org/abs/1904.10509)ï¼‰å’Œå…¶ä»– NLP è®ºæ–‡ï¼Œ**å½“è¾“å…¥åºåˆ—å¾ˆé•¿æ—¶**ç”¨äºå‡å°‘è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„äºŒæ¬¡å¤æ‚åº¦ã€‚ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ·±å…¥äº†è§£ _ç¨€ç–æ¦‚ç‡_ è‡ªæ³¨æ„åŠ›æœºåˆ¶ å’Œ _è’¸é¦_ æ“ä½œï¼Œå¹¶æä¾›ä»£ç ç¤ºä¾‹ã€‚

###  ç¨€ç–æ¦‚ç‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆProbSparse attentionï¼‰

ç¨€ç–æ¦‚ç‡çš„ä¸»è¦æ€æƒ³æ˜¯è§„èŒƒçš„è‡ªæ³¨æ„åŠ›åˆ†æ•°å½¢æˆé•¿å°¾åˆ†å¸ƒï¼Œå…¶ä¸­â€œæ¿€æ´»â€ query ä½äºâ€œå¤´éƒ¨â€åˆ†æ•°ï¼Œâ€œæ²‰é»˜â€ query ä½äºâ€œå°¾éƒ¨â€åŒºåŸŸçš„åˆ†æ•°ã€‚é€šè¿‡â€œæ¿€æ´»â€ queryï¼Œæˆ‘ä»¬çš„æ„æ€æ˜¯ query \\(q_i\\) è¿™æ ·ç‚¹ç§¯ \\(\langle q_i,k_i \rangle\\) **æœ‰åŠ©äº**ä¸»è¦çš„æ³¨æ„åŠ›ï¼Œè€Œâ€œæ²‰é»˜â€ query å½¢æˆä¸€ä¸ªç‚¹ç§¯ï¼Œäº§ç”Ÿ **çç¢çš„** æ³¨æ„åŠ›ã€‚è¿™é‡Œï¼Œ\\(q_i\\) å’Œ \\(k_i\\) åˆ†åˆ«æ˜¯ \\(Q\\) å’Œ \\(K\\) æ³¨æ„åŠ›çŸ©é˜µä¸­çš„ç¬¬ \\(i\\) è¡Œã€‚

| ![informer_full_vs_sparse_attention](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/informer_full_vs_sparse_attention.png) |
|:--:|
| åœ¨ [Autoformer (Wu, Haixu, et al., 2021)](https://wuhaixu2016.github.io/pdf/NeurIPS2021_Autoformer.pdf)ä¸­ï¼ŒåŸå§‹è‡ªæ³¨æ„åŠ›æœºåˆ¶ vs ç¨€ç–æ¦‚ç‡è‡ªæ³¨æ„åŠ›æœºåˆ¶  |

åŸºäºâ€œæ¿€æ´»â€å’Œâ€œæ²‰é»˜â€ query çš„æƒ³æ³•ï¼Œç¨€ç–æ¦‚ç‡è‡ªæ³¨æ„åŠ›æœºåˆ¶é€‰æ‹©â€œæ¿€æ´»â€ query ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„ query çŸ©é˜µ \\(Q_{reduced}\\) ç”¨äºè®¡ç®— \\ ä¸­çš„æ³¨æ„åŠ›æƒé‡(O(T \log T)\\)ã€‚è®©æˆ‘ä»¬é€šè¿‡ä»£ç ç¤ºä¾‹æ›´è¯¦ç»†åœ°äº†è§£è¿™ä¸€ç‚¹ã€‚
    
å›å¿†ä¸€ä¸‹å…¸å‹çš„è‡ªæ³¨æ„åŠ›å…¬å¼ï¼š

$$
\textrm{Attention}(Q, K, V) = \textrm{softmax}(\frac{QK^T}{\sqrt{d_k}} )V
$$

å…¶ä¸­ \\(Q\in \mathbb{R}^{L_Q \times d}\\)ã€\\(K\in \mathbb{R}^{L_K \times d}\\) å’Œ \\(V\in \mathbb{R}^{L_V \times d}\\)ã€‚è¯·æ³¨æ„ï¼Œåœ¨å®è·µä¸­ï¼Œquery å’Œ key çš„è¾“å…¥é•¿åº¦åœ¨è‡ªæ³¨æ„åŠ›è®¡ç®—ä¸­é€šå¸¸æ˜¯ç­‰æ•ˆçš„ï¼Œå³ \\(L_Q = L_K = T\\) å…¶ä¸­ \\(T\\) æ˜¯æ—¶é—´åºåˆ—é•¿åº¦ã€‚å› æ­¤ï¼Œ\\(QK^T\\) ä¹˜æ³•éœ€è¦ \\(O(T^2 \cdot d)\\) è®¡ç®—å¤æ‚åº¦ã€‚åœ¨ç¨€ç–æ¦‚ç‡è‡ªæ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªæ–°çš„ \\(Q_{reduce}\\) çŸ©é˜µå¹¶å®šä¹‰ï¼š

$$
\textrm{ProbSparseAttention}(Q, K, V) = \textrm{softmax}(\frac{Q_{reduce}K^T}{\sqrt{d_k}} )V
$$

å…¶ä¸­ \\(Q_{reduce}\\) çŸ©é˜µä»…é€‰æ‹© Top \\(u\\) ä¸ªâ€œæ¿€æ´»â€ query ã€‚è¿™é‡Œï¼Œ\\(u = c \cdot \log L_Q\\) å’Œ \\(c\\) è°ƒç”¨äº†ç¨€ç–æ¦‚ç‡è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ _é‡‡æ ·å› å­_ è¶…å‚æ•°ã€‚ç”±äº \\(Q_{reduce}\\) ä»…é€‰æ‹© Top \\(u\\) queryï¼Œå…¶å¤§å°ä¸º \\(c\cdot \log L_Q \times d\\)ï¼Œå› æ­¤ä¹˜æ³• \\(Q_ {reduce}K^T\\) åªéœ€è¦ \\(O(L_K \log L_Q) = O(T \log T)\\)ã€‚

è¿™å¾ˆå¥½ï¼ä½†æ˜¯æˆ‘ä»¬å¦‚ä½•é€‰æ‹© \\(u\\) ä¸ªâ€œæ¿€æ´»â€ query æ¥åˆ›å»º \\(Q_{reduce}\\)ï¼Ÿè®©æˆ‘ä»¬å®šä¹‰ _Query ç¨€ç–åº¦æµ‹é‡(Query Sparsity Measurement)_ã€‚

#### Query ç¨€ç–åº¦æµ‹é‡(Query Sparsity Measurement)
Query ç¨€ç–åº¦æµ‹é‡ \\(M(q_i, K)\\) ç”¨äºåœ¨ \\(Q\\) ä¸­é€‰æ‹© \\(u\\) â€œæ¿€æ´»â€ query \\(q_i\\) ä»¥åˆ›å»º \\ ï¼ˆQ_{reduce}\\ï¼‰ã€‚ä»ç†è®ºä¸Šè®²ï¼Œå ä¸»å¯¼åœ°ä½çš„ \\(\langle q_i,k_i \rangle\\) å¯¹é¼“åŠ±â€œæ¿€æ´»â€ \\(q_i\\) çš„æ¦‚ç‡åˆ†å¸ƒ**è¿œç¦»**å‡åŒ€åˆ†å¸ƒï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚å› æ­¤ï¼Œå®é™… query åˆ†å¸ƒä¸å‡åŒ€åˆ†å¸ƒä¹‹é—´çš„ [KL æ•£åº¦](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) ç”¨äºå®šä¹‰ç¨€ç–åº¦åº¦é‡ã€‚

| ![informer_probsparse](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/informer_probsparse.png) | 
|:--:|
|ä»å®˜æ–¹[ä»“åº“](https://github.com/zhouhaoyi/Informer2020) ç»™å‡ºçš„ç¨€ç–æ¦‚ç‡è‡ªæ³¨æ„åŠ›æœºåˆ¶æè¿°|


å®é™…ä¸­ï¼Œæµ‹é‡è¢«å®šä¹‰ä¸ºï¼š

$$
M(q_i, K) = \max_j \frac{q_ik_j^T}{\sqrt{d}}-\frac{1}{L_k} \sum_{j=1}^{L_k}\frac{q_ik_j^T}{\sqrt{d}}
$$

è¿™é‡Œè¦ç†è§£çš„é‡è¦ä¸€ç‚¹æ˜¯å½“ \\(M(q_i, K)\\) è¾ƒå¤§æ—¶ï¼ŒQuery \\(q_i\\) åº”è¯¥åœ¨ \\(Q_{reduce}\\) ä¸­ï¼Œåä¹‹äº¦ç„¶ã€‚

ä½†æ˜¯æˆ‘ä»¬å¦‚ä½•è®¡ç®—éäºŒæ¬¡æ—¶é—´çš„é¡¹ \\(q_ik_j^T\\) å‘¢ï¼Ÿå›æƒ³ä¸€ä¸‹ï¼Œå¤§å¤šæ•°ç‚¹ç§¯ \\(\langle q_i,k_i \rangle\\) éƒ½ä¼šäº§ç”Ÿæ­£å¸¸çš„æ³¨æ„åŠ›ï¼ˆå³é•¿å°¾åˆ†å¸ƒå±æ€§ï¼‰ï¼Œæ‰€ä»¥ä» \\(K\\) ä¸­éšæœºæŠ½å–ä¸€ä¸ªé”®å­é›†å°±è¶³å¤Ÿäº†ï¼Œè¿™åœ¨ä»£ç ä¸­ç§°ä¸º `K_sample`ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€çœ‹ `probsparse_attention` çš„ä»£ç ï¼š
    
```python
from torch import nn
import math


def probsparse_attention(query_states, key_states, value_states, sampling_factor=5):
    """
    Compute the probsparse self-attention.
    Input shape: Batch x Time x Channel

    Note the additional `sampling_factor` input.
    """
    # get input sizes with logs
    L_K = key_states.size(1)
    L_Q = query_states.size(1)
    log_L_K = np.ceil(np.log1p(L_K)).astype("int").item()
    log_L_Q = np.ceil(np.log1p(L_Q)).astype("int").item()

    # calculate a subset of samples to slice from K and create Q_K_sample
    U_part = min(sampling_factor * L_Q * log_L_K, L_K)

    # create Q_K_sample (the q_i * k_j^T term in the sparsity measurement)
    index_sample = torch.randint(0, L_K, (U_part,))
    K_sample = key_states[:, index_sample, :]
    Q_K_sample = torch.bmm(query_states, K_sample.transpose(1, 2))

    # calculate the query sparsity measurement with Q_K_sample
    M = Q_K_sample.max(dim=-1)[0] - torch.div(Q_K_sample.sum(dim=-1), L_K)

    # calculate u to find the Top-u queries under the sparsity measurement
    u = min(sampling_factor * log_L_Q, L_Q)
    M_top = M.topk(u, sorted=False)[1]

    # calculate Q_reduce as query_states[:, M_top]
    dim_for_slice = torch.arange(query_states.size(0)).unsqueeze(-1)
    Q_reduce = query_states[dim_for_slice, M_top]  # size: c*log_L_Q x channel

    # and now, same as the canonical
    d_k = query_states.size(-1)
    attn_scores = torch.bmm(Q_reduce, key_states.transpose(-2, -1))  # Q_reduce x K^T
    attn_scores = attn_scores / math.sqrt(d_k)
    attn_probs = nn.functional.softmax(attn_scores, dim=-1)
    attn_output = torch.bmm(attn_probs, value_states)

    return attn_output, attn_scores
```
    

æˆ‘ä»¬åšåˆ°äº†ï¼è¯·æ³¨æ„ï¼Œè¿™åªæ˜¯ `probsparse_attention` çš„éƒ¨åˆ†å®ç°ï¼Œå®Œæ•´çš„å®ç°å¯ä»¥åœ¨ ğŸ¤— Transformers ä¸­æ‰¾åˆ°ã€‚

### è’¸é¦(distilling)

ç”±äºæ¦‚ç‡ç¨€ç–è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œç¼–ç å™¨çš„ç‰¹å¾å›¾æœ‰ä¸€äº›å¯ä»¥å»é™¤çš„å†—ä½™ã€‚æ‰€ä»¥ï¼Œ
è’¸é¦æ“ä½œç”¨äºå°†ç¼–ç å™¨å±‚ä¹‹é—´çš„è¾“å…¥å¤§å°å‡å°‘åˆ°å®ƒçš„åŠç‰‡ï¼Œä»è€Œåœ¨ç†è®ºä¸Šæ¶ˆé™¤äº†è¿™ç§å†—ä½™ã€‚å®é™…ä¸Šï¼ŒInformer çš„â€œè’¸é¦â€æ“ä½œåªæ˜¯åœ¨æ¯ä¸ªç¼–ç å™¨å±‚ä¹‹é—´æ·»åŠ ä¸€ç»´å·ç§¯å±‚å’Œæœ€å¤§æ± åŒ–ã€‚è®¾ \\(X_n\\) ä¸ºç¬¬ \\(n\\) ç¼–ç å±‚çš„è¾“å‡ºï¼Œåˆ™è’¸é¦æ“ä½œå®šä¹‰ä¸ºï¼š


$$
X_{n+1} = \textrm{MaxPool} ( \textrm{ELU}(\textrm{Conv1d}(X_n))
$$


è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹ä»£ç ï¼š
    
```python
from torch import nn

# ConvLayer is a class with forward pass applying ELU and MaxPool1d
def informer_encoder_forward(x_input, num_encoder_layers=3, distil=True):
    # Initialize the convolution layers
    if distil:
        conv_layers = nn.ModuleList([ConvLayer() for _ in range(num_encoder_layers - 1)])
        conv_layers.append(None)
    else:
        conv_layers = [None] * num_encoder_layers
    
    # Apply conv_layer between each encoder_layer
    for encoder_layer, conv_layer in zip(encoder_layers, conv_layers):
        output = encoder_layer(x_input)
        if conv_layer is not None:
            output = conv_layer(loutput)
    
    return output
```

é€šè¿‡å°†æ¯å±‚çš„è¾“å…¥å‡å°‘ä¸¤ä¸ªï¼Œæˆ‘ä»¬å¾—åˆ°çš„å†…å­˜ä½¿ç”¨é‡ä¸º \\(O(N\cdot T \log T)\\) è€Œä¸æ˜¯ \\(O(N\cdot T^2)\\) å…¶ä¸­\\(N\\) æ˜¯ç¼–ç å™¨/è§£ç å™¨å±‚æ•°ã€‚è¿™å°±æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼    

Informer æ¨¡å‹åœ¨ ğŸ¤— Transformers åº“ä¸­ [ç°å·²å¯ç”¨](https://huggingface.co/docs/transformers/main/en/model_doc/informer)ï¼Œç®€ç§°ä¸º `InformerModel`ã€‚åœ¨ä¸‹é¢çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åœ¨è‡ªå®šä¹‰å¤šå…ƒæ—¶é—´åºåˆ—æ•°æ®é›†ä¸Šè®­ç»ƒæ­¤æ¨¡å‹ã€‚    


## è®¾ç½®ç¯å¢ƒ

é¦–å…ˆï¼Œè®©æˆ‘ä»¬å®‰è£…å¿…è¦çš„åº“ï¼šğŸ¤— Transformersã€ğŸ¤— Datasetsã€ğŸ¤— Evaluateã€ğŸ¤— Accelerate å’Œ [GluonTS](https://github.com/awslabs/gluonts)ã€‚

æ­£å¦‚æˆ‘ä»¬å°†å±•ç¤ºçš„é‚£æ ·ï¼ŒGluonTS å°†ç”¨äºè½¬æ¢æ•°æ®ä»¥åˆ›å»ºç‰¹å¾ä»¥åŠåˆ›å»ºé€‚å½“çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ‰¹æ¬¡ã€‚


```python
!pip install -q git+https://github.com/huggingface/transformers.git datasets evaluate accelerate gluonts ujson
```

## åŠ è½½æ•°æ®é›†

åœ¨è¿™ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [Hugging Face Hub](https://huggingface.co/datasets/monash_tsf) ä¸Šæä¾›çš„ `traffic_hourly` æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å« [Lai ç­‰äººä½¿ç”¨çš„æ—§é‡‘å±±äº¤é€šæ•°æ®é›†ã€‚ (2017)](https://arxiv.org/abs/1703.07015)ã€‚å®ƒåŒ…å« 862 ä¸ªå°æ—¶çš„æ—¶é—´åºåˆ—ï¼Œæ˜¾ç¤º 2015 å¹´è‡³ 2016 å¹´æ—§é‡‘å±±æ¹¾åŒºé«˜é€Ÿå…¬è·¯ \\([0, 1]\\) èŒƒå›´å†…çš„é“è·¯å ç”¨ç‡ã€‚

æ­¤æ•°æ®é›†æ˜¯ [Monash Time Series Forecasting](https://forecastingdata.org/) ä»“åº“çš„ä¸€éƒ¨åˆ†ï¼Œè¯¥ä»“åº“æ˜¯æ¥è‡ªå¤šä¸ªé¢†åŸŸçš„æ—¶é—´åºåˆ—æ•°æ®é›†çš„é›†åˆã€‚å®ƒå¯ä»¥è¢«è§†ä¸ºæ—¶é—´åºåˆ—é¢„æµ‹çš„ [GLUE åŸºå‡†](https://gluebenchmark.com/)ã€‚


```python
from datasets import load_dataset

dataset = load_dataset("monash_tsf", "traffic_hourly")
```

å¯ä»¥çœ‹åˆ°ï¼Œæ•°æ®é›†åŒ…å« 3 ä¸ªåˆ‡ç‰‡ï¼šè®­ç»ƒé›†ï¼ŒéªŒè¯é›†ï¼Œæµ‹è¯•é›†ã€‚

```python
dataset

>>> DatasetDict({
        train: Dataset({
            features: ['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'],
            num_rows: 862
        })
        test: Dataset({
            features: ['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'],
            num_rows: 862
        })
        validation: Dataset({
            features: ['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'],
            num_rows: 862
        })
    })
```

æ¯ä¸ªç¤ºä¾‹éƒ½åŒ…å«ä¸€äº›é”®ï¼Œå…¶ä¸­ `start`å’Œ `target` æ˜¯æœ€é‡è¦çš„é”®ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹æ•°æ®é›†ä¸­çš„ç¬¬ä¸€ä¸ªæ—¶é—´åºåˆ—ï¼š


```python
train_example = dataset["train"][0]
train_example.keys()

>>> dict_keys(['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'])
```

`start` ä»…æŒ‡ç¤ºæ—¶é—´åºåˆ—çš„å¼€å§‹ï¼ˆä½œä¸ºæ—¥æœŸæ—¶é—´ï¼‰ï¼Œè€Œ `taâ€‹â€‹rget` åŒ…å«æ—¶é—´åºåˆ—çš„å®é™…å€¼ã€‚

`start` å°†æœ‰åŠ©äºå°†æ—¶é—´ç›¸å…³çš„ç‰¹å¾æ·»åŠ åˆ°æ—¶é—´åºåˆ—å€¼ä¸­ï¼Œä½œä¸ºæ¨¡å‹çš„é¢å¤–è¾“å…¥ï¼ˆä¾‹å¦‚â€œä¸€å¹´ä¸­çš„æœˆä»½â€ï¼‰ã€‚å› ä¸ºæˆ‘ä»¬çŸ¥é“æ•°æ®çš„é¢‘ç‡æ˜¯`æ¯å°æ—¶`ï¼Œæ‰€ä»¥æˆ‘ä»¬çŸ¥é“ä¾‹å¦‚ç¬¬äºŒä¸ªå€¼çš„æ—¶é—´æˆ³ä¸º`2015-01-01 01:00:01`ã€`2015-01-01 02:00:01` ç­‰ç­‰ã€‚


```python
print(train_example["start"])
print(len(train_example["target"]))

>>> 2015-01-01 00:00:01
    17448
```

éªŒè¯é›†åŒ…å«ä¸è®­ç»ƒé›†ç›¸åŒçš„æ•°æ®ï¼Œåªæ˜¯ `prediction_length` çš„æ—¶é—´æ›´é•¿ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ ¹æ®çœŸå®æƒ…å†µéªŒè¯æ¨¡å‹çš„é¢„æµ‹ã€‚

ä¸éªŒè¯é›†ç›¸æ¯”ï¼Œæµ‹è¯•é›†ä¹Ÿæ˜¯ä¸€ä¸ª `prediction_length` é•¿æ•°æ®ï¼ˆæˆ–è€…ä¸ç”¨äºåœ¨å¤šä¸ªæ»šåŠ¨çª—å£ä¸Šè¿›è¡Œæµ‹è¯•çš„è®­ç»ƒé›†ç›¸æ¯”ï¼Œ`prediction_length` é•¿æ•°æ®çš„è‹¥å¹²å€ï¼‰ã€‚


```python
validation_example = dataset["validation"][0]
validation_example.keys()

>>> dict_keys(['start', 'target', 'feat_static_cat', 'feat_dynamic_real', 'item_id'])
```
åˆå§‹å€¼ä¸ç›¸åº”çš„è®­ç»ƒç¤ºä¾‹å®Œå…¨ç›¸åŒã€‚ä½†æ˜¯ï¼Œä¸è®­ç»ƒç¤ºä¾‹ç›¸æ¯”ï¼Œæ­¤ç¤ºä¾‹å…·æœ‰ `prediction_length=48`ï¼ˆ48 å°æ—¶æˆ– 2 å¤©ï¼‰é™„åŠ å€¼ã€‚è®©æˆ‘ä»¬éªŒè¯ä¸€ä¸‹ã€‚


```python
freq = "1H"
prediction_length = 48

assert len(train_example["target"]) + prediction_length == len(
    dataset["validation"][0]["target"]
)
```

è®©æˆ‘ä»¬å¯è§†åŒ–çœ‹ä¸€ä¸‹ï¼š


```python
import matplotlib.pyplot as plt

num_of_samples = 150

figure, axes = plt.subplots()
axes.plot(train_example["target"][-num_of_samples:], color="blue")
axes.plot(
    validation_example["target"][-num_of_samples - prediction_length :],
    color="red",
    alpha=0.5,
)

plt.show()
```
    
![png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/output_22_0.png)
    

è®©æˆ‘ä»¬åˆ’åˆ†ä¸€ä¸‹æ•°æ®ï¼š


```python
train_dataset = dataset["train"]
test_dataset = dataset["test"]
```

## æ›´æ–° `start` åˆ° `pd.Period`

æˆ‘ä»¬è¦åšçš„ç¬¬ä¸€ä»¶äº‹æ˜¯ä½¿ç”¨æ•°æ®çš„ `freq` å°†æ¯ä¸ªæ—¶é—´åºåˆ—çš„ `start` ç‰¹å¾è½¬æ¢ä¸º pandas `Period` ç´¢å¼•ï¼š


```python
from functools import lru_cache

import pandas as pd
import numpy as np


@lru_cache(10_000)
def convert_to_pandas_period(date, freq):
    return pd.Period(date, freq)


def transform_start_field(batch, freq):
    batch["start"] = [convert_to_pandas_period(date, freq) for date in batch["start"]]
    return batch
```

æˆ‘ä»¬ç°åœ¨ä½¿ç”¨ `datasets`' [`set_transform`](https://huggingface.co/docs/datasets/v2.7.0/en/package_reference/main_classes#datasets.Dataset.set_transform) åŠŸèƒ½æ¥å³æ—¶æ‰§è¡Œæ­¤æ“ä½œåˆ°ä½ï¼š


```python
from functools import partial

train_dataset.set_transform(partial(transform_start_field, freq=freq))
test_dataset.set_transform(partial(transform_start_field, freq=freq))
```

ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ GluonTS ä¸­çš„ `MultivariateGrouper` å°†æ•°æ®é›†è½¬æ¢ä¸ºå¤šå…ƒæ—¶é—´åºåˆ—ã€‚è¯¥ grouper ä¼šå°†å•ä¸ªä¸€ç»´æ—¶é—´åºåˆ—è½¬æ¢ä¸ºå•ä¸ªäºŒç»´çŸ©é˜µã€‚


```python
from gluonts.dataset.multivariate_grouper import MultivariateGrouper

num_of_variates = len(train_dataset)

train_grouper = MultivariateGrouper(max_target_dim=num_of_variates)
test_grouper = MultivariateGrouper(
    max_target_dim=num_of_variates,
    num_test_dates=len(test_dataset) // num_of_variates, # number of rolling test windows
)

multi_variate_train_dataset = train_grouper(train_dataset)
multi_variate_test_dataset = test_grouper(test_dataset)
```

è¯·æ³¨æ„ï¼Œç›®æ ‡ç°åœ¨æ˜¯äºŒç»´çš„ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯å˜é‡çš„æ•°é‡ï¼ˆæ—¶é—´åºåˆ—çš„æ•°é‡ï¼‰ï¼Œç¬¬äºŒä¸ªæ˜¯æ—¶é—´åºåˆ—å€¼ï¼ˆæ—¶é—´ç»´åº¦ï¼‰ï¼š


```python
multi_variate_train_example = multi_variate_train_dataset[0]
print("multi_variate_train_example["target"].shape =", multi_variate_train_example["target"].shape)

>>> multi_variate_train_example["target"].shape = (862, 17448)
```

## å®šä¹‰æ¨¡å‹

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬å®ä¾‹åŒ–ä¸€ä¸ªæ¨¡å‹ã€‚è¯¥æ¨¡å‹å°†ä»å¤´å¼€å§‹è®­ç»ƒï¼Œå› æ­¤æˆ‘ä»¬ä¸ä¼šåœ¨è¿™é‡Œä½¿ç”¨ `from_pretrained` æ–¹æ³•ï¼Œè€Œæ˜¯ä» [`config`](https://huggingface.co/docs/transformers/main/en/model_doc/informer#transformers.InformerConfig) éšæœºåˆå§‹åŒ–æ¨¡å‹ã€‚

æˆ‘ä»¬ä¸ºæ¨¡å‹æŒ‡å®šäº†å‡ ä¸ªé™„åŠ å‚æ•°ï¼š

- `prediction_length` (åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­, `48` å°æ—¶): è¿™æ˜¯ Informer çš„è§£ç å™¨å°†å­¦ä¹ é¢„æµ‹çš„èŒƒå›´ï¼›
- `context_length`: å¦‚æœæœªæŒ‡å®š `context_length` ï¼Œæ¨¡å‹ä¼šå°† `context_length` ï¼ˆç¼–ç å™¨çš„è¾“å…¥ï¼‰è®¾ç½®ä¸ºç­‰äº `prediction_length`ï¼›
- ç»™å®šé¢‘ç‡çš„ `lags` : è¿™äº›æŒ‡å®šäº†ä¸€ç§æœ‰æ•ˆçš„â€œå›é¡¾â€æœºåˆ¶ï¼Œæˆ‘ä»¬å°†è¿‡å»çš„å€¼è¿æ¥åˆ°å½“å‰å€¼ä½œä¸ºé™„åŠ åŠŸèƒ½ï¼Œä¾‹å¦‚å¯¹äº`æ¯æ—¥`é¢‘ç‡ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè€ƒè™‘å›é¡¾`[1, 7, 30, ...]`ï¼Œæˆ–è€…å¯¹äº`åˆ†é’Ÿ`æ•°æ®ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šè€ƒè™‘`[1, 30, 60, 60*24, ... ]` ç­‰ï¼›
- æ—¶é—´ç‰¹å¾çš„æ•°é‡: åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œè¿™å°†æ˜¯ `5`ï¼Œå› ä¸ºæˆ‘ä»¬å°†æ·»åŠ  `HourOfDay`ã€`DayOfWeek` â€¦â€¦ å’Œ `Age` ç‰¹å¾ï¼ˆè§ä¸‹æ–‡ï¼‰ã€‚

è®©æˆ‘ä»¬æ£€æŸ¥ GluonTS ä¸ºç»™å®šé¢‘ç‡ï¼ˆâ€œæ¯å°æ—¶â€ï¼‰æä¾›çš„é»˜è®¤ lagsï¼š


```python
from gluonts.time_feature import get_lags_for_frequency

lags_sequence = get_lags_for_frequency(freq)
print(lags_sequence)

>>> [1, 2, 3, 4, 5, 6, 7, 23, 24, 25, 47, 48, 49, 71, 72, 73, 95, 96, 97, 119, 120, 
     121, 143, 144, 145, 167, 168, 169, 335, 336, 337, 503, 504, 505, 671, 672, 673, 719, 720, 721]
```

è¿™æ„å‘³ç€æ¯ä¸ªæ—¶é—´æ­¥é•¿æœ€å¤šå¯å›é¡¾ 721 å°æ—¶ï¼ˆçº¦ 30 å¤©ï¼‰ï¼Œä½œä¸ºé™„åŠ åŠŸèƒ½ã€‚ä½†æ˜¯ï¼Œç”Ÿæˆçš„ç‰¹å¾å‘é‡æœ€ç»ˆçš„å¤§å°ä¸º `len(lags_sequence)*num_of_variates`ï¼Œå¯¹äºæˆ‘ä»¬çš„ä¾‹å­æ¥è¯´æ˜¯ 34480ï¼è¿™æ˜¯è¡Œä¸é€šçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†ä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„åˆç†æ»åã€‚

æˆ‘ä»¬è¿˜æ£€æŸ¥ GluonTS ä¸ºæˆ‘ä»¬æä¾›çš„é»˜è®¤æ—¶é—´åŠŸèƒ½ï¼š


```python
from gluonts.time_feature import time_features_from_frequency_str

time_features = time_features_from_frequency_str(freq)
print(time_features)

>>> [<function hour_of_day at 0x7f3809539240>, <function day_of_week at 0x7f3809539360>, <function day_of_month at 0x7f3809539480>, <function day_of_year at 0x7f38095395a0>]
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœ‰å››ä¸ªé™„åŠ ç‰¹å¾ï¼Œå³â€œä¸€å¤©ä¸­çš„å°æ—¶â€ã€â€œæ˜ŸæœŸå‡ â€ã€â€œæœˆä¸­çš„å¤©â€å’Œâ€œå¹´ä¸­çš„å¤©â€ã€‚è¿™æ„å‘³ç€å¯¹äºæ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬å°†è¿™äº›ç‰¹å¾æ·»åŠ ä¸ºæ ‡é‡å€¼ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘æ—¶é—´æˆ³ `2015-01-01 01:00:01`ã€‚å››ä¸ªé™„åŠ å‡½æ•°æ˜¯ï¼š


```python
from pandas.core.arrays.period import period_array

timestamp = pd.Period("2015-01-01 01:00:01", freq=freq)
timestamp_as_index = pd.PeriodIndex(data=period_array([timestamp]))
additional_features = [
    (time_feature.__name__, time_feature(timestamp_as_index))
    for time_feature in time_features
]
print(dict(additional_features))

>>> {'hour_of_day': array([-0.45652174]), 'day_of_week': array([0.]), 'day_of_month': array([-0.5]), 'day_of_year': array([-0.5])}
```

è¯·æ³¨æ„ï¼Œå°æ—¶å’Œå¤©è¢«ç¼–ç ä¸ºæ¥è‡ª GluonTS çš„`[-0.5, 0.5]`ä¹‹é—´çš„å€¼ã€‚æœ‰å…³ `time_features` çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[è¿™é‡Œ](https://github.com/awslabs/gluonts/blob/dev/src/gluonts/time_feature/_base.py)ã€‚é™¤äº†è¿™ 4 ä¸ªç‰¹å¾ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å°†æ·»åŠ ä¸€ä¸ªâ€œå¹´é¾„â€ç‰¹å¾ï¼Œæˆ‘ä»¬å°†åœ¨ç¨åçš„æ•°æ®  transformations ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚

æˆ‘ä»¬ç°åœ¨æ‹¥æœ‰äº†å®šä¹‰æ¨¡å‹çš„ä¸€åˆ‡ï¼š


```python
from transformers import InformerConfig, InformerForPrediction

config = InformerConfig(
    # in the multivariate setting, input_size is the number of variates in the time series per time step
    input_size=num_of_variates,
    # prediction length:
    prediction_length=prediction_length,
    # context length:
    context_length=prediction_length * 2,
    # lags value copied from 1 week before:
    lags_sequence=[1, 24 * 7],
    # we'll add 5 time features ("hour_of_day", ..., and "age"):
    num_time_features=len(time_features) + 1,
    
    # informer params:
    dropout=0.1,
    encoder_layers=6,
    decoder_layers=4,
    # project input from num_of_variates*len(lags_sequence)+num_time_features to:
    d_model=64,
)

model = InformerForPrediction(config)
```
é»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨å¯¹è§’ Student-t åˆ†å¸ƒï¼ˆä½†è¿™æ˜¯ [å¯é…ç½®çš„](https://huggingface.co/docs/transformers/main/en/internal/time_series_utils)ï¼‰ï¼š

```python
model.config.distribution_output

>>> 'student_t'
```

## å®šä¹‰ Transformations

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å®šä¹‰æ•°æ®çš„ transformationsï¼Œç‰¹åˆ«æ˜¯æ—¶é—´ç‰¹å¾çš„åˆ›å»ºï¼ˆåŸºäºæ•°æ®é›†æˆ–é€šç”¨æ•°æ®é›†ï¼‰ã€‚

åŒæ ·ï¼Œæˆ‘ä»¬å°†ä¸ºæ­¤ä½¿ç”¨ GluonTS åº“ã€‚æˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ª transformations `é“¾`ï¼ˆæœ‰ç‚¹ç±»ä¼¼äºå›¾åƒçš„ `torchvision.transforms.Compose`ï¼‰ã€‚å®ƒå…è®¸æˆ‘ä»¬å°†å¤šä¸ª transformations ç»„åˆåˆ°ä¸€ä¸ª pipeline ä¸­ã€‚


```python
from gluonts.time_feature import TimeFeature
from gluonts.dataset.field_names import FieldName
from gluonts.transform import (
    AddAgeFeature,
    AddObservedValuesIndicator,
    AddTimeFeatures,
    AsNumpyArray,
    Chain,
    ExpectedNumInstanceSampler,
    InstanceSplitter,
    RemoveFields,
    SelectFields,
    SetField,
    TestSplitSampler,
    Transformation,
    ValidationSplitSampler,
    VstackFeatures,
    RenameFields,
)
```

ä¸‹é¢çš„ transformations å¸¦æœ‰æ³¨é‡Šï¼Œä»¥è§£é‡Šå®ƒä»¬çš„ä½œç”¨ã€‚åœ¨é«˜å±‚æ¬¡ä¸Šï¼Œæˆ‘ä»¬å°†è¿­ä»£æ•°æ®é›†çš„å„ä¸ªæ—¶é—´åºåˆ—å¹¶æ·»åŠ /åˆ é™¤å­—æ®µæˆ–ç‰¹å¾ï¼š


```python
from transformers import PretrainedConfig


def create_transformation(freq: str, config: PretrainedConfig) -> Transformation:
    # create list of fields to remove later
    remove_field_names = []
    if config.num_static_real_features == 0:
        remove_field_names.append(FieldName.FEAT_STATIC_REAL)
    if config.num_dynamic_real_features == 0:
        remove_field_names.append(FieldName.FEAT_DYNAMIC_REAL)
    if config.num_static_categorical_features == 0:
        remove_field_names.append(FieldName.FEAT_STATIC_CAT)

    return Chain(
        # step 1: remove static/dynamic fields if not specified
        [RemoveFields(field_names=remove_field_names)]
        # step 2: convert the data to NumPy (potentially not needed)
        + (
            [
                AsNumpyArray(
                    field=FieldName.FEAT_STATIC_CAT,
                    expected_ndim=1,
                    dtype=int,
                )
            ]
            if config.num_static_categorical_features > 0
            else []
        )
        + (
            [
                AsNumpyArray(
                    field=FieldName.FEAT_STATIC_REAL,
                    expected_ndim=1,
                )
            ]
            if config.num_static_real_features > 0
            else []
        )
        + [
            AsNumpyArray(
                field=FieldName.TARGET,
                # we expect an extra dim for the multivariate case:
                expected_ndim=1 if config.input_size == 1 else 2,
            ),
            # step 3: handle the NaN's by filling in the target with zero
            # and return the mask (which is in the observed values)
            # true for observed values, false for nan's
            # the decoder uses this mask (no loss is incurred for unobserved values)
            # see loss_weights inside the xxxForPrediction model
            AddObservedValuesIndicator(
                target_field=FieldName.TARGET,
                output_field=FieldName.OBSERVED_VALUES,
            ),
            # step 4: add temporal features based on freq of the dataset
            # these serve as positional encodings
            AddTimeFeatures(
                start_field=FieldName.START,
                target_field=FieldName.TARGET,
                output_field=FieldName.FEAT_TIME,
                time_features=time_features_from_frequency_str(freq),
                pred_length=config.prediction_length,
            ),
            # step 5: add another temporal feature (just a single number)
            # tells the model where in the life the value of the time series is
            # sort of running counter
            AddAgeFeature(
                target_field=FieldName.TARGET,
                output_field=FieldName.FEAT_AGE,
                pred_length=config.prediction_length,
                log_scale=True,
            ),
            # step 6: vertically stack all the temporal features into the key FEAT_TIME
            VstackFeatures(
                output_field=FieldName.FEAT_TIME,
                input_fields=[FieldName.FEAT_TIME, FieldName.FEAT_AGE]
                + (
                    [FieldName.FEAT_DYNAMIC_REAL]
                    if config.num_dynamic_real_features > 0
                    else []
                ),
            ),
            # step 7: rename to match HuggingFace names
            RenameFields(
                mapping={
                    FieldName.FEAT_STATIC_CAT: "static_categorical_features",
                    FieldName.FEAT_STATIC_REAL: "static_real_features",
                    FieldName.FEAT_TIME: "time_features",
                    FieldName.TARGET: "values",
                    FieldName.OBSERVED_VALUES: "observed_mask",
                }
            ),
        ]
    )
```

## å®šä¹‰ `InstanceSplitter`

ä¸ºäº†è®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥åˆ›å»ºä¸€ä¸ª `InstanceSplitter`ï¼Œç”¨äºä»æ•°æ®é›†ä¸­å¯¹çª—å£è¿›è¡Œé‡‡æ ·ï¼ˆå› ä¸ºï¼Œè¯·è®°ä½ï¼Œç”±äºæ—¶é—´å’Œå†…å­˜é™åˆ¶ï¼Œæˆ‘ä»¬æ— æ³•å°†æ•´ä¸ªå†å²å€¼ä¼ é€’ç»™æ¨¡å‹ï¼‰ã€‚

å®ä¾‹æ‹†åˆ†å™¨ä»æ•°æ®ä¸­éšæœºé‡‡æ ·å¤§å°ä¸º `context_length` å’Œåç»­å¤§å°ä¸º`prediction_length` çš„çª—å£ï¼Œå¹¶å°† `past_` æˆ– `future_`é”®é™„åŠ åˆ°å„ä¸ªçª—å£çš„ä»»ä½•æ—¶é—´é”®ã€‚è¿™ç¡®ä¿äº† `values` å°†è¢«æ‹†åˆ†ä¸º `past_values` å’Œåç»­çš„ `future_values` é”®ï¼Œå®ƒä»¬å°†åˆ†åˆ«ç”¨ä½œç¼–ç å™¨å’Œè§£ç å™¨çš„è¾“å…¥ã€‚ `time_series_fields` å‚æ•°ä¸­çš„ä»»ä½•é”®éƒ½ä¼šå‘ç”ŸåŒæ ·çš„æƒ…å†µï¼š


```python
from gluonts.transform.sampler import InstanceSampler
from typing import Optional


def create_instance_splitter(
    config: PretrainedConfig,
    mode: str,
    train_sampler: Optional[InstanceSampler] = None,
    validation_sampler: Optional[InstanceSampler] = None,
) -> Transformation:
    assert mode in ["train", "validation", "test"]

    instance_sampler = {
        "train": train_sampler
        or ExpectedNumInstanceSampler(
            num_instances=1.0, min_future=config.prediction_length
        ),
        "validation": validation_sampler
        or ValidationSplitSampler(min_future=config.prediction_length),
        "test": TestSplitSampler(),
    }[mode]

    return InstanceSplitter(
        target_field="values",
        is_pad_field=FieldName.IS_PAD,
        start_field=FieldName.START,
        forecast_start_field=FieldName.FORECAST_START,
        instance_sampler=instance_sampler,
        past_length=config.context_length + max(config.lags_sequence),
        future_length=config.prediction_length,
        time_series_fields=["time_features", "observed_mask"],
    )
```

## åˆ›å»º PyTorch DataLoaders

ä¸‹é¢æ˜¯æ—¶å€™åˆ›å»º PyTorch DataLoaders äº†,è¿™å°†å…è®¸æˆ‘ä»¬è¿™å…è®¸æˆ‘ä»¬æ‹¥æœ‰æˆæ‰¹çš„ï¼ˆè¾“å…¥ã€è¾“å‡ºï¼‰å¯¹â€”â€”æˆ–è€…æ¢å¥è¯è¯´ï¼ˆ`past_values`ã€`future_values`ï¼‰ã€‚


```python
from typing import Iterable

import torch
from gluonts.itertools import Cached, Cyclic
from gluonts.dataset.loader import as_stacked_batches


def create_train_dataloader(
    config: PretrainedConfig,
    freq,
    data,
    batch_size: int,
    num_batches_per_epoch: int,
    shuffle_buffer_length: Optional[int] = None,
    cache_data: bool = True,
    **kwargs,
) -> Iterable:
    PREDICTION_INPUT_NAMES = [
        "past_time_features",
        "past_values",
        "past_observed_mask",
        "future_time_features",
    ]
    if config.num_static_categorical_features > 0:
        PREDICTION_INPUT_NAMES.append("static_categorical_features")

    if config.num_static_real_features > 0:
        PREDICTION_INPUT_NAMES.append("static_real_features")

    TRAINING_INPUT_NAMES = PREDICTION_INPUT_NAMES + [
        "future_values",
        "future_observed_mask",
    ]

    transformation = create_transformation(freq, config)
    transformed_data = transformation.apply(data, is_train=True)
    if cache_data:
        transformed_data = Cached(transformed_data)

    # we initialize a Training instance
    instance_splitter = create_instance_splitter(config, "train")

    # the instance splitter will sample a window of
    # context length + lags + prediction length (from all the possible transformed time series, 1 in our case)
    # randomly from within the target time series and return an iterator.
    stream = Cyclic(transformed_data).stream()
    training_instances = instance_splitter.apply(
        stream, is_train=True
    )
    
    return as_stacked_batches(
        training_instances,
        batch_size=batch_size,
        shuffle_buffer_length=shuffle_buffer_length,
        field_names=TRAINING_INPUT_NAMES,
        output_type=torch.tensor,
        num_batches_per_epoch=num_batches_per_epoch,
    )
```


```python
def create_test_dataloader(
    config: PretrainedConfig,
    freq,
    data,
    batch_size: int,
    **kwargs,
):
    PREDICTION_INPUT_NAMES = [
        "past_time_features",
        "past_values",
        "past_observed_mask",
        "future_time_features",
    ]
    if config.num_static_categorical_features > 0:
        PREDICTION_INPUT_NAMES.append("static_categorical_features")

    if config.num_static_real_features > 0:
        PREDICTION_INPUT_NAMES.append("static_real_features")

    transformation = create_transformation(freq, config)
    transformed_data = transformation.apply(data, is_train=False)

    # we create a Test Instance splitter which will sample the very last
    # context window seen during training only for the encoder.
    instance_sampler = create_instance_splitter(config, "test")

    # we apply the transformations in test mode
    testing_instances = instance_sampler.apply(transformed_data, is_train=False)
    
    return as_stacked_batches(
        testing_instances,
        batch_size=batch_size,
        output_type=torch.tensor,
        field_names=PREDICTION_INPUT_NAMES,
    )
```


```python
train_dataloader = create_train_dataloader(
    config=config,
    freq=freq,
    data=multi_variate_train_dataset,
    batch_size=256,
    num_batches_per_epoch=100,
    num_workers=2,
)

test_dataloader = create_test_dataloader(
    config=config,
    freq=freq,
    data=multi_variate_test_dataset,
    batch_size=32,
)
```

è®©æˆ‘ä»¬æŸ¥çœ‹ä¸€ä¸‹ç¬¬ä¸€æ‰¹æ¬¡ï¼š


```python
batch = next(iter(train_dataloader))
for k, v in batch.items():
    print(k, v.shape, v.type())

>>> past_time_features torch.Size([256, 264, 5]) torch.FloatTensor
    past_values torch.Size([256, 264, 862]) torch.FloatTensor
    past_observed_mask torch.Size([256, 264, 862]) torch.FloatTensor
    future_time_features torch.Size([256, 48, 5]) torch.FloatTensor
    future_values torch.Size([256, 48, 862]) torch.FloatTensor
    future_observed_mask torch.Size([256, 48, 862]) torch.FloatTensor
```

å¯ä»¥çœ‹å‡ºï¼Œæˆ‘ä»¬æ²¡æœ‰å°† `input_ids` å’Œ `attention_mask` æä¾›ç»™ç¼–ç å™¨ï¼ˆNLP æ¨¡å‹å°±æ˜¯è¿™ç§æƒ…å†µï¼‰ï¼Œè€Œæ˜¯å°† `past_values` ä»¥åŠ `past_observed_mask`ã€`past_time_features` å’Œ `static_real_features` æä¾›ç»™ç¼–ç å™¨.

è§£ç å™¨è¾“å…¥åŒ…æ‹¬ `future_values`ã€`future_observed_mask` å’Œ `future_time_features`ã€‚ `future_values` å¯ä»¥ç­‰åŒäº NLP ä¸­çš„ `decoder_input_ids` ã€‚

æˆ‘ä»¬å‚è€ƒäº†[æ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/model_doc/informer#transformers.InformerModel.forward.past_values) ä»¥è·å¾—å¯¹å®ƒä»¬ä¸­æ¯ä¸€ä¸ªçš„è¯¦ç»†è§£é‡Šã€‚

## å‰å‘ä¼ é€’

è®©æˆ‘ä»¬å¯¹åˆšåˆšåˆ›å»ºçš„æ‰¹æ¬¡æ‰§è¡Œä¸€æ¬¡å‰å‘ä¼ é€’ï¼š


```python
# perform forward pass
outputs = model(
    past_values=batch["past_values"],
    past_time_features=batch["past_time_features"],
    past_observed_mask=batch["past_observed_mask"],
    static_categorical_features=batch["static_categorical_features"]
    if config.num_static_categorical_features > 0
    else None,
    static_real_features=batch["static_real_features"]
    if config.num_static_real_features > 0
    else None,
    future_values=batch["future_values"],
    future_time_features=batch["future_time_features"],
    future_observed_mask=batch["future_observed_mask"],
    output_hidden_states=True,
)
```


```python
print("Loss:", outputs.loss.item())

>>> Loss: -1071.5718994140625
```

è¯·æ³¨æ„ï¼Œè¯¥æ¨¡å‹æ­£åœ¨è¿”å›æŸå¤±ã€‚è¿™æ˜¯å¯èƒ½çš„ï¼Œå› ä¸ºè§£ç å™¨ä¼šè‡ªåŠ¨å°† `future_values` å‘å³ç§»åŠ¨ä¸€ä¸ªä½ç½®ä»¥è·å¾—æ ‡ç­¾ã€‚è¿™å°†å…è®¸è®¡ç®—é¢„æµ‹å€¼å’Œæ ‡ç­¾ä¹‹é—´çš„æŸå¤±ã€‚æŸå¤±æ˜¯é¢„æµ‹åˆ†å¸ƒç›¸å¯¹äºçœŸå®å€¼çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼Œå¹¶ä¸”è¶‹äºè´Ÿæ— ç©·å¤§ã€‚

å¦å¤–è¯·æ³¨æ„ï¼Œè§£ç å™¨ä½¿ç”¨å› æœæ©ç æ¥é®ç›–æœªæ¥ï¼Œå› ä¸ºå®ƒéœ€è¦é¢„æµ‹çš„å€¼åœ¨ `future_values` å¼ é‡ä¸­ã€‚

## è®­ç»ƒæ¨¡å‹

æ˜¯æ—¶å€™è®­ç»ƒæ¨¡å‹äº†ï¼æˆ‘ä»¬å°†ä¼šä½¿ç”¨æ ‡å‡†çš„ PyTorch training loopã€‚


æˆ‘ä»¬å°†åœ¨è¿™é‡Œä½¿ç”¨ ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate/index) åº“ï¼Œå®ƒä¼šè‡ªåŠ¨å°†æ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œæ•°æ®åŠ è½½å™¨æ”¾ç½®åœ¨é€‚å½“çš„`è®¾å¤‡`ä¸Šã€‚

```python
from accelerate import Accelerator
from torch.optim import AdamW

epochs = 25
loss_history = []

accelerator = Accelerator()
device = accelerator.device

model.to(device)
optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)

model, optimizer, train_dataloader = accelerator.prepare(
    model,
    optimizer,
    train_dataloader,
)

model.train()
for epoch in range(epochs):
    for idx, batch in enumerate(train_dataloader):
        optimizer.zero_grad()
        outputs = model(
            static_categorical_features=batch["static_categorical_features"].to(device)
            if config.num_static_categorical_features > 0
            else None,
            static_real_features=batch["static_real_features"].to(device)
            if config.num_static_real_features > 0
            else None,
            past_time_features=batch["past_time_features"].to(device),
            past_values=batch["past_values"].to(device),
            future_time_features=batch["future_time_features"].to(device),
            future_values=batch["future_values"].to(device),
            past_observed_mask=batch["past_observed_mask"].to(device),
            future_observed_mask=batch["future_observed_mask"].to(device),
        )
        loss = outputs.loss

        # Backpropagation
        accelerator.backward(loss)
        optimizer.step()

        loss_history.append(loss.item())
        if idx % 100 == 0:
            print(loss.item())

>>> -1081.978515625
    ...
    -2877.723876953125
```

```python
# view training
loss_history = np.array(loss_history).reshape(-1)
x = range(loss_history.shape[0])
plt.figure(figsize=(10, 5))
plt.plot(x, loss_history, label="train")
plt.title("Loss", fontsize=15)
plt.legend(loc="upper right")
plt.xlabel("iteration")
plt.ylabel("nll")
plt.show()
```

![png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/output_62_0.png)
    

## æ¨ç†

åœ¨æ¨ç†æ—¶ï¼Œå»ºè®®ä½¿ç”¨ `generate()` æ–¹æ³•è¿›è¡Œè‡ªå›å½’ç”Ÿæˆï¼Œç±»ä¼¼äº NLP æ¨¡å‹ã€‚

é¢„æµ‹æ¶‰åŠä»æµ‹è¯•å®ä¾‹é‡‡æ ·å™¨è·å–æ•°æ®ï¼Œè¯¥é‡‡æ ·å™¨å°†ä»æ•°æ®é›†ä¸­æ¯ä¸ªæ—¶é—´åºåˆ—çš„æœ€åä¸€ä¸ª `context_length` å¤§å°çš„å€¼çª—å£ä¸­é‡‡æ ·ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™æ¨¡å‹ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å°†æå‰å·²çŸ¥çš„ `future_time_features` ä¼ é€’ç»™è§£ç å™¨ã€‚

è¯¥æ¨¡å‹å°†ä»é¢„æµ‹åˆ†å¸ƒä¸­è‡ªå›å½’é‡‡æ ·ä¸€å®šæ•°é‡çš„å€¼ï¼Œå¹¶å°†å®ƒä»¬ä¼ å›è§£ç å™¨ä»¥è¿”å›é¢„æµ‹è¾“å‡ºï¼š


```python
model.eval()

forecasts_ = []

for batch in test_dataloader:
    outputs = model.generate(
        static_categorical_features=batch["static_categorical_features"].to(device)
        if config.num_static_categorical_features > 0
        else None,
        static_real_features=batch["static_real_features"].to(device)
        if config.num_static_real_features > 0
        else None,
        past_time_features=batch["past_time_features"].to(device),
        past_values=batch["past_values"].to(device),
        future_time_features=batch["future_time_features"].to(device),
        past_observed_mask=batch["past_observed_mask"].to(device),
    )
    forecasts_.append(outputs.sequences.cpu().numpy())
```

è¯¥æ¨¡å‹è¾“å‡ºå½¢çŠ¶çš„å¼ é‡ï¼ˆ`batch_size`ã€`number of samples`ã€`prediction length`ã€`input_size`ï¼‰ã€‚

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯¹äº `862` æ—¶é—´åºåˆ—ä¸­çš„æ¯ä¸ªæ—¶é—´åºåˆ—ï¼Œæˆ‘ä»¬åœ¨æ¥ä¸‹æ¥çš„ `48` å°æ—¶å†…è·å¾— `100` ä¸ªå¯èƒ½å€¼ï¼ˆå¯¹äºå¤§å°ä¸º `1` çš„æ‰¹å¤„ç†ä¸­çš„æ¯ä¸ªç¤ºä¾‹ï¼Œå› ä¸ºæˆ‘ä»¬åªæœ‰ä¸€ä¸ªå¤šå…ƒæ—¶é—´åºåˆ—ï¼‰ï¼š


```python
forecasts_[0].shape

>>> (1, 100, 48, 862)
```

æˆ‘ä»¬å°†å‚ç›´å †å å®ƒä»¬ï¼Œä»¥è·å¾—æµ‹è¯•æ•°æ®é›†ä¸­æ‰€æœ‰æ—¶é—´åºåˆ—çš„é¢„æµ‹ï¼ˆä»¥é˜²ä¸‡ä¸€æµ‹è¯•é›†ä¸­æœ‰æ›´å¤šæ—¶é—´åºåˆ—ï¼‰ï¼š

```python
forecasts = np.vstack(forecasts_)
print(forecasts.shape)

>>> (1, 100, 48, 862)
```

æˆ‘ä»¬å¯ä»¥æ ¹æ®æµ‹è¯•é›†ä¸­å­˜åœ¨çš„æ ·æœ¬å€¼ï¼Œæ ¹æ®çœŸå®æƒ…å†µè¯„ä¼°ç”Ÿæˆçš„é¢„æµ‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ ğŸ¤— [Evaluate](https://huggingface.co/docs/evaluate/index) åº“ï¼Œå…¶ä¸­åŒ…æ‹¬ [MASE](https://huggingface.co/spaces/evaluate-metric/mase) å’Œ [sMAPE](https://huggingface.co/spaces/evaluate-metric/smape) æŒ‡æ ‡ã€‚

æˆ‘ä»¬è®¡ç®—æ•°æ®é›†ä¸­æ¯ä¸ªæ—¶é—´åºåˆ—å˜é‡çš„ä¸¤ä¸ªæŒ‡æ ‡ï¼š


```python
from evaluate import load
from gluonts.time_feature import get_seasonality

mase_metric = load("evaluate-metric/mase")
smape_metric = load("evaluate-metric/smape")

forecast_median = np.median(forecasts, 1).squeeze(0).T

mase_metrics = []
smape_metrics = []

for item_id, ts in enumerate(test_dataset):
    training_data = ts["target"][:-prediction_length]
    ground_truth = ts["target"][-prediction_length:]
    mase = mase_metric.compute(
        predictions=forecast_median[item_id],
        references=np.array(ground_truth),
        training=np.array(training_data),
        periodicity=get_seasonality(freq),
    )
    mase_metrics.append(mase["mase"])

    smape = smape_metric.compute(
        predictions=forecast_median[item_id],
        references=np.array(ground_truth),
    )
    smape_metrics.append(smape["smape"])
```


```python
print(f"MASE: {np.mean(mase_metrics)}")

>>> MASE: 1.1913437728068093

print(f"sMAPE: {np.mean(smape_metrics)}")

>>> sMAPE: 0.5322665081607634
```


```python
plt.scatter(mase_metrics, smape_metrics, alpha=0.2)
plt.xlabel("MASE")
plt.ylabel("sMAPE")
plt.show()
```

![png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/output_73_0.png)
    
ä¸ºäº†ç»˜åˆ¶ä»»ä½•æ—¶é—´åºåˆ—çš„é¢„æµ‹ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä»¥ä¸‹åŠ©æ‰‹ï¼š


```python
import matplotlib.dates as mdates


def plot(ts_index, mv_index):
    fig, ax = plt.subplots()

    index = pd.period_range(
        start=multi_variate_test_dataset[ts_index][FieldName.START],
        periods=len(multi_variate_test_dataset[ts_index][FieldName.TARGET]),
        freq=multi_variate_test_dataset[ts_index][FieldName.START].freq,
    ).to_timestamp()

    ax.xaxis.set_minor_locator(mdates.HourLocator())

    ax.plot(
        index[-2 * prediction_length :],
        multi_variate_test_dataset[ts_index]["target"][mv_index, -2 * prediction_length :],
        label="actual",
    )

    ax.plot(
        index[-prediction_length:],
        forecasts[ts_index, ..., mv_index].mean(axis=0),
        label="mean",
    )
    ax.fill_between(
        index[-prediction_length:],
        forecasts[ts_index, ..., mv_index].mean(0)
        - forecasts[ts_index, ..., mv_index].std(axis=0),
        forecasts[ts_index, ..., mv_index].mean(0)
        + forecasts[ts_index, ..., mv_index].std(axis=0),
        alpha=0.2,
        interpolate=True,
        label="+/- 1-std",
    )
    ax.legend()
    fig.autofmt_xdate()
```

ä¸¾ä¸ªä¾‹å­ï¼š


```python
plot(0, 344)
```

![png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/informer/output_77_0.png)
    

## ç»“è®º

æˆ‘ä»¬å¦‚ä½•ä¸å…¶ä»–æ¨¡å‹è¿›è¡Œæ¯”è¾ƒï¼Ÿ [Monash Time Series Repository](https://forecastingdata.org/#results) æœ‰ä¸€ä¸ªæµ‹è¯•é›† MASE æŒ‡æ ‡çš„æ¯”è¾ƒè¡¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶æ·»åŠ åˆ°é‡Œé¢ï¼š

|Dataset | 	SES| 	Theta | 	TBATS| 	ETS	| (DHR-)ARIMA| 	PR|	CatBoost |	FFNN	| DeepAR | 	N-BEATS | 	WaveNet|  Transformer (uni.) | **Informer (mv. our)**| 
|:------------------:|:-----------------:|:--:|:--:|:--:|:--:|:--:|:--:|:---:|:---:|:--:|:--:|:--:|:--:|
|Traffic Hourly | 1.922	| 1.922	| 2.482 |	2.294|	2.535|	1.281|	1.571	|0.892|	0.825	|1.100|	1.066	| **0.821** | 1.191 |

å¯ä»¥çœ‹å‡ºï¼Œä¹Ÿè®¸æœ‰äº›äººä¼šæ„Ÿåˆ°æƒŠè®¶ï¼Œå¤šå˜é‡é¢„æµ‹é€šå¸¸æ¯”å•å˜é‡é¢„æµ‹_æ›´å·®_ï¼ŒåŸå› æ˜¯éš¾ä»¥ä¼°è®¡è·¨ç³»åˆ—ç›¸å…³æ€§/å…³ç³»ã€‚ä¼°è®¡å¢åŠ çš„é¢å¤–æ–¹å·®é€šå¸¸ä¼šæŸå®³æœ€ç»ˆçš„é¢„æµ‹æˆ–æ¨¡å‹å­¦ä¹ è™šå‡ç›¸å…³æ€§ã€‚æˆ‘ä»¬å‚è€ƒ [è¿™ç¯‡æ–‡ç« ](https://openreview.net/forum?id=GpW327gxLTF) æ¥è¿›ä¸€æ­¥é˜…è¯»ã€‚å½“å¯¹å¤§é‡æ•°æ®è¿›è¡Œè®­ç»ƒæ—¶ï¼Œå¤šå˜é‡æ¨¡å‹å¾€å¾€æ•ˆæœå¾ˆå¥½ã€‚

æ‰€ä»¥åŸå§‹ Transformer åœ¨è¿™é‡Œä»ç„¶è¡¨ç°æœ€å¥½ï¼å°†æ¥ï¼Œæˆ‘ä»¬å¸Œæœ›é›†ä¸­çš„æ›´å¥½åœ°å¯¹è¿™äº›æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œä»¥ä¾¿äºé‡ç°å‡ ç¯‡è®ºæ–‡çš„ç»“æœã€‚æ•¬è¯·æœŸå¾…æ›´å¤šï¼

## èµ„æº

æˆ‘ä»¬å»ºè®®æŸ¥çœ‹ [Informer æ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/model_doc/informer) å’Œ [ç¤ºä¾‹ notebook](https://github.com/huggingface/notebooks/blob/main/examples/multivariate_informer.ipynb) é“¾æ¥åœ¨æ­¤åšå®¢æ–‡ç« çš„é¡¶éƒ¨ã€‚
