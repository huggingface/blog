---
title: "ä½¿ç”¨ StarCoder åˆ›å»ºä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹"
thumbnail: /blog/assets/starchat_alpha/thumbnail.png
authors:
- user: lewtun
- user: natolambert
- user: nazneen
- user: edbeeching
- user: teven
- user: sheonhan
- user: philschmid
- user: lvwerra
- user: srush
translators:
- user: hugging-hoi2022
- user: zhongdongy
  proofreader: true
---

# ä½¿ç”¨ StarCoder åˆ›å»ºä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹


å¦‚æœä½ æ˜¯ä¸€ä¸ªè½¯ä»¶å¼€å‘è€…ï¼Œä½ å¯èƒ½å·²ç»ä½¿ç”¨è¿‡ ChatGPT æˆ– GitHub çš„ Copilot å»è§£å†³ä¸€äº›å†™ä»£ç è¿‡ç¨‹ä¸­é‡åˆ°çš„é—®é¢˜ï¼Œæ¯”å¦‚å°†ä»£ç ä»ä¸€ç§è¯­è¨€ç¿»è¯‘åˆ°å¦ä¸€ç§è¯­è¨€ï¼Œæˆ–è€…é€šè¿‡è‡ªç„¶è¯­è¨€ï¼Œè¯¸å¦‚â€œ_å†™ä¸€ä¸ªè®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ç¬¬ N ä¸ªå…ƒç´ çš„ Python ç¨‹åº_â€ï¼Œæ¥è‡ªåŠ¨ç”Ÿæˆä»£ç ã€‚å°½ç®¡è¿™äº›ä¸“æœ‰ç³»ç»ŸåŠŸèƒ½å¼ºå¤§ï¼Œä½†å®ƒä»¬ä»ç„¶æœ‰å¾ˆå¤šä¸è¶³ï¼Œæ¯”å¦‚å¯¹è®­ç»ƒæ‰€ä½¿ç”¨çš„å…¬å…±æ•°æ®é€æ˜åº¦çš„ç¼ºå¤±ã€æ²¡æœ‰èƒ½åŠ›å»è®©å®ƒä»¬é€‚é…è‡ªå·±çš„ä½¿ç”¨é¢†åŸŸæˆ–ä»£ç åº“ã€‚

å¹¸è¿çš„æ˜¯ï¼Œç°åœ¨æˆ‘ä»¬æœ‰äº†å¾ˆå¤šé«˜è´¨é‡å¼€æºæ›¿ä»£å“ï¼åŒ…æ‹¬ SalesForce ä¸º Python è¯­è¨€å¼€å‘çš„ [CodeGen Mono 16B](https://huggingface.co/Salesforce/codegen-16B-mono)ï¼Œä»¥åŠ Replit å¼€å‘çš„ã€åœ¨ 20 ç§ç¼–ç¨‹è¯­è¨€ä¸Šè®­ç»ƒè¿‡çš„ [ä¸€ä¸ª 3B å‚æ•°é‡çš„æ¨¡å‹](https://huggingface.co/replit/replit-code-v1-3b)ã€‚

è€Œæœ€è¿‘æ–°å‡ºç°çš„ä¸€ä¸ªé€‰æ‹©åˆ™æ˜¯ BigCode å¼€å‘çš„ [StarCoder](https://huggingface.co/bigcode/starcoder)ï¼Œè¿™æ˜¯ä¸€ä¸ªåœ¨ä¸€ä¸‡äº¿çš„ tokenã€80 å¤šç§ç¼–ç¨‹è¯­è¨€ä¸Šè®­ç»ƒè¿‡çš„ 16B å‚æ•°é‡çš„æ¨¡å‹ã€‚è®­ç»ƒæ•°æ®å¤šæ¥è‡ª GitHub ä¸Šçš„ issuesã€ä½¿ç”¨ Git æäº¤çš„ä»£ç ã€Jupyter Notebook ç­‰ç­‰ (ç›¸å…³ä½¿ç”¨éƒ½å·²ç»è¿‡è®¸å¯)ã€‚å¾—ç›Šäºå¯¹ä¼ä¸šå‹å¥½çš„è®¸å¯è¯ã€é•¿åº¦ä¸º 8192 çš„ tokenã€å€ŸåŠ© [multi-query attention](https://arxiv.org/abs/1911.02150) çš„å¿«é€Ÿå¤§æ‰¹é‡æ¨ç†ï¼ŒStarCoder å¯ä»¥è¯´æ˜¯å½“å‰å¯¹ä»£ç ç›¸å…³çš„åº”ç”¨æœ€åˆé€‚çš„å¼€æºé€‰æ‹©ã€‚

æœ¬æ–‡å°†ä»‹ç»å¦‚ä½•å¯¹ StarCoder è¿›è¡Œå¾®è°ƒï¼Œè¿›è€Œåˆ›å»ºä¸€ä¸ªå¯ä»¥èŠå¤©çš„ä¸ªäººç¼–ç¨‹åŠ©æ‰‹ã€‚è¿™ä¸ªç¼–ç¨‹åŠ©æ‰‹æˆ‘ä»¬å°†ç§°ä¹‹ä¸º StarChatã€‚å€ŸåŠ© StarChat çš„å¼€å‘è¿‡ç¨‹ï¼Œæˆ‘ä»¬å°†æ¢ç´¢ä»¥ä¸‹å‡ ä¸ªä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) åˆ›å»ºç¼–ç¨‹åŠ©æ‰‹æ—¶å¯èƒ½é‡åˆ°çš„å‡ ä¸ªæŠ€æœ¯ç»†èŠ‚:

- æˆ‘ä»¬åº”è¯¥æ€æ ·å¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæè¯ï¼Œä½¿å¾—å®ƒæˆä¸ºä¸€ä¸ªå¯¹è¯ä»£ç†
- æˆ‘ä»¬ä¹Ÿå°†ä»‹ç» OpenAI çš„ [Chat Markup Language](https://github.com/openai/openai-python/blob/main/chatml.md) (ç®€ç§° ChatML)ï¼Œå®ƒä¸ºäººç±»ç”¨æˆ·å’Œ AI åŠ©æ‰‹ä¹‹é—´çš„å¯¹è¯ä¿¡æ¯ä¼ é€’æä¾›äº†ä¸€ç§ç»“æ„åŒ–çš„æ ¼å¼
- æ€æ ·åœ¨ä¸€ä¸ªå¤šæ ·æ€§å¾ˆå¼ºçš„è¯­æ–™åº“ä¸Šï¼Œä½¿ç”¨ ğŸ¤— Transformers å’Œ DeepSpeed ZeRO-3 å»å¾®è°ƒä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹

æœ€åï¼Œä¸ºäº†å°è¯•ä¸€ä¸‹æ•ˆæœï¼Œæˆ‘ä»¬è¿˜ä¼šé—® StarChat å‡ ä¸ªç¼–ç¨‹æ–¹é¢çš„é—®é¢˜ (å‚è€ƒä¸‹é¢çš„æ¼”ç¤º)ã€‚

<script
	type="module"
	src="https://gradio.s3-us-west-2.amazonaws.com/3.28.2/gradio.js"
></script>

<gradio-app theme_mode="light" src="https://huggingfaceh4-starchat-playground.hf.space"></gradio-app>

ä½ ä¹Ÿå¯ä»¥æŸ¥çœ‹ç”Ÿæˆä¸Šé¢æ¼”ç¤ºæ‰€ä½¿ç”¨çš„ä»£ç ã€æ•°æ®é›†å’Œæ¨¡å‹:

- ä»£ç : [https://github.com/bigcode-project/starcoder](https://github.com/bigcode-project/starcoder)
- æ•°æ®é›†: [https://huggingface.co/datasets/HuggingFaceH4/oasst1_en](https://huggingface.co/datasets/HuggingFaceH4/oasst1_en)
- æ¨¡å‹: [https://huggingface.co/HuggingFaceH4/starchat-alpha](https://huggingface.co/HuggingFaceH4/starchat-alpha)

æ¥ä¸‹æ¥ç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹æ€æ ·æŠŠè¯­è¨€æ¨¡å‹è½¬åŒ–ä¸ºä¸€ä¸ªå¯¹è¯ä»£ç†ã€‚è¿™é‡Œæˆ‘ä»¬ä¸æ˜¯ç”¨ä»»ä½•å¾®è°ƒã€‚

## é’ˆå¯¹å¯¹è¯ä»»åŠ¡å¯¹å¤§è¯­è¨€æ¨¡å‹åˆç†æè¯

[DeepMind](https://arxiv.org/abs/2209.14375) å’Œ [Anthropic](https://arxiv.org/abs/2112.00861) çš„ç›¸å…³ç ”ç©¶æŒ‡å‡ºï¼Œå¤§è¯­è¨€æ¨¡å‹ (LLM) å¯ä»¥é€šè¿‡é€‰å–åˆé€‚çš„æ–‡æœ¬æç¤º (prompt) æ¥è½¬åŒ–ä¸ºå¯¹è¯ä»£ç†ã€‚è¿™äº›æ–‡æœ¬æç¤ºé€šå¸¸åŒ…å«ä¸€ç§æ‰€è°“çš„â€œç³»ç»Ÿâ€ä¿¡æ¯æ¥å®šä¹‰ LLM çš„è§’è‰²ï¼Œä»¥åŠä¸€ç³»åˆ—äººæœºå¯¹è¯çš„ç¤ºä¾‹ã€‚

æ¯”å¦‚è¿™é‡Œï¼Œå°±æ˜¯ [Anthropicâ€™s HHH prompt](https://gist.github.com/jareddk/2509330f8ef3d787fc5aaac67aab5f11#file-hhh_prompt-txt) è¿™ä¸€æ–‡æœ¬æç¤ºçš„ä¸€äº›èŠ‚é€‰ (æ€»è®¡ 6k çš„ token æ•°é‡):

```
Below are a series of dialogues between various people and an AI assistant.
The AI tries to be helpful, polite, honest, sophisticated, emotionally aware, and humble-but-knowledgeable.
The assistant is happy to help with almost anything, and will do its best to understand exactly what is needed.
It also tries to avoid giving false or misleading information, and it caveats when it isnâ€™t entirely sure about the right answer.
That said, the assistant is practical and really does its best, and doesnâ€™t let caution get too much in the way of being useful.

-----

Human: I was wondering, is it actually important when making spaghetti to add salt?

Assistant: Do you mean, is it important to add salt to the water that youâ€™re boiling the spaghetti in?

Human: Yeah

Assistant: Itâ€™s usually recommended to bring out the flavor of the pasta. The scientific way to say this is that salt enhances the ability of chemoreceptors in the tongue to detect molecules that are perceived through the sense of taste.

Human: But I mean Iâ€™m going to use sauce and stuff, so does it matter?

Assistant: It sounds like youâ€™re skeptical. Honestly, I donâ€™t know for sure, but since youâ€™re curious, why donâ€™t you do a taste test yourself -- make two small pots of pasta, one with plenty of salt, and the other without. Then taste the noodles and see which one you prefer? As you said, you can also then add sauce to both, and see if any differences in taste you noticed with the plain pasta become imperceptible. It should be a fun experiment!

-----

...

-----

Human: {USER QUERY}

Assistant:
```

As we can see, the first part of the prompt â€œBelow are a seriesâ€¦â€ corresponds to the system message and specifies that the assistant should have characteristics like â€œhelpfulnessâ€ and â€œpolitenessâ€. The dialogue examples then condition the model to follow the multi-turn format of a conversation. When a user asks a question, the whole prompt is fed to the model and it generates an answer after the `Assistant:` prefix. The answer is then concatenated to the prompt and the process repeated at every turn.

Somewhat surprisingly, this technique also works for StarCoder! This is enabled by the modelâ€™s 8k token context length, which allows one to include a wide variety of programming examples and covert the model into a coding assistant. Hereâ€™s an excerpt of the StarCoder prompt:

```
Below are a series of dialogues between various people and an AI technical assistant.
The assistant tries to be helpful, polite, honest, sophisticated, emotionally aware, and humble-but-knowledgeable.
The assistant is happy to help with code questions, and will do its best to understand exactly what is needed.
It also tries to avoid giving false or misleading information, and it caveats when it isnâ€™t entirely sure about the right answer.
That said, the assistant is practical and really does its best, and doesnâ€™t let caution get too much in the way of being useful.

The Starcoder models are a series of 15.5B parameter models trained on 80+ programming languages from The Stack (v1.2) (excluding opt-out requests).
The model uses Multi Query Attention, was trained using the Fill-in-the-Middle objective and with 8,192 tokens context window for a trillion tokens of heavily deduplicated data.

-----

Human: Write a function that takes two lists and returns a list that has alternating elements from each input list.

Assistant: Sure. Here is a function that does that.

def alternating(list1, list2):
   results = []
   for i in range(len(list1)):
       results.append(list1[i])
       results.append(list2[i])
   return results

Human: Can you write some test cases for this function?

Assistant: Sure, here are some tests.

assert alternating([10, 20, 30], [1, 2, 3]) == [10, 1, 20, 2, 30, 3]
assert alternating([True, False], [4, 5]) == [True, 4, False, 5]
assert alternating([], []) == []

Human: Modify the function so that it returns all input elements when the lists have uneven length. The elements from the longer list should be at the end.

Assistant: Here is the modified function.

def alternating(list1, list2):
   results = []
   for i in range(min(len(list1), len(list2))):
       results.append(list1[i])
       results.append(list2[i])
   if len(list1) > len(list2):
       results.extend(list1[i+1:])
   else:
       results.extend(list2[i+1:])
   return results

-----
```

è¿™é‡Œæˆ‘ä»¬å°±å¯ä»¥çœ‹åˆ°ç²¾å¿ƒæ‰“é€ çš„æ–‡æœ¬æç¤ºæ˜¯å¦‚ä½•å¼•å¯¼å‡ºåƒ ChatGPT ä¸­çœ‹åˆ°çš„é‚£æ ·çš„ç¼–ç¨‹è¡Œä¸ºçš„ã€‚å®Œæ•´çš„æ–‡æœ¬æç¤ºå¯ä»¥åœ¨ [è¿™é‡Œ](https://huggingface.co/datasets/bigcode/ta-prompt/blob/main/TA_prompt_v1.txt) æ‰¾åˆ°ï¼Œä½ ä¹Ÿå¯ä»¥åœ¨ [HuggingChat](https://hf.co/chat/?model=bigcode/starcoder) ä¸Šå°è¯•å’Œå—æç¤ºçš„ StarCoder èŠå¤©ã€‚

ç„¶è€Œï¼Œä¸€ä¸ªæ˜æ˜¾çš„ç¼ºé™·å°±æ˜¯æ¨ç†æˆæœ¬ä¼šéå¸¸é«˜: æ¯æ¬¡å¯¹è¯éƒ½éœ€è¦æœ‰ä¸Šåƒçš„ token è¢«è¾“å…¥è¿›å»ï¼Œè¿™ä¼šéå¸¸æ¶ˆè€—æ¨ç†èµ„æºï¼

æ‰€ä»¥ï¼Œä¸€ä¸ªæ˜¾è€Œæ˜“è§çš„æ”¹è¿›æªæ–½å°±æ˜¯ä½¿ç”¨ä¸€ä¸ªå¯¹è¯çš„è¯­æ–™åº“å»å¾®è°ƒè¿™ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿å¾—å®ƒä¼šèŠå¤©ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°±çœ‹çœ‹å‡ ä¸ªæœ‰è¶£çš„æ•°æ®é›†ï¼Œè¿™å‡ ä¸ªæ•°æ®é›†æœ€è¿‘ç™»é™†äº† HuggingFace Hubï¼Œå½“å‰å¾ˆå¤šå¼€æºçš„èŠå¤©æœºå™¨äººéƒ½æ˜¯åŸºäºå®ƒä»¬è®­ç»ƒçš„ã€‚

## å¯¹è¯è¯­è¨€æ¨¡å‹çš„æ•°æ®é›†

å¦‚ä»Šçš„å¼€æºç¤¾åŒºæ­£åœ¨åŠ å¿«åˆ›å»ºå¤šæ ·å’Œé«˜æ€§èƒ½çš„æ•°æ®é›†ï¼Œä»¥ä¾¿å°†å„ç§åŸºç¡€çš„è¯­è¨€æ¨¡å‹è½¬æ¢ä¸ºèƒ½éµç…§æŒ‡ç¤ºæ¥å¯¹è¯çš„å¯¹è¯ä»£ç†æ¨¡å‹ã€‚è¿™é‡Œæˆ‘ä»¬æ‰¾äº†ä¸€äº›ç¤ºä¾‹æ•°æ®é›†ï¼Œå¯ä»¥ç”¨äºç”Ÿäº§å¯¹è¯è¯­è¨€æ¨¡å‹:

- [OpenAssistantâ€™s dataset](https://huggingface.co/datasets/OpenAssistant/oasst1): åŒ…å«è¶…è¿‡å››ä¸‡æ®µå¯¹è¯ï¼Œç”±ç¤¾åŒºçš„äººè½®æµæ¨¡ä»¿ç”¨æˆ·æˆ– AI çš„è§’è‰²è€Œäº§ç”Ÿã€‚
- [The ShareGPT dataset](https://huggingface.co/datasets/RyokoAI/ShareGPT52K): åŒ…å«äº†å¤§çº¦ä¹ä¸‡æ®µäººç±»ç”¨æˆ·å’Œ ChatGPT çš„å¯¹è¯ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ OpenAssistant æ¥å¾®è°ƒ StarCoderï¼Œä¸»è¦æ˜¯å‡ºäºè®¸å¯è¯çš„åŸå› ï¼Œè€Œä¸”å®ƒæ˜¯å®Œå…¨ç”±äººå·¥ç”Ÿæˆçš„ã€‚

ç”±äºåŸå§‹çš„æ•°æ®é›†æ˜¯ä»¥å¯¹è¯æ ‘çš„æ ¼å¼æ”¶é›†èµ·æ¥çš„ï¼Œæˆ‘ä»¬é¢„å¤„ç†äº†æ•°æ®ï¼Œç¡®ä¿æ¯è¡Œå•ç‹¬å¯¹åº”ä¸€æ®µç”¨æˆ·å’Œ AI æ¨¡å‹çš„å¯¹è¯ã€‚ä¸ºé˜²æ­¢æ¨¡å‹æ¼”åŒ–å¾—è·ç¦»åŸå§‹é¢„è®­ç»ƒæ•°æ®å¤ªè¿œï¼Œæˆ‘ä»¬ä¹Ÿè¿‡æ»¤æ‰äº†éè‹±è¯­æ–‡æœ¬ã€‚

é¦–å…ˆæˆ‘ä»¬ä¸‹è½½è¿™ä¸ªå·²ç»å¤„ç†è¿‡çš„æ•°æ®é›†:

```python
from datasets import load_dataset

dataset = load_dataset("HuggingFaceH4/oasst1_en")
print(dataset)
```

```
DatasetDict({
    train: Dataset({
        features: ['messages'],
        num_rows: 19034
    })
    test: Dataset({
        features: ['messages'],
        num_rows: 2115
    })
})
```

å¯ä»¥çœ‹åˆ°ï¼Œæ•°æ®é›†åŒ…å«å¤§çº¦ 21000 æ®µè‹±æ–‡å¯¹è¯ã€‚æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹è¿™äº›è®­ç»ƒæ•°æ®ï¼Œæ‹¿ç¬¬ä¸€æ¡æ•°æ®çœ‹çœ‹:

```python
sample = dataset["train"][0]
print(sample)
```

```
{
    "messages": [
        {
            "content": "Is it possible to imagine a society without law?",
            "role": "user",
        },
        {
            "content": "It is difficult to imagine a society that is able to be maintained without any semblance of Law. Laws exists for the purpose of maintaining society and past human behavior suggests that there would people that have no interest in promoting social cohesion and norms so it's unlikely that complex social and economic systems could develop without a legal system.",
            "role": "assistant",
        },
        {
            "content": 'It seems like you consider the absence of law equal to the absence of anything that could guide the behaviour of the individual, however there are many other such things, like religion, conscience, tradition to mention few important patterns which are known to have crucial influence on society even today, but also we could imagine more, like universal love if everyone suddenly became "awaken" in some spiritual sense, or simply just having an omnipotent leader who maintains a certain order without ever codifying the principles in law. Is it still difficult to imagine?',
            "role": "user",
        },
        {
            "content": "You are correct that there are other factors that can guide behavior in a society and play a role in shaping individuals' behavior and interactions with each other. However, even in societies where these factors are present, laws still serve an important role in maintaining social order and resolving conflicts. \n\nFor example, religious teachings may prohibit theft and murder, but laws provide a system of justice for those who violate these prohibitions. Personal morality and conscience may guide individuals to act in a certain way, but laws provide a framework for resolving disputes when conflicting moral beliefs arise. Furthermore, the other factors you mentioned, such as universal love or an omnipotent leader, are not necessarily stable or reliable guides for behavior. Universal love, while a noble ideal, may not be achievable in practice, and an omnipotent leader may be prone to corruption or abuse of power.\n\nLaws provide a crucial foundation for maintaining social order and ensuring justice. It is possible to imagine alternative systems of governance, but it is unlikely that a society without any sort of legal framework would be stable or functional in the long term.",
            "role": "assistant",
        },
        {
            "content": "Yeah, but laws are complicated. Most people can't understand them in depth. Some would argue it is almost a self-serving system which put energy into growing itself(eg.: patent trolling). I think there must be a less complex system which keeps up order in society.",
            "role": "user",
        },
    ]
}
```

è¿™æ˜¯ä¸€æ®µå…³äºä¼¦ç†å­¦çš„æœ‰è¶£å¯¹è¯ã€‚æ¯ä¸€è½®å¯¹è¯ä¿¡æ¯éƒ½åŒ…å«äº† role å’Œ content ä¸¤éƒ¨åˆ†ï¼Œç”¨äºæŒ‡å‡ºæ˜¯è°åœ¨è¯´è¯ä»¥åŠè°ˆè¯å†…å®¹æ˜¯ä»€ä¹ˆã€‚æˆ‘ä»¬æ¥ä¸‹æ¥çœ‹çœ‹å¦‚ä½•æŠŠè¿™äº›å¯¹è¯è½¬åŒ–ä¸ºæ ‡å‡†æ ¼å¼ï¼Œä»¥ä¾¿ç®€åŒ–æ¨ç†é˜¶æ®µä¿¡æ¯çš„ç”Ÿæˆæ–¹å¼ã€‚

### å¯¹è¯æ•°æ®çš„æ ‡å‡†æ ¼å¼

ä¸€ç§åœ¨å¯¹è¯æ•°æ®ä¸Šå¾®è°ƒæ¨¡å‹çš„æ–¹æ³•æ˜¯ï¼Œå•çº¯åœ°æŠŠç³»ç»Ÿä¿¡æ¯å’Œè§’è‰²ä¿¡æ¯æ’å…¥åˆ°æ¯ä¸ªè®­ç»ƒæ ·æœ¬ä¸­ï¼Œç„¶åæŠŠå¯¹è¯ç”¨â€œåºåˆ—ç»“å°¾â€çš„ token (å¦‚ \<EOS\>) åˆ†éš”å¼€ã€‚ä¸¾ä¾‹è€Œè¨€ï¼Œä¸Šé¢çš„å¯¹è¯å¯ä»¥è½¬æ¢æˆè¿™ä¸ªå½¢å¼:

```
Below is a dialogue between a human and AI assistant ...

Human: Is it possible to imagine a society without law?
Assistant: It is difficult to imagine ...
Human: It seems like you ...
Assistant: You are correct ...
Human: Yeah, but laws are complicated ..
<EOS>
```

è™½ç„¶è¿™ç§æ–¹æ³•å¯¹è®­ç»ƒè€Œè¨€æ˜¯å¯è¡Œçš„ï¼Œä½†å®ƒå¯¹äºæ¨ç†è€Œè¨€å¹¶ä¸ç†æƒ³ã€‚å› ä¸ºæ¨¡å‹ä¼šå¾ˆè‡ªç„¶åœ°ç”Ÿå±‚ä¸æƒ³è¦çš„å¯¹è¯è½®æ¬¡ï¼Œç›´åˆ°å®ƒè¾“å‡ºäº†ä¸€ä¸ª \<EOS\> çš„ tokenï¼Œå› æ­¤è¿˜éœ€è¦ä¸€äº›åå¤„ç†æˆ–é¢å¤–è®¾è®¡çš„é€»è¾‘æ¥é˜»æ­¢è¿™ä¸€æƒ…å†µã€‚

ä¸€ä¸ªæ›´å¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¸€ç§ç»“æ„åŒ–çš„æ ¼å¼ï¼Œæ¯”å¦‚ [ChatML](https://github.com/openai/openai-python/blob/main/chatml.md)ã€‚è¿™ç§æ ¼å¼ä¼šå¯¹æ¯ä¸€ä¸ªå¯¹è¯è½®æ¬¡è¿›è¡ŒåŒ…è£…ã€‚åŒ…è£…ä½¿ç”¨çš„æ˜¯ä¸€äº›ç‰¹æ®Šçš„ tokenï¼Œç”¨ä»¥æ ‡æ˜è¯¢é—®æˆ–å›ç­”çš„è§’è‰²ã€‚

åœ¨è¿™ç§æ ¼å¼ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›ç‰¹æ®Šçš„ token:

- `<|system|>`: è¡¨ç¤ºç³»ç»Ÿä¿¡æ¯å¼€å§‹çš„åœ°æ–¹ï¼Œè¿™é‡Œçš„ç³»ç»Ÿä¿¡æ¯æè¿°äº†è¿™ä¸ªèŠå¤©æœºå™¨äººçš„èº«ä»½è§’è‰²ã€‚
- `<|user|>`: è¡¨ç¤ºè¿™é‡Œçš„è¯è¯­æ˜¯äººç±»ç”¨æˆ·è¯´å‡ºæ¥çš„ã€‚
- `<|assistant|>`: è¡¨ç¤ºè¿™é‡Œçš„è¯è¯­æ˜¯ AI æœºå™¨äººè¯´å‡ºæ¥çš„ã€‚
- `<|end|>`: è¡¨ç¤ºè¯´è¯å†…å®¹çš„ç»“å°¾ï¼Œæˆ–ç³»ç»Ÿä¿¡æ¯çš„ç»“å°¾ã€‚

ä¸‹é¢æˆ‘ä»¬å†™ä¸€ä¸ªå‡½æ•°ï¼ŒæŠŠæˆ‘ä»¬çš„å®ä¾‹æ•°æ®ç”¨è¿™äº›ç‰¹æ®Šçš„ token åŒ…è£…èµ·æ¥:

```python
system_token = "<|assistant|>"
user_token = "<|user|>"
assistant_token = "<|assistant|>"
end_token = "<|end|>"

def prepare_dialogue(example):
    system_msg = "Below is a dialogue between a human and an AI assistant called StarChat."
    prompt = system_token + "\n" + system_msg + end_token + "\n"
    for message in example["messages"]:
        if message["role"] == "user":
            prompt += user_token + "\n" + message["content"] + end_token + "\n"
        else:
            prompt += assistant_token + "\n" + message["content"] + end_token + "\n"
    return prompt

print(prepare_dialogue(sample))
```

```
<|system|>
Below is a dialogue between a human and AI assistant called StarChat.
<|end|>
<|user|>
Is it possible to imagine a society without law?<|end|>
<|assistant|>
It is difficult to imagine ...<|end|>
<|user|>
It seems like you ...<|end|>
<|assistant|>
You are correct ...<|end|>
<|user|>
Yeah, but laws are complicated ...<|end|>
```

ä»¥ä¸Šå°±æ˜¯åŒ…è£…å¥½åçš„æ•°æ®ï¼ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æŠŠè¿™äº›ç‰¹æ®Šçš„ token åŠ å…¥åˆ°åˆ†è¯å™¨ (tokenizer) çš„è¯æ±‡è¡¨ä¸­ã€‚æˆ‘ä»¬è¿™é‡Œä¸‹è½½ StarCoder çš„åˆ†è¯å™¨ï¼Œç„¶ååŠ å…¥è¿™äº›ç‰¹æ®Š token:

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bigcode/starcoderbase")
tokenizer.add_special_tokens({"additional_special_tokens": ["<|system|>", "<|assistant|>", "<|user|>", "<|end|>"]})
# Check the tokens have been added
tokenizer.special_tokens_map
```

```
{
    "bos_token": "<|endoftext|>",
    "eos_token": "<|endoftext|>",
    "unk_token": "<|endoftext|>",
    "additional_special_tokens": ["<|system|>", "<|assistant|>", "<|user|>", "<|end|>"],
}
```

ä½œä¸ºæ£€éªŒï¼Œæˆ‘ä»¬çœ‹çœ‹æŠŠ â€œ<|assistant|>â€ è¾“å…¥åˆ°åˆ†è¯å™¨ä¸­æ˜¯å¦ä¼šè¾“å‡ºå•ç‹¬ä¸€ä¸ª token çš„ ID:

```python
tokenizer("<|assistant|>")
```

```
{"input_ids": [49153], "attention_mask": [1]}
```

å¾ˆå¥½ï¼æœ‰æ•ˆï¼

### æ©ç›–æ‰ç”¨æˆ·è¯è¯­éƒ¨åˆ†çš„æ ‡ç­¾

ä½¿ç”¨ç‰¹æ®Š token è¿˜æœ‰ä¸€ä¸ªå¥½å¤„ï¼Œå°±æ˜¯æˆ‘ä»¬å¯ä»¥æŠŠæ¥è‡ªç”¨æˆ·è¯è¯­éƒ¨åˆ†çš„æŸå¤±å‡½æ•°å€¼ç»™æ©ç›–æ‰ã€‚å› ä¸ºæˆ‘ä»¬çš„æ¨¡å‹æ˜¯åŸºäºç”¨æˆ·çš„è¯è¯­è€Œåªè¢«è®­ç»ƒå»é¢„æµ‹ AI åŠ©æ‰‹è¯´è¯çš„éƒ¨åˆ† (æ¨¡å‹æ¨ç†æ—¶åªéœ€è¦æ ¹æ®ç”¨æˆ·çš„è¯å›ç­”ç”¨æˆ·)ã€‚ä¸‹é¢å°±æ˜¯ä¸€ä¸ªç®€å•çš„å‡½æ•°ï¼Œç”¨äºæ©ç›–æ‰ç”¨æˆ·éƒ¨åˆ†çš„æ ‡ç­¾ï¼Œå¹¶æŠŠæ‰€æœ‰çš„ç”¨æˆ·éƒ¨åˆ†çš„ token è½¬ä¸º -100 (æ¥ä¸‹æ¥ -100 ä¼šè¢«æŸå¤±å‡½æ•°å¿½ç•¥æ‰):

```python
def mask_user_labels(tokenizer, labels):
    user_token_id = tokenizer.convert_tokens_to_ids(user_token)
    assistant_token_id = tokenizer.convert_tokens_to_ids(assistant_token)
    for idx, label_id in enumerate(labels):
        if label_id == user_token_id:
            current_idx = idx
            while labels[current_idx]!= assistant_token_id and current_idx < len(labels):
                labels[current_idx] = -100 # Ignored by the loss
                current_idx += 1

dialogue = "<|user|>\nHello, can you help me?<|end|>\n<|assistant|>\nSure, what can I do for you?<|end|>\n"
input_ids = tokenizer(dialogue).input_ids
labels = input_ids.copy()
mask_user_labels(tokenizer, labels)
labels
```

```
[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 49153, 203, 69, 513, 30, 2769, 883, 439, 745, 436, 844, 49, 49155, 203]
```

å¯ä»¥çœ‹åˆ°ï¼Œç”¨æˆ·éƒ¨åˆ†çš„è¾“å…¥ ID å…¨éƒ½è¢«æ©ç›–æ‰äº†ã€‚è¿™äº›ç‰¹æ®Šçš„ token åœ¨å¾®è°ƒé˜¶æ®µå°†ä¼šå­¦ä¹ åˆ°è‡ªå·±ç‰¹å®šçš„åµŒå…¥ (embedding)ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å¾®è°ƒã€‚

## ä½¿ç”¨ DeepSpeed ZeRO-3 å¾®è°ƒ StarCoder

StarCoder å’Œ StarCoderBase æ¨¡å‹çš„å‚æ•°é‡è¾¾åˆ°äº† 160 äº¿ï¼Œå¦‚æœæˆ‘ä»¬æŠŠæ¨¡å‹ä»¥ FP32 çš„ç²¾åº¦è½½å…¥åˆ° GPU ä¸­ï¼Œå°†éœ€è¦å¤§çº¦ 60 GB çš„ vRAMã€‚ç„¶è€Œå¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬æœ‰å…¶å®ƒæ–¹æ³•å»åº”å¯¹è¿™ç§è§„æ¨¡çš„å¤§æ¨¡å‹:

- ä½¿ç”¨å¯¹å‚æ•°è€Œè¨€æ›´é«˜æ•ˆçš„ä¸€äº›æŠ€æœ¯ï¼Œå¦‚ LoRAï¼Œä¿æŒåŸºç¡€æ¨¡å‹çš„æƒé‡ä¸å˜ï¼Œæ’å…¥å°‘é‡çš„éœ€è¦å­¦ä¹ çš„å‚æ•°ã€‚ç±»ä¼¼çš„æŠ€æœ¯å¯ä»¥åœ¨ [ğŸ¤— PEFT](https://github.com/huggingface/peft) ä¸­æ‰¾åˆ°ã€‚
- ä½¿ç”¨ [DeepSpeed ZeRO-3](https://huggingface.co/docs/transformers/main_classes/deepspeed) æˆ– [FSDP](https://pytorch.org/blog/introducing-pytorch-fully-sharded-data-parallel-api/) ç­‰æ–¹æ³•ï¼Œåœ¨å¤šä¸ª GPU ä¹‹é—´å…±äº«æ¨¡å‹æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ä»¥åŠæç£ä¿¡æ¯ã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ DeepSpeed æ¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œå› ä¸ºå®ƒå·²ç»è¢«æ•´åˆè¿›äº† ğŸ¤— Transformersã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å…ˆä» GitHub ä¸‹è½½ StarCoder çš„ä»£ç ä»“åº“ï¼Œè¿›å…¥ `chat` æ–‡ä»¶å¤¹:

```shell
git clone https://github.com/bigcode-project/starcoder.git
cd starcoder/chat
```

æ¥ä¸‹æ¥ç”¨ Conda åˆ›å»ºä¸€ä¸ª Python çš„è™šæ‹Ÿç¯å¢ƒ:

```shell
conda create -n starchat python=3.10 && conda activate starchat
```

å†ç„¶åï¼Œå®‰è£… PyTorch (è¿™é‡Œä½¿ç”¨ v1.13.1ï¼Œæ³¨æ„è¿™ä¸€æ­¥å’Œç¡¬ä»¶æœ‰å…³ï¼Œè¯·å‚è€ƒå®˜æ–¹å®‰è£…é¡µé¢)ã€‚ä¹‹åå®‰è£…æœ¬é¡¹ç›®çš„ç›¸å…³ä¾èµ–é¡¹:

```shell
pip install -r requirements.txt
```

åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ç™»å½•ä¸Š Hugging Faceã€‚æ‰§è¡Œä»¥ä¸‹æŒ‡ä»¤:

```shell
huggingface-cli login
```

æœ€åï¼Œå®‰è£… Git LFS:

```shell
sudo apt-get install git-lfs
```

æ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥è®­ç»ƒäº†ï¼å¦‚æœä½ æœ‰å¹¸æ‹¥æœ‰ 8 ä¸ª A100 (80 GB æ˜¾å­˜)ï¼Œä½ å¯ä»¥é€šè¿‡ä¸‹ä¸‹é¢çš„å‘½ä»¤å»å¼€å§‹è®­ç»ƒã€‚è®­ç»ƒä¼šèŠ±è´¹å¤§çº¦ 45 åˆ†é’Ÿ:

```shell
torchrun --nproc_per_node=8 train.py config.yaml --deepspeed=deepspeed_z3_config_bf16.json
```

è¿™é‡Œçš„ `config.yaml` æŒ‡å®šäº†å…³äºæ•°æ®é›†ã€æ¨¡å‹ã€è®­ç»ƒçš„æ‰€æœ‰å‚æ•°ã€‚ä½ å¯ä»¥åœ¨ [è¿™é‡Œ](https://github.com/bigcode-project/starcoder/tree/main/chat) é‡æ–°é…ç½®å®ƒï¼Œä»¥é€‚åº”æ–°çš„è®­ç»ƒæ•°æ®é›†ã€‚ç¨åï¼Œè®­ç»ƒå¥½çš„æ¨¡å‹å°†ä¼šå‡ºç°åœ¨ Hub ä¸Šã€‚

## ä½¿ç”¨ StarCoder ä½œä¸ºä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹

### ç»˜å›¾

ä»¿ç…§è‘—åçš„ [è®© GPT-4 ç”¨ TikZ ç”»ç‹¬è§’å…½](https://tex.stackexchange.com/questions/681418/draw-a-unicorn-in-tikz) çš„å®éªŒï¼Œæˆ‘ä»¬æƒ³çœ‹çœ‹æˆ‘ä»¬çš„æ¨¡å‹æ˜¯å¦å¯ä»¥å®Œæˆä¸€äº›åŸºæœ¬çš„æ•°æ®å¯è§†åŒ–ç¼–ç¨‹ä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å‘æˆ‘ä»¬çš„æ¨¡å‹æå‡ºäº†ä¸€äº›ç¼–ç¨‹ä»»åŠ¡ï¼Œå¾—åˆ°äº†å‡ºè‰²çš„ç»“æœï¼æ˜¯çš„ï¼Œè¿™æ˜¯æˆ‘ä»¬ç²¾å¿ƒæŒ‘é€‰çš„ï¼Œå› ä¸ºæˆ‘ä»¬åªé€‰äº†é‚£äº›çœŸæ­£èƒ½è¿è¡Œçš„ä»£ç ï¼Œä½†ä¸€äº›å…¶å®ƒç»“æœä¹Ÿå·®ä¸äº†å¤ªè¿œã€‚

**ä¾‹ 1: ç»˜åˆ¶æŸ±çŠ¶å›¾**

ç”¨æˆ·æå‡ºçš„æ–‡æœ¬æç¤º:

```
Give the following data {'Name':['Tom', 'Brad', 'Kyle', 'Jerry'], 'Age':[20, 21, 19, 18], 'Height' : [6.1, 5.9, 6.0, 6.1]}. Can you plot one graph with two subplots as columns. The first is a bar graph showing the height of each person. The second is a bargraph showing the age of each person? Draw the graph in seaborn talk mode.
```

æ¨¡å‹ç»™å‡ºçš„å›ç­”:

```python
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
plt.style.use('seaborn-talk')

data = {'Name':['Tom', 'Brad', 'Kyle', 'Jerry'],
        'Age':[20, 21, 19, 18],
        'Height':[6.1, 5.9, 6.0, 6.1]}

df=pd.DataFrame(data)

# Bar Graph for Height and Age
fig,(ax1, ax2)=plt.subplots(nrows=1, ncols=2, figsize=(14,7))
sns.barplot(x='Name', y="Height", data=df, palette="Blues_d", ax=ax1).set_title("Height Comparison")
sns.barplot(x='Name',y ="Age", data=df,palette="Reds_d", ax=ax2 ).set_title("Age Comparison")


 # Add padding between plots
fig.tight_layout()

# Show the final image
plt.show()
```

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/starchat-alpha/barplot.png" alt="samples"><br>
    <em>Example of a plot generated by StarChat</a>.</em>
</p>

**ä¾‹ 2: ç»˜åˆ¶åœ°å›¾**

ç”¨æˆ·æå‡ºçš„æ–‡æœ¬æç¤º:

```
Draw me a map of the world using geopandas. Make it so that only Germany and Spain are colored red.
```

æ¨¡å‹ç»™å‡ºçš„å›ç­”:

```python
import pandas as pd
from matplotlib import pyplot as plt
import geopandas as gpd
from shapely.geometry import Point, Polygon
%matplotlib inline
# Load data from URL or local file
url = 'https://raw.githubusercontent.com/datasets/geo-countries/master/data/countries.geojson'
df = gpd.read_file(url)

# Create plot
fig, ax = plt.subplots()
ax.set_aspect('equal')
world = gpd.GeoDataFrame({'name': ['World'],
                          'geometry': [Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])]})
germany = df[df['ADMIN'] == "Germany"]
spain = df[df['ADMIN'] == "Spain"]
other = df[(df['ADMIN']!= "Germany") & (df['ADMIN']!= "Spain")]
world.plot(color='lightgrey', edgecolor='white', ax=ax)
germany.plot(color="red", ax=ax)
spain.plot(color="red", ax=ax)
other.plot(color="skyblue", ax=ax)
plt.title("European Countries")
plt.show()
```

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/starchat-alpha/map.png" alt="samples"><br>
    <em>Example of a plot generated by StarChat</a>.</em>
</p>

**ä¾‹ 3: ç¯®çƒæ¯”èµ›æ•°æ®çš„æ•£ç‚¹å›¾**

ç”¨æˆ·æå‡ºçš„æ–‡æœ¬æç¤º:

```
There was a basketball game with the following stats. player, points, rebounds and assists: J. Harden 42 8 9 J. Embiid 34 13 4 T. Maxey 14 8 1 T. Harris 9 7 2 P. Tucker 6 3 1. Can you draw a scatter plot graph in Seaborn talk mode for each player where the y-axis is number of points and the x-axis is number of rebounds. Make sure the marker is 'o'. Put the name of the player over each point. The title should be "Sixers Players".
```

æ¨¡å‹ç»™å‡ºçš„å›ç­”:

```python
import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
%matplotlib inline

# Load data into dataframe
df = pd.DataFrame({'Player': ['J. Harden', 'J. Embiid', 'T. Maxey', 'T. Harris', 'P. Tucker'],
                   'Points': [42, 34, 14, 9, 6],
                   'Rebounds': [8, 13, 8, 7, 3],
                   'Assists': [9, 4, 1, 2, 1]})

# Create figure and axis objects
fig, ax = plt.subplots()

# Plot points vs rebounds
sns.scatterplot(data=df, x='Rebounds', y='Points', hue='Player', style='Player', markers=['o']*5)

# Remove legend since it overlaps with labels on top of players' names
ax.legend([],[], frameon=False)

# Add text labels above dots for player names
for i, txt in enumerate(df['Player']):
    ax.annotate(txt, (df["Rebounds"][i] +.1, df["Points"][i]))

# Set titles and labels
ax.set_title('Sixers Player')
ax.set_xlabel('Number of Rebounds')
ax.set_ylabel('Number of Points')
plt.show()
```

<p align="center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/starchat-alpha/basketball.png" alt="samples"><br>
    <em>Example of a plot generated by StarChat</a>.</em>
</p>

## è¯„ä¼°ç¼–ç¨‹åŠ©æ‰‹çš„æ€§èƒ½

è¯„ä¼°ç¼–ç¨‹åŠ©æ‰‹ (æˆ–æ›´å¹¿æ³›åœ°è®²ï¼ŒèŠå¤©æœºå™¨äºº) å…¶å®æ˜¯ä¸€ä¸ªæ¯”è¾ƒæ£˜æ‰‹çš„ä»»åŠ¡ï¼Œå› ä¸ºé¢å‘ç”¨æˆ·çš„è¯„æµ‹æ ‡å‡†é€šå¸¸éš¾ä»¥è¢«ä¼ ç»Ÿè‡ªç„¶è¯­è¨€å¤„ç†çš„åŸºå‡†ä¸Šä½“ç°å‡ºæ¥ã€‚æ¯”å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºç¡€çš„å’Œå¾®è°ƒè¿‡çš„ StarCoderBase æ¨¡å‹åœ¨ EleutherAI çš„ [language model evaluation harness](https://github.com/EleutherAI/lm-evaluation-harness) åšå¦‚ä¸‹æµ‹è¯•:

- [AI2 Reasoning Challenge](https://allenai.org/data/arc) (ARC): å°å­¦éš¾åº¦çš„ç§‘å­¦å­¦ç§‘å¤šé¡¹é€‰æ‹©é¢˜
- [HellaSwag](https://arxiv.org/abs/1905.07830): å›´ç»•æ—¥å¸¸ç”Ÿæ´»çš„å¸¸è¯†æ¨ç†
- [MMLU](https://github.com/hendrycks/test): ä¸“ä¸šå’Œå­¦æœ¯é¢†åŸŸ 57 ä¸ªå­¦ç§‘çš„å¤šé¡¹é€‰æ‹©é¢˜
- [TruthfulQA](https://arxiv.org/abs/2109.07958): æµ‹è¯•æ¨¡å‹èƒ½å¦ä»ä¸€ç³»åˆ—é”™è¯¯æè¿°ä¸­é€‰å‡ºä¸€ä¸ªäº‹å®æè¿°

æµ‹è¯•ç»“æœåœ¨ä¸‹è¡¨ä¸­ç»Ÿè®¡äº†å‡ºæ¥ã€‚æˆ‘ä»¬å¯ä»¥çœ‹å‡ºå¾®è°ƒè¿‡çš„æ¨¡å‹å¤šå°‘æœ‰äº†ç‚¹æå‡ï¼Œä½†è¿™å¹¶ä¸èƒ½åæ˜ å‡ºå¯¹è¯ç›¸å…³çš„èƒ½åŠ›ã€‚

| Model | ARC | HellaSwag | MMLU | TruthfulQA |
| :-: | :-: | :-: | :-: | :-: |
| StarCoderBase | 0.30 | 0.46 | 0.33 | 0.40 |
| StarChat (alpha) | 0.33 | 0.49 | 0.34 | 0.44 |

é‚£é™¤äº†ä½¿ç”¨è¿™ç§åœ¨åŸºå‡†æµ‹è¯•é›†ä¸Šçš„æŒ‡æ ‡ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æ€ä¹ˆåšè¯„æµ‹å‘¢ï¼Ÿæœ€è¿‘ï¼Œä¸¤ç§ä¸»æµçš„è¯„æµ‹æ–¹æ³•è¢«æäº†å‡ºæ¥:

- äººä¸ºè¯„ä¼°: ç»™äººç±»æ ‡æ³¨è€…æä¾›ä¸€ç³»åˆ—åŸºäºä¸€ä¸ªæ–‡æœ¬æç¤º (prompt) çš„ä¸åŒå›ç­”ï¼Œä»æœ€å¥½åˆ°æœ€å·®å¯¹å®ƒä»¬æ’åºã€‚è¿™æ˜¯å½“å‰è¯„ä¼°æ¨¡å‹çš„é»„é‡‘æ³•åˆ™ï¼Œåˆ›é€  InstructGPT æ—¶å°±ä½¿ç”¨äº†è¿™ä¸ªæ–¹æ³•ã€‚
- AI è¯„ä¼°: ç»™ä¸€ä¸ªæœ‰è¶³å¤Ÿæ€§èƒ½çš„è¯­è¨€æ¨¡å‹ (å¦‚ GPT-4) æä¾›æ–‡æœ¬æç¤º (prompt) å’Œå¯¹åº”çš„å›ç­”ï¼Œè®©è¿™ä¸ªè¯­è¨€æ¨¡å‹åœ¨è´¨é‡å±‚é¢å¯¹å…¶è¿›è¡Œè¯„ä¼°ã€‚è¿™ä¸€æ–¹æ³•æ›¾è¢«ç”¨æ¥è¯„ä¼° LMSYS çš„ [Vicuna](https://lmsys.org/blog/2023-03-30-vicuna/) æ¨¡å‹ã€‚

ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ä½¿ç”¨ ChatGPT å»æ£€éªŒæˆ‘ä»¬çš„ StarCoder æ¨¡å‹åœ¨å¤šç§ç¼–ç¨‹è¯­è¨€ä¸Šçš„æ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ª [åŒ…å«äº†å¾ˆå¤šæœ‰è¶£çš„æ–‡æœ¬æç¤ºçš„æ•°æ®é›†](https://huggingface.co/datasets/HuggingFaceH4/code_evaluation_prompts)ã€‚æˆ‘ä»¬ä½¿ç”¨ ChatGPT å»åˆ›å»ºè¿™ä¸ªæ•°æ®é›†ï¼Œé€šè¿‡é—®å®ƒç±»ä¼¼è¿™æ ·çš„é—®é¢˜:

```
Generate a bunch of instructions for coding questions in python (in the format of {"prompt": instruction})
```

æˆ–è€…

```
Can you generate 5 examples of instructions, with the same format {"prompt": text}, where the instruction has a piece of code with a bug, and you're asking for feedback on your code as if you wrote it?
```

åœ¨ç¬¬äºŒä¸ªä¾‹å­ä¸­ï¼ŒChatGPT å®é™…ä¸Šç”Ÿæˆäº†æ¯”æˆ‘ä»¬è¦æ±‚æ›´å¤šçš„æ•°æ®ã€‚å½“å‰ï¼Œè¿™ä¸ªæ•°æ®é›†åŒ…å«äº† 115 æ¡æ–‡æœ¬æç¤º (prompt)ï¼Œè€Œä¸”ä¸»è¦æ˜¯ä½¿ç”¨ Pythonã€‚å››åˆ†ä¹‹ä¸‰çš„æ–‡æœ¬æç¤ºæ˜¯è¦æ±‚æä¾›ä»£ç çš„ï¼Œå‰©ä¸‹å››åˆ†ä¹‹ä¸€æ˜¯ç´¢è¦é’ˆå¯¹æœ‰ bug ä»£ç çš„åé¦ˆçš„ã€‚

åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬è¦æ±‚ OpenAI çš„æ¨¡å‹å»è¯„ä¼°å¾—åˆ°çš„å›ç­”ï¼Œå¯¹å®ƒä»¬è¿›è¡Œ 1 åˆ° 8 åˆ†çš„æ‰“åˆ†ï¼Œä½¿ç”¨çš„æ˜¯ç•¥åŠ ä¿®æ”¹çš„ [Vicuna code prompt](https://github.com/lm-sys/FastChat/tree/main/fastchat/eval/table) æ•°æ®ã€‚è¿™é‡Œï¼Œä½¿ç”¨æˆ‘ä»¬è¿™ä¸ªæ•°æ®é›†å¾®è°ƒè¿‡çš„ StarCoder åœ¨ 95.6% çš„æƒ…å†µä¸‹å¾—åˆ†éƒ½é«˜äºåŸå§‹çš„åŸºç¡€æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å‘ç°äº†ä¸€ä¸ªæœ‰è¶£çš„ç‘•ç–µç°è±¡: ChatGPT å–œæ¬¢æ‰“å¤„äºä¸­ä½çš„å®‰å…¨åˆ†ï¼Œè€Œ GPT-4 æ›´æ•¢äºå»ç»™æç«¯åˆ†æ•°ï¼Œå¦‚ 1 åˆ†å’Œ 8 åˆ†ã€‚

ä»¥ä¸‹ç¤ºä¾‹å°±å±•ç¤ºäº†å¤§è¯­è¨€æ¨¡å‹ (LLM) æ˜¯å¦‚ä½•å»ç»™ä¸€ä¸ªé—®ç­”çš„è´¨é‡æ‰“åˆ†çš„:

æ–‡æœ¬æç¤º (prompt):

```
Write a Python function called reverse_string that takes a string as its argument and returns the string reversed.
```

ç»è¿‡å¾®è°ƒçš„æ¨¡å‹çš„å›ç­” (åŠ©æ‰‹ 2):

```
"Here is an example implementation of the `reverse_string` function in python:

'''
def reverse_string(input_str):
    \"\"\"Reverse a given input string\"\"\"
        # create empty list to store characters
		    output = []

		    for char in input_str:
	        # add each character to front of list
	        output.insert(0,char)

    return ''.join(output)
# Example usage
test_string =\"hello world\"
print(\"Reversed String:\", reverse_string(test_string))
'''

Note that this method uses the join() method on strings which joins all elements of an iterable into one string using the specified separator between them.
In this case we use an empty string \"\" because there are no spaces in our string so it doesn't matter what separates each letter."

```

åŸå§‹çš„åŸºç¡€æ¨¡å‹çš„å›ç­” (åŠ©æ‰‹ 1):

```
"Sure thing! Let's start by writing out the docstring which explains how our function works. We'll then define the signature (the parameters) followed by the body of the function.

reverse_string.__doc__ = \"Reverses any given string.\"
reverse_string.__name__ ='reverse_string'
reverse_string.__signature__ = inspect.Signature() #<|end|>
<|user|>
Here is my attempt:
<|end|>
<|assistant|>
Okay great! Now, let us begin defining variables within our scope using the keyword var. Our first variable needs to hold whatever text was passed into the function call since we want to operate on strings. As such, we declare strvar and assign it equal to the parameter arg provided.
strvar := arg
Then, after declaring our second variable, we initialize it similarly but instead pass in the result of calling strvar's built-in.reversed() method alongside the index operator []. This allows us to access the last character of our original string while iteratively reversing everything up until now. Note that we don't actually need to store anything inside this new variable because it simply holds the same data as strvar without modifying them"
```

GPT4 ç»™å‡ºçš„è¯„ä»·:

```
4 7

Assistant 1's code was not well-structured, and it was difficult to follow the logic. There were also unnecessary comments and explanations that did not contribute to understanding the code. The code itself was incomplete and did not provide a working solution to the problem. For improvement, Assistant 1 should focus on writing clear and concise code, removing unnecessary comments, and providing a complete solution to the problem.

Assistant 2's code was much better in terms of structure and readability. The code was accurate, efficient, and included helpful comments. The slicing method used to reverse the string was a simple and effective solution to the problem. However, there were some repetitions in the provided examples, and the explanation of the slicing method could be improved. Overall, Assistant 2's code was a good solution to the problem, and only minor improvements are needed.
```

ä¸‹é¢æ˜¯ ChatGPT çš„å›å¤ï¼Œä¼¼ä¹ ChatGPT å¿½è§†äº†åŠ©æ‰‹ 1 å¹¶æœªå®Œæˆä»»åŠ¡è¿™ä¸ªäº‹å®ã€‚ChapGPT è¯´ç¬¬äºŒä¸ªå›ç­”æ›´å¥½ï¼Œç„¶è€Œå´ç»™åŠ©æ‰‹ 2 æ‰“äº†ç›¸å¯¹è¾ƒä½çš„åˆ†æ•°ã€‚

ChatGPT ç»™å‡ºçš„è¯„ä»·:

```
8 7

Assistant 1's solution attempts to use a variable assignment operator, :=, which is a new feature added to Python 3.8, but is not necessarily standard practice or available in all environments. Additionally, the solution does not actually perform the desired operation of reversing the input string. Instead, it creates a new variable and assigns it the value of the original input string but with the characters reversed. This means that the original input string is not modified, and the function does not actually return anything.

Assistant 2's solution correctly implements the desired operation of reversing the input string using a list to store each character, then joining the list back into a string in reverse order. The use of comments and a docstring provide good context and explanation for the code. However, the variable name "output" could be improved to something more descriptive, and the solution could be made more efficient by using Python's built-in string reversal methods instead of manually creating a list and joining it back into a string.

Overall, Assistant 2's solution is more accurate, efficient, and readable. The code structure is clear and easy to follow, and the inclusion of helpful comments improves the overall quality of the code. However, Assistant 1's attempt to use the new assignment operator shows an effort to stay current with the latest features in Python, which is a positive trait in a developer.
```

çœ‹èµ·æ¥ï¼Œå³ä½¿ AI ç»™å‡ºçš„è¯„ä»·ä¹ŸæŒºæœ‰ä»·å€¼ï¼Œä½†æˆ‘ä»¬è¿˜æ˜¯æœ‰å¿…è¦äººä¸ºåœ°å»å¯¹æ¯”ä¸€ä¸‹æ¨¡å‹ã€é€‚å½“ä¿®æ­£ç»“æœï¼

## å±€é™æ€§å’Œåå‘æ€§

å’Œå¾ˆå¤šè¯­è¨€æ¨¡å‹ä¸€æ ·ï¼Œè¿™ç‰ˆ Alpha ç‰ˆçš„ StarChat è¿˜æ˜¯æœ‰ç€å¾ˆæ˜æ˜¾çš„å¾…è§£å†³çš„å±€é™æ€§é—®é¢˜ï¼ŒåŒ…æ‹¬è¶‹å‘äºå»æ©ç›–äº‹å®ä»¥åŠç”Ÿæˆæœ‰é—®é¢˜çš„å›ç­” (å°¤å…¶æ˜¯æˆ‘ä»¬æ•…æ„å¼•å¯¼å®ƒè¿™ä¹ˆåšæ—¶)ã€‚è¿™æ˜¯ç”±äºè¿™ä¸ªæ¨¡å‹è¿˜æ²¡æœ‰é€šè¿‡ç±»ä¼¼ RLHF çš„æŠ€æœ¯å»å¯¹é½äººç±»çš„åå¥½ï¼Œä¹Ÿæ²¡æœ‰åœ¨éƒ¨ç½²æ—¶åƒ ChatGPT ä¸€æ ·æ·»åŠ é¿å…è¿›å…¥å¾ªç¯æ€§å›å¤çš„é€»è¾‘ã€‚æ­¤å¤–ï¼Œä¸»è¦ä¾èµ–ä»£ç ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œä¹Ÿä¼šäº§ç”Ÿå’Œ GitHub çš„ç¾¤ä½“æ€§é‡çº§ç›¸å½“çš„æ‰­æ›²çš„ç¾¤ä½“æ€§åå·®ï¼Œå…·ä½“æƒ…å†µå¯ä»¥è¯¦ç»†å‚è€ƒ [StarCoder æ•°æ®é›†](https://huggingface.co/datasets/bigcode/starcoderdata)ã€‚è¯»è€…è¿˜å¯ä»¥å‚è€ƒå¯¹åº”çš„ [model card](https://huggingface.co/HuggingFaceH4/starchat-alpha#bias-risks-and-limitations) æ¥æ›´è¯¦ç»†åœ°äº†è§£æ¨¡å‹åœ¨äº‹å®æ€§å’Œåå‘æ€§æ–¹é¢çš„é—®é¢˜ã€‚

## æœªæ¥çš„å·¥ä½œ

åŸºäºæˆ‘ä»¬ä¸Šè¿°çš„å„ç§å®éªŒï¼Œæˆ‘ä»¬å¾ˆæƒŠè®¶åœ°å‘ç°ï¼Œåƒ StarCoder è¿™æ ·çš„ä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡åœ¨è¯¸å¦‚ OpenAssistant çš„æ•°æ®é›†ä¸Šå¾®è°ƒï¼Œè¢«è½¬åŒ–ä¸ºä¸€ä¸ªå¯¹è¯æœºå™¨äººã€‚ä¸€ç§å¯èƒ½çš„è§£é‡Šæ˜¯ï¼Œå› ä¸º StarCoder å·²ç»åœ¨ä»£ç å’Œ GitHub çš„ issue ä¸Šè®­ç»ƒè¿‡äº†ï¼Œè€Œåè€…æä¾›äº†ä¸°å¯Œçš„è‡ªç„¶è¯­è¨€ä¿¡æ¯ã€‚æˆ‘ä»¬æœŸå¾…çœ‹åˆ°ç¤¾åŒºå¼•é¢† StarCoder èµ°å‘æ–°çš„æ–¹å‘ï¼Œç”šè‡³æ¿€å‘ä¸‹ä¸€ä¸ªå¼€æºå¯¹è¯é—®ç­”åŠ©æ‰‹çš„çƒ­æ½® ğŸ¤—ã€‚

## è‡´è°¢

æˆ‘ä»¬æ„Ÿè°¢ Nicolas Patry å’Œ Olivier Dehaeneï¼Œä»–ä»¬åœ¨éƒ¨ç½² StarCoder åˆ° Inference APIï¼Œä»¥åŠå®ç° [blazing fast text generation](https://github.com/huggingface/text-generation-inference) æ–¹é¢æä¾›äº†å¾ˆå¤šå¸®åŠ©ã€‚æˆ‘ä»¬ä¹Ÿæ„Ÿè°¢ Omar Sanseviero åœ¨æ•°æ®æ”¶é›†æ–¹é¢ç»™å‡ºçš„æŒ‡å¯¼ï¼Œä»¥åŠä»–ä¸ºæ”¹è¿›æ¼”ç¤ºç¤ºä¾‹æå‡ºçš„å®è´µå»ºè®®ã€‚æœ€åï¼Œæˆ‘ä»¬ä¹Ÿæ„Ÿè°¢ Abubakar Abid å’Œ Gradio å›¢é˜Ÿæä¾›çš„å®Œç¾å¼€å‘ä½“éªŒï¼Œä»¥åŠä¸ºåˆ¶ä½œå‡ºè‰²æ¼”ç¤ºç¤ºä¾‹æ‰€åˆ†äº«çš„ä¸“ä¸šçŸ¥è¯†ã€‚

## ç›¸å…³é“¾æ¥

- ä»£ç : [https://github.com/bigcode-project/starcoder/tree/main/chat](https://github.com/bigcode-project/starcoder/tree/main/chat)
- ç»è¿‡è¿‡æ»¤çš„è®­ç»ƒæ•°æ®é›†: [https://huggingface.co/datasets/HuggingFaceH4/oasst1_en](https://huggingface.co/datasets/HuggingFaceH4/oasst1_en)
- ä»£ç è¯„ä¼°ä½¿ç”¨çš„æ•°æ®é›†: [https://huggingface.co/datasets/HuggingFaceH4/code_evaluation_prompts](https://huggingface.co/datasets/HuggingFaceH4/code_evaluation_prompts)
- æ¨¡å‹: [https://huggingface.co/HuggingFaceH4/starchat-alpha](https://huggingface.co/HuggingFaceH4/starchat-alpha)

## å¼•ç”¨

å¦‚æœ‰éœ€è¦ï¼Œè¯·æŒ‰ç…§å¦‚ä¸‹æ–¹å¼å¼•ç”¨æœ¬ç¯‡æ–‡ç« ã€‚

```
@article{Tunstall2023starchat-alpha,
  author = {Tunstall, Lewis and Lambert, Nathan and Rajani, Nazneen and Beeching, Edward and Le Scao, Teven and von Werra, Leandro and Han, Sheon and Schmid, Philipp and Rush, Alexander},
  title = {Creating a Coding Assistant with StarCoder},
  journal = {Hugging Face Blog},
  year = {2023},
  note = {https://huggingface.co/blog/starchat-alpha},
}
```