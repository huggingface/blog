---
title: "æ¬¢è¿ Stable Diffusion 3 åŠ å…¥ ğŸ§¨ Diffusers"
thumbnail: /blog/assets/sd3/thumbnail.png
authors:
- user: dn6
- user: YiYiXu
- user: sayakpaul
- user: OzzyGT
- user: kashif
- user: multimodalart
translators:
- user: hugging-hoi2022
- user: zhongdongy
  proofreader: true
---

# æ¬¢è¿ Stable Diffusion 3 åŠ å…¥ ğŸ§¨ Diffusers

ä½œä¸º Stability AI çš„ Stable Diffusion å®¶æ—æœ€æ–°çš„æ¨¡å‹ï¼Œ[Stable Diffusion 3](https://stability.ai/news/stable-diffusion-3-research-paper) (SD3) ç°å·²ç™»é™† Hugging Face Hubï¼Œå¹¶ä¸”å¯ç”¨åœ¨ ğŸ§¨ Diffusers ä¸­ä½¿ç”¨äº†ã€‚

å½“å‰æ”¾å‡ºçš„æ¨¡å‹ç‰ˆæœ¬æ˜¯ Stable Diffusion 3 Mediumï¼Œæœ‰äºŒåäº¿ (2B) çš„å‚æ•°é‡ã€‚

é’ˆå¯¹å½“å‰å‘å¸ƒç‰ˆæœ¬ï¼Œæˆ‘ä»¬æä¾›äº†:

1. Hub ä¸Šå¯ä¾›ä¸‹è½½çš„æ¨¡å‹
2. Diffusers çš„ä»£ç é›†æˆ
3. SD3 çš„ Dreambooth å’Œ LoRA è®­ç»ƒè„šæœ¬

## ç›®å½•

- [SD3 æ–°ç‰¹æ€§](#SD3 æ–°ç‰¹æ€§)
- [åœ¨ Diffusers ä¸­ä½¿ç”¨ SD3](#åœ¨ Diffusers ä¸­ä½¿ç”¨ SD3)
- [å¯¹ SD3 è¿›è¡Œå†…å­˜ä¼˜åŒ–ä»¥é€‚é…å„ç§ç¡¬ä»¶](#å¯¹ SD3 è¿›è¡Œå†…å­˜ä¼˜åŒ–)
- [æ€§èƒ½ä¼˜åŒ–ä¸æ¨ç†åŠ é€Ÿ](#SD3 æ€§èƒ½ä¼˜åŒ–)
- [SD3 å¾®è°ƒå’Œ LoRA åˆ›å»º](#ä½¿ç”¨ DreamBooth å’Œ LoRA è¿›è¡Œå¾®è°ƒ)

## SD3 æ–°ç‰¹æ€§

### æ¨¡å‹

ä½œä¸ºä¸€ä¸ªéšå˜é‡æ‰©æ•£æ¨¡å‹ï¼ŒSD3 åŒ…å«äº†ä¸‰ä¸ªä¸åŒçš„æ–‡æœ¬ç¼–ç å™¨ ([CLIP L/14](https://huggingface.co/openai/clip-vit-large-patch14)ã€[OpenCLIP bigG/14](https://huggingface.co/laion/CLIP-ViT-bigG-14-laion2B-39B-b160k) å’Œ [T5-v1.1-XXL](https://huggingface.co/google/t5-v1_1-xxl)) ã€ä¸€ä¸ªæ–°æå‡ºçš„å¤šæ¨¡æ€ Diffusion Transformer (MMDiT) æ¨¡å‹ï¼Œä»¥åŠä¸€ä¸ª 16 é€šé“çš„ AutoEncoder æ¨¡å‹ (ä¸ [Stable Diffusion XL](https://arxiv.org/abs/2307.01952) ä¸­çš„ç±»ä¼¼)ã€‚

SD3 ä»¥åºåˆ— Embedding çš„å½¢å¼å¤„ç†æ–‡æœ¬è¾“å…¥å’Œè§†è§‰éšç©ºé—´ç‰¹å¾ã€‚ä½ç½®ç¼–ç  (Positional Encoding) æ˜¯æ–½åŠ åœ¨éšç©ºé—´ç‰¹å¾çš„ 2x2 patch ä¸Šçš„ï¼Œéšåè¢«å±•å¼€æˆ patch çš„ Enbedding åºåˆ—ã€‚è¿™ä¸€åºåˆ—å’Œæ–‡æœ¬çš„ç‰¹å¾åºåˆ—ä¸€èµ·ï¼Œè¢«é€å…¥ MMDiT çš„å„ä¸ªæ¨¡å—ä¸­å»ã€‚ä¸¤ç§ç‰¹å¾åºåˆ—è¢«è½¬åŒ–æˆç›¸åŒç‰¹å¾ç»´åº¦ï¼Œæ‹¼æ¥åœ¨ä¸€èµ·ï¼Œç„¶åé€å…¥ä¸€ç³»åˆ—æ³¨æ„åŠ›æœºåˆ¶æ¨¡å—å’Œå¤šå±‚æ„ŸçŸ¥æœº (MLP) é‡Œã€‚

ä¸ºåº”å¯¹ä¸¤ç§æ¨¡æ€é—´çš„å·®å¼‚ï¼ŒMMDiT æ¨¡å—ä½¿ç”¨ä¸¤ç»„ä¸åŒçš„æƒé‡å»è½¬æ¢æ–‡æœ¬å’Œå›¾åƒåºåˆ—çš„ç‰¹å¾ç»´åº¦ã€‚ä¸¤ä¸ªåºåˆ—ä¹‹åä¼šåœ¨æ³¨æ„åŠ›æ“ä½œä¹‹å‰è¢«åˆå¹¶åœ¨ä¸€èµ·ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ä¸¤ç§è¡¨å¾èƒ½åœ¨è‡ªå·±çš„ç‰¹å¾ç©ºé—´é‡Œå·¥ä½œï¼ŒåŒæ—¶ä¹Ÿä½¿å¾—å®ƒä»¬ä¹‹é—´å¯ä»¥é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ [1] ä»å¯¹æ–¹çš„ç‰¹å¾ä¸­æå–æœ‰ç”¨çš„ä¿¡æ¯ã€‚è¿™ç§æ–‡æœ¬å’Œå›¾åƒé—´åŒå‘çš„ä¿¡æ¯æµåŠ¨æœ‰åˆ«äºä»¥å‰çš„æ–‡ç”Ÿå›¾æ¨¡å‹ï¼Œåè€…çš„æ–‡æœ¬ä¿¡æ¯æ˜¯é€šè¿‡ cross-attention é€å…¥æ¨¡å‹çš„ï¼Œä¸”ä¸åŒå±‚è¾“å…¥çš„æ–‡æœ¬ç‰¹å¾å‡æ˜¯æ–‡æœ¬ç¼–ç å™¨çš„è¾“å‡ºï¼Œä¸éšæ·±åº¦çš„å˜åŒ–è€Œæ”¹å˜ã€‚

æ­¤å¤–ï¼ŒSD3 è¿˜åœ¨æ—¶é—´æ­¥ (timestep) è¿™ä¸€æ¡ä»¶ä¿¡æ¯ä¸ŠåŠ å…¥äº†æ±‡åˆè¿‡çš„æ–‡æœ¬ç‰¹å¾ï¼Œè¿™äº›æ–‡æœ¬ç‰¹å¾æ¥è‡ªä½¿ç”¨çš„ä¸¤ä¸ª CLIP æ¨¡å‹ã€‚è¿™äº›æ±‡åˆè¿‡çš„æ–‡æœ¬ç‰¹å¾è¢«æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œç„¶ååŠ åˆ°æ—¶é—´æ­¥çš„ Embedding ä¸Šï¼Œå†é€å…¥æ¯ä¸ª MMDiT æ¨¡å—ã€‚

### ä½¿ç”¨ Rectified Flow Matching è®­ç»ƒ

é™¤äº†ç»“æ„ä¸Šçš„åˆ›æ–°ï¼ŒSD3 ä¹Ÿä½¿ç”¨äº† [conditional flow-matching](https://arxiv.org/html/2403.03206v1#S2) ä½œä¸ºè®­ç»ƒç›®æ ‡å‡½æ•°æ¥è®­ç»ƒæ¨¡å‹ã€‚è¿™ä¸€æ–¹æ³•ä¸­ï¼Œå‰å‘åŠ å™ªè¿‡ç¨‹è¢«å®šä¹‰ä¸ºä¸€ä¸ª [rectified flow](https://arxiv.org/html/2403.03206v1#S3)ï¼Œä»¥ä¸€æ¡ç›´çº¿è¿æ¥æ•°æ®åˆ†å¸ƒå’Œå™ªå£°åˆ†å¸ƒã€‚

é‡‡æ ·è¿‡ç¨‹ä¹Ÿå˜å¾—æ›´ç®€å•äº†ï¼Œå½“é‡‡æ ·æ­¥æ•°å‡å°‘çš„æ—¶å€™ï¼Œæ¨¡å‹æ€§èƒ½ä¹Ÿå¾ˆç¨³å®šã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä¹Ÿå¼•å…¥äº†æ–°çš„ scheduler ( `FlowMatchEulerDiscreteScheduler` )ï¼Œé›†æˆäº† rectified flow-matching çš„è¿ç®—å…¬å¼ä»¥åŠæ¬§æ‹‰æ–¹æ³• (Euler Method) çš„é‡‡æ ·æ­¥éª¤ã€‚åŒæ—¶è¿˜æå‡ºäº†ä¸€ä¸ªä¸ç”Ÿæˆåˆ†è¾¨ç‡ç›¸å…³çš„ `shift` å‚æ•°ã€‚å¯¹äºé«˜åˆ†è¾¨ç‡ï¼Œå¢å¤§ `shift` çš„å€¼å¯ä»¥æ›´å¥½åœ°å¤„ç† noise scalingã€‚é’ˆå¯¹ 2B æ¨¡å‹ï¼Œæˆ‘ä»¬å»ºè®®è®¾ç½® `shift=3.0` ã€‚

å¦‚æƒ³å¿«é€Ÿå°è¯• SD3ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ä¸€ä¸ªåŸºäº Gradio çš„åº”ç”¨:

<script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.36.1/gradio.js"> </script>
<gradio-app theme_mode="light" space="stabilityai/stable-diffusion-3-medium"></gradio-app>

## åœ¨ Diffusers ä¸­ä½¿ç”¨ SD3

å¦‚æƒ³åœ¨ diffusers ä¸­ä½¿ç”¨ SD3ï¼Œé¦–å…ˆè¯·ç¡®ä¿å®‰è£…çš„ diffusers æ˜¯æœ€æ–°ç‰ˆæœ¬:

```python
pip install --upgrade diffusers
```

ä½¿ç”¨æ¨¡å‹å‰ï¼Œä½ éœ€è¦å…ˆåˆ° [Stable Diffusion 3 Medium åœ¨ Hugging Face çš„é¡µé¢](https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers)ï¼Œå¡«å†™è¡¨æ ¼å¹¶åŒæ„ç›¸å…³å†…å®¹ã€‚ä¸€åˆ‡å°±ç»ªåï¼Œä½ éœ€è¦ç™»å½•ä½ çš„ huggingface è´¦å·:

```bash
huggingface-cli login
```

ä¸‹é¢ç¨‹åºå°†ä¼šä¸‹è½½ SD3 çš„ 2B å‚æ•°æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ `fp16` ç²¾åº¦ã€‚Stability AI åŸæœ¬å‘å¸ƒçš„æ¨¡å‹ç²¾åº¦å°±æ˜¯ `fp16` ï¼Œè¿™ä¹Ÿæ˜¯æ¨èçš„æ¨¡å‹æ¨ç†ç²¾åº¦ã€‚

### æ–‡ç”Ÿå›¾

```python
import torch
from diffusers import StableDiffusion3Pipeline

pipe = StableDiffusion3Pipeline.from_pretrained("stabilityai/stable-diffusion-3-medium-diffusers", torch_dtype=torch.float16)
pipe = pipe.to("cuda")

image = pipe(
	"A cat holding a sign that says hello world",
	negative_prompt="",
    num_inference_steps=28,
    guidance_scale=7.0,
).images[0]
image
```

![hello_world_cat](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/sd3/hello_world_cat.png)

### å›¾ç”Ÿå›¾

```python
import torch
from diffusers import StableDiffusion3Img2ImgPipeline
from diffusers.utils import load_image

pipe = StableDiffusion3Img2ImgPipeline.from_pretrained("stabilityai/stable-diffusion-3-medium-diffusers", torch_dtype=torch.float16)
pipe = pipe.to("cuda")

init_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png")
prompt = "cat wizard, gandalf, lord of the rings, detailed, fantasy, cute, adorable, Pixar, Disney, 8k"
image = pipe(prompt, image=init_image).images[0]
image
```

![wizard_cat](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/sd3/wizard_cat.png)

ç›¸å…³çš„ SD3 æ–‡æ¡£å¯åœ¨ [è¿™é‡Œ](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/stable_diffusion_3) æŸ¥çœ‹ã€‚

## å¯¹ SD3 è¿›è¡Œå†…å­˜ä¼˜åŒ–

SD3 ä½¿ç”¨äº†ä¸‰ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼Œå…¶ä¸­ä¸€ä¸ªæ˜¯ [T5-XXL model](https://huggingface.co/google/t5-v1_1-xxl)ï¼Œæ˜¯ä¸€ä¸ªå¾ˆå¤§çš„æ¨¡å‹ã€‚è¿™ä½¿å¾—åœ¨æ˜¾å­˜å°äº 24GB çš„ GPU ä¸Šè·‘æ¨¡å‹éå¸¸å›°éš¾ï¼Œå³ä½¿ä½¿ç”¨çš„æ˜¯ `fp16` ç²¾åº¦ã€‚

å¯¹æ­¤ï¼Œdiffusers é›†æˆäº†ä¸€äº›å†…å­˜ä¼˜åŒ–æ‰‹æ®µï¼Œæ¥è®© SD3 èƒ½åœ¨æ›´å¤šçš„ GPU ä¸Šè·‘èµ·æ¥ã€‚

### ä½¿ç”¨ Model Offloading æ¨ç†

Diffusers ä¸Šä¸€ä¸ªæœ€å¸¸ç”¨çš„å†…å­˜ä¼˜åŒ–æ‰‹æ®µå°±æ˜¯ model offloadingã€‚å®ƒä½¿å¾—ä½ å¯ä»¥åœ¨æ¨ç†æ—¶ï¼ŒæŠŠä¸€äº›å½“å‰ä¸éœ€è¦çš„æ¨¡å‹ç»„ä»¶å¸è½½åˆ° CPU ä¸Šï¼Œä»¥æ­¤èŠ‚çœ GPU æ˜¾å­˜ã€‚ä½†è¿™ä¼šå¼•å…¥å°‘é‡çš„æ¨ç†æ—¶é•¿å¢é•¿ã€‚åœ¨æ¨ç†æ—¶ï¼Œmodel offloading åªä¼šå°†æ¨¡å‹å½“å‰éœ€è¦å‚ä¸è®¡ç®—çš„éƒ¨åˆ†æ”¾åœ¨ GPU ä¸Šï¼Œè€ŒæŠŠå‰©ä½™éƒ¨åˆ†æ”¾åœ¨ CPU ä¸Šã€‚

```python
import torch
from diffusers import StableDiffusion3Pipeline

pipe = StableDiffusion3Pipeline.from_pretrained("stabilityai/stable-diffusion-3-medium-diffusers", torch_dtype=torch.float16)
pipe.enable_model_cpu_offload()

prompt = "smiling cartoon dog sits at a table, coffee mug on hand, as a room goes up in flames. â€œThis is fine,â€ the dog assures himself."
image = pipe(prompt).images[0]
```

### ä¸ä½¿ç”¨ T5 æ¨¡å‹è¿›è¡Œæ¨ç†

[æ¨ç†æ—¶ç§»é™¤æ‰ 4.7B å‚æ•°é‡çš„ T5-XXL æ–‡æœ¬ç¼–ç å™¨](https://arxiv.org/html/2403.03206v1#S5.F9) å¯ä»¥å¾ˆå¤§ç¨‹åº¦åœ°å‡å°‘å†…å­˜éœ€æ±‚ï¼Œå¸¦æ¥çš„æ€§èƒ½æŸå¤±å´å¾ˆå°ã€‚

```python
import torch
from diffusers import StableDiffusion3Pipeline

pipe = StableDiffusion3Pipeline.from_pretrained("stabilityai/stable-diffusion-3-medium-diffusers", text_encoder_3=None, tokenizer_3=None, torch_dtype=torch.float16)
pipe = pipe.to("cuda")

prompt = "smiling cartoon dog sits at a table, coffee mug on hand, as a room goes up in flames. â€œThis is fine,â€ the dog assures himself."
image = pipe("").images[0]
```

## ä½¿ç”¨é‡åŒ–ç‰ˆçš„ T5-XXL æ¨¡å‹

ä½¿ç”¨ `bitsandbytes` è¿™ä¸ªåº“ï¼Œä½ ä¹Ÿå¯ä»¥åŠ è½½ 8 æ¯”ç‰¹é‡åŒ–ç‰ˆçš„ T5-XXL æ¨¡å‹ï¼Œè¿›ä¸€æ­¥å‡å°‘æ˜¾å­˜éœ€æ±‚ã€‚

```python
import torch
from diffusers import StableDiffusion3Pipeline
from transformers import T5EncoderModel, BitsAndBytesConfig

# Make sure you have `bitsandbytes` installed.
quantization_config = BitsAndBytesConfig(load_in_8bit=True)

model_id = "stabilityai/stable-diffusion-3-medium-diffusers"
text_encoder = T5EncoderModel.from_pretrained(
    model_id,
    subfolder="text_encoder_3",
    quantization_config=quantization_config,
)
pipe = StableDiffusion3Pipeline.from_pretrained(
    model_id,
    text_encoder_3=text_encoder,
    device_map="balanced",
    torch_dtype=torch.float16
)
```

_å®Œæ•´ä»£ç åœ¨ [è¿™é‡Œ](https://gist.github.com/sayakpaul/82acb5976509851f2db1a83456e504f1)ã€‚_

### æ˜¾å­˜ä¼˜åŒ–å°ç»“

æ‰€æœ‰çš„åŸºå‡†æµ‹è¯•éƒ½ç”¨äº† 2B å‚æ•°é‡çš„ SD3 æ¨¡å‹ï¼Œæµ‹è¯•åœ¨ä¸€ä¸ª A100-80G ä¸Šè¿›è¡Œï¼Œä½¿ç”¨ `fp16` ç²¾åº¦æ¨ç†ï¼ŒPyTorch ç‰ˆæœ¬ä¸º 2.3ã€‚

æˆ‘ä»¬å¯¹æ¯ä¸ªæ¨ç†è°ƒç”¨è·‘åæ¬¡ï¼Œè®°å½•å¹³å‡å³°å€¼æ˜¾å­˜ç”¨é‡å’Œ 20 æ­¥é‡‡æ ·çš„å¹³å‡æ—¶é•¿ã€‚

## SD3 æ€§èƒ½ä¼˜åŒ–

ä¸ºåŠ é€Ÿæ¨ç†ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `torch.compile()` æ¥è·å–ä¼˜åŒ–è¿‡çš„ `vae` å’Œ `transformer` éƒ¨åˆ†çš„è®¡ç®—å›¾ã€‚

```python
import torch
from diffusers import StableDiffusion3Pipeline

torch.set_float32_matmul_precision("high")

torch._inductor.config.conv_1x1_as_mm = True
torch._inductor.config.coordinate_descent_tuning = True
torch._inductor.config.epilogue_fusion = False
torch._inductor.config.coordinate_descent_check_all_directions = True

pipe = StableDiffusion3Pipeline.from_pretrained(
    "stabilityai/stable-diffusion-3-medium-diffusers",
    torch_dtype=torch.float16
).to("cuda")
pipe.set_progress_bar_config(disable=True)

pipe.transformer.to(memory_format=torch.channels_last)
pipe.vae.to(memory_format=torch.channels_last)

pipe.transformer = torch.compile(pipe.transformer, mode="max-autotune", fullgraph=True)
pipe.vae.decode = torch.compile(pipe.vae.decode, mode="max-autotune", fullgraph=True)

# Warm Up
prompt = "a photo of a cat holding a sign that says hello world",
for _ in range(3):
 _ = pipe(prompt=prompt, generator=torch.manual_seed(1))

# Run Inference
image = pipe(prompt=prompt, generator=torch.manual_seed(1)).images[0]
image.save("sd3_hello_world.png")
```

_å®Œæ•´ä»£ç å¯å‚è€ƒ [è¿™é‡Œ](https://gist.github.com/sayakpaul/508d89d7aad4f454900813da5d42ca97)ã€‚_

æˆ‘ä»¬æµ‹é‡äº†ä½¿ç”¨è¿‡ `torch.compile()` çš„ SD3 çš„æ¨ç†é€Ÿåº¦ (åœ¨ A100-80G ä¸Šï¼Œä½¿ç”¨ `fp16` æ¨ç†ï¼ŒPyTorch ç‰ˆæœ¬ä¸º 2.3)ã€‚æˆ‘ä»¬é’ˆå¯¹æ¯ä¸ªç”Ÿæˆä»»åŠ¡è·‘ 10 éï¼Œæ¯æ¬¡æ¨ç†ä½¿ç”¨ 20 æ­¥é‡‡æ ·ã€‚å¹³å‡æ¨ç†è€—æ—¶æ˜¯ **0.585 ç§’**ï¼Œ _è¿™æ¯” eager execution æ¨¡å¼ä¸‹å¿«äº†å››å€_ ã€‚

## ä½¿ç”¨ DreamBooth å’Œ LoRA è¿›è¡Œå¾®è°ƒ

æœ€åï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä½¿ç”¨ [LoRA](https://huggingface.co/blog/lora) çš„ [DreamBooth](https://dreambooth.github.io/) ä»£ç ï¼Œç”¨äºå¾®è°ƒ SD3ã€‚è¿™ä¸€ç¨‹åºä¸ä»…èƒ½å¾®è°ƒæ¨¡å‹ï¼Œè¿˜èƒ½ä½œä¸ºä¸€ä¸ªå‚è€ƒï¼Œå¦‚æœä½ æƒ³ä½¿ç”¨ rectified flow æ¥è®­ç»ƒæ¨¡å‹ã€‚å½“ç„¶ï¼Œçƒ­é—¨çš„ rectified flow å®ç°ä»£ç è¿˜æœ‰ [minRF](https://github.com/cloneofsimo/minRF/)ã€‚

å¦‚æœéœ€è¦ä½¿ç”¨è¯¥ç¨‹åºï¼Œé¦–å…ˆéœ€è¦ç¡®ä¿å„é¡¹è®¾ç½®éƒ½å·²å®Œæˆï¼ŒåŒæ—¶å‡†å¤‡å¥½ä¸€ä¸ªæ•°æ®é›† (æ¯”å¦‚ [è¿™ä¸ª](https://huggingface.co/datasets/diffusers/dog-example))ã€‚ä½ éœ€è¦å®‰è£… `peft` å’Œ `bitsandbytes` ï¼Œç„¶åå†å¼€å§‹è¿è¡Œè®­ç»ƒç¨‹åº:

```bash
export MODEL_NAME="stabilityai/stable-diffusion-3-medium-diffusers"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="dreambooth-sd3-lora"

accelerate launch train_dreambooth_lora_sd3.py \
  --pretrained_model_name_or_path=${MODEL_NAME} \
  --instance_data_dir=${INSTANCE_DIR} \
  --output_dir=/raid/.cache/${OUTPUT_DIR} \
  --mixed_precision="fp16" \
  --instance_prompt="a photo of sks dog" \
  --resolution=1024 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=4 \
  --learning_rate=1e-5 \
  --report_to="wandb" \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps=500 \
  --weighting_scheme="logit_normal" \
  --validation_prompt="A photo of sks dog in a bucket" \
  --validation_epochs=25 \
  --seed="0" \
  --push_to_hub
```

## å£°æ˜

æ„Ÿè°¢ Stability AI å›¢é˜Ÿå¼€å‘å¹¶å¼€æºäº† Stable Diffusion 3 å¹¶è®©æˆ‘ä»¬ææ—©ä½“éªŒï¼Œä¹Ÿæ„Ÿè°¢ [Linoy](https://huggingface.co/linoyts) å¯¹æ’°å†™æ­¤æ–‡çš„å¸®åŠ©ã€‚