{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75faf867ad9944bcacc49edaf5ce90d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34e265f69cd34f8c948cd3d99ab4fb03",
              "IPY_MODEL_7a7d86b9aa244e8b9ae8ffa3c302e1c5",
              "IPY_MODEL_fa6f26b5215e48e79859d6dd999d7b2e"
            ],
            "layout": "IPY_MODEL_1071e490d708477fb04db937f246f79a"
          }
        },
        "34e265f69cd34f8c948cd3d99ab4fb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a71ae1f14034a48bb921cc35f68242e",
            "placeholder": "​",
            "style": "IPY_MODEL_ccc6bf4ff6674b27ab8ed75fcdbb6dab",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7a7d86b9aa244e8b9ae8ffa3c302e1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92c2dfa6dd4c4adbb93eab6c4e085ca6",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a0c7815adbe42db93d84917e60b8a95",
            "value": 4
          }
        },
        "fa6f26b5215e48e79859d6dd999d7b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfcc63dd885441908ccebf26eeddac71",
            "placeholder": "​",
            "style": "IPY_MODEL_1e1daf771e204a3cab5aec5cf8f49fef",
            "value": " 4/4 [01:14&lt;00:00, 15.58s/it]"
          }
        },
        "1071e490d708477fb04db937f246f79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a71ae1f14034a48bb921cc35f68242e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc6bf4ff6674b27ab8ed75fcdbb6dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92c2dfa6dd4c4adbb93eab6c4e085ca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a0c7815adbe42db93d84917e60b8a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfcc63dd885441908ccebf26eeddac71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e1daf771e204a3cab5aec5cf8f49fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tool Use with 🤗 `transformers`"
      ],
      "metadata": {
        "id": "qq_TE-iBfdJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by initializing our model as normal. We'll use a small, ungated model so you can run this on Colab - make sure you've got a GPU, though, because it won't fit in CPU memory alone!"
      ],
      "metadata": {
        "id": "xoeShkLUftDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "checkpoint = \"NousResearch/Hermes-2-Pro-Llama-3-8B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype=torch.bfloat16, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "75faf867ad9944bcacc49edaf5ce90d0",
            "34e265f69cd34f8c948cd3d99ab4fb03",
            "7a7d86b9aa244e8b9ae8ffa3c302e1c5",
            "fa6f26b5215e48e79859d6dd999d7b2e",
            "1071e490d708477fb04db937f246f79a",
            "8a71ae1f14034a48bb921cc35f68242e",
            "ccc6bf4ff6674b27ab8ed75fcdbb6dab",
            "92c2dfa6dd4c4adbb93eab6c4e085ca6",
            "5a0c7815adbe42db93d84917e60b8a95",
            "cfcc63dd885441908ccebf26eeddac71",
            "1e1daf771e204a3cab5aec5cf8f49fef"
          ]
        },
        "id": "UUmokuFrffjJ",
        "outputId": "d22f2512-f5b7-4ccb-ee4a-719ee4c1ed38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75faf867ad9944bcacc49edaf5ce90d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll define a simple tool function for our model - but in a real scenario, you'll probably want to use more than one! The type hints and docstrings are mandatory - those are going to be parsed and used by the model to understand what the tools do.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "S9BAyr70f1Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_temperature(location: str):\n",
        "    \"\"\"\n",
        "    Gets the temperature at a given location.\n",
        "\n",
        "    Args:\n",
        "        location: The location to get the temperature for, in the format \"city, country\"\n",
        "    \"\"\"\n",
        "    return 22.0  # bug: Sometimes the temperature is not 22. low priority to fix tho\n",
        "\n",
        "tools = [get_current_temperature]\n"
      ],
      "metadata": {
        "id": "8QWuToHTbiQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we set up a simple chat."
      ],
      "metadata": {
        "id": "zMyCg0b0f9fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = [\n",
        "    {\"role\": \"user\", \"content\": \"Hey, what's the weather like in Paris right now?\"}\n",
        "]"
      ],
      "metadata": {
        "id": "CIZnlw8gblIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We pass the tools to the chat template, and generate text from the model using the formatted prompt."
      ],
      "metadata": {
        "id": "4KEC1HLlgCJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_prompt = tokenizer.apply_chat_template(\n",
        "    chat,\n",
        "    tools=tools,\n",
        "    return_tensors=\"pt\",\n",
        "    return_dict=True,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "tool_prompt = tool_prompt.to(model.device)\n",
        "\n",
        "out = model.generate(**tool_prompt, max_new_tokens=128)\n",
        "generated_text = out[0, tool_prompt['input_ids'].shape[1]:]\n",
        "\n",
        "print(tokenizer.decode(generated_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AZ8l7zDboD8",
        "outputId": "f82cdf4c-8349-4c54-e214-aff12d49f1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128003 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tool_call>\n",
            "{\"arguments\": {\"location\": \"Paris, France\"}, \"name\": \"get_current_temperature\"}\n",
            "</tool_call><|im_end|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has chosen to call a tool, and picked an argument that matches both the user's request and the format in the tool docstring! Let's add this tool call to the chat as a message!"
      ],
      "metadata": {
        "id": "6H1fqDvTgHK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_call = {\"name\": \"get_current_temperature\", \"arguments\": {\"location\": \"Paris, France\"}}\n",
        "chat.append({\"role\": \"assistant\", \"tool_calls\": [{\"type\": \"function\", \"function\": tool_call}]})"
      ],
      "metadata": {
        "id": "QApSN0mObvIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we add the tool response containing the function output to the chat as well. Both the tool call (containing the arguments passed to the tool) and tool response (containing the tool's output) must be included in the chat history."
      ],
      "metadata": {
        "id": "C55M3uLBgLHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat.append({\"role\": \"tool\", \"name\": \"get_current_temperature\", \"content\": \"22.0\"})"
      ],
      "metadata": {
        "id": "lb8qbiV1c-wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we apply the chat template and generate text once again."
      ],
      "metadata": {
        "id": "hVrbGCU7gWLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_prompt = tokenizer.apply_chat_template(\n",
        "    chat,\n",
        "    tools=tools,\n",
        "    return_tensors=\"pt\",\n",
        "    return_dict=True,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "tool_prompt = tool_prompt.to(model.device)\n",
        "\n",
        "out = model.generate(**tool_prompt, max_new_tokens=128)\n",
        "generated_text = out[0, tool_prompt['input_ids'].shape[1]:]\n",
        "\n",
        "print(tokenizer.decode(generated_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9JTN62odBGT",
        "outputId": "fbfb8c06-ddc0-450b-ce5e-983384798eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128003 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current temperature in Paris is 22.0°C. Enjoy your day!<|im_end|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success! The model has used the tool response correctly in its response to the user."
      ],
      "metadata": {
        "id": "k1lLSczhgY64"
      }
    }
  ]
}