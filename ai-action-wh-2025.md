---
title: "AI Policy @ðŸ¤—: Response to the White House AI Action Plan RFI"
thumbnail: /blog/assets/151_policy_ntia_rfc/us_policy_thumbnail.png
authors:
- user: yjernite
- user: evijit
- user: irenesolaiman
---

# AI Policy @ðŸ¤—: Response to the White House AI Action Plan RFI

On March 14, we submitted Hugging Face's response to the White House Office of Science and Technology Policy's request for information on the [White House AI Action Plan](https://www.whitehouse.gov/briefings-statements/2025/02/public-comment-invited-on-artificial-intelligence-action-plan/). We took this opportunity to (re-)assert the fundamental role that open AI systems and open science play in enabling the technology to be more performant and efficient, broadly and reliably adopted, and meeting the highest standards of security. This blog post provides a summary of our response, the full text is available [here](https://huggingface.co/datasets/huggingface/policy-docs/resolve/main/2025_Hugging_Face_Response_to_AI_Action_Plan.pdf).

#### Context: Don't Sleep on (Strongly) Open Models' Capabilities

Open approaches to AI development are not only ([typically](https://crfm.stanford.edu/fmti/May-2024/index.html)) more transparent, adaptable, and scientifically sound, they have also consistently **reproduced or surpassed the performance** of widely-used API-only commercial offerings on many tasks; and are increasingly doing so on **shorter timelines**, with **increased resource efficiency**.
Our team's recent [OlympicCoder outperforming Claude 3.7](https://huggingface.co/blog/open-r1/update-3) on complex coding tasks with [7B parameters](https://huggingface.co/open-r1/OlympicCoder-7B) and an [open-source post-training recipe](https://github.com/huggingface/open-r1), or AI2's fully open [OLMo 2 models](https://huggingface.co/collections/allenai/olmo-2-674117b93ab84e98afc72edc) (with [open training data](https://huggingface.co/datasets/allenai/dolmino-mix-1124)) [matching o1-mini performances]((https://allenai.org/blog/olmo2-32B)), are two of the most recent compelling examples.
These successes show that a robust AI strategy must leverage open and collaborative development to best drive performance, adoption, and security of the technology. We make three major recommendations in this direction.

#### Recommendation 1: Recognize Open Source and Open Science as Fundamental to AI Success

The most advanced AI systems to date all stand on a strong foundation of open research ([attention mechanisms](https://arxiv.org/abs/1409.0473), [transformer architectures](https://arxiv.org/abs/1706.03762), [cheaper post-training algorithms](https://arxiv.org/abs/2305.18290)) and open source software ([PyTorch](https://pytorch.org/), [Hugging Face libraries](https://github.com/huggingface), [supercomputer operating systems](https://www.top500.org/)) &mdash; which shows the critical value of continued support for openness in sustaining further progress. Investment in systems that can freely be re-used and adapted has also been shown to have a [strong economic impact multiplying effect](https://www.hbs.edu/ris/Publication%20Files/24-038_51f8444f-502c-4139-8bf2-56eb4b65c58a.pdf#page=31.22), driving a [significant percentage of countries' GDP](https://link.springer.com/article/10.1007/s10961-023-09993-x#Sec7). As AI systems with open weights and training techniques become increasingly attractive options for developers in terms of [both performance and cost](https://huggingface.co/open-r1/OlympicCoder-7B), prioritizing public [research](https://nairrpilot.org/) infrastructure and broad access to [compute](https://www.adalovelaceinstitute.org/blog/the-role-of-public-compute/), [customizable models](https://huggingface.co/models), and [trusted](https://www.ibm.com/case-studies/blog/how-ibm-and-the-data-trust-alliance-are-fostering-greater-transparency-across-the-data-ecosystem) open [datasets](https://huggingface.co/datasets) &mdash; especially for smaller developers and researchers &mdash; will be essential to the further technical and economic success of AI technology.

#### Recommendation 2: Prioritize Efficiency and Reliability to Unlock Broad Innovation

[Addressing the resource constraints](https://moderndiplomacy.eu/2024/11/12/the-hidden-costs-of-ai-implementation-in-small-businesses/) of organizations adopting and adapting AI technology will be essential to supporting its diffusion and fostering innovation from adopters across the entire development chain. [Smaller models](https://huggingface.co/google/gemma-3-4b-it) (that may even be used on [edge devices](https://huggingface.co/blog/smolvlm)), techniques to [reduce computational requirements at inference](https://huggingface.co/docs/optimum/en/concept_guides/quantization), and efforts to [facilitate mid-scale training](https://huggingface.co/spaces/nanotron/ultrascale-playbook) for organizations with modest to moderate computational resources all support the development of models that meet the specific needs of their use context, especially in high-risk settings [such as healthcare](https://www.nature.com/articles/s41467-024-50952-3) where [fully generalist models have proven unreliable](https://www.clinicaltrialsarena.com/news/hallucinations-in-ai-generated-medical-summaries-remain-a-grave-concern/). 
More efficient and purpose-designed AI systems facilitate better [in-context evaluation](https://www.patronus.ai/blog/introducing-the-enterprise-scenarios-leaderboard-a-leaderboard-for-real-world-use-cases), [better resource utilization](https://www.nist.gov/itl/ai-risk-management-framework), and enable organizations to [build technical capacity](https://coe.gsa.gov/coe/artificial-intelligence.html) at all stages of the AI development chain to ensure that all users can leverage the system that best fits their needs.

#### Recommendation 3: Secure AI through Open, Traceable, and Transparent Systems

Finally, if decades of information security and cybersecurity in open source software are any indication, open and transparent AI systems will have a fundamental role to play in securing AI development and deployment especially in the most critical settings &mdash; with different levels of openness needed for different security requirements. [Fully transparent models](https://allenai.org/blog/olmo2-32B) providing access to their training data and procedures can support the most extensive safety certifications. Open infrastructure and open-source tooling implementing the [latest training techniques](https://github.com/huggingface/open-r1) can empower organizations to train the models they need in fully controlled environments. Open-weight models that can be run in air-gapped environments can be a critical component in managing information risks. Prioritizing adoption of the most transparent systems, supporting the development of the open resources outlined, and building capacity to leverage them especially in critical settings of AI adoption are essential to enabling more secure AI adoption.

Please refer to the [full response](https://huggingface.co/datasets/huggingface/policy-docs/resolve/main/2025_Hugging_Face_Response_to_AI_Action_Plan.pdf) for our more detailed recommendations!
