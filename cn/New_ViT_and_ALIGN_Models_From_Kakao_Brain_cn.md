# New ViT and ALIGN Models From Kakao Brain

Created by: cony zhang
Created time: March 7, 2023 7:08 AM
Last edited by: cony zhang
Last edited time: March 9, 2023 9:01 AM
URL: https://huggingface.co/blog/vit-align

# **Kakao Brain å‘å¸ƒå¼€æº ViT and ALIGNæ¨¡åž‹å’Œæ•°æ®**

æœ€è¿‘ Kakao Brain åœ¨ Hugging Face å‘å¸ƒäº†ä¸€ä¸ªå…¨æ–°çš„å¼€æºå›¾åƒæ–‡æœ¬æ•°æ®é›† COYOï¼ŒåŒ…å«7äº¿å¯¹å›¾åƒå’Œæ–‡æœ¬ï¼Œå¹¶è®­ç»ƒäº†ä¸¤ä¸ªæ–°çš„è§†è§‰è¯­è¨€æ¨¡åž‹ ViT å’Œ ALIGN [ViT]ï¼ˆhttps://github.com/kakaobrain/coyo-vitï¼‰å’Œ[ALIGN]ï¼ˆhttps://github.com/kakaobrain/coyo-alignï¼‰ã€‚

è¿™æ˜¯ ALIGN æ¨¡åž‹é¦–æ¬¡å…¬å¼€å‘å¸ƒä¾›å¼€æºä½¿ç”¨ï¼ŒåŒæ—¶ ViT å’Œ ALIGN æ¨¡åž‹çš„å‘å¸ƒéƒ½é™„å¸¦æœ‰è®­ç»ƒæ•°æ®é›†ã€‚

Google çš„ ViT å’Œ ALIGN æ¨¡åž‹éƒ½ä½¿ç”¨äº†å·¨å¤§çš„æ•°æ®é›†ï¼ˆViT è®­ç»ƒäºŽ 3 äº¿å¼ å›¾åƒï¼ŒALIGN è®­ç»ƒäºŽ 18 äº¿ä¸ªå›¾åƒ-æ–‡æœ¬å¯¹ï¼‰è¿›è¡Œè®­ç»ƒï¼Œå› ä¸ºæ•°æ®é›†ä¸å…¬å¼€å¯¼è‡´æ— æ³•å¤çŽ°ã€‚Kakao Brain çš„ ViT å’Œ ALIGN æ¨¡åž‹é‡‡ç”¨ä¸Ž Google åŽŸå§‹æ¨¡åž‹ç›¸åŒçš„æž¶æž„å’Œè¶…å‚æ•°ï¼Œä¸åŒçš„æ˜¯å…¶åœ¨å¼€æº [COYO](https://github.com/kakaobrain/coyo-dataset) æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚å¯¹äºŽæƒ³è¦æ‹¥æœ‰æ•°æ®å¹¶å¤çŽ°è§†è§‰è¯­è¨€æ¨¡åž‹çš„ç ”ç©¶äººå‘˜æœ‰å¾ˆå¤§çš„ä»·å€¼ã€‚è¯¦ç»†çš„ Kakao ViT å’Œ ALIGN æ¨¡åž‹ä¿¡æ¯å¯ä»¥å‚ç…§ï¼š

[`https://huggingface.co/kakaobrain`](https://huggingface.co/kakaobrain)

è¿™ç¯‡åšå®¢å°†ä»‹ç»æ–°çš„ [COYO](https://github.com/kakaobrain/coyo-dataset) æ•°æ®é›†ã€Kakao Brain çš„ ViT å’Œ ALIGN æ¨¡åž‹ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼ä»¥ä¸‹æ˜¯ä¸»è¦è¦ç‚¹ï¼š

- ç¬¬ä¸€ä¸ªå¼€æºçš„ ALIGN æ¨¡åž‹ï¼
- ç¬¬ä¸€ä¸ªåœ¨å¼€æºæ•°æ®é›† [COYO](https://github.com/kakaobrain/coyo-dataset) ä¸Šè®­ç»ƒçš„å¼€æº ViT å’Œ ALIGN æ¨¡åž‹ã€‚
- Kakao Brain çš„ ViTå’Œ ALIGN æ¨¡åž‹è¡¨çŽ°ä¸Ž Google ç‰ˆæœ¬ç›¸å½“ã€‚
- ViTæ¨¡åž‹åœ¨HFä¸Šå¯æ¼”ç¤ºï¼æ‚¨å¯ä»¥ä½¿ç”¨è‡ªå·±çš„å›¾åƒæ ·æœ¬åœ¨çº¿ä½“éªŒViTï¼

## æ€§èƒ½æ¯”è¾ƒ

Kakao Brain å‘å¸ƒçš„ ViT å’Œ ALIGN æ¨¡åž‹ä¸Ž Google çš„æ¨¡åž‹è¡¨çŽ°ç›¸å½“ï¼ŒæŸäº›æ–¹é¢ç”šè‡³æ›´å¥½ã€‚Kakao Brain çš„ ALIGN-B7-Base æ¨¡åž‹è™½ç„¶è®­ç»ƒçš„æ•°æ®å¯¹å°‘å¾—å¤šï¼ˆ 7 äº¿VS 1.8 äº¿ï¼‰ï¼Œä½†åœ¨å›¾åƒ KNN åˆ†ç±»ä»»åŠ¡ä¸Šè¡¨çŽ°ä¸Ž Google çš„ ALIGN-B7-Base ç›¸å½“ï¼Œåœ¨ MS-COCO å›¾åƒ-æ–‡æœ¬æ£€ç´¢ã€æ–‡æœ¬-å›¾åƒæ£€ç´¢ä»»åŠ¡ä¸Šè¡¨çŽ°æ›´å¥½ã€‚Kakao Brain çš„ ViT-L/16 åœ¨384Ã—512çš„ ImageNet å’Œ ImageNet-ReaL æ•°æ®ä¸Šçš„è¡¨çŽ°ä¸Ž Google çš„ViT-L/16 ç›¸å½“ã€‚è¿™æ„å‘³ç€åŒè¡Œå¯ä»¥ä½¿ç”¨Kakao Brainçš„ ViT å’Œ ALIGN æ¨¡åž‹æ¥å¤çŽ° Googleçš„ ViT å’Œ ALIGN ï¼Œå°¤å…¶æ˜¯å½“ç”¨æˆ·éœ€è¦è®­ç»ƒæ•°æ®æ—¶ã€‚æ‰€ä»¥æˆ‘ä»¬å¾ˆé«˜å…´å¼€æºè¿™äº›ä¸ŽçŽ°æœ‰æŠ€æœ¯ç›¸å½“çš„æ¨¡åž‹ï¼

![New%20ViT%20and%20ALIGN%20Models%20From%20Kakao%20Brain%2096dc66c155824d38814f76b7e882ad2f/vit-align-performance.png](https://s3.amazonaws.com/moonup/production/uploads/1678324148590-640816c18dca6cec91cacc42.png)

## COYO æ•°æ®é›†

![New%20ViT%20and%20ALIGN%20Models%20From%20Kakao%20Brain%2096dc66c155824d38814f76b7e882ad2f/coyo-samples.png](https://s3.amazonaws.com/moonup/production/uploads/1678324151809-640816c18dca6cec91cacc42.png)

æœ¬æ¬¡å‘å¸ƒçš„æ¨¡åž‹ç‰¹åˆ«ä¹‹å¤„åœ¨äºŽéƒ½æ˜¯åŸºäºŽå¼€æºçš„ COYO æ•°æ®é›†è®­ç»ƒçš„ã€‚[COYO](https://github.com/kakaobrain/coyo-dataset#dataset-preview) æ•°æ®é›†åŒ…å«7äº¿å›¾åƒ-æ–‡æœ¬å¯¹ï¼Œç±»ä¼¼äºŽ Google çš„`ALIGN 1.8B`å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ï¼Œæ˜¯ä»Žç½‘é¡µä¸Šæ”¶é›†çš„â€œå˜ˆæ‚â€çš„htmlæ–‡æœ¬ï¼ˆalt-text)å’Œå›¾åƒå¯¹ã€‚`COYO-700M`å’Œ`ALIGN 1.8B`éƒ½æ˜¯â€œå˜ˆæ‚â€çš„ï¼Œåªä½¿ç”¨äº†é€‚å½“çš„æ¸…æ´—å¤„ç†ã€‚`COYO`ç±»ä¼¼äºŽå¦ä¸€ä¸ªå¼€æºçš„å›¾åƒâ€“æ–‡æœ¬æ•°æ®é›†`LAION`ï¼Œä½†æœ‰ä¸€äº›åŒºåˆ«ã€‚å°½ç®¡`LAION 2B`æ˜¯ä¸€ä¸ªæ›´å¤§çš„æ•°æ®é›†ï¼ŒåŒ…å«20äº¿ä¸ªè‹±è¯­é…å¯¹ï¼Œä½†`COYO`çš„é™„å¸¦æœ‰æ›´å¤šå…ƒæ•°æ®ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¤šçµæ´»æ€§å’Œæ›´ç»†ç²’åº¦çš„ä½¿ç”¨ã€‚ä»¥ä¸‹è¡¨æ ¼æ˜¾ç¤ºäº†å®ƒä»¬ä¹‹é—´çš„åŒºåˆ«ï¼š`COYO`æ‰€æœ‰æ•°æ®å¯¹éƒ½æä¾›äº†ç¾Žæ„Ÿè¯„åˆ†ï¼Œæ›´å¥å£®çš„æ°´å°è¯„åˆ†å’Œé¢éƒ¨è®¡æ•°ä¿¡æ¯ï¼ˆface count dataï¼‰ã€‚

| COYO | LAION 2B | ALIGN 1.8B |
| --- | --- | --- |
| Image-text similarity score calculated with CLIP ViT-B/32 and ViT-L/14 models, they are provided as metadata but nothing is filtered out so as to avoid possible elimination bias | Image-text similarity score provided with CLIP (ViT-B/32) - only examples above threshold 0.28 | Minimal, Frequency based filtering |
| NSFW filtering on images and text | NSFW filtering on images | Google Cloud API |
| Face recognition (face count) data provided as meta-data | No face recognition data | NA |
| 700 million pairs all English | 2 billion English | 1.8 billion |
| From CC 2020 Oct - 2021 Aug | From CC 2014-2020 | NA |
| Aesthetic Score | Aesthetic Score Partial | NA |
| More robust Watermark score | Watermark Score | NA |
| Hugging Face Hub | Hugging Face Hub | Not made public |
| English | English | English? |

## ViTå’ŒALIGNæ˜¯å¦‚ä½•å·¥ä½œçš„

è¿™äº›æ¨¡åž‹æ˜¯å¹²ä»€ä¹ˆçš„ï¼Ÿè®©æˆ‘ä»¬ç®€è¦è®¨è®ºä¸€ä¸‹ ViTå’ŒALIGNæ¨¡åž‹çš„å·¥ä½œåŽŸç†ã€‚

ViTâ€”Vision Transformer æ˜¯è°·æ­ŒäºŽ 2020 å¹´æå‡ºçš„ä¸€ç§è§†è§‰æ¨¡åž‹ï¼Œç±»ä¼¼äºŽæ–‡æœ¬Transformeræž¶æž„ã€‚è¿™æ˜¯ä¸€ç§ä¸Žå·ç§¯ç¥žç»ç½‘ç»œä¸åŒçš„è§†è§‰æ–¹æ³•(AlexNetè‡ª2012å¹´ä»¥æ¥ä¸€ç›´ä¸»å¯¼è§†è§‰ä»»åŠ¡ï¼‰ã€‚åŒæ ·è¡¨çŽ°ä¸‹ï¼Œå®ƒçš„è®¡ç®—æ•ˆçŽ‡æ¯”CNNé«˜è¾¾å››å€ï¼Œä¸”å…·æœ‰åŸŸä¸å¯çŸ¥æ€§ï¼ˆdomain agnosticï¼‰ã€‚ViTå°†è¾“å…¥çš„å›¾åƒåˆ†è§£æˆä¸€ç³»åˆ—å›¾åƒå—ï¼ˆpatchï¼‰ï¼Œå°±åƒæ–‡æœ¬ Transformer è¾“å…¥æ–‡æœ¬åºåˆ—ä¸€æ ·ï¼Œç„¶åŽä¸ºæ¯ä¸ªå—æä¾›ä½ç½®åµŒå…¥ä»¥å­¦ä¹ å›¾åƒç»“æž„ã€‚ViT çš„æ€§èƒ½å°¤å…¶åœ¨äºŽå…·æœ‰å‡ºè‰²çš„æ€§èƒ½-è®¡ç®—æƒè¡¡ã€‚è°·æ­Œçš„ä¸€äº›ViTæ¨¡åž‹æ˜¯å¼€æºçš„ï¼Œä½†å…¶è®­ç»ƒä½¿ç”¨çš„JFT-300ç™¾ä¸‡å›¾åƒ-æ ‡ç­¾å¯¹æ•°æ®é›†å°šæœªå…¬å¼€å‘å¸ƒã€‚Kakao Brainçš„è®­ç»ƒæ¨¡åž‹æ˜¯åŸºäºŽå…¬å¼€å‘å¸ƒçš„COYO-Labeled-300Mè¿›è¡Œè®­ç»ƒï¼Œå¯¹åº”çš„ViTæ¨¡åž‹åœ¨å„ç§ä»»åŠ¡ä¸Šå…·æœ‰ç›¸ä¼¼è¡¨çŽ°ï¼Œå…¶ä»£ç ã€æ¨¡åž‹å’Œè®­ç»ƒæ•°æ®ï¼ˆCOYO-Labeled-300Mï¼‰å®Œå…¨å…¬å¼€ï¼Œä»¥ä¾¿èƒ½å¤Ÿè¿›è¡Œå¤çŽ°å’Œç§‘å­¦ç ”ç©¶ã€‚

![New%20ViT%20and%20ALIGN%20Models%20From%20Kakao%20Brain%2096dc66c155824d38814f76b7e882ad2f/vit-architecture.gif](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/132_vit_align/vit-architecture.gif)

è°·æ­Œåœ¨2021å¹´æŽ¨å‡ºäº† ALIGNï¼Œå®ƒæ˜¯ä¸€ç§åŸºäºŽâ€œå˜ˆæ‚â€æ–‡æœ¬â€“å›¾åƒæ•°æ®è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡åž‹ï¼Œå¯ç”¨äºŽå„ç§è§†è§‰å’Œè·¨æ¨¡æ€ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬-å›¾åƒæ£€ç´¢ã€‚ALIGN é‡‡ç”¨ç®€å•çš„åŒç¼–ç å™¨æž¶æž„ï¼Œé€šè¿‡å¯¹æ¯”æŸå¤±å‡½æ•°å­¦ä¹ å›¾åƒå’Œæ–‡æœ¬å¯¹ï¼ŒALIGN çš„â€œå˜ˆæ‚â€è®­ç»ƒè¯­æ–™ç‰¹ç‚¹åŒ…æ‹¬ç”¨è¯­æ–™è§„æ¨¡å¼¥è¡¥å…¶å™ªéŸ³ä»¥åŠå¼ºå¤§çš„é²æ£’æ€§ã€‚ä¹‹å‰çš„è§†è§‰è¯­è¨€è¡¨ç¤ºå­¦ä¹ éƒ½æ˜¯åœ¨æ‰‹åŠ¨æ ‡æ³¨çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¿™å°±éœ€è¦å¤§é‡çš„é¢„å…ˆå¤„ç†å’Œæˆæœ¬ã€‚ALIGN çš„è¯­æ–™åº“ä½¿ç”¨HTMLæ–‡æœ¬(alt-text)æ•°æ®ä½œä¸ºå›¾åƒçš„æè¿°ï¼Œå¯¼è‡´æ•°æ®é›†ä¸å¯é¿å…åœ°å˜ˆæ‚ï¼Œä½†æ›´å¤§çš„æ•°æ®é‡ï¼ˆ18äº¿å¯¹ï¼‰ä½¿ALIGNèƒ½å¤Ÿåœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨çŽ°å‡ºSoTAæ°´å¹³ã€‚Kakao Brainçš„æ¨¡åž‹æ˜¯ç¬¬ä¸€ä¸ªALIGNå¼€æºç‰ˆæœ¬ï¼Œå®ƒåœ¨ COYO æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œè¡¨çŽ°æ¯”è°·æ­Œçš„ç»“æžœæ›´å¥½ã€‚

![New%20ViT%20and%20ALIGN%20Models%20From%20Kakao%20Brain%2096dc66c155824d38814f76b7e882ad2f/align-architecture.png](https://s3.amazonaws.com/moonup/production/uploads/1678324149262-640816c18dca6cec91cacc42.png)

## å¦‚ä½•ä½¿ç”¨COYOæ•°æ®é›†

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ HuggingFaceðŸ¤—æ•°æ®é›†åº“çš„ä¸€è¡Œä»£ç æ–¹ä¾¿åœ°ä¸‹è½½ COYO æ•°æ®é›†ã€‚è¦é¢„è§ˆCOYOæ•°æ®é›†å¹¶äº†è§£æ•°æ®å¤„ç†è¿‡ç¨‹å’ŒåŒ…å«çš„å…ƒå±žæ€§ï¼Œè¯·å‰å¾€hubæ•°æ®é›†é¡µé¢ã€‚

[`https://huggingface.co/datasets/kakaobrain/coyo-700m`](https://huggingface.co/datasets/kakaobrain/coyo-700m)

å¼€å§‹å‰ï¼Œè¯·å®‰è£…HuggingFaceðŸ¤—æ•°æ®é›†åº“ï¼š`pip install datasets`ï¼Œç„¶åŽä¸‹è½½æ•°æ®é›†ã€‚

```python
from datasets import load_dataset

dataset = load_dataset('kakaobrain/coyo-700m')
dataset
```

ç”±äºŽ COYO æ•°æ®é›†éžå¸¸åºžå¤§ï¼ŒåŒ…å«747Mä¸ªå›¾åƒ-æ–‡æœ¬å¯¹ï¼Œæ‚¨å¯èƒ½æ— æ³•åœ¨æœ¬åœ°ä¸‹è½½æ•´ä¸ªæ•°æ®é›†ã€‚æˆ–è€…å¯èƒ½åªéœ€è¦ä¸‹è½½å’Œä½¿ç”¨æ•°æ®é›†çš„å­é›†ã€‚ä¸ºæ­¤ï¼Œå¯ä»¥ç®€å•åœ°å°†`streaming=True`å‚æ•°ä¼ é€’ç»™`load_dataset()`æ–¹æ³•ï¼Œä»¥åˆ›å»ºå¯è¿­ä»£æ•°æ®é›†ï¼Œå¹¶åœ¨éœ€è¦æ—¶ä¸‹è½½æ•°æ®å®žä¾‹ã€‚

```python
from datasets import load_dataset

dataset = load_dataset('kakaobrain/coyo-700m', streaming=True)
print(next(iter(dataset['train'])))
{'id': 2680060225205, 'url': 'https://cdn.shopify.com/s/files/1/0286/3900/2698/products/TVN_Huile-olive-infuse-et-s-227x300_e9a90ffd-b6d2-4118-95a1-29a5c7a05a49_800x.jpg?v=1616684087', 'text': 'Olive oil infused with Tuscany herbs', 'width': 227, 'height': 300, 'image_phash': '9f91e133b1924e4e', 'text_length': 36, 'word_count': 6, 'num_tokens_bert': 6, 'num_tokens_gpt': 9, 'num_faces': 0, 'clip_similarity_vitb32': 0.19921875, 'clip_similarity_vitl14': 0.147216796875, 'nsfw_score_opennsfw2': 0.0058441162109375, 'nsfw_score_gantman': 0.018961310386657715, 'watermark_score': 0.11015450954437256, 'aesthetic_score_laion_v2': 4.871710777282715}
```

## å¦‚ä½•ä½¿ç”¨ Hub ä¸­çš„ ViT å’Œ ALIGN

è®©æˆ‘ä»¬å°è¯•ä¸€ä¸‹æ–°çš„ ViT å’Œ ALIGN æ¨¡åž‹ã€‚ç”±äºŽ ALIGN æ˜¯æ–°åŠ å…¥ HuggingFaceðŸ¤— Transformers çš„ï¼Œæˆ‘ä»¬å…ˆå®‰è£…æœ€æ–°ç‰ˆæœ¬çš„åº“ï¼š`pip install -q git+https://github.com/huggingface/transformers.git`ç„¶åŽå¯¼å…¥æˆ‘ä»¬å°†è¦ä½¿ç”¨çš„æ¨¡å—å’Œåº“ï¼Œå¼€å§‹ä½¿ç”¨ ViT è¿›è¡Œå›¾åƒåˆ†ç±»ã€‚è¯·æ³¨æ„ï¼Œæ–°æ·»åŠ çš„ ALIGN æ¨¡åž‹å°†ä¼šåŒ…å«åˆ°ä¸‹ä¸€ç‰ˆ PyPI åŒ…ã€‚

```python
import requests
from PIL import Image
import torch
from transformers import ViTImageProcessor, ViTForImageClassification
```

æŽ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä»ŽCOCOæ•°æ®é›†ä¸­éšæœºä¸‹è½½ä¸€å¼ æœ‰æ²™å‘å›¾åƒï¼Œä¸Šè¾¹æœ‰ä¸¤åªçŒ«å’Œä¸€ä¸ªé¥æŽ§å™¨ï¼Œå¹¶å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ä¸ºæ¨¡åž‹æ‰€æœŸæœ›çš„è¾“å…¥æ ¼å¼ï¼Œæˆ‘ä»¬å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨ç›¸åº”çš„é¢„å¤„ç†å™¨ç±»ï¼ˆ`ViTProcessor`ï¼‰å®žçŽ°è¿™ä¸€æ­¥ã€‚åˆå§‹åŒ–æ¨¡åž‹å’Œé¢„å¤„ç†å™¨ï¼Œå¯ä»¥ä½¿ç”¨hubä¸­[Kakao Brain ViÂ·T repos](https://huggingface.co/models?search=kakaobrain/vit)ä¹‹ä¸€ã€‚è¯·æ³¨æ„ä½¿ç”¨hub ä¸­çš„åº“é¢„å¤„ç†å™¨ï¼Œç¡®ä¿é¢„å¤„ç†åŽçš„å›¾åƒç¬¦åˆç‰¹å®šé¢„è®­ç»ƒæ¨¡åž‹æ‰€éœ€çš„æ ¼å¼ã€‚

```python
url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
image = Image.open(requests.get(url, stream=True).raw)

processor = ViTImageProcessor.from_pretrained('kakaobrain/vit-large-patch16-384')
model = ViTForImageClassification.from_pretrained('kakaobrain/vit-large-patch16-384')
```

æŽ¥ä¸‹æ¥å°†å›¾åƒé¢„å¤„ç†å¹¶å°†å…¶è¾“å…¥åˆ°æ¨¡åž‹ï¼Œå®žçŽ°æ£€ç´¢ç±»åˆ«æ ‡ç­¾ã€‚Kakao Brain ViTå›¾åƒåˆ†ç±»æ¨¡åž‹æ˜¯åœ¨ImageNetæ ‡ç­¾ä¸Šè®­ç»ƒçš„ï¼Œè¾“å‡ºå½¢çŠ¶ä¸º batch_sizeÃ—1000ç»´åº¦çš„ç±»åˆ«ï¼ˆlogitsï¼‰ã€‚

```python
# preprocess image or list of images
inputs = processor(images=image, return_tensors="pt")

# inference
with torch.no_grad():
    outputs = model(**inputs)

# apply SoftMax to logits to compute the probability of each class
preds = torch.nn.functional.softmax(outputs.logits, dim=-1)

# print the top 5 class predictions and their probabilities
top_class_preds = torch.argsort(preds, descending=True)[0, :5]

for c in top_class_preds:
    print(f"{model.config.id2label[c.item()]} with probability {round(preds[0, c.item()].item(), 4)}")
```

åˆ°è¿™é‡Œå°±å®Œæˆäº†ï¼ä¸ºäº†æ›´åŠ ç®€å•å’Œç®€æ´ï¼Œè¿˜å¯ä»¥ä½¿ç”¨å›¾åƒåˆ†ç±»ç®¡é“ï¼ˆpipelineï¼‰å¹¶å°†Kakao Brain ViTä»“åº“åç§°ä½œä¸ºç›®æ ‡æ¨¡åž‹ä¼ é€’ç»™åˆå§‹åŒ–ç®¡é“ã€‚ç„¶åŽï¼Œæˆ‘ä»¬å¯ä»¥ä¼ å…¥å›¾åƒçš„URLæˆ–æœ¬åœ°è·¯å¾„ï¼Œæˆ–Pillowå›¾åƒï¼Œå¯é€‰â€œtop_kâ€å‚æ•°è¡¨è¿°è¿”å›žå‰kä¸ªé¢„æµ‹ã€‚è®©æˆ‘ä»¬ç»§ç»­å¯¹çŒ«å’Œé¥æŽ§å™¨å›¾ç‰‡èŽ·å–å‰5ä¸ªé¢„æµ‹ç»“æžœã€‚

```python
from transformers import pipeline

classifier = pipeline(task='image-classification', model='kakaobrain/vit-large-patch16-384')
classifier('http://images.cocodataset.org/val2017/000000039769.jpg', top_k=5)
```

å¦‚æžœæ‚¨æƒ³æ›´å¤šåœ°å°è¯• Kakao Brain ViTæ¨¡åž‹ï¼Œè¯·å‰å¾€ðŸ¤— ä¸­å¿ƒçš„é¡¹ç›®ç©ºé—´ã€‚

[`https://huggingface.co/spaces/adirik/kakao-brain-vit`](https://huggingface.co/spaces/adirik/kakao-brain-vit)

![New%20ViT%20and%20ALIGN%20Models%20From%20Kakao%20Brain%2096dc66c155824d38814f76b7e882ad2f/vit_demo.png](https://s3.amazonaws.com/moonup/production/uploads/1678324149619-640816c18dca6cec91cacc42.png)

æˆ‘ä»¬å¼€å§‹å®žéªŒ ALIGNï¼Œå®ƒå¯ç”¨äºŽæ£€ç´¢æ–‡æœ¬æˆ–å›¾åƒçš„å¤šæ¨¡æ€åµŒå…¥æˆ–æ‰§è¡Œé›¶æ ·æœ¬å›¾åƒåˆ†ç±»ã€‚ALIGN çš„ Transformer å®žçŽ°å’Œç”¨æ³•ç±»ä¼¼äºŽ [CLIP](https://huggingface.co/docs/transformers/main/en/model_doc/clip)ã€‚é¦–å…ˆï¼Œä¸‹è½½é¢„è®­ç»ƒæ¨¡åž‹å’Œå…¶å¤„ç†å™¨ï¼ˆprocessorï¼‰ï¼Œå¤„ç†å™¨é¢„å¤„ç†å›¾åƒå’Œæ–‡æœ¬ï¼Œä½¿å®ƒä»¬ç¬¦åˆ ALIGN çš„é¢„æœŸæ ¼å¼ï¼Œä»¥ä¾¿å°†å…¶è¾“å…¥åˆ°è§†è§‰å’Œæ–‡æœ¬ç¼–ç å™¨ä¸­ã€‚è¿™æ­¥å¯¼å…¥äº†æˆ‘ä»¬å°†è¦ä½¿ç”¨çš„æ¨¡å—å¹¶åˆå§‹åŒ–é¢„å¤„ç†å™¨å’Œæ¨¡åž‹ã€‚

```python
import requests
from PIL import Image
import torch
from transformers import AlignProcessor, AlignModel

url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
image = Image.open(requests.get(url, stream=True).raw)

processor = AlignProcessor.from_pretrained('kakaobrain/align-base')
model = AlignModel.from_pretrained('kakaobrain/align-base')
```

å…ˆä»Žé›¶æ ·æœ¬å›¾åƒåˆ†ç±»å¼€å§‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†æä¾›å€™é€‰æ ‡ç­¾ï¼ˆè‡ªç”±æ ¼å¼æ–‡æœ¬ï¼‰ï¼Œå¹¶ä½¿ç”¨ AlignModel æ‰¾å‡ºæ›´å¥½åœ°æè¿°å›¾åƒçš„è¡¨è¿°ã€‚æˆ‘ä»¬å°†é¦–å…ˆé¢„å¤„ç†å›¾åƒå’Œæ–‡æœ¬è¾“å…¥ï¼Œå¹¶å°†é¢„å¤„ç†åŽçš„è¾“å…¥é€åˆ° AlignModel ä¸­ã€‚

```python
candidate_labels = ['an image of a cat', 'an image of a dog']

inputs = processor(images=image, text=candidate_labels, return_tensors='pt')

with torch.no_grad():
    outputs = model(**inputs)

# this is the image-text similarity score
logits_per_image = outputs.logits_per_image  

# we can take the softmax to get the label probabilities
probs = logits_per_image.softmax(dim=1)  
print(probs)
```

å®Œæˆäº†ï¼Œå°±è¿™ä¹ˆç®€å•ã€‚è¦è¿›ä¸€æ­¥å°è¯• Kakao Brain ALIGN æ¨¡åž‹è¿›è¡Œé›¶æ ·æœ¬å›¾åƒåˆ†ç±»ï¼Œåªéœ€å‰å¾€ HuggingFaceðŸ¤— Hub ä¸Šçš„ demoæ¼”ç¤ºã€‚è¯·æ³¨æ„ï¼Œ`AlignModel` çš„è¾“å‡ºåŒ…æ‹¬ `text_embeds` å’Œ `image_embeds`ï¼ˆå‚é˜… ALIGN çš„ [æ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/model_doc/align)ï¼‰ã€‚å¦‚æžœä¸éœ€è¦è®¡ç®—ç”¨äºŽé›¶æ ·æœ¬åˆ†ç±»çš„æ¯ä¸ªå›¾åƒå’Œæ¯ä¸ªæ–‡æœ¬çš„é€»è¾‘(logits)ï¼Œå¯ä»¥ä½¿ç”¨ `AlignModel` ç±»ä¸­çš„ `get_image_features()` å’Œ `get_text_features()` æ–¹æ³•ä¾¿æ·åœ°æ£€ç´¢è§†è§‰å’Œæ–‡æœ¬åµŒå…¥ã€‚

```python
text_embeds = model.get_text_features(
    input_ids=inputs['input_ids'],
    attention_mask=inputs['attention_mask'],
    token_type_ids=inputs['token_type_ids'],
)
image_embeds = model.get_image_features(
    pixel_values=inputs['pixel_values'],
)
```

æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ ALIGN çš„ç‹¬ç«‹è§†è§‰å’Œæ–‡æœ¬ç¼–ç å™¨èŽ·å–å¤šæ¨¡æ€åµŒå…¥ã€‚ç„¶åŽå¯ä»¥ä½¿ç”¨è¿™äº›åµŒå…¥ç”¨äºŽå„ç§ä¸‹æ¸¸ä»»åŠ¡çš„æ¨¡åž‹è®­ç»ƒï¼Œä¾‹å¦‚ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²å’Œå›¾åƒå­—å¹•ç”Ÿæˆã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ `AlignTextModel` å’Œ `AlignVisionModel` èŽ·å–è¿™äº›åµŒå…¥ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¾¿æ·çš„AlignProcessor ç±»åˆ†åˆ«å¯¹æ–‡æœ¬å’Œå›¾åƒè¿›è¡Œé¢„å¤„ç†ã€‚

```python
from transformers import AlignTextModel

processor = AlignProcessor.from_pretrained('kakaobrain/align-base')
model = AlignTextModel.from_pretrained('kakaobrain/align-base')

# get embeddings of two text queries
inputs = processor(['an image of a cat', 'an image of a dog'], return_tensors='pt')

with torch.no_grad():
    outputs = model(**inputs)

# get the last hidden state and the final pooled output 
last_hidden_state = outputs.last_hidden_state
pooled_output = outputs.pooler_output
```

æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨æŽ¨ç†è¿‡ç¨‹ä¸­è®¾ç½®output_hidden_stateså’Œoutput_attentionså‚æ•°ä¸ºTrueï¼Œä»¥è¿”å›žæ‰€æœ‰éšè—çŠ¶æ€å’Œæ³¨æ„åŠ›å€¼ã€‚

```python
with torch.no_grad():
    outputs = model(**inputs, output_hidden_states=True, output_attentions=True)
# print what information is returned
for key, value in outputs.items():
    print(key)
```

åœ¨ AlignVisionModel ä¸­æ‰§è¡Œç›¸åŒçš„æ“ä½œï¼ŒèŽ·å–å›¾åƒçš„å¤šæ¨¡æ€åµŒå…¥ã€‚

```python
from transformers import AlignVisionModel

processor = AlignProcessor.from_pretrained('kakaobrain/align-base')
model = AlignVisionModel.from_pretrained('kakaobrain/align-base')

url = 'http://images.cocodataset.org/val2017/000000039769.jpg'
image = Image.open(requests.get(url, stream=True).raw)

inputs = processor(images=image, return_tensors='pt')

with torch.no_grad():
    outputs = model(**inputs)

# print the last hidden state and the final pooled output 
last_hidden_state = outputs.last_hidden_state
pooled_output = outputs.pooler_output
```

ä¸ŽViTç±»ä¼¼ï¼Œä½¿ç”¨é›¶æ ·æœ¬å›¾åƒåˆ†ç±»ç®¡é“ï¼ˆpipelineï¼‰å¯ä»¥è®©è¿‡ç¨‹æ›´åŠ è½»æ¾ã€‚ä»¥ä¸‹å®žçŽ°äº†å¦‚ä½•ä½¿ç”¨æ­¤æµç¨‹ä½¿ç”¨è‡ªç”±æ–‡æœ¬å€™é€‰æ ‡ç­¾åœ¨é‡Žå¤–æ‰§è¡Œå›¾åƒåˆ†ç±»ã€‚

```python
from transformers import pipeline

classifier = pipeline(task='zero-shot-image-classification', model='kakaobrain/align-base')
classifier(
    'https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png',
    candidate_labels=['animals', 'humans', 'landscape'],
)

classifier(
   'https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png',
   candidate_labels=['black and white', 'photorealist', 'painting'],
)
```

## ç»“è®º

è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€å–å¾—äº†ä»¤äººéš¾ä»¥ç½®ä¿¡çš„è¿›å±•ï¼Œä¾‹å¦‚ CLIP å’Œ ALIGN ç­‰æ¨¡åž‹èµ‹èƒ½äº†å„ç§ä¸‹æ¸¸ä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒæè¿°ã€é›¶æ ·æœ¬å›¾åƒåˆ†ç±»å’Œå¼€æ”¾ä¸–ç•Œç›®æ ‡æ£€æµ‹ã€‚æœ¬åšå®¢ï¼Œæˆ‘ä»¬ä»‹ç»äº†ç”± Kakao Brain è´¡çŒ®çš„æœ€æ–°å¼€æºä»£ç  ViT å’Œ ALIGN æ¨¡åž‹ï¼Œä»¥åŠæ–°çš„ COYO æ–‡æœ¬-å›¾åƒæ•°æ®é›†ã€‚å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨è¿™äº›æ¨¡åž‹æ‰§è¡Œå„ç§ä»»åŠ¡ï¼Œåªéœ€å‡ è¡Œä»£ç å³å¯å•ç‹¬ä½¿ç”¨æˆ–ä½œä¸º ðŸ¤—Transformers pipeline çš„ä¸€éƒ¨åˆ†ä½¿ç”¨ã€‚

æˆ‘ä»¬æ­£åœ¨ç»§ç»­æ•´åˆæœ€æœ‰å½±å“åŠ›çš„è®¡ç®—æœºè§†è§‰å’Œå¤šæ¨¡åž‹æ¨¡åž‹ï¼Œå¹¶ä¹äºŽå¬å–æ‚¨çš„åé¦ˆã€‚è¦äº†è§£è®¡ç®—æœºè§†è§‰å’Œå¤šæ¨¡æ€ç ”ç©¶çš„æœ€æ–°æ¶ˆæ¯ï¼Œä½œè€…åŠ Twitter ï¼š@adirikã€@a_e_robertsã€@NielsRoggeã€@RisingSayak å’Œ @huggingfaceã€‚

> è‹±æ–‡åŽŸæ–‡: [https://huggingface.co/blog/vit-align](https://huggingface.co/blog/vit-align) è¯‘è€…: Cony Zhang (å¼ èªèª)
>
