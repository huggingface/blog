{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree of Thoughts for problem solving with large language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TLDR: This blog post is about using \"Tree of Thoughts\", a tree-based framework to solve the Game of 24 tasks with a large language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, \"Tree of Thoughts\", the authors introduced  a new tree-based approach to solve LLMs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using Hugging face ```transformers``` to generate text with our LLMs. First, we start off by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the popular open-source language model, Mistral-7B. We can load the model and the tokenizer by:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test out if your model works, you can run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hi! My name is \", return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement Tree of Thought (ToT) algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ToT algorithm is a tree-based approach that uses the LLM to generate a tree of possible solutions to a problem. The tree is constructed by recursively generating text from the LLM and selecting the most likely continuation at each node. The algorithm is designed to be flexible and can be applied to a wide range of problems. The core feature of the ToT algorithm can be separted into 4 parts:\n",
    "\n",
    "\n",
    "- Generation\n",
    "- Evaluation\n",
    "- Selection\n",
    "\n",
    "\n",
    "Below, we define the prompts (taken from the original repo for ToT) for guiding each of the different parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-shot\n",
    "standard_prompt = '''Use numbers and basic arithmetic operations (+ - * /) to obtain 24.\n",
    "Input: 4 4 6 8\n",
    "Answer: (4 + 8) * (6 - 4) = 24\n",
    "Input: 2 9 10 12\n",
    "Answer: 2 * 12 * (10 - 9) = 24\n",
    "Input: 4 9 10 13\n",
    "Answer: (13 - 9) * (10 - 4) = 24\n",
    "Input: 1 4 8 8\n",
    "Answer: (8 / 4 + 1) * 8 = 24\n",
    "Input: 5 5 5 9\n",
    "Answer: 5 + 5 + 5 + 9 = 24\n",
    "Input: {input}\n",
    "'''\n",
    "\n",
    "# 5-shot\n",
    "cot_prompt = '''Use numbers and basic arithmetic operations (+ - * /) to obtain 24. Each step, you are only allowed to choose two of the remaining numbers to obtain a new number.\n",
    "Input: 4 4 6 8\n",
    "Steps:\n",
    "4 + 8 = 12 (left: 4 6 12)\n",
    "6 - 4 = 2 (left: 2 12)\n",
    "2 * 12 = 24 (left: 24)\n",
    "Answer: (6 - 4) * (4 + 8) = 24\n",
    "Input: 2 9 10 12\n",
    "Steps:\n",
    "12 * 2 = 24 (left: 9 10 24)\n",
    "10 - 9 = 1 (left: 1 24)\n",
    "24 * 1 = 24 (left: 24)\n",
    "Answer: (12 * 2) * (10 - 9) = 24\n",
    "Input: 4 9 10 13\n",
    "Steps:\n",
    "13 - 10 = 3 (left: 3 4 9)\n",
    "9 - 3 = 6 (left: 4 6)\n",
    "4 * 6 = 24 (left: 24)\n",
    "Answer: 4 * (9 - (13 - 10)) = 24\n",
    "Input: 1 4 8 8\n",
    "Steps:\n",
    "8 / 4 = 2 (left: 1 2 8)\n",
    "1 + 2 = 3 (left: 3 8)\n",
    "3 * 8 = 24 (left: 24)\n",
    "Answer: (1 + 8 / 4) * 8 = 24\n",
    "Input: 5 5 5 9\n",
    "Steps:\n",
    "5 + 5 = 10 (left: 5 9 10)\n",
    "10 + 5 = 15 (left: 9 15)\n",
    "15 + 9 = 24 (left: 24)\n",
    "Answer: ((5 + 5) + 5) + 9 = 24\n",
    "Input: {input}\n",
    "'''\n",
    "\n",
    "# 1-shot\n",
    "propose_prompt = '''Input: 2 8 8 14\n",
    "Possible next steps:\n",
    "2 + 8 = 10 (left: 8 10 14)\n",
    "8 / 2 = 4 (left: 4 8 14)\n",
    "14 + 2 = 16 (left: 8 8 16)\n",
    "2 * 8 = 16 (left: 8 14 16)\n",
    "8 - 2 = 6 (left: 6 8 14)\n",
    "14 - 8 = 6 (left: 2 6 8)\n",
    "14 /  2 = 7 (left: 7 8 8)\n",
    "14 - 2 = 12 (left: 8 8 12)\n",
    "Input: {input}\n",
    "Possible next steps:\n",
    "'''\n",
    "\n",
    "value_prompt = '''Evaluate if given numbers can reach 24 (sure/likely/impossible)\n",
    "10 14\n",
    "10 + 14 = 24\n",
    "sure\n",
    "11 12\n",
    "11 + 12 = 23\n",
    "12 - 11 = 1\n",
    "11 * 12 = 132\n",
    "11 / 12 = 0.91\n",
    "impossible\n",
    "4 4 10\n",
    "4 + 4 + 10 = 8 + 10 = 18\n",
    "4 * 10 - 4 = 40 - 4 = 36\n",
    "(10 - 4) * 4 = 6 * 4 = 24\n",
    "sure\n",
    "4 9 11\n",
    "9 + 11 + 4 = 20 + 4 = 24\n",
    "sure\n",
    "5 7 8\n",
    "5 + 7 + 8 = 12 + 8 = 20\n",
    "(8 - 5) * 7 = 3 * 7 = 21\n",
    "I cannot obtain 24 now, but numbers are within a reasonable range\n",
    "likely\n",
    "5 6 6\n",
    "5 + 6 + 6 = 17\n",
    "(6 - 5) * 6 = 1 * 6 = 6\n",
    "I cannot obtain 24 now, but numbers are within a reasonable range\n",
    "likely\n",
    "10 10 11\n",
    "10 + 10 + 11 = 31\n",
    "(11 - 10) * 10 = 10\n",
    "10 10 10 are all too big\n",
    "impossible\n",
    "1 3 3\n",
    "1 * 3 * 3 = 9\n",
    "(1 + 3) * 3 = 12\n",
    "1 3 3 are all too small\n",
    "impossible\n",
    "{input}\n",
    "'''\n",
    "\n",
    "value_last_step_prompt = '''Use numbers and basic arithmetic operations (+ - * /) to obtain 24. Given an input and an answer, give a judgement (sure/impossible) if the answer is correct, i.e. it uses each input exactly once and no other numbers, and reach 24.\n",
    "Input: 4 4 6 8\n",
    "Answer: (4 + 8) * (6 - 4) = 24\n",
    "Judge: \n",
    "sure\n",
    "Input: 2 9 10 12\n",
    "Answer: 2 * 12 * (10 - 9) = 24\n",
    "Judge: \n",
    "sure\n",
    "Input: 4 9 10 13\n",
    "Answer: (13 - 9) * (10 - 4) = 24\n",
    "Judge: \n",
    "sure\n",
    "Input: 4 4 6 8\n",
    "Answer: (4 + 8) * (6 - 4) + 1 = 25\n",
    "Judge: \n",
    "impossible\n",
    "Input: 2 9 10 12\n",
    "Answer: 2 * (12 - 10) = 24\n",
    "Judge: \n",
    "impossible\n",
    "Input: 4 9 10 13\n",
    "Answer: (13 - 4) * (10 - 9) = 24\n",
    "Judge: \n",
    "impossible\n",
    "Input: {input}\n",
    "Answer: {answer}\n",
    "Judge:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll start implementing our ToT algorithm. We'll define a function for each core part of the ToT algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation\n",
    "def get_proposals(task, x, y): \n",
    "    propose_prompt = task.propose_prompt_wrap(x, y)\n",
    "    proposals = gpt(propose_prompt, n=1, stop=None)[0].split('\\n') #TODO: Change GPT to another function that uses mistral\n",
    "    return [y + _ + '\\n' for _ in proposals]\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "def get_value(task, x, y, n_evaluate_sample, cache_value=True):\n",
    "    value_prompt = task.value_prompt_wrap(x, y)\n",
    "    if cache_value and value_prompt in task.value_cache:\n",
    "        return task.value_cache[value_prompt]\n",
    "    value_outputs = gpt(value_prompt, n=n_evaluate_sample, stop=None)\n",
    "    value = task.value_outputs_unwrap(x, y, value_outputs)\n",
    "    if cache_value:\n",
    "        task.value_cache[value_prompt] = value\n",
    "    return value\n",
    "\n",
    "def get_values(task, x, ys, n_evaluate_sample, cache_value=True):\n",
    "    values = []\n",
    "    local_value_cache = {}\n",
    "    for y in ys:  # each partial output\n",
    "        if y in local_value_cache:  # avoid duplicate candidates\n",
    "            value = 0\n",
    "        else:    \n",
    "            value = get_value(task, x, y, n_evaluate_sample, cache_value=cache_value)\n",
    "            local_value_cache[y] = value\n",
    "        values.append(value)\n",
    "    return values\n",
    "\n",
    "\n",
    "# Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run ToT with sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll take some example data i.e the sequence 4 5 6 10, and check if ToT can generate the correct expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"4 5 6 10\"\n",
    "ys = ['']\n",
    "x = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Finish for loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_steps = 4\n",
    "\n",
    "for step in num_of_steps:\n",
    "    \n",
    "    # Generation (Propose / Sample)\n",
    "    new_ys = [get_proposals(x, y) for y in ys]\n",
    "    new_ys = list(itertools.chain(*new_ys))\n",
    "    ids = list(range(len(new_ys)))\n",
    "\n",
    "    # Evaluation (Value / Vote)\n",
    "    values = get_values(task, x, new_ys, args.n_evaluate_sample)\n",
    "    \n",
    "    # Selection (Sample/Greedy)\n",
    "    select_ids = sorted(ids, key=lambda x: values[x], reverse=True)[:args.n_select_sample]\n",
    "    select_new_ys = [new_ys[select_id] for select_id in select_ids]\n",
    "    \n",
    "    #infos.append({'step': step, 'x': x, 'ys': ys, 'new_ys': new_ys, 'values': values, 'select_new_ys': select_new_ys})\n",
    "    ys = select_new_ys\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
