{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree of Thoughts for problem solving with large language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TLDR: This blog post is about using \"Tree of Thoughts\", a tree-based framework to solve the Game of 24 tasks with a large language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree of Thoughts (ToT) is a framework used by LLMs to solve complex reasoning problems. The intermediate steps in a reasoning process are split into “thoughts”, with the ToT algorithm encouraging exploration of these thoughts through search algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using Hugging face ```transformers``` to generate text with our LLMs. First, we start off by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the popular open-source language model, Mistral-7B. We can load the model and the tokenizer by:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"mistralai/Mistral-7B-v0.3\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a function called ```mistral``` which we'll use to feed in our prompts and receive completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mistral(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "mistral(\"Hi! My name is \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative, we can also use OpenAI's GPT-3.5/4 models. We can load the model by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from constants import OPENAI_API_KEY\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", OPENAI_API_KEY)\n",
    "\n",
    "if api_key != \"\":\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "else:\n",
    "    print(\"Warning: OPENAI_API_KEY is not set\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "global response\n",
    "\n",
    "def gpt(prompt, model=\"gpt-4\", temperature=0.7, max_tokens=1000, n=1, stop=None) -> list:\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    outputs = []\n",
    "\n",
    "    res = client.chat.completions.create(model=model, messages=messages, temperature=temperature, max_tokens=max_tokens, n=n, stop=stop)\n",
    "    response = res\n",
    "\n",
    "    for choice in res.choices:\n",
    "        outputs.extend([choice.message.content])\n",
    "\n",
    "    return outputs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementing Tree of Thoughts (ToT) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToT can be broken down into 4 key steps:\n",
    "\n",
    "(a) Thought Decomposition\n",
    "\n",
    "(b) Thought Generation\n",
    "- In this step, the LLM is prompted to generate thoughts by either one of two ways:\n",
    "    - Sample: The thoughts are generated by sampling i.i.d thoughts from a Chain of Thought prompt.\n",
    "    - Propose: The thoughts are propsed sequentially depending on the previous prompts. \n",
    "\n",
    "(c) Thought Evaluation\n",
    "- The LLMs are prompted to evaluate the thoughts generated in the previous step, by either: \n",
    "    - Value:\n",
    "    - Vote:   \n",
    "\n",
    "(d) Search Algorithm\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "In this tutorial, we'll be using ToT with Mistral to solve the Game of 24.\n",
    "\n",
    "The Game of 24 is a task where given a sequence of 4 numbers, we’ll need to find the correct mathematical operations (add, subtract, multiply, divide) that’ll lead to the number 24. For example, if the sequence is {4, 9, 10, 13}, the correct operations using the 4 numbers are: (10 - 4) * (13 - 9) = 24. Each number in the sequence can only be used once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-shot\n",
    "standard_prompt = '''Use numbers and basic arithmetic operations (+ - * /) to obtain 24.\n",
    "Input: 4 4 6 8\n",
    "Answer: (4 + 8) * (6 - 4) = 24\n",
    "Input: 2 9 10 12\n",
    "Answer: 2 * 12 * (10 - 9) = 24\n",
    "Input: 4 9 10 13\n",
    "Answer: (13 - 9) * (10 - 4) = 24\n",
    "Input: 1 4 8 8\n",
    "Answer: (8 / 4 + 1) * 8 = 24\n",
    "Input: 5 5 5 9\n",
    "Answer: 5 + 5 + 5 + 9 = 24\n",
    "Input: {input}\n",
    "'''\n",
    "\n",
    "# 5-shot\n",
    "cot_prompt = '''Use numbers and basic arithmetic operations (+ - * /) to obtain 24. Each step, you are only allowed to choose two of the remaining numbers to obtain a new number.\n",
    "Input: 4 4 6 8\n",
    "Steps:\n",
    "4 + 8 = 12 (left: 4 6 12)\n",
    "6 - 4 = 2 (left: 2 12)\n",
    "2 * 12 = 24 (left: 24)\n",
    "Answer: (6 - 4) * (4 + 8) = 24\n",
    "Input: 2 9 10 12\n",
    "Steps:\n",
    "12 * 2 = 24 (left: 9 10 24)\n",
    "10 - 9 = 1 (left: 1 24)\n",
    "24 * 1 = 24 (left: 24)\n",
    "Answer: (12 * 2) * (10 - 9) = 24\n",
    "Input: 4 9 10 13\n",
    "Steps:\n",
    "13 - 10 = 3 (left: 3 4 9)\n",
    "9 - 3 = 6 (left: 4 6)\n",
    "4 * 6 = 24 (left: 24)\n",
    "Answer: 4 * (9 - (13 - 10)) = 24\n",
    "Input: 1 4 8 8\n",
    "Steps:\n",
    "8 / 4 = 2 (left: 1 2 8)\n",
    "1 + 2 = 3 (left: 3 8)\n",
    "3 * 8 = 24 (left: 24)\n",
    "Answer: (1 + 8 / 4) * 8 = 24\n",
    "Input: 5 5 5 9\n",
    "Steps:\n",
    "5 + 5 = 10 (left: 5 9 10)\n",
    "10 + 5 = 15 (left: 9 15)\n",
    "15 + 9 = 24 (left: 24)\n",
    "Answer: ((5 + 5) + 5) + 9 = 24\n",
    "Input: {input}\n",
    "'''\n",
    "\n",
    "# 1-shot\n",
    "propose_prompt = '''Input: 2 8 8 14\n",
    "Possible next steps:\n",
    "2 + 8 = 10 (left: 8 10 14)\n",
    "8 / 2 = 4 (left: 4 8 14)\n",
    "14 + 2 = 16 (left: 8 8 16)\n",
    "2 * 8 = 16 (left: 8 14 16)\n",
    "8 - 2 = 6 (left: 6 8 14)\n",
    "14 - 8 = 6 (left: 2 6 8)\n",
    "14 /  2 = 7 (left: 7 8 8)\n",
    "14 - 2 = 12 (left: 8 8 12)\n",
    "Input: {input}\n",
    "Possible next steps:\n",
    "'''\n",
    "\n",
    "value_prompt = '''Evaluate if given numbers can reach 24 (sure/likely/impossible)\n",
    "10 14\n",
    "10 + 14 = 24\n",
    "sure\n",
    "11 12\n",
    "11 + 12 = 23\n",
    "12 - 11 = 1\n",
    "11 * 12 = 132\n",
    "11 / 12 = 0.91\n",
    "impossible\n",
    "4 4 10\n",
    "4 + 4 + 10 = 8 + 10 = 18\n",
    "4 * 10 - 4 = 40 - 4 = 36\n",
    "(10 - 4) * 4 = 6 * 4 = 24\n",
    "sure\n",
    "4 9 11\n",
    "9 + 11 + 4 = 20 + 4 = 24\n",
    "sure\n",
    "5 7 8\n",
    "5 + 7 + 8 = 12 + 8 = 20\n",
    "(8 - 5) * 7 = 3 * 7 = 21\n",
    "I cannot obtain 24 now, but numbers are within a reasonable range\n",
    "likely\n",
    "5 6 6\n",
    "5 + 6 + 6 = 17\n",
    "(6 - 5) * 6 = 1 * 6 = 6\n",
    "I cannot obtain 24 now, but numbers are within a reasonable range\n",
    "likely\n",
    "10 10 11\n",
    "10 + 10 + 11 = 31\n",
    "(11 - 10) * 10 = 10\n",
    "10 10 10 are all too big\n",
    "impossible\n",
    "1 3 3\n",
    "1 * 3 * 3 = 9\n",
    "(1 + 3) * 3 = 12\n",
    "1 3 3 are all too small\n",
    "impossible\n",
    "{input}\n",
    "'''\n",
    "\n",
    "value_last_step_prompt = '''Use numbers and basic arithmetic operations (+ - * /) to obtain 24. Given an input and an answer, give a judgement (sure/impossible) if the answer is correct, i.e. it uses each input exactly once and no other numbers, and reach 24.\n",
    "Input: 4 4 6 8\n",
    "Answer: (4 + 8) * (6 - 4) = 24\n",
    "Judge: \n",
    "sure\n",
    "Input: 2 9 10 12\n",
    "Answer: 2 * 12 * (10 - 9) = 24\n",
    "Judge: \n",
    "sure\n",
    "Input: 4 9 10 13\n",
    "Answer: (13 - 9) * (10 - 4) = 24\n",
    "Judge: \n",
    "sure\n",
    "Input: 4 4 6 8\n",
    "Answer: (4 + 8) * (6 - 4) + 1 = 25\n",
    "Judge: \n",
    "impossible\n",
    "Input: 2 9 10 12\n",
    "Answer: 2 * (12 - 10) = 24\n",
    "Judge: \n",
    "impossible\n",
    "Input: 4 9 10 13\n",
    "Answer: (13 - 4) * (10 - 9) = 24\n",
    "Judge: \n",
    "impossible\n",
    "Input: {input}\n",
    "Answer: {answer}\n",
    "Judge:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll start implementing our ToT algorithm. We'll define a function for each core part of the ToT algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll define functions necessary for \"Thought Generation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_numbers(y: str) -> str:\n",
    "    last_line = y.strip().split('\\n')[-1]\n",
    "    return last_line.split('left: ')[-1].split(')')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def propose_prompt_wrap(x: str, y: str='') -> str:\n",
    "#     current_numbers = get_current_numbers(y if y else x)\n",
    "#     if current_numbers == '24':\n",
    "#         prompt = cot_prompt.format(input=x) + 'Steps:' + y\n",
    "#         # print([prompt])\n",
    "#     else:\n",
    "#         prompt = propose_prompt.format(input=current_numbers)\n",
    "#     return prompt\n",
    "    \n",
    "\n",
    "# Generation\n",
    "def generate_thoughts(prompt):\n",
    "    \n",
    "    current_numbers = get_current_numbers(prompt) # current_numbers = get_current_numbers(y if y else x)\n",
    "    prompt = propose_prompt.format(input=current_numbers)\n",
    "    \n",
    "    thoughts = gpt(prompt)[0].split('\\n')\n",
    "\n",
    "    return thoughts\n",
    "\n",
    "\n",
    "def get_proposals(task, x, y): \n",
    "    propose_prompt = task.propose_prompt_wrap(x, y)\n",
    "    proposals = gpt(propose_prompt, n=1, stop=None)[0].split('\\n')\n",
    "    return [y + _ + '\\n' for _ in proposals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:  ['']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m thoughts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_of_steps):\n\u001b[0;32m----> 5\u001b[0m     thoughts \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_thoughts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthoughts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThoughts: \u001b[39m\u001b[38;5;124m'\u001b[39m, thoughts)\n",
      "Cell \u001b[0;32mIn[52], line 15\u001b[0m, in \u001b[0;36mgenerate_thoughts\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_thoughts\u001b[39m(prompt):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROMPT: \u001b[39m\u001b[38;5;124m'\u001b[39m, prompt)\n\u001b[0;32m---> 15\u001b[0m     current_numbers \u001b[38;5;241m=\u001b[39m \u001b[43mget_current_numbers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m propose_prompt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mcurrent_numbers)\n\u001b[1;32m     18\u001b[0m     thoughts \u001b[38;5;241m=\u001b[39m gpt(prompt)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[57], line 2\u001b[0m, in \u001b[0;36mget_current_numbers\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_current_numbers\u001b[39m(y: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     last_line \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "num_of_steps = 1\n",
    "thoughts = ['']\n",
    "\n",
    "for _ in range(0, num_of_steps):\n",
    "    thoughts = generate_thoughts(thoughts)\n",
    "    print('Thoughts: ', thoughts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "num_of_steps = 1\n",
    "thoughts = ['']\n",
    "\n",
    " new_ys = [get_proposals(task, x, y) for y in ys]\n",
    "        # new_ys = list(itertools.chain(*new_ys))\n",
    "        # print('FINAL YS: ', new_ys)\n",
    "        \n",
    "for step in range(0, num_of_steps):\n",
    "    \n",
    "    # Thought Generation\n",
    "    thoughts = generate_thoughts(thoughts)\n",
    "    #thoughts = list(itertools.chain(*thoughts))\n",
    "    ids = list(range(len(thoughts)))\n",
    "\n",
    "    print('THOUGHTS: ', thoughts)\n",
    "\n",
    "    # Thought evaluation\n",
    "    #values = evaluate_thoughts(thoughts)\n",
    "\n",
    "    # Search algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create the functions necessary for \"Thought Evaluation\", where each of the thoughts are evaluated by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_numbers(y: str) -> str:\n",
    "    last_line = y.strip().split('\\n')[-1]\n",
    "    return last_line.split('left: ')[-1].split(')')[0]\n",
    "\n",
    "# def value_prompt_wrap(x: str, y: str) -> str:\n",
    "#     last_line = y.strip().split('\\n')[-1]\n",
    "#     if 'left: ' not in last_line:  # last step\n",
    "#         ans = last_line.lower().replace('answer: ', '')\n",
    "#         return value_last_step_prompt.format(input=x, answer=ans)\n",
    "#     current_numbers = get_current_numbers(y)\n",
    "#     return value_prompt.format(input=current_numbers) # This replaces the input term\n",
    "\n",
    "\n",
    "def get_value(thought):\n",
    "    \n",
    "    current_numbers = get_current_numbers(thought)\n",
    "    value_prompt = value_prompt.format(input=current_numbers)\n",
    "    value_outputs = mistral(value_prompt)\n",
    "    \n",
    "    value_names = [_.split('\\n')[-1] for _ in value_outputs]\n",
    "    value_map = {'impossible': 0.001, 'likely': 1, 'sure': 20}  \n",
    "    \n",
    "    for name, value in value_map.items():\n",
    "        value = sum(value * value_names.count(name))\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def evaluate_thoughts(thoughts):\n",
    "    \n",
    "    values = []\n",
    "\n",
    "    for thought in thoughts:\n",
    "        value = get_value(thought)\n",
    "\n",
    "    values.append(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll implement the \"Search Algorithm\" which will be used to search through the thoughts generated by the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement search algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run ToT with sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll test our implementation with some sample data i.e the sequence 4 5 6 10. If ToT works sucessfully, it should output the operations that can be performed to reach 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"4 5 6 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def propose_prompt_wrap(x: str, y: str='') -> str:\n",
    "#     current_numbers = get_current_numbers(y if y else x)\n",
    "#     if current_numbers == '24':\n",
    "#         prompt = cot_prompt.format(input=x) + 'Steps:' + y\n",
    "#         # print([prompt])\n",
    "#     else:\n",
    "#         prompt = propose_prompt.format(input=current_numbers)\n",
    "#     return prompt\n",
    "    \n",
    "\n",
    "# Generation\n",
    "def generate_thoughts(prompt):\n",
    "    for p in prompt:\n",
    "        \n",
    "    \n",
    "    print('PROMPT: ', prompt)\n",
    "    current_numbers = get_current_numbers(prompt)\n",
    "    prompt = propose_prompt.format(input=current_numbers)\n",
    "    \n",
    "    thoughts = gpt(prompt)[0].split('\\n')\n",
    "\n",
    "    return thoughts\n",
    "\n",
    "\n",
    "def get_proposals(task, x, y): \n",
    "    propose_prompt = task.propose_prompt_wrap(x, y)\n",
    "    proposals = gpt(propose_prompt, n=1, stop=None)[0].split('\\n')\n",
    "    return [y + _ + '\\n' for _ in proposals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:  []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m thoughts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, num_of_steps):\n\u001b[1;32m      6\u001b[0m     \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Thought Generation\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     thoughts \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_thoughts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthoughts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#thoughts = list(itertools.chain(*thoughts))\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(thoughts)))\n",
      "Cell \u001b[0;32mIn[52], line 15\u001b[0m, in \u001b[0;36mgenerate_thoughts\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_thoughts\u001b[39m(prompt):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROMPT: \u001b[39m\u001b[38;5;124m'\u001b[39m, prompt)\n\u001b[0;32m---> 15\u001b[0m     current_numbers \u001b[38;5;241m=\u001b[39m \u001b[43mget_current_numbers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m propose_prompt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mcurrent_numbers)\n\u001b[1;32m     18\u001b[0m     thoughts \u001b[38;5;241m=\u001b[39m gpt(prompt)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m, in \u001b[0;36mget_current_numbers\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_current_numbers\u001b[39m(y: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     last_line \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft: \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "num_of_steps = 1\n",
    "thoughts = ['']\n",
    "\n",
    " new_ys = [get_proposals(task, x, y) for y in ys]\n",
    "        # new_ys = list(itertools.chain(*new_ys))\n",
    "        # print('FINAL YS: ', new_ys)\n",
    "        \n",
    "for step in range(0, num_of_steps):\n",
    "    \n",
    "    # Thought Generation\n",
    "    thoughts = generate_thoughts(thoughts)\n",
    "    #thoughts = list(itertools.chain(*thoughts))\n",
    "    ids = list(range(len(thoughts)))\n",
    "\n",
    "    print('THOUGHTS: ', thoughts)\n",
    "\n",
    "    # Thought evaluation\n",
    "    #values = evaluate_thoughts(thoughts)\n",
    "\n",
    "    # Search algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# num_of_steps = 4\n",
    "\n",
    "# for step in num_of_steps:\n",
    "#     thoughts = \n",
    "    \n",
    "#     # Generation (Propose / Sample)\n",
    "#     new_ys = [get_proposals(x, y) for y in ys]\n",
    "#     new_ys = list(itertools.chain(*new_ys))\n",
    "#     ids = list(range(len(new_ys)))\n",
    "\n",
    "#     # Evaluation (Value / Vote)\n",
    "#     values = get_values(task, x, new_ys, args.n_evaluate_sample)\n",
    "    \n",
    "#     # Selection (Sample/Greedy)\n",
    "#     select_ids = sorted(ids, key=lambda x: values[x], reverse=True)[:args.n_select_sample]\n",
    "#     select_new_ys = [new_ys[select_id] for select_id in select_ids]\n",
    "    \n",
    "#     #infos.append({'step': step, 'x': x, 'ys': ys, 'new_ys': new_ys, 'values': values, 'select_new_ys': select_new_ys})\n",
    "#     ys = select_new_ys\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
